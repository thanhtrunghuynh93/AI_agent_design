{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ee88f5-776e-44cd-aff1-21475cc4adb6",
   "metadata": {},
   "source": [
    "Here‚Äôs a crisp, paper-grounded take you can drop into a lit review or proposal.\n",
    "\n",
    "1) Landscape: how current ‚Äúagentic RS‚Äù work is organized\n",
    "\n",
    "Three paradigms\n",
    "\n",
    "Recommender-oriented ‚Äì agents directly make picks using planning/memory/tool use over user history (e.g., RecMind, MACRec). Goal: better ranking/selection. \n",
    "\n",
    "Interaction-oriented ‚Äì agents run multi-turn dialogues to elicit preferences, explain, and adapt strategies (e.g., InteRecAgent, MACRS, AutoConcierge). Goal: interpretability + preference discovery. \n",
    "\n",
    "Simulation-oriented ‚Äì generative agents simulate users/items to test policies offline (e.g., Agent4Rec, AgentCF, LUSIM). Goal: cheaper experimentation & long-horizon learning. \n",
    "\n",
    "Canonical agent stack (across all three)\n",
    "\n",
    "Profile (dynamic user/item representations), Memory (factual + emotional; short/long-term), Planning (high-level strategies + micro actions), Action (tool calls: search/retrieve/rank/chat). \n",
    "\n",
    "Evaluation & data\n",
    "\n",
    "Datasets: Amazon (Books/Beauty/‚Ä¶); MovieLens (100K‚Üí20M); Steam/LastFM/Yelp; ReDial/Reddit/OpenDialKG for conversational setups.\n",
    "\n",
    "Metrics: recommendation (Recall/NDCG/HR), conversation efficiency (Success Rate, Avg. Turns), language quality (BLEU/ROUGE), RL-style rewards for long-term engagement. \n",
    "\n",
    "2) What‚Äôs missing (recurring drawbacks & open gaps)\n",
    "\n",
    "Shallow integration with classical RS: many works wrap LLMs around retrieval/ranking but don‚Äôt jointly optimize with CF/sequence models; fusion is ad-hoc. \n",
    "\n",
    "Planning without guarantees: planners produce sensible text plans, but there‚Äôs little verification, calibration, or safety constraints on actions. \n",
    "\n",
    "Memory bloat & drift: long contexts + fuzzy retrieval; few principled policies for write/forget/summarize across factual vs. affective memory. \n",
    "\n",
    "Evaluation fragmentation: heterogeneous datasets, proxy metrics, and simulated users; limited external validity to real user outcomes; frequent dataset subsampling for cost. \n",
    "\n",
    "Cost & latency: multi-agent prompting and tool chains are expensive; little work on budget-aware controllers or small-model distillation. \n",
    "\n",
    "Security & robustness: prompt-/tool-induced attacks on agent loops are underexplored in RS (emerging evidence they are vulnerable). \n",
    "\n",
    "Multi-objective trade-offs: accuracy dominates; diversity, serendipity, fairness, and long-term retention rarely optimized jointly. \n",
    "\n",
    "3) Concrete research ideas (ready to operationalize)\n",
    "\n",
    "Hybrid Policy Learning (CF + Agent Planner)\n",
    "\n",
    "Idea: learn a two-head policy: (A) neural CF scorer; (B) symbolic/LLM plan that sets constraints (diversity/novelty/tool budget). Fuse via learned Lagrange multipliers.\n",
    "\n",
    "Eval: ML-1M/Steam; NDCG@K + calibrated constraint satisfaction; ablate planner on/off. \n",
    "\n",
    "Budget-aware Orchestrator\n",
    "\n",
    "Idea: controller that treats each tool/LMM call as a cost; optimize a reward = utility ‚àí Œª¬∑cost with bandit or tree-search over tools.\n",
    "\n",
    "Eval: response time, $/session, SR/AT on conversational sets; Pareto curves utility vs. cost. \n",
    "\n",
    "Trustworthy Planning with Constraints\n",
    "\n",
    "Idea: declarative constraints (e.g., ‚Äúnever recommend 18+ to minors‚Äù, ‚Äúcap repetition per week‚Äù) checked by a verifier before action.\n",
    "\n",
    "Eval: constraint violation rate, utility loss, longitudinal compliance. \n",
    "\n",
    "Principled Agent Memory\n",
    "\n",
    "Idea: split memory into episodic (temporary), semantic (summarized), affective (valence/intensity). Learn write/evict via RL + information bottlenecks; privacy tags to keep PII out of long-term stores.\n",
    "\n",
    "Eval: retrieval precision@k of relevant past facts; win-rate in follow-up recs vs. baseline context windows. \n",
    "\n",
    "Counterfactual Simulators aligned to Logs\n",
    "\n",
    "Idea: align simulated agents to real logs with inverse propensity scoring and moment-matching so simulator metrics better predict A/B lifts.\n",
    "\n",
    "Eval: correlation between offline (sim) and online (or held-out temporal) deltas; policy ranking stability. \n",
    "\n",
    "Uncertainty-aware Recommendations\n",
    "\n",
    "Idea: have the agent estimate epistemic uncertainty (ensembles/dropout or posterior over CF embeddings) and steer exploration (ask vs. recommend).\n",
    "\n",
    "Eval: regret, #clarifying questions, SR/AT on ReDial; user-perceived confidence calibration. \n",
    "\n",
    "Serendipity-seeking Planner\n",
    "\n",
    "Idea: explicit objective on (relevance √ó novelty √ó diversity) with user-conditioned novelty tolerance; plan mixes ‚Äúsafe‚Äù and ‚Äústretch‚Äù items.\n",
    "\n",
    "Eval: serendipity metrics, dwell time on novel items, retention over weeks (sim + logs). \n",
    "\n",
    "Security-hardened Agent Loops\n",
    "\n",
    "Idea: red-team prompts/tools; add a gatekeeper model to detect tool-misuse, prompt injection, vendor link-spam; apply recovery policies.\n",
    "\n",
    "Eval: attack success rate ‚Üì, false positive rate, utility under attack. \n",
    "\n",
    "Small-Model Distillation for Agents\n",
    "\n",
    "Idea: distill the multi-step agent into an SLM (+ retrieval) for hot paths; keep big LLM only for rare branches.\n",
    "\n",
    "Eval: cost/latency reduction at fixed NDCG/HR; confusion matrix of escalations to big LLM. \n",
    "\n",
    "Unified, Multi-objective Benchmark\n",
    "\n",
    "Idea: release a benchmark coupling logs + dialogues + item KG with tasks spanning ranking, elicitation, explanation, and long-term rewards; standardized SR/AT/NDCG/serendipity/fairness/security checks.\n",
    "\n",
    "Eval: leaderboard + ablation protocol; report cards per objective. \n",
    "\n",
    "Tool-use as First-class Actions\n",
    "\n",
    "Idea: define a typed tool schema (retrieve CF candidates, KG hop, price filter, toxicity check) and learn a tool-policy with credit assignment to downstream recommender gains.\n",
    "\n",
    "Eval: tool-selection accuracy, end-to-end improvements vs. fixed pipelines. \n",
    "\n",
    "Human-in-the-loop Preference Repair\n",
    "\n",
    "Idea: when memory/planner conflict with new feedback, trigger concise preference repair prompts and write atomic updates to profile with provenance.\n",
    "\n",
    "Eval: post-repair NDCG lift, churn risk proxy, explanation helpfulness (ROUGE + human). \n",
    "\n",
    "TL;DR you can reuse in your proposal\n",
    "\n",
    "The field clusters into recommender-, interaction-, and simulation-oriented strands, all built from profile, memory, planning, action modules; evaluations are diverse but fragmented.\n",
    "\n",
    "Key gaps: weak fusion with classic RS, planning without guarantees, messy memory, cost/latency, security, and limited external validity.\n",
    "\n",
    "The next wave should target constraint-aware planning, budgeted orchestration, principled memory, log-aligned simulators, uncertainty & serendipity objectives, security hardening, SLM distillation, and a unified benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f39e4c0c-26bb-43d0-92d6-197b75d57696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "from datetime import datetime\n",
    "\n",
    "def search_arxiv(query: str, max_results: int = 5):\n",
    "    \"\"\"\n",
    "    Search arXiv and return papers with abstracts included.\n",
    "    \"\"\"\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    query_url = (f\"{base_url}?search_query=all:{query.replace(' ', '+')}\"\n",
    "                 f\"&start=0&max_results={max_results}\")\n",
    "    \n",
    "    response = requests.get(query_url)\n",
    "    feed = feedparser.parse(response.text)\n",
    "    \n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        arxiv_id = entry.id.split('/abs/')[-1]\n",
    "        results.append({\n",
    "            \"id\": arxiv_id,\n",
    "            \"title\": entry.title,\n",
    "            \"published\": entry.published,\n",
    "            \"summary\": entry.summary,   # üëà This is the abstract\n",
    "            \"pdf_link\": f\"http://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def download_arxiv_pdf(arxiv_id: str, save_dir: str = \"downloads\"):\n",
    "    \"\"\"\n",
    "    Download the full paper PDF from arXiv given its ID.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    pdf_url = f\"http://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(save_dir, f\"{arxiv_id}.pdf\")\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"‚úÖ Downloaded: {file_path}\")\n",
    "        return file_path\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download PDF (status {response.status_code})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2a9b6a9-f185-4ee2-ab93-de7ceb4fdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"agentic recommendation\"\n",
    "res = search_arxiv(q, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae9e82b3-43ee-4422-af74-b37c2aa793fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '2410.20027v2',\n",
       "  'title': 'Agentic Feedback Loop Modeling Improves Recommendation and User\\n  Simulation',\n",
       "  'published': '2024-10-26T00:51:39Z',\n",
       "  'summary': 'Large language model-based agents are increasingly applied in the\\nrecommendation field due to their extensive knowledge and strong planning\\ncapabilities. While prior research has primarily focused on enhancing either\\nthe recommendation agent or the user agent individually, the collaborative\\ninteraction between the two has often been overlooked. Towards this research\\ngap, we propose a novel framework that emphasizes the feedback loop process to\\nfacilitate the collaboration between the recommendation agent and the user\\nagent. Specifically, the recommendation agent refines its understanding of user\\npreferences by analyzing the feedback from the user agent on the item\\nrecommendation. Conversely, the user agent further identifies potential user\\ninterests based on the items and recommendation reasons provided by the\\nrecommendation agent. This iterative process enhances the ability of both\\nagents to infer user behaviors, enabling more effective item recommendations\\nand more accurate user simulations. Extensive experiments on three datasets\\ndemonstrate the effectiveness of the agentic feedback loop: the agentic\\nfeedback loop yields an average improvement of 11.52% over the single\\nrecommendation agent and 21.12% over the single user agent. Furthermore, the\\nresults show that the agentic feedback loop does not exacerbate popularity or\\nposition bias, which are typically amplified by the real-world feedback loop,\\nhighlighting its robustness. The source code is available at\\nhttps://github.com/Lanyu0303/AFL.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.20027v2.pdf'},\n",
       " {'id': '2402.18240v2',\n",
       "  'title': 'Prospect Personalized Recommendation on Large Language Model-based Agent\\n  Platform',\n",
       "  'published': '2024-02-28T11:12:17Z',\n",
       "  'summary': 'The new kind of Agent-oriented information system, exemplified by GPTs, urges\\nus to inspect the information system infrastructure to support Agent-level\\ninformation processing and to adapt to the characteristics of Large Language\\nModel (LLM)-based Agents, such as interactivity. In this work, we envisage the\\nprospect of the recommender system on LLM-based Agent platforms and introduce a\\nnovel recommendation paradigm called Rec4Agentverse, comprised of Agent Items\\nand Agent Recommender. Rec4Agentverse emphasizes the collaboration between\\nAgent Items and Agent Recommender, thereby promoting personalized information\\nservices and enhancing the exchange of information beyond the traditional\\nuser-recommender feedback loop. Additionally, we prospect the evolution of\\nRec4Agentverse and conceptualize it into three stages based on the enhancement\\nof the interaction and information exchange among Agent Items, Agent\\nRecommender, and the user. A preliminary study involving several cases of\\nRec4Agentverse validates its significant potential for application. Lastly, we\\ndiscuss potential issues and promising directions for future research.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.18240v2.pdf'},\n",
       " {'id': '2402.15235v3',\n",
       "  'title': 'MACRec: a Multi-Agent Collaboration Framework for Recommendation',\n",
       "  'published': '2024-02-23T09:57:20Z',\n",
       "  'summary': 'LLM-based agents have gained considerable attention for their decision-making\\nskills and ability to handle complex tasks. Recognizing the current gap in\\nleveraging agent capabilities for multi-agent collaboration in recommendation\\nsystems, we introduce MACRec, a novel framework designed to enhance\\nrecommendation systems through multi-agent collaboration. Unlike existing work\\non using agents for user/item simulation, we aim to deploy multi-agents to\\ntackle recommendation tasks directly. In our framework, recommendation tasks\\nare addressed through the collaborative efforts of various specialized agents,\\nincluding Manager, User/Item Analyst, Reflector, Searcher, and Task\\nInterpreter, with different working flows. Furthermore, we provide application\\nexamples of how developers can easily use MACRec on various recommendation\\ntasks, including rating prediction, sequential recommendation, conversational\\nrecommendation, and explanation generation of recommendation results. The\\nframework and demonstration video are publicly available at\\nhttps://github.com/wzf2000/MACRec.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.15235v3.pdf'},\n",
       " {'id': '2502.10050v1',\n",
       "  'title': 'A Survey on LLM-powered Agents for Recommender Systems',\n",
       "  'published': '2025-02-14T09:57:07Z',\n",
       "  'summary': 'Recommender systems are essential components of many online platforms, yet\\ntraditional approaches still struggle with understanding complex user\\npreferences and providing explainable recommendations. The emergence of Large\\nLanguage Model (LLM)-powered agents offers a promising approach by enabling\\nnatural language interactions and interpretable reasoning, potentially\\ntransforming research in recommender systems. This survey provides a systematic\\nreview of the emerging applications of LLM-powered agents in recommender\\nsystems. We identify and analyze three key paradigms in current research: (1)\\nRecommender-oriented approaches, which leverage intelligent agents to enhance\\nthe fundamental recommendation mechanisms; (2) Interaction-oriented approaches,\\nwhich facilitate dynamic user engagement through natural dialogue and\\ninterpretable suggestions; and (3) Simulation-oriented approaches, which employ\\nmulti-agent frameworks to model complex user-item interactions and system\\ndynamics. Beyond paradigm categorization, we analyze the architectural\\nfoundations of LLM-powered recommendation agents, examining their essential\\ncomponents: profile construction, memory management, strategic planning, and\\naction execution. Our investigation extends to a comprehensive analysis of\\nbenchmark datasets and evaluation frameworks in this domain. This systematic\\nexamination not only illuminates the current state of LLM-powered agent\\nrecommender systems but also charts critical challenges and promising research\\ndirections in this transformative field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.10050v1.pdf'},\n",
       " {'id': '2201.05970v1',\n",
       "  'title': 'Learning from Atypical Behavior: Temporary Interest Aware Recommendation\\n  Based on Reinforcement Learning',\n",
       "  'published': '2022-01-16T05:29:21Z',\n",
       "  'summary': \"Traditional robust recommendation methods view atypical user-item\\ninteractions as noise and aim to reduce their impact with some kind of noise\\nfiltering technique, which often suffers from two challenges. First, in real\\nworld, atypical interactions may signal users' temporary interest different\\nfrom their general preference. Therefore, simply filtering out the atypical\\ninteractions as noise may be inappropriate and degrade the personalization of\\nrecommendations. Second, it is hard to acquire the temporary interest since\\nthere are no explicit supervision signals to indicate whether an interaction is\\natypical or not. To address this challenges, we propose a novel model called\\nTemporary Interest Aware Recommendation (TIARec), which can distinguish\\natypical interactions from normal ones without supervision and capture the\\ntemporary interest as well as the general preference of users. Particularly, we\\npropose a reinforcement learning framework containing a recommender agent and\\nan auxiliary classifier agent, which are jointly trained with the objective of\\nmaximizing the cumulative return of the recommendations made by the recommender\\nagent. During the joint training process, the classifier agent can judge\\nwhether the interaction with an item recommended by the recommender agent is\\natypical, and the knowledge about learning temporary interest from atypical\\ninteractions can be transferred to the recommender agent, which makes the\\nrecommender agent able to alone make recommendations that balance the general\\npreference and temporary interest of users. At last, the experiments conducted\\non real world datasets verify the effectiveness of TIARec.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.05970v1.pdf'},\n",
       " {'id': '2507.02626v1',\n",
       "  'title': 'VRAgent-R1: Boosting Video Recommendation with MLLM-based Agents via\\n  Reinforcement Learning',\n",
       "  'published': '2025-07-03T13:52:24Z',\n",
       "  'summary': 'Owing to powerful natural language processing and generative capabilities,\\nlarge language model (LLM) agents have emerged as a promising solution for\\nenhancing recommendation systems via user simulation. However, in the realm of\\nvideo recommendation, existing studies predominantly resort to prompt-based\\nsimulation using frozen LLMs and encounter the intricate challenge of\\nmultimodal content understanding. This frequently results in suboptimal item\\nmodeling and user preference learning, thereby ultimately constraining\\nrecommendation performance. To address these challenges, we introduce\\nVRAgent-R1, a novel agent-based paradigm that incorporates human-like\\nintelligence in user simulation. Specifically, VRAgent-R1 comprises two\\ndistinct agents: the Item Perception (IP) Agent and the User Simulation (US)\\nAgent, designed for interactive user-item modeling. Firstly, the IP Agent\\nemulates human-like progressive thinking based on MLLMs, effectively capturing\\nhidden recommendation semantics in videos. With a more comprehensive multimodal\\ncontent understanding provided by the IP Agent, the video recommendation system\\nis equipped to provide higher-quality candidate items. Subsequently, the US\\nAgent refines the recommended video sets based on in-depth chain-of-thought\\n(CoT) reasoning and achieves better alignment with real user preferences\\nthrough reinforcement learning. Experimental results on a large-scale video\\nrecommendation benchmark have demonstrated the effectiveness of our proposed\\nVRAgent-R1 method, e.g., the IP Agent achieves a 6.0\\\\% improvement in NDCG@10\\non the MicroLens-100k dataset, while the US Agent shows approximately 45.0\\\\%\\nhigher accuracy in user decision simulation compared to state-of-the-art\\nbaselines.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.02626v1.pdf'},\n",
       " {'id': '2302.03667v2',\n",
       "  'title': 'A Random Dictator Is All You Need',\n",
       "  'published': '2023-02-07T18:38:53Z',\n",
       "  'summary': \"We study information aggregation with a decision maker aggregating binary\\nrecommendations from symmetric agents. Each agent's recommendation depends on\\nher private information about a hidden state. While the decision maker knows\\nthe prior distribution over states and the marginal distribution of each\\nagent's recommendation, the recommendations are adversarially-correlated. The\\ndecision maker's goal is choosing a robustly-optimal aggregation rule.\\n  We prove that for a large number of agents, for the three standard robustness\\nparadigms - minimax, regret and approximation ratio - the unique optimal\\naggregation rule is random dictator. We further characterize the minimal regret\\nfor any agents' number through concavification.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.03667v2.pdf'},\n",
       " {'id': '2006.04803v1',\n",
       "  'title': 'A two-level solution to fight against dishonest opinions in\\n  recommendation-based trust systems',\n",
       "  'published': '2020-06-09T00:34:11Z',\n",
       "  'summary': \"In this paper, we propose a mechanism to deal with dishonest opinions in\\nrecommendation-based trust models, at both the collection and processing\\nlevels. We consider a scenario in which an agent requests recommendations from\\nmultiple parties to build trust toward another agent. At the collection level,\\nwe propose to allow agents to self-assess the accuracy of their recommendations\\nand autonomously decide on whether they would participate in the recommendation\\nprocess or not. At the processing level, we propose a recommendations\\naggregation technique that is resilient to collusion attacks, followed by a\\ncredibility update mechanism for the participating agents. The originality of\\nour work stems from its consideration of dishonest opinions at both the\\ncollection and processing levels, which allows for better and more persistent\\nprotection against dishonest recommenders. Experiments conducted on the\\nEpinions dataset show that our solution yields better performance in protecting\\nthe recommendation process against Sybil attacks, in comparison with a\\ncompeting model that derives the optimal network of advisors based on the\\nagents' trust values.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.04803v1.pdf'},\n",
       " {'id': '2410.19855v1',\n",
       "  'title': 'Personalized Recommendation Systems using Multimodal, Autonomous, Multi\\n  Agent Systems',\n",
       "  'published': '2024-10-22T14:11:26Z',\n",
       "  'summary': 'This paper describes a highly developed personalised recommendation system\\nusing multimodal, autonomous, multi-agent systems. The system focuses on the\\nincorporation of futuristic AI tech and LLMs like Gemini-1.5- pro and LLaMA-70B\\nto improve customer service experiences especially within e-commerce. Our\\napproach uses multi agent, multimodal systems to provide best possible\\nrecommendations to its users. The system is made up of three agents as a whole.\\nThe first agent recommends products appropriate for answering the given\\nquestion, while the second asks follow-up questions based on images that belong\\nto these recommended products and is followed up with an autonomous search by\\nthe third agent. It also features a real-time data fetch, user\\npreferences-based recommendations and is adaptive learning. During complicated\\nqueries the application processes with Symphony, and uses the Groq API to\\nanswer quickly with low response times. It uses a multimodal way to utilize\\ntext and images comprehensively, so as to optimize product recommendation and\\ncustomer interaction.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.19855v1.pdf'},\n",
       " {'id': '2507.01060v1',\n",
       "  'title': 'Optimizing Conversational Product Recommendation via Reinforcement\\n  Learning',\n",
       "  'published': '2025-06-30T00:59:58Z',\n",
       "  'summary': 'We propose a reinforcement learning-based approach to optimize conversational\\nstrategies for product recommendation across diverse industries. As\\norganizations increasingly adopt intelligent agents to support sales and\\nservice operations, the effectiveness of a conversation hinges not only on what\\nis recommended but how and when recommendations are delivered. We explore a\\nmethodology where agentic systems learn optimal dialogue policies through\\nfeedback-driven reinforcement learning. By mining aggregate behavioral patterns\\nand conversion outcomes, our approach enables agents to refine talk tracks that\\ndrive higher engagement and product uptake, while adhering to contextual and\\nregulatory constraints. We outline the conceptual framework, highlight key\\ninnovations, and discuss the implications for scalable, personalized\\nrecommendation in enterprise environments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.01060v1.pdf'},\n",
       " {'id': '2507.02097v2',\n",
       "  'title': 'The Future is Agentic: Definitions, Perspectives, and Open Challenges of\\n  Multi-Agent Recommender Systems',\n",
       "  'published': '2025-07-02T19:25:44Z',\n",
       "  'summary': 'Large language models (LLMs) are rapidly evolving from passive engines of\\ntext generation into agentic entities that can plan, remember, invoke external\\ntools, and co-operate with one another. This perspective paper investigates how\\nsuch LLM agents (and societies thereof) can transform the design space of\\nrecommender systems.\\n  We introduce a unified formalism that (i) models an individual agent as a\\ntuple comprising its language core, tool set, and hierarchical memory, and (ii)\\ncaptures a multi-agent recommender as a triple of agents, shared environment,\\nand communication protocol. Within this framework, we present four end-to-end\\nuse cases-interactive party planning, synthetic user-simulation for offline\\nevaluation, multi-modal furniture recommendation, and brand-aligned explanation\\ngeneration-each illustrating a distinct capability unlocked by agentic\\norchestration.\\n  We then surface five cross-cutting challenge families: protocol complexity,\\nscalability, hallucination and error propagation, emergent misalignment\\n(including covert collusion), and brand compliance.\\n  For each, we formalize the problem, review nascent mitigation strategies, and\\noutline open research questions. The result is both a blueprint and an agenda:\\na blueprint that shows how memory-augmented, tool-using LLM agents can be\\ncomposed into robust recommendation pipelines, and an agenda inviting the\\nRecSys community to develop benchmarks, theoretical guarantees, and governance\\ntools that keep pace with this new degree of autonomy. By unifying agentic\\nabstractions with recommender objectives, the paper lays the groundwork for the\\nnext generation of personalized, trustworthy, and context-rich recommendation\\nservices.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.02097v2.pdf'},\n",
       " {'id': '2505.19623v2',\n",
       "  'title': 'AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender\\n  Systems',\n",
       "  'published': '2025-05-26T07:45:11Z',\n",
       "  'summary': \"The emergence of agentic recommender systems powered by Large Language Models\\n(LLMs) represents a paradigm shift in personalized recommendations, leveraging\\nLLMs' advanced reasoning and role-playing capabilities to enable autonomous,\\nadaptive decision-making. Unlike traditional recommendation approaches, agentic\\nrecommender systems can dynamically gather and interpret user-item interactions\\nfrom complex environments, generating robust recommendation strategies that\\ngeneralize across diverse scenarios. However, the field currently lacks\\nstandardized evaluation protocols to systematically assess these methods. To\\naddress this critical gap, we propose: (1) an interactive textual\\nrecommendation simulator incorporating rich user and item metadata and three\\ntypical evaluation scenarios (classic, evolving-interest, and cold-start\\nrecommendation tasks); (2) a unified modular framework for developing and\\nstudying agentic recommender systems; and (3) the first comprehensive benchmark\\ncomparing 10 classical and agentic recommendation methods. Our findings\\ndemonstrate the superiority of agentic systems and establish actionable design\\nguidelines for their core components. The benchmark environment has been\\nrigorously validated through an open challenge and remains publicly available\\nwith a continuously maintained\\nleaderboard~\\\\footnote[2]{https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html},\\nfostering ongoing community engagement and reproducible research. The benchmark\\nis available at:\\n\\\\hyperlink{https://huggingface.co/datasets/SGJQovo/AgentRecBench}{https://huggingface.co/datasets/SGJQovo/AgentRecBench}.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.19623v2.pdf'},\n",
       " {'id': '2508.13423v1',\n",
       "  'title': 'AdaptJobRec: Enhancing Conversational Career Recommendation through an\\n  LLM-Powered Agentic System',\n",
       "  'published': '2025-08-19T00:44:25Z',\n",
       "  'summary': \"In recent years, recommendation systems have evolved from providing a single\\nlist of recommendations to offering a comprehensive suite of topic focused\\nservices. To better accomplish this task, conversational recommendation systems\\n(CRS) have progressed from basic retrieval augmented LLM generation to agentic\\nsystems with advanced reasoning and self correction capabilities. However,\\nagentic systems come with notable response latency, a longstanding challenge\\nfor conversational recommendation systems. To balance the trade off between\\nhandling complex queries and minimizing latency, we propose AdaptJobRec, the\\nfirst conversational job recommendation system that leverages autonomous agent\\nto integrate personalized recommendation algorithm tools. The system employs a\\nuser query complexity identification mechanism to minimize response latency.\\nFor straightforward queries, the agent directly selects the appropriate tool\\nfor rapid responses. For complex queries, the agent uses the memory processing\\nmodule to filter chat history for relevant content, then passes the results to\\nthe intelligent task decomposition planner, and finally executes the tasks\\nusing personalized recommendation tools. Evaluation on Walmart's real world\\ncareer recommendation scenarios demonstrates that AdaptJobRec reduces average\\nresponse latency by up to 53.3% compared to competitive baselines, while\\nsignificantly improving recommendation accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.13423v1.pdf'},\n",
       " {'id': '2206.07353v1',\n",
       "  'title': 'Rethinking Reinforcement Learning for Recommendation: A Prompt\\n  Perspective',\n",
       "  'published': '2022-06-15T08:05:16Z',\n",
       "  'summary': \"Modern recommender systems aim to improve user experience. As reinforcement\\nlearning (RL) naturally fits this objective -- maximizing an user's reward per\\nsession -- it has become an emerging topic in recommender systems. Developing\\nRL-based recommendation methods, however, is not trivial due to the\\n\\\\emph{offline training challenge}. Specifically, the keystone of traditional RL\\nis to train an agent with large amounts of online exploration making lots of\\n`errors' in the process. In the recommendation setting, though, we cannot\\nafford the price of making `errors' online. As a result, the agent needs to be\\ntrained through offline historical implicit feedback, collected under different\\nrecommendation policies; traditional RL algorithms may lead to sub-optimal\\npolicies under these offline training settings.\\n  Here we propose a new learning paradigm -- namely Prompt-Based Reinforcement\\nLearning (PRL) -- for the offline training of RL-based recommendation agents.\\nWhile traditional RL algorithms attempt to map state-action input pairs to\\ntheir expected rewards (e.g., Q-values), PRL directly infers actions (i.e.,\\nrecommended items) from state-reward inputs. In short, the agents are trained\\nto predict a recommended item given the prior interactions and an observed\\nreward value -- with simple supervised learning. At deployment time, this\\nhistorical (training) data acts as a knowledge base, while the state-reward\\npairs are used as a prompt. The agents are thus used to answer the question:\\n\\\\emph{ Which item should be recommended given the prior interactions \\\\& the\\nprompted reward value}? We implement PRL with four notable recommendation\\nmodels and conduct experiments on two real-world e-commerce datasets.\\nExperimental results demonstrate the superior performance of our proposed\\nmethods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.07353v1.pdf'},\n",
       " {'id': '2506.23485v1',\n",
       "  'title': 'Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent',\n",
       "  'published': '2025-06-30T03:15:50Z',\n",
       "  'summary': \"Interactive recommendation is a typical information-seeking task that allows\\nusers to interactively express their needs through natural language and obtain\\npersonalized recommendations. Large language model-powered (LLM-powered) agents\\nhave become a new paradigm in interactive recommendations, effectively\\ncapturing users' real-time needs and enhancing personalized experiences.\\nHowever, due to limited planning and generalization capabilities, existing\\nformulations of LLM-powered interactive recommender agents struggle to\\neffectively address diverse and complex user intents, such as intuitive,\\nunrefined, or occasionally ambiguous requests. To tackle this challenge, we\\npropose a novel thought-augmented interactive recommender agent system (TAIRA)\\nthat addresses complex user intents through distilled thought patterns.\\nSpecifically, TAIRA is designed as an LLM-powered multi-agent system featuring\\na manager agent that orchestrates recommendation tasks by decomposing user\\nneeds and planning subtasks, with its planning capacity strengthened through\\nThought Pattern Distillation (TPD), a thought-augmentation method that extracts\\nhigh-level thoughts from the agent's and human experts' experiences. Moreover,\\nwe designed a set of user simulation schemes to generate personalized queries\\nof different difficulties and evaluate the recommendations based on specific\\ndatasets. Through comprehensive experiments conducted across multiple datasets,\\nTAIRA exhibits significantly enhanced performance compared to existing methods.\\nNotably, TAIRA shows a greater advantage on more challenging tasks while\\ngeneralizing effectively on novel tasks, further validating its superiority in\\nmanaging complex user intents within interactive recommendation systems. The\\ncode is publicly available at:https://github.com/Alcein/TAIRA.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.23485v1.pdf'},\n",
       " {'id': '2509.10397v1',\n",
       "  'title': 'RecoWorld: Building Simulated Environments for Agentic Recommender\\n  Systems',\n",
       "  'published': '2025-09-12T16:44:34Z',\n",
       "  'summary': 'We present RecoWorld, a blueprint for building simulated environments\\ntailored to agentic recommender systems. Such environments give agents a proper\\ntraining space where they can learn from errors without impacting real users.\\nRecoWorld distinguishes itself with a dual-view architecture: a simulated user\\nand an agentic recommender engage in multi-turn interactions aimed at\\nmaximizing user retention. The user simulator reviews recommended items,\\nupdates its mindset, and when sensing potential user disengagement, generates\\nreflective instructions. The agentic recommender adapts its recommendations by\\nincorporating these user instructions and reasoning traces, creating a dynamic\\nfeedback loop that actively engages users. This process leverages the\\nexceptional reasoning capabilities of modern LLMs. We explore diverse content\\nrepresentations within the simulator, including text-based, multimodal, and\\nsemantic ID modeling, and discuss how multi-turn RL enables the recommender to\\nrefine its strategies through iterative interactions. RecoWorld also supports\\nmulti-agent simulations, allowing creators to simulate the responses of\\ntargeted user populations. It marks an important first step toward recommender\\nsystems where users and agents collaboratively shape personalized information\\nstreams. We envision new interaction paradigms where \"user instructs,\\nrecommender responds,\" jointly optimizing user retention and engagement.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.10397v1.pdf'},\n",
       " {'id': '2007.03812v3',\n",
       "  'title': 'Robust Multi-Agent Multi-Armed Bandits',\n",
       "  'published': '2020-07-07T22:27:30Z',\n",
       "  'summary': 'Recent works have shown that agents facing independent instances of a\\nstochastic $K$-armed bandit can collaborate to decrease regret. However, these\\nworks assume that each agent always recommends their individual best-arm\\nestimates to other agents, which is unrealistic in envisioned applications\\n(machine faults in distributed computing or spam in social recommendation\\nsystems). Hence, we generalize the setting to include $n$ honest and $m$\\nmalicious agents who recommend best-arm estimates and arbitrary arms,\\nrespectively. We first show that even with a single malicious agent, existing\\ncollaboration-based algorithms fail to improve regret guarantees over a\\nsingle-agent baseline. We propose a scheme where honest agents learn who is\\nmalicious and dynamically reduce communication with (i.e., \"block\") them. We\\nshow that collaboration indeed decreases regret for this algorithm, assuming\\n$m$ is small compared to $K$ but without assumptions on malicious agents\\'\\nbehavior, thus ensuring that our algorithm is robust against any malicious\\nrecommendation strategy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.03812v3.pdf'},\n",
       " {'id': '1302.6834v1',\n",
       "  'title': 'Models of Consensus for Multiple Agent Systems',\n",
       "  'published': '2013-02-27T14:18:41Z',\n",
       "  'summary': 'Models of consensus are used to manage multiple agent systems in order to\\nchoose between different recommendations provided by the system. It is assumed\\nthat there is a central agent that solicits recommendations or plans from other\\nagents. That agent the n determines the consensus of the other agents, and\\nchooses the resultant consensus recommendation or plan. Voting schemes such as\\nthis have been used in a variety of domains, including air traffic control.\\nThis paper uses an analytic model to study the use of consensus in multiple\\nagent systems. The binomial model is used to study the probability that the\\nconsensus judgment is correct or incorrect. That basic model is extended to\\naccount for both different levels of agent competence and unequal prior odds.\\nThe analysis of that model is critical in the investigation of multiple agent\\nsystems, since the model leads us to conclude that in some cases consensus\\njudgment is not appropriate. In addition, the results allow us to determine how\\nmany agents should be used to develop consensus decisions, which agents should\\nbe used to develop consensus decisions and under which conditions the consensus\\nmodel should be used.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1302.6834v1.pdf'},\n",
       " {'id': '2310.10108v3',\n",
       "  'title': 'On Generative Agents in Recommendation',\n",
       "  'published': '2023-10-16T06:41:16Z',\n",
       "  'summary': \"Recommender systems are the cornerstone of today's information dissemination,\\nyet a disconnect between offline metrics and online performance greatly hinders\\ntheir development. Addressing this challenge, we envision a recommendation\\nsimulator, capitalizing on recent breakthroughs in human-level intelligence\\nexhibited by Large Language Models (LLMs). We propose Agent4Rec, a user\\nsimulator in recommendation, leveraging LLM-empowered generative agents\\nequipped with user profile, memory, and actions modules specifically tailored\\nfor the recommender system. In particular, these agents' profile modules are\\ninitialized using real-world datasets (e.g. MovieLens, Steam, Amazon-Book),\\ncapturing users' unique tastes and social traits; memory modules log both\\nfactual and emotional memories and are integrated with an emotion-driven\\nreflection mechanism; action modules support a wide variety of behaviors,\\nspanning both taste-driven and emotion-driven actions. Each agent interacts\\nwith personalized recommender models in a page-by-page manner, relying on a\\npre-implemented collaborative filtering-based recommendation algorithm. We\\ndelve into both the capabilities and limitations of Agent4Rec, aiming to\\nexplore an essential research question: ``To what extent can LLM-empowered\\ngenerative agents faithfully simulate the behavior of real, autonomous humans\\nin recommender systems?'' Extensive and multi-faceted evaluations of Agent4Rec\\nhighlight both the alignment and deviation between agents and user-personalized\\npreferences. Beyond mere performance comparison, we explore insightful\\nexperiments, such as emulating the filter bubble effect and discovering the\\nunderlying causal relationships in recommendation tasks. Our codes are\\navailable at https://github.com/LehengTHU/Agent4Rec.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.10108v3.pdf'},\n",
       " {'id': '2501.13333v1',\n",
       "  'title': 'AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to\\n  Human Feedback',\n",
       "  'published': '2025-01-23T02:25:44Z',\n",
       "  'summary': 'Multi-agent systems must decide which agent is the most appropriate for a\\ngiven task. We propose a novel architecture for recommending which LLM agent\\nout of many should perform a task given a natural language prompt by extending\\nthe Sentence-BERT (SBERT) encoder model. On test data, we are able to achieve a\\ntop-1 accuracy of 92.2% with each classification taking less than 300\\nmilliseconds. In contrast to traditional classification methods, our\\narchitecture is computationally cheap, adaptive to new classes, interpretable,\\nand controllable with arbitrary metrics through reinforcement learning. By\\nencoding natural language prompts into sentence embeddings, our model captures\\nthe semantic content relevant to recommending an agent. The distance between\\nsentence embeddings that belong to the same agent is then minimized through\\nfine-tuning and aligned to human values through reinforcement learning from\\nhuman feedback. This allows the classification of natural language prompts\\nbased on their nearest neighbors by measuring the cosine similarity between\\nembeddings. This work is made possible through the generation of a synthetic\\ndataset for agent recommendation, which we have open-sourced to the public\\nalong with the code for AgentRec recommendation system at\\nhttps://github.com/joshprk/agentrec.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.13333v1.pdf'},\n",
       " {'id': '2506.21931v2',\n",
       "  'title': 'ARAG: Agentic Retrieval Augmented Generation for Personalized\\n  Recommendation',\n",
       "  'published': '2025-06-27T05:45:59Z',\n",
       "  'summary': 'Retrieval-Augmented Generation (RAG) has shown promise in enhancing\\nrecommendation systems by incorporating external context into large language\\nmodel prompts. However, existing RAG-based approaches often rely on static\\nretrieval heuristics and fail to capture nuanced user preferences in dynamic\\nrecommendation scenarios. In this work, we introduce ARAG, an Agentic\\nRetrieval-Augmented Generation framework for Personalized Recommendation, which\\nintegrates a multi-agent collaboration mechanism into the RAG pipeline. To\\nbetter understand the long-term and session behavior of the user, ARAG\\nleverages four specialized LLM-based agents: a User Understanding Agent that\\nsummarizes user preferences from long-term and session contexts, a Natural\\nLanguage Inference (NLI) Agent that evaluates semantic alignment between\\ncandidate items retrieved by RAG and inferred intent, a context summary agent\\nthat summarizes the findings of NLI agent, and an Item Ranker Agent that\\ngenerates a ranked list of recommendations based on contextual fit. We evaluate\\nARAG accross three datasets. Experimental results demonstrate that ARAG\\nsignificantly outperforms standard RAG and recency-based baselines, achieving\\nup to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an\\nablation study to analyse the effect by different components of ARAG. Our\\nfindings highlight the effectiveness of integrating agentic reasoning into\\nretrieval-augmented recommendation and provide new directions for LLM-based\\npersonalization.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.21931v2.pdf'},\n",
       " {'id': '2211.15381v2',\n",
       "  'title': 'Incentive-Aware Recommender Systems in Two-Sided Markets',\n",
       "  'published': '2022-11-23T22:20:12Z',\n",
       "  'summary': 'Online platforms in the Internet Economy commonly incorporate recommender\\nsystems that recommend products (or \"arms\") to users (or \"agents\"). A key\\nchallenge in this domain arises from myopic agents who are naturally\\nincentivized to exploit by choosing the optimal arm based on current\\ninformation, rather than exploring various alternatives to gather information\\nthat benefits the collective. We propose a novel recommender system that aligns\\nwith agents\\' incentives while achieving asymptotically optimal performance, as\\nmeasured by regret in repeated interactions. Our framework models this\\nincentive-aware system as a multi-agent bandit problem in two-sided markets,\\nwhere the interactions of agents and arms are facilitated by recommender\\nsystems on online platforms. This model incorporates incentive constraints\\ninduced by agents\\' opportunity costs. In scenarios where opportunity costs are\\nknown to the platform, we show the existence of an incentive-compatible\\nrecommendation algorithm. This algorithm pools recommendations between a\\ngenuinely good arm and an unknown arm using a randomized and adaptive strategy.\\nMoreover, when these opportunity costs are unknown, we introduce an algorithm\\nthat randomly pools recommendations across all arms, utilizing the cumulative\\nloss from each arm as feedback for strategic exploration. We demonstrate that\\nboth algorithms satisfy an ex-post fairness criterion, which protects agents\\nfrom over-exploitation. All code for using the proposed algorithms and\\nreproducing results is made available on GitHub.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.15381v2.pdf'},\n",
       " {'id': '2408.03166v1',\n",
       "  'title': 'CADRL: Category-aware Dual-agent Reinforcement Learning for Explainable\\n  Recommendations over Knowledge Graphs',\n",
       "  'published': '2024-08-06T13:07:08Z',\n",
       "  'summary': 'Knowledge graphs (KGs) have been widely adopted to mitigate data sparsity and\\naddress cold-start issues in recommender systems. While existing KGs-based\\nrecommendation methods can predict user preferences and demands, they fall\\nshort in generating explicit recommendation paths and lack explainability. As a\\nstep beyond the above methods, recent advancements utilize reinforcement\\nlearning (RL) to find suitable items for a given user via explainable\\nrecommendation paths. However, the performance of these solutions is still\\nlimited by the following two points. (1) Lack of ability to capture contextual\\ndependencies from neighboring information. (2) The excessive reliance on short\\nrecommendation paths due to efficiency concerns. To surmount these challenges,\\nwe propose a category-aware dual-agent reinforcement learning (CADRL) model for\\nexplainable recommendations over KGs. Specifically, our model comprises two\\ncomponents: (1) a category-aware gated graph neural network that jointly\\ncaptures context-aware item representations from neighboring entities and\\ncategories, and (2) a dual-agent RL framework where two agents efficiently\\ntraverse long paths to search for suitable items. Finally, experimental results\\nshow that CADRL outperforms state-of-the-art models in terms of both\\neffectiveness and efficiency on large-scale datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.03166v1.pdf'},\n",
       " {'id': '2502.18988v1',\n",
       "  'title': 'Overcoming the Price of Anarchy by Steering with Recommendations',\n",
       "  'published': '2025-02-26T09:49:28Z',\n",
       "  'summary': \"Varied real world systems such as transportation networks, supply chains and\\nenergy grids present coordination problems where many agents must learn to\\nshare resources. It is well known that the independent and selfish interactions\\nof agents in these systems may lead to inefficiencies, often referred to as the\\n`Price of Anarchy'. Effective interventions that reduce the Price of Anarchy\\nwhile preserving individual autonomy are of great interest. In this paper we\\nexplore recommender systems as one such intervention mechanism. We start with\\nthe Braess Paradox, a congestion game model of a routing problem related to\\ntraffic on roads, packets on the internet, and electricity on power grids.\\nFollowing recent literature, we model the interactions of agents as a repeated\\ngame between $Q$-learners, a common type of reinforcement learning agents. This\\nwork introduces the Learning Dynamic Manipulation Problem, where an external\\nrecommender system can strategically trigger behavior by picking the states\\nobserved by $Q$-learners during learning. Our computational contribution\\ndemonstrates that appropriately chosen recommendations can robustly steer the\\nsystem towards convergence to the social optimum, even for many players. Our\\ntheoretical and empirical results highlight that increases in the\\nrecommendation space can increase the steering potential of a recommender\\nsystem, which should be considered in the design of recommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.18988v1.pdf'},\n",
       " {'id': '1807.05342v1',\n",
       "  'title': 'Another Approach to Consensus of Multi-agents',\n",
       "  'published': '2018-07-14T06:58:49Z',\n",
       "  'summary': 'In this short note, we recommend another approach to deal with the topic\\nConsensus of Multi-agents, which was proposed in \\\\cite{Chena}.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.05342v1.pdf'},\n",
       " {'id': '0806.2216v1',\n",
       "  'title': 'An Intelligent Multi-Agent Recommender System for Human Capacity\\n  Building',\n",
       "  'published': '2008-06-13T09:56:36Z',\n",
       "  'summary': 'This paper presents a Multi-Agent approach to the problem of recommending\\ntraining courses to engineering professionals. The recommendation system is\\nbuilt as a proof of concept and limited to the electrical and mechanical\\nengineering disciplines. Through user modelling and data collection from a\\nsurvey, collaborative filtering recommendation is implemented using intelligent\\nagents. The agents work together in recommending meaningful training courses\\nand updating the course information. The system uses a users profile and\\nkeywords from courses to rank courses. A ranking accuracy for courses of 90% is\\nachieved while flexibility is achieved using an agent that retrieves\\ninformation autonomously using data mining techniques from websites. This\\nmanner of recommendation is scalable and adaptable. Further improvements can be\\nmade using clustering and recording user feedback.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0806.2216v1.pdf'},\n",
       " {'id': '2504.20094v1',\n",
       "  'title': 'MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational\\n  Recommender?',\n",
       "  'published': '2025-04-26T00:55:43Z',\n",
       "  'summary': 'In this paper, we propose a multi-agent collaboration framework called MATCHA\\nfor conversational recommendation system, leveraging large language models\\n(LLMs) to enhance personalization and user engagement. Users can request\\nrecommendations via free-form text and receive curated lists aligned with their\\ninterests, preferences, and constraints. Our system introduces specialized\\nagents for intent analysis, candidate generation, ranking, re-ranking,\\nexplainability, and safeguards. These agents collaboratively improve\\nrecommendations accuracy, diversity, and safety. On eight metrics, our model\\nachieves superior or comparable performance to the current state-of-the-art.\\nThrough comparisons with six baseline models, our approach addresses key\\nchallenges in conversational recommendation systems for game recommendations,\\nincluding: (1) handling complex, user-specific requests, (2) enhancing\\npersonalization through multi-agent collaboration, (3) empirical evaluation and\\ndeployment, and (4) ensuring safe and trustworthy interactions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.20094v1.pdf'},\n",
       " {'id': '2410.19627v2',\n",
       "  'title': 'Knowledge Graph Enhanced Language Agents for Recommendation',\n",
       "  'published': '2024-10-25T15:25:36Z',\n",
       "  'summary': 'Language agents have recently been used to simulate human behavior and\\nuser-item interactions for recommendation systems. However, current language\\nagent simulations do not understand the relationships between users and items,\\nleading to inaccurate user profiles and ineffective recommendations. In this\\nwork, we explore the utility of Knowledge Graphs (KGs), which contain extensive\\nand reliable relationships between users and items, for recommendation. Our key\\ninsight is that the paths in a KG can capture complex relationships between\\nusers and items, eliciting the underlying reasons for user preferences and\\nenriching user profiles. Leveraging this insight, we propose Knowledge Graph\\nEnhanced Language Agents(KGLA), a framework that unifies language agents and KG\\nfor recommendation systems. In the simulated recommendation scenario, we\\nposition the user and item within the KG and integrate KG paths as natural\\nlanguage descriptions into the simulation. This allows language agents to\\ninteract with each other and discover sufficient rationale behind their\\ninteractions, making the simulation more accurate and aligned with real-world\\ncases, thus improving recommendation performance. Our experimental results show\\nthat KGLA significantly improves recommendation performance (with a 33%-95%\\nboost in NDCG@1 among three widely used benchmarks) compared to the previous\\nbest baseline method.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.19627v2.pdf'},\n",
       " {'id': '2004.03728v1',\n",
       "  'title': 'Practical Data Poisoning Attack against Next-Item Recommendation',\n",
       "  'published': '2020-04-07T22:04:52Z',\n",
       "  'summary': 'Online recommendation systems make use of a variety of information sources to\\nprovide users the items that users are potentially interested in. However, due\\nto the openness of the online platform, recommendation systems are vulnerable\\nto data poisoning attacks. Existing attack approaches are either based on\\nsimple heuristic rules or designed against specific recommendations approaches.\\nThe former often suffers unsatisfactory performance, while the latter requires\\nstrong knowledge of the target system. In this paper, we focus on a general\\nnext-item recommendation setting and propose a practical poisoning attack\\napproach named LOKI against blackbox recommendation systems. The proposed LOKI\\nutilizes the reinforcement learning algorithm to train the attack agent, which\\ncan be used to generate user behavior samples for data poisoning. In real-world\\nrecommendation systems, the cost of retraining recommendation models is high,\\nand the interaction frequency between users and a recommendation system is\\nrestricted.Given these real-world restrictions, we propose to let the agent\\ninteract with a recommender simulator instead of the target recommendation\\nsystem and leverage the transferability of the generated adversarial samples to\\npoison the target system. We also propose to use the influence function to\\nefficiently estimate the influence of injected samples on the recommendation\\nresults, without re-training the models within the simulator. Extensive\\nexperiments on two datasets against four representative recommendation models\\nshow that the proposed LOKI achieves better attacking performance than existing\\nmethods.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2004.03728v1.pdf'},\n",
       " {'id': '2407.10081v1',\n",
       "  'title': 'All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems\\n  Across the LLM Era',\n",
       "  'published': '2024-07-14T05:02:21Z',\n",
       "  'summary': \"Recommender systems (RS) are vital for managing information overload and\\ndelivering personalized content, responding to users' diverse information\\nneeds. The emergence of large language models (LLMs) offers a new horizon for\\nredefining recommender systems with vast general knowledge and reasoning\\ncapabilities. Standing across this LLM era, we aim to integrate recommender\\nsystems into a broader picture, and pave the way for more comprehensive\\nsolutions for future research. Therefore, we first offer a comprehensive\\noverview of the technical progression of recommender systems, particularly\\nfocusing on language foundation models and their applications in\\nrecommendation. We identify two evolution paths of modern recommender systems\\n-- via list-wise recommendation and conversational recommendation. These two\\npaths finally converge at LLM agents with superior capabilities of long-term\\nmemory, reflection, and tool intelligence. Along these two paths, we point out\\nthat the information effectiveness of the recommendation is increased, while\\nthe user's acquisition cost is decreased. Technical features, research\\nmethodologies, and inherent challenges for each milestone along the path are\\ncarefully investigated -- from traditional list-wise recommendation to\\nLLM-enhanced recommendation to recommendation with LLM agents. Finally, we\\nhighlight several unresolved challenges crucial for the development of future\\npersonalization technologies and interfaces and discuss the future prospects.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.10081v1.pdf'},\n",
       " {'id': '2308.14296v3',\n",
       "  'title': 'RecMind: Large Language Model Powered Agent For Recommendation',\n",
       "  'published': '2023-08-28T04:31:04Z',\n",
       "  'summary': \"While the recommendation system (RS) has advanced significantly through deep\\nlearning, current RS approaches usually train and fine-tune models on\\ntask-specific datasets, limiting their generalizability to new recommendation\\ntasks and their ability to leverage external knowledge due to model scale and\\ndata size constraints. Thus, we designed an LLM-powered autonomous recommender\\nagent, RecMind, which is capable of leveraging external knowledge, utilizing\\ntools with careful planning to provide zero-shot personalized recommendations.\\nWe propose a Self-Inspiring algorithm to improve the planning ability. At each\\nintermediate step, the LLM self-inspires to consider all previously explored\\nstates to plan for the next step. This mechanism greatly improves the model's\\nability to comprehend and utilize historical information in planning for\\nrecommendation. We evaluate RecMind's performance in various recommendation\\nscenarios. Our experiment shows that RecMind outperforms existing zero/few-shot\\nLLM-based recommendation baseline methods in various tasks and achieves\\ncomparable performance to a fully trained recommendation model P5.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.14296v3.pdf'},\n",
       " {'id': '2310.04230v1',\n",
       "  'title': 'Lending Interaction Wings to Recommender Systems with Conversational\\n  Agents',\n",
       "  'published': '2023-10-06T13:16:27Z',\n",
       "  'summary': 'Recommender systems trained on offline historical user behaviors are\\nembracing conversational techniques to online query user preference. Unlike\\nprior conversational recommendation approaches that systemically combine\\nconversational and recommender parts through a reinforcement learning\\nframework, we propose CORE, a new offline-training and online-checking paradigm\\nthat bridges a COnversational agent and REcommender systems via a unified\\nuncertainty minimization framework. It can benefit any recommendation platform\\nin a plug-and-play style. Here, CORE treats a recommender system as an offline\\nrelevance score estimator to produce an estimated relevance score for each\\nitem; while a conversational agent is regarded as an online relevance score\\nchecker to check these estimated scores in each session. We define uncertainty\\nas the summation of unchecked relevance scores. In this regard, the\\nconversational agent acts to minimize uncertainty via querying either\\nattributes or items. Based on the uncertainty minimization framework, we derive\\nthe expected certainty gain of querying each attribute and item, and develop a\\nnovel online decision tree algorithm to decide what to query at each turn.\\nExperimental results on 8 industrial datasets show that CORE could be\\nseamlessly employed on 9 popular recommendation approaches. We further\\ndemonstrate that our conversational agent could communicate as a human if\\nempowered by a pre-trained large language model.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.04230v1.pdf'},\n",
       " {'id': '2012.09342v1',\n",
       "  'title': 'Adaptive Multi-Agent E-Learning Recommender Systems',\n",
       "  'published': '2020-12-17T01:02:14Z',\n",
       "  'summary': \"Educational recommender systems have become a necessity in the recent years\\ndue to overload of available educational resource which makes it difficult for\\nan individual to manually hunt for the required resource on the internet.\\nE-learning recommender systems simplify the tedious task of gathering the right\\nweb pages and web documents from the scattered world wide web repositories\\naccording to every users' requirements thus increasing the demand and hence the\\ncuriosity to study them. Retrieval of a handful of recommendations from a very\\nhuge collection of web pages using different recommendation techniques becomes\\na productive and time efficient process when the system functions with a set of\\ncooperative agents. The system is also required to keep up with the changing\\nuser interests and web resources in the dynamic web environment, and hence\\nadaptivity is an important factor in determining the efficiency of recommender\\nsystems. The paper provides an overview of such adaptive multi-agent e-learning\\nrecommender systems and the concepts employed to implement them. It precisely\\nprovides all the information required by a researcher who wants to study the\\nstate-of-the-art work on such systems thus enabling him to decide on the\\nimplementation concepts for his own system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.09342v1.pdf'},\n",
       " {'id': '2409.00720v1',\n",
       "  'title': 'Fair Reciprocal Recommendation in Matching Markets',\n",
       "  'published': '2024-09-01T13:33:41Z',\n",
       "  'summary': \"Recommender systems play an increasingly crucial role in shaping people's\\nopportunities, particularly in online dating platforms. It is essential from\\nthe user's perspective to increase the probability of matching with a suitable\\npartner while ensuring an appropriate level of fairness in the matching\\nopportunities. We investigate reciprocal recommendation in two-sided matching\\nmarkets between agents divided into two sides. In our model, a match is\\nconsidered successful only when both individuals express interest in each\\nother. Additionally, we assume that agents prefer to appear prominently in the\\nrecommendation lists presented to those on the other side. We define each\\nagent's opportunity to be recommended and introduce its fairness criterion,\\nenvy-freeness, from the perspective of fair division theory. The\\nrecommendations that approximately maximize the expected number of matches,\\nempirically obtained by heuristic algorithms, are likely to result in\\nsignificant unfairness of opportunity. Therefore, there can be a trade-off\\nbetween maximizing the expected matches and ensuring fairness of opportunity.\\nTo address this challenge, we propose a method to find a policy that is close\\nto being envy-free by leveraging the Nash social welfare function. Experiments\\non synthetic and real-world datasets demonstrate the effectiveness of our\\napproach in achieving both relatively high expected matches and fairness for\\nopportunities of both sides in reciprocal recommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.00720v1.pdf'},\n",
       " {'id': '2109.06473v1',\n",
       "  'title': 'Position Paper on Simulating Privacy Dynamics in Recommender Systems',\n",
       "  'published': '2021-09-14T06:50:28Z',\n",
       "  'summary': \"In this position paper, we discuss the merits of simulating privacy dynamics\\nin recommender systems. We study this issue at hand from two perspectives:\\nFirstly, we present a conceptual approach to integrate privacy into recommender\\nsystem simulations, whose key elements are privacy agents. These agents can\\nenhance users' profiles with different privacy preferences, e.g., their\\ninclination to disclose data to the recommender system. Plus, they can protect\\nusers' privacy by guarding all actions that could be a threat to privacy. For\\nexample, agents can prohibit a user's privacy-threatening actions or apply\\nprivacy-enhancing techniques, e.g., Differential Privacy, to make actions less\\nthreatening. Secondly, we identify three critical topics for future research in\\nprivacy-aware recommender system simulations: (i) How could we model users'\\nprivacy preferences and protect users from performing any privacy-threatening\\nactions? (ii) To what extent do privacy agents modify the users' document\\npreferences? (iii) How do privacy preferences and privacy protections impact\\nrecommendations and privacy of others? Our conceptual privacy-aware simulation\\napproach makes it possible to investigate the impact of privacy preferences and\\nprivacy protection on the micro-level, i.e., a single user, but also on the\\nmacro-level, i.e., all recommender system users. With this work, we hope to\\npresent perspectives on how privacy-aware simulations could be realized, such\\nthat they enable researchers to study the dynamics of privacy within a\\nrecommender system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.06473v1.pdf'},\n",
       " {'id': '2208.05142v3',\n",
       "  'title': 'Plug-and-Play Model-Agnostic Counterfactual Policy Synthesis for Deep\\n  Reinforcement Learning based Recommendation',\n",
       "  'published': '2022-08-10T04:39:22Z',\n",
       "  'summary': \"Recent advances in recommender systems have proved the potential of\\nReinforcement Learning (RL) to handle the dynamic evolution processes between\\nusers and recommender systems. However, learning to train an optimal RL agent\\nis generally impractical with commonly sparse user feedback data in the context\\nof recommender systems. To circumvent the lack of interaction of current\\nRL-based recommender systems, we propose to learn a general Model-Agnostic\\nCounterfactual Synthesis (MACS) Policy for counterfactual user interaction data\\naugmentation. The counterfactual synthesis policy aims to synthesise\\ncounterfactual states while preserving significant information in the original\\nstate relevant to the user's interests, building upon two different training\\napproaches we designed: learning with expert demonstrations and joint training.\\nAs a result, the synthesis of each counterfactual data is based on the current\\nrecommendation agent's interaction with the environment to adapt to users'\\ndynamic interests. We integrate the proposed policy Deep Deterministic Policy\\nGradient (DDPG), Soft Actor Critic (SAC) and Twin Delayed DDPG in an adaptive\\npipeline with a recommendation agent that can generate counterfactual data to\\nimprove the performance of recommendation. The empirical results on both online\\nsimulation and offline datasets demonstrate the effectiveness and\\ngeneralisation of our counterfactual synthesis policy and verify that it\\nimproves the performance of RL recommendation agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.05142v3.pdf'},\n",
       " {'id': '2508.13404v2',\n",
       "  'title': 'TASER: Table Agents for Schema-guided Extraction and Recommendation',\n",
       "  'published': '2025-08-18T23:48:22Z',\n",
       "  'summary': \"Real-world financial documents report essential information about an entity's\\nfinancial holdings that can span millions of different financial instrument\\ntypes. Yet, these details are often buried in messy, multi-page, fragmented\\ntables - for example, 99.4% of the tables in our dataset have no bounding boxes\\nwith the maximum number of rows amounting to 426 per table across 44 pages. To\\ntackle these unique challenges from real-world tables, we present a\\ncontinuously learning, agentic table extraction system, TASER (Table Agents for\\nSchema-guided Extraction and Recommendation) that extracts highly unstructured,\\nmulti-page, heterogeneous tables into normalized, schema-conforming outputs.\\nOur table agents execute on table detection, classification, extraction, and\\nrecommendations by leveraging an initial schema. Then, our Recommender Agent\\nreviews the outputs, recommends schema revisions, and decides on the final\\nrecommendations, enabling TASER to outperform existing table detection models\\nsuch as Table Transformer by 10.1%. Within this continuous learning process, we\\nhighlight that larger batch sizes result in a 104.3% increase in schema\\nrecommendations that are actionable and utilized, resulting in a 9.8% increase\\nin extracted holdings - highlighting the importance of a continuous learning\\nprocess. To train TASER, we have manually labeled 22,584 pages (28,150,449\\ntokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of\\nthe first real financial table datasets. We release our dataset TASERTab to\\nenable the research community to access real-world financial tables and\\noutputs. Our results highlight the promise of agentic, schema-guided extraction\\nsystems for robust understanding of real-world financial tables.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.13404v2.pdf'},\n",
       " {'id': '2110.15089v2',\n",
       "  'title': 'D2RLIR : an improved and diversified ranking function in interactive\\n  recommendation systems based on deep reinforcement learning',\n",
       "  'published': '2021-10-28T13:11:29Z',\n",
       "  'summary': \"Recently, interactive recommendation systems based on reinforcement learning\\nhave been attended by researchers due to the consider recommendation procedure\\nas a dynamic process and update the recommendation model based on immediate\\nuser feedback, which is neglected in traditional methods. The existing works\\nhave two significant drawbacks. Firstly, inefficient ranking function to\\nproduce the Top-N recommendation list. Secondly, focusing on recommendation\\naccuracy and inattention to other evaluation metrics such as diversity. This\\npaper proposes a deep reinforcement learning based recommendation system by\\nutilizing Actor-Critic architecture to model dynamic users' interaction with\\nthe recommender agent and maximize the expected long-term reward. Furthermore,\\nwe propose utilizing Spotify's ANNoy algorithm to find the most similar items\\nto generated action by actor-network. After that, the Total Diversity Effect\\nRanking algorithm is used to generate the recommendations concerning relevancy\\nand diversity. Moreover, we apply positional encoding to compute\\nrepresentations of the user's interaction sequence without using\\nsequence-aligned recurrent neural networks. Extensive experiments on the\\nMovieLens dataset demonstrate that our proposed model is able to generate a\\ndiverse while relevance recommendation list based on the user's preferences.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.15089v2.pdf'},\n",
       " {'id': '2302.11225v2',\n",
       "  'title': 'The Amplification Paradox in Recommender Systems',\n",
       "  'published': '2023-02-22T09:12:48Z',\n",
       "  'summary': \"Automated audits of recommender systems found that blindly following\\nrecommendations leads users to increasingly partisan, conspiratorial, or false\\ncontent. At the same time, studies using real user traces suggest that\\nrecommender systems are not the primary driver of attention toward extreme\\ncontent; on the contrary, such content is mostly reached through other means,\\ne.g., other websites. In this paper, we explain the following apparent paradox:\\nif the recommendation algorithm favors extreme content, why is it not driving\\nits consumption? With a simple agent-based model where users attribute\\ndifferent utilities to items in the recommender system, we show through\\nsimulations that the collaborative-filtering nature of recommender systems and\\nthe nicheness of extreme content can resolve the apparent paradox: although\\nblindly following recommendations would indeed lead users to niche content,\\nusers rarely consume niche content when given the option because it is of low\\nutility to them, which can lead the recommender system to deamplify such\\ncontent. Our results call for a nuanced interpretation of ``algorithmic\\namplification'' and highlight the importance of modeling the utility of content\\nto users when auditing recommender systems. Code available:\\nhttps://github.com/epfl-dlab/amplification_paradox.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.11225v2.pdf'},\n",
       " {'id': '2503.05659v2',\n",
       "  'title': 'A Survey of Large Language Model Empowered Agents for Recommendation and\\n  Search: Towards Next-Generation Information Retrieval',\n",
       "  'published': '2025-03-07T18:20:30Z',\n",
       "  'summary': 'Information technology has profoundly altered the way humans interact with\\ninformation. The vast amount of content created, shared, and disseminated\\nonline has made it increasingly difficult to access relevant information. Over\\nthe past two decades, recommender systems and search (collectively referred to\\nas information retrieval systems) have evolved significantly to address these\\nchallenges. Recent advances in large language models (LLMs) have demonstrated\\ncapabilities that surpass human performance in various language-related tasks\\nand exhibit general understanding, reasoning, and decision-making abilities.\\nThis paper explores the transformative potential of LLM agents in enhancing\\nrecommender and search systems. We discuss the motivations and roles of LLM\\nagents, and establish a classification framework to elaborate on the existing\\nresearch. We highlight the immense potential of LLM agents in addressing\\ncurrent challenges in recommendation and search, providing insights into future\\nresearch directions. This paper is the first to systematically review and\\nclassify the research on LLM agents in these domains, offering a novel\\nperspective on leveraging this advanced AI technology for information\\nretrieval. To help understand the existing works, we list the existing papers\\non LLM agent based recommendation and search at this link:\\nhttps://github.com/tsinghua-fib-lab/LLM-Agent-for-Recommendation-and-Search.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.05659v2.pdf'},\n",
       " {'id': '0909.2376v1',\n",
       "  'title': \"Performing Hybrid Recommendation in Intermodal Transportation-the\\n  FTMarket System's Recommendation Module\",\n",
       "  'published': '2009-09-12T22:21:12Z',\n",
       "  'summary': 'Diverse recommendation techniques have been already proposed and encapsulated\\ninto several e-business applications, aiming to perform a more accurate\\nevaluation of the existing information and accordingly augment the assistance\\nprovided to the users involved. This paper reports on the development and\\nintegration of a recommendation module in an agent-based transportation\\ntransactions management system. The module is built according to a novel hybrid\\nrecommendation technique, which combines the advantages of collaborative\\nfiltering and knowledge-based approaches. The proposed technique and supporting\\nmodule assist customers in considering in detail alternative transportation\\ntransactions that satisfy their requests, as well as in evaluating completed\\ntransactions. The related services are invoked through a software agent that\\nconstructs the appropriate knowledge rules and performs a synthesis of the\\nrecommendation policy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0909.2376v1.pdf'},\n",
       " {'id': '1707.08755v1',\n",
       "  'title': 'Group Recommendations: Axioms, Impossibilities, and Random Walks',\n",
       "  'published': '2017-07-27T07:52:24Z',\n",
       "  'summary': 'We introduce an axiomatic approach to group recommendations, in line of\\nprevious work on the axiomatic treatment of trust-based recommendation systems,\\nranking systems, and other foundational work on the axiomatic approach to\\ninternet mechanisms in social choice settings. In group recommendations we wish\\nto recommend to a group of agents, consisting of both opinionated and undecided\\nmembers, a joint choice that would be acceptable to them. Such a system has\\nmany applications, such as choosing a movie or a restaurant to go to with a\\ngroup of friends, recommending games for online game players, & other communal\\nactivities.\\n  Our method utilizes a given social graph to extract information on the\\nundecided, relying on the agents influencing them. We first show that a set of\\nfairly natural desired requirements (a.k.a axioms) leads to an impossibility,\\nrendering mutual satisfaction of them unreachable. However, we also show a\\nmodified set of axioms that fully axiomatize a group variant of the random-walk\\nrecommendation system, expanding a previous result from the individual\\nrecommendation case.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1707.08755v1.pdf'},\n",
       " {'id': '2108.11068v1',\n",
       "  'title': 'Understanding Longitudinal Dynamics of Recommender Systems with\\n  Agent-Based Modeling and Simulation',\n",
       "  'published': '2021-08-25T06:28:19Z',\n",
       "  'summary': \"Today's research in recommender systems is largely based on experimental\\ndesigns that are static in a sense that they do not consider potential\\nlongitudinal effects of providing recommendations to users. In reality,\\nhowever, various important and interesting phenomena only emerge or become\\nvisible over time, e.g., when a recommender system continuously reinforces the\\npopularity of already successful artists on a music streaming site or when\\nrecommendations that aim at profit maximization lead to a loss of consumer\\ntrust in the long run. In this paper, we discuss how Agent-Based Modeling and\\nSimulation (ABM) techniques can be used to study such important longitudinal\\ndynamics of recommender systems. To that purpose, we provide an overview of the\\nABM principles, outline a simulation framework for recommender systems based on\\nthe literature, and discuss various practical research questions that can be\\naddressed with such an ABM-based simulation framework.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2108.11068v1.pdf'},\n",
       " {'id': '2308.09904v2',\n",
       "  'title': 'RAH! RecSys-Assistant-Human: A Human-Centered Recommendation Framework\\n  with LLM Agents',\n",
       "  'published': '2023-08-19T04:46:01Z',\n",
       "  'summary': \"The rapid evolution of the web has led to an exponential growth in content.\\nRecommender systems play a crucial role in Human-Computer Interaction (HCI) by\\ntailoring content based on individual preferences. Despite their importance,\\nchallenges persist in balancing recommendation accuracy with user satisfaction,\\naddressing biases while preserving user privacy, and solving cold-start\\nproblems in cross-domain situations. This research argues that addressing these\\nissues is not solely the recommender systems' responsibility, and a\\nhuman-centered approach is vital. We introduce the RAH Recommender system,\\nAssistant, and Human) framework, an innovative solution with LLM-based agents\\nsuch as Perceive, Learn, Act, Critic, and Reflect, emphasizing the alignment\\nwith user personalities. The framework utilizes the Learn-Act-Critic loop and a\\nreflection mechanism for improving user alignment. Using the real-world data,\\nour experiments demonstrate the RAH framework's efficacy in various\\nrecommendation domains, from reducing human burden to mitigating biases and\\nenhancing user control. Notably, our contributions provide a human-centered\\nrecommendation framework that partners effectively with various recommendation\\nmodels.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.09904v2.pdf'},\n",
       " {'id': 'nlin/0611054v3',\n",
       "  'title': 'A Model of a Trust-based Recommendation System on a Social Network',\n",
       "  'published': '2006-11-28T16:06:34Z',\n",
       "  'summary': 'In this paper, we present a model of a trust-based recommendation system on a\\nsocial network. The idea of the model is that agents use their social network\\nto reach information and their trust relationships to filter it. We investigate\\nhow the dynamics of trust among agents affect the performance of the system by\\ncomparing it to a frequency-based recommendation system. Furthermore, we\\nidentify the impact of network density, preference heterogeneity among agents,\\nand knowledge sparseness to be crucial factors for the performance of the\\nsystem. The system self-organises in a state with performance near to the\\noptimum; the performance on the global level is an emergent property of the\\nsystem, achieved without explicit coordination from the local interactions of\\nagents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/nlin/0611054v3.pdf'},\n",
       " {'id': '2101.06890v1',\n",
       "  'title': 'Cooperative and Competitive Biases for Multi-Agent Reinforcement\\n  Learning',\n",
       "  'published': '2021-01-18T05:52:22Z',\n",
       "  'summary': \"Training a multi-agent reinforcement learning (MARL) algorithm is more\\nchallenging than training a single-agent reinforcement learning algorithm,\\nbecause the result of a multi-agent task strongly depends on the complex\\ninteractions among agents and their interactions with a stochastic and dynamic\\nenvironment. We propose an algorithm that boosts MARL training using the biased\\naction information of other agents based on a friend-or-foe concept. For a\\ncooperative and competitive environment, there are generally two groups of\\nagents: cooperative-agents and competitive-agents. In the proposed algorithm,\\neach agent updates its value function using its own action and the biased\\naction information of other agents in the two groups. The biased joint action\\nof cooperative agents is computed as the sum of their actual joint action and\\nthe imaginary cooperative joint action, by assuming all the cooperative agents\\njointly maximize the target agent's value function. The biased joint action of\\ncompetitive agents can be computed similarly. Each agent then updates its own\\nvalue function using the biased action information, resulting in a biased value\\nfunction and corresponding biased policy. Subsequently, the biased policy of\\neach agent is inevitably subjected to recommend an action to cooperate and\\ncompete with other agents, thereby introducing more active interactions among\\nagents and enhancing the MARL policy learning. We empirically demonstrate that\\nour algorithm outperforms existing algorithms in various mixed\\ncooperative-competitive environments. Furthermore, the introduced biases\\ngradually decrease as the training proceeds and the correction based on the\\nimaginary assumption vanishes.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.06890v1.pdf'},\n",
       " {'id': '1903.09374v1',\n",
       "  'title': 'Deep Hierarchical Reinforcement Learning Based Recommendations via\\n  Multi-goals Abstraction',\n",
       "  'published': '2019-03-22T06:43:49Z',\n",
       "  'summary': 'The recommender system is an important form of intelligent application, which\\nassists users to alleviate from information redundancy. Among the metrics used\\nto evaluate a recommender system, the metric of conversion has become more and\\nmore important. The majority of existing recommender systems perform poorly on\\nthe metric of conversion due to its extremely sparse feedback signal. To tackle\\nthis challenge, we propose a deep hierarchical reinforcement learning based\\nrecommendation framework, which consists of two components, i.e., high-level\\nagent and low-level agent. The high-level agent catches long-term sparse\\nconversion signals, and automatically sets abstract goals for low-level agent,\\nwhile the low-level agent follows the abstract goals and interacts with\\nreal-time environment. To solve the inherent problem in hierarchical\\nreinforcement learning, we propose a novel deep hierarchical reinforcement\\nlearning algorithm via multi-goals abstraction (HRL-MG). Our proposed algorithm\\ncontains three characteristics: 1) the high-level agent generates multiple\\ngoals to guide the low-level agent in different stages, which reduces the\\ndifficulty of approaching high-level goals; 2) different goals share the same\\nstate encoder parameters, which increases the update frequency of the\\nhigh-level agent and thus accelerates the convergence of our proposed\\nalgorithm; 3) an appreciate benefit assignment function is designed to allocate\\nrewards in each goal so as to coordinate different goals in a consistent\\ndirection. We evaluate our proposed algorithm based on a real-world e-commerce\\ndataset and validate its effectiveness.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1903.09374v1.pdf'},\n",
       " {'id': '2311.07127v4',\n",
       "  'title': 'Multi-agent Attacks for Black-box Social Recommendations',\n",
       "  'published': '2023-11-13T07:40:23Z',\n",
       "  'summary': \"The rise of online social networks has facilitated the evolution of social\\nrecommender systems, which incorporate social relations to enhance users'\\ndecision-making process. With the great success of Graph Neural Networks (GNNs)\\nin learning node representations, GNN-based social recommendations have been\\nwidely studied to model user-item interactions and user-user social relations\\nsimultaneously. Despite their great successes, recent studies have shown that\\nthese advanced recommender systems are highly vulnerable to adversarial\\nattacks, in which attackers can inject well-designed fake user profiles to\\ndisrupt recommendation performances. While most existing studies mainly focus\\non argeted attacks to promote target items on vanilla recommender systems,\\nuntargeted attacks to degrade the overall prediction performance are less\\nexplored on social recommendations under a black-box scenario. To perform\\nuntargeted attacks on social recommender systems, attackers can construct\\nmalicious social relationships for fake users to enhance the attack\\nperformance. However, the coordination of social relations and item profiles is\\nchallenging for attacking black-box social recommendations. To address this\\nlimitation, we first conduct several preliminary studies to demonstrate the\\neffectiveness of cross-community connections and cold-start items in degrading\\nrecommendations performance. Specifically, we propose a novel framework\\nMultiAttack based on multi-agent reinforcement learning to coordinate the\\ngeneration of cold-start item profiles and cross-community social relations for\\nconducting untargeted attacks on black-box social recommendations.\\nComprehensive experiments on various real-world datasets demonstrate the\\neffectiveness of our proposed attacking framework under the black-box setting.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.07127v4.pdf'},\n",
       " {'id': '2310.09233v1',\n",
       "  'title': 'AgentCF: Collaborative Learning with Autonomous Language Agents for\\n  Recommender Systems',\n",
       "  'published': '2023-10-13T16:37:14Z',\n",
       "  'summary': \"Recently, there has been an emergence of employing LLM-powered agents as\\nbelievable human proxies, based on their remarkable decision-making capability.\\nHowever, existing studies mainly focus on simulating human dialogue. Human\\nnon-verbal behaviors, such as item clicking in recommender systems, although\\nimplicitly exhibiting user preferences and could enhance the modeling of users,\\nhave not been deeply explored. The main reasons lie in the gap between language\\nmodeling and behavior modeling, as well as the incomprehension of LLMs about\\nuser-item relations.\\n  To address this issue, we propose AgentCF for simulating user-item\\ninteractions in recommender systems through agent-based collaborative\\nfiltering. We creatively consider not only users but also items as agents, and\\ndevelop a collaborative learning approach that optimizes both kinds of agents\\ntogether. Specifically, at each time step, we first prompt the user and item\\nagents to interact autonomously. Then, based on the disparities between the\\nagents' decisions and real-world interaction records, user and item agents are\\nprompted to reflect on and adjust the misleading simulations collaboratively,\\nthereby modeling their two-sided relations. The optimized agents can also\\npropagate their preferences to other agents in subsequent interactions,\\nimplicitly capturing the collaborative filtering idea. Overall, the optimized\\nagents exhibit diverse interaction behaviors within our framework, including\\nuser-item, user-user, item-item, and collective interactions. The results show\\nthat these agents can demonstrate personalized behaviors akin to those of\\nreal-world individuals, sparking the development of next-generation user\\nbehavior simulation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.09233v1.pdf'},\n",
       " {'id': '2412.12464v1',\n",
       "  'title': \"LLM is Knowledge Graph Reasoner: LLM's Intuition-aware Knowledge Graph\\n  Reasoning for Cold-start Sequential Recommendation\",\n",
       "  'published': '2024-12-17T01:52:15Z',\n",
       "  'summary': \"Knowledge Graphs (KGs) represent relationships between entities in a graph\\nstructure and have been widely studied as promising tools for realizing\\nrecommendations that consider the accurate content information of items.\\nHowever, traditional KG-based recommendation methods face fundamental\\nchallenges: insufficient consideration of temporal information and poor\\nperformance in cold-start scenarios. On the other hand, Large Language Models\\n(LLMs) can be considered databases with a wealth of knowledge learned from the\\nweb data, and they have recently gained attention due to their potential\\napplication as recommendation systems. Although approaches that treat LLMs as\\nrecommendation systems can leverage LLMs' high recommendation literacy, their\\ninput token limitations make it impractical to consider the entire\\nrecommendation domain dataset and result in scalability issues. To address\\nthese challenges, we propose a LLM's Intuition-aware Knowledge graph Reasoning\\nmodel (LIKR). Our main idea is to treat LLMs as reasoners that output intuitive\\nexploration strategies for KGs. To integrate the knowledge of LLMs and KGs, we\\ntrained a recommendation agent through reinforcement learning using a reward\\nfunction that integrates different recommendation strategies, including LLM's\\nintuition and KG embeddings. By incorporating temporal awareness through prompt\\nengineering and generating textual representations of user preferences from\\nlimited interactions, LIKR can improve recommendation performance in cold-start\\nscenarios. Furthermore, LIKR can avoid scalability issues by using KGs to\\nrepresent recommendation domain datasets and limiting the LLM's output to KG\\nexploration strategies. Experiments on real-world datasets demonstrate that our\\nmodel outperforms state-of-the-art recommendation methods in cold-start\\nsequential recommendation scenarios.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.12464v1.pdf'},\n",
       " {'id': '2401.06470v1',\n",
       "  'title': 'UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender\\n  Systems with UNidirectional EXecution',\n",
       "  'published': '2024-01-12T09:32:34Z',\n",
       "  'summary': \"In recent years, there has been a growing interest in utilizing reinforcement\\nlearning (RL) to optimize long-term rewards in recommender systems. Since\\nindustrial recommender systems are typically designed as multi-stage systems,\\nRL methods with a single agent face challenges when optimizing multiple stages\\nsimultaneously. The reason is that different stages have different observation\\nspaces, and thus cannot be modeled by a single agent. To address this issue, we\\npropose a novel UNidirectional-EXecution-based multi-agent Reinforcement\\nLearning (UNEX-RL) framework to reinforce the long-term rewards in multi-stage\\nrecommender systems. We show that the unidirectional execution is a key feature\\nof multi-stage recommender systems, bringing new challenges to the applications\\nof multi-agent reinforcement learning (MARL), namely the observation dependency\\nand the cascading effect. To tackle these challenges, we provide a cascading\\ninformation chain (CIC) method to separate the independent observations from\\naction-dependent observations and use CIC to train UNEX-RL effectively. We also\\ndiscuss practical variance reduction techniques for UNEX-RL. Finally, we show\\nthe effectiveness of UNEX-RL on both public datasets and an online recommender\\nsystem with over 100 million users. Specifically, UNEX-RL reveals a 0.558%\\nincrease in users' usage time compared with single-agent RL algorithms in\\nonline A/B experiments, highlighting the effectiveness of UNEX-RL in industrial\\nrecommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.06470v1.pdf'},\n",
       " {'id': '2507.00535v1',\n",
       "  'title': 'Rethinking Group Recommender Systems in the Era of Generative AI: From\\n  One-Shot Recommendations to Agentic Group Decision Support',\n",
       "  'published': '2025-07-01T07:56:37Z',\n",
       "  'summary': 'More than twenty-five years ago, first ideas were developed on how to design\\na system that can provide recommendations to groups of users instead of\\nindividual users. Since then, a rich variety of algorithmic proposals were\\npublished, e.g., on how to acquire individual preferences, how to aggregate\\nthem, and how to generate recommendations for groups of users. However, despite\\nthe rich literature on the topic, barely any examples of real-world group\\nrecommender systems can be found. This lets us question common assumptions in\\nacademic research, in particular regarding communication processes in a group\\nand how recommendation-supported decisions are made. In this essay, we argue\\nthat these common assumptions and corresponding system designs often may not\\nmatch the needs or expectations of users. We thus call for a reorientation in\\nthis research area, leveraging the capabilities of modern Generative AI\\nassistants like ChatGPT. Specifically, as one promising future direction, we\\nenvision group recommender systems to be systems where human group members\\ninteract in a chat and an AI-based group recommendation agent assists the\\ndecision-making process in an agentic way. Ultimately, this shall lead to a\\nmore natural group decision-making environment and finally to wider adoption of\\ngroup recommendation systems in practice.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.00535v1.pdf'},\n",
       " {'id': '2210.11218v2',\n",
       "  'title': 'Explainable Multi-Agent Recommendation System for Energy-Efficient\\n  Decision Support in Smart Homes',\n",
       "  'published': '2022-10-20T12:51:18Z',\n",
       "  'summary': \"Understandable and persuasive recommendations support the electricity\\nconsumers' behavioral change to tackle the energy efficiency problem.\\nGenerating load shifting recommendations for household appliances as\\nexplainable increases the transparency and trustworthiness of the system. This\\npaper proposes an explainable multi-agent recommendation system for load\\nshifting for household appliances. First, we provide agents with enhanced\\npredictive capacity by including weather data, applying state-of-the-art\\nmodels, and tuning the hyperparameters. Second, we suggest an Explainability\\nAgent providing transparent recommendations. We also provide an overview of the\\npredictive and explainability performance. Third, we discuss the impact and\\nscaling potential of the suggested approach.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.11218v2.pdf'},\n",
       " {'id': '2506.17765v2',\n",
       "  'title': 'CARTS: Collaborative Agents for Recommendation Textual Summarization',\n",
       "  'published': '2025-06-21T17:18:35Z',\n",
       "  'summary': 'Current recommendation systems often require some form of textual data\\nsummarization, such as generating concise and coherent titles for product\\ncarousels or other grouped item displays. While large language models have\\nshown promise in NLP domains for textual summarization, these approaches do not\\ndirectly apply to recommendation systems, where explanations must be highly\\nrelevant to the core features of item sets, adhere to strict word limit\\nconstraints. In this paper, we propose CARTS (Collaborative Agents for\\nRecommendation Textual Summarization), a multi-agent LLM framework designed for\\nstructured summarization in recommendation systems. CARTS decomposes the task\\ninto three stages-Generation Augmented Generation (GAG), refinement circle, and\\narbitration, where successive agent roles are responsible for extracting\\nsalient item features, iteratively refining candidate titles based on relevance\\nand length feedback, and selecting the final title through a collaborative\\narbitration process. Experiments on large-scale e-commerce data and live A/B\\ntesting show that CARTS significantly outperforms single-pass and\\nchain-of-thought LLM baselines, delivering higher title relevance and improved\\nuser engagement metrics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.17765v2.pdf'},\n",
       " {'id': '2310.14609v1',\n",
       "  'title': 'Long Short-Term Planning for Conversational Recommendation Systems',\n",
       "  'published': '2023-10-23T06:34:39Z',\n",
       "  'summary': 'In Conversational Recommendation Systems (CRS), the central question is how\\nthe conversational agent can naturally ask for user preferences and provide\\nsuitable recommendations. Existing works mainly follow the hierarchical\\narchitecture, where a higher policy decides whether to invoke the conversation\\nmodule (to ask questions) or the recommendation module (to make\\nrecommendations). This architecture prevents these two components from fully\\ninteracting with each other. In contrast, this paper proposes a novel\\narchitecture, the long short-term feedback architecture, to connect these two\\nessential components in CRS. Specifically, the recommendation predicts the\\nlong-term recommendation target based on the conversational context and the\\nuser history. Driven by the targeted recommendation, the conversational model\\npredicts the next topic or attribute to verify if the user preference matches\\nthe target. The balance feedback loop continues until the short-term planner\\noutput matches the long-term planner output, that is when the system should\\nmake the recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.14609v1.pdf'},\n",
       " {'id': '2504.06277v1',\n",
       "  'title': 'Dynamic Evaluation Framework for Personalized and Trustworthy Agents: A\\n  Multi-Session Approach to Preference Adaptability',\n",
       "  'published': '2025-03-08T22:50:26Z',\n",
       "  'summary': 'Recent advancements in generative AI have significantly increased interest in\\npersonalized agents. With increased personalization, there is also a greater\\nneed for being able to trust decision-making and action taking capabilities of\\nthese agents. However, the evaluation methods for these agents remain outdated\\nand inadequate, often failing to capture the dynamic and evolving nature of\\nuser interactions. In this conceptual article, we argue for a paradigm shift in\\nevaluating personalized and adaptive agents. We propose a comprehensive novel\\nframework that models user personas with unique attributes and preferences. In\\nthis framework, agents interact with these simulated users through structured\\ninterviews to gather their preferences and offer customized recommendations.\\nThese recommendations are then assessed dynamically using simulations driven by\\nLarge Language Models (LLMs), enabling an adaptive and iterative evaluation\\nprocess. Our flexible framework is designed to support a variety of agents and\\napplications, ensuring a comprehensive and versatile evaluation of\\nrecommendation strategies that focus on proactive, personalized, and\\ntrustworthy aspects.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.06277v1.pdf'},\n",
       " {'id': '1209.1719v1',\n",
       "  'title': 'Semi-metric networks for recommender systems',\n",
       "  'published': '2012-09-08T14:02:12Z',\n",
       "  'summary': 'Weighted graphs obtained from co-occurrence in user-item relations lead to\\nnon-metric topologies. We use this semi-metric behavior to issue\\nrecommendations, and discuss its relationship to transitive closure on fuzzy\\ngraphs. Finally, we test the performance of this method against other item- and\\nuser-based recommender systems on the Movielens benchmark. We show that\\nincluding highly semi-metric edges in our recommendation algorithms leads to\\nbetter recommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1209.1719v1.pdf'},\n",
       " {'id': '2308.11336v1',\n",
       "  'title': 'On the Opportunities and Challenges of Offline Reinforcement Learning\\n  for Recommender Systems',\n",
       "  'published': '2023-08-22T10:28:02Z',\n",
       "  'summary': 'Reinforcement learning serves as a potent tool for modeling dynamic user\\ninterests within recommender systems, garnering increasing research attention\\nof late. However, a significant drawback persists: its poor data efficiency,\\nstemming from its interactive nature. The training of reinforcement\\nlearning-based recommender systems demands expensive online interactions to\\namass adequate trajectories, essential for agents to learn user preferences.\\nThis inefficiency renders reinforcement learning-based recommender systems a\\nformidable undertaking, necessitating the exploration of potential solutions.\\nRecent strides in offline reinforcement learning present a new perspective.\\nOffline reinforcement learning empowers agents to glean insights from offline\\ndatasets and deploy learned policies in online settings. Given that recommender\\nsystems possess extensive offline datasets, the framework of offline\\nreinforcement learning aligns seamlessly. Despite being a burgeoning field,\\nworks centered on recommender systems utilizing offline reinforcement learning\\nremain limited. This survey aims to introduce and delve into offline\\nreinforcement learning within recommender systems, offering an inclusive review\\nof existing literature in this domain. Furthermore, we strive to underscore\\nprevalent challenges, opportunities, and future pathways, poised to propel\\nresearch in this evolving field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.11336v1.pdf'},\n",
       " {'id': '1801.00209v3',\n",
       "  'title': 'Deep Reinforcement Learning for List-wise Recommendations',\n",
       "  'published': '2017-12-30T23:30:36Z',\n",
       "  'summary': \"Recommender systems play a crucial role in mitigating the problem of\\ninformation overload by suggesting users' personalized items or services. The\\nvast majority of traditional recommender systems consider the recommendation\\nprocedure as a static process and make recommendations following a fixed\\nstrategy. In this paper, we propose a novel recommender system with the\\ncapability of continuously improving its strategies during the interactions\\nwith users. We model the sequential interactions between users and a\\nrecommender system as a Markov Decision Process (MDP) and leverage\\nReinforcement Learning (RL) to automatically learn the optimal strategies via\\nrecommending trial-and-error items and receiving reinforcements of these items\\nfrom users' feedbacks. In particular, we introduce an online user-agent\\ninteracting environment simulator, which can pre-train and evaluate model\\nparameters offline before applying the model online. Moreover, we validate the\\nimportance of list-wise recommendations during the interactions between users\\nand agent, and develop a novel approach to incorporate them into the proposed\\nframework LIRD for list-wide recommendations. The experimental results based on\\na real-world e-commerce dataset demonstrate the effectiveness of the proposed\\nframework.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1801.00209v3.pdf'},\n",
       " {'id': '2012.02476v1',\n",
       "  'title': 'Offline Meta-level Model-based Reinforcement Learning Approach for\\n  Cold-Start Recommendation',\n",
       "  'published': '2020-12-04T08:58:35Z',\n",
       "  'summary': \"Reinforcement learning (RL) has shown great promise in optimizing long-term\\nuser interest in recommender systems. However, existing RL-based recommendation\\nmethods need a large number of interactions for each user to learn a robust\\nrecommendation policy. The challenge becomes more critical when recommending to\\nnew users who have a limited number of interactions. To that end, in this\\npaper, we address the cold-start challenge in the RL-based recommender systems\\nby proposing a meta-level model-based reinforcement learning approach for fast\\nuser adaptation. In our approach, we learn to infer each user's preference with\\na user context variable that enables recommendation systems to better adapt to\\nnew users with few interactions. To improve adaptation efficiency, we learn to\\nrecover the user policy and reward from only a few interactions via an inverse\\nreinforcement learning method to assist a meta-level recommendation agent.\\nMoreover, we model the interaction relationship between the user model and\\nrecommendation agent from an information-theoretic perspective. Empirical\\nresults show the effectiveness of the proposed method when adapting to new\\nusers with only a single interaction sequence. We further provide a theoretical\\nanalysis of the recommendation performance bound.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.02476v1.pdf'},\n",
       " {'id': '2110.15097v1',\n",
       "  'title': 'Choosing the Best of Both Worlds: Diverse and Novel Recommendations\\n  through Multi-Objective Reinforcement Learning',\n",
       "  'published': '2021-10-28T13:22:45Z',\n",
       "  'summary': 'Since the inception of Recommender Systems (RS), the accuracy of the\\nrecommendations in terms of relevance has been the golden criterion for\\nevaluating the quality of RS algorithms. However, by focusing on item\\nrelevance, one pays a significant price in terms of other important metrics:\\nusers get stuck in a \"filter bubble\" and their array of options is\\nsignificantly reduced, hence degrading the quality of the user experience and\\nleading to churn. Recommendation, and in particular session-based/sequential\\nrecommendation, is a complex task with multiple - and often conflicting\\nobjectives - that existing state-of-the-art approaches fail to address.\\n  In this work, we take on the aforementioned challenge and introduce\\nScalarized Multi-Objective Reinforcement Learning (SMORL) for the RS setting, a\\nnovel Reinforcement Learning (RL) framework that can effectively address\\nmulti-objective recommendation tasks. The proposed SMORL agent augments\\nstandard recommendation models with additional RL layers that enforce it to\\nsimultaneously satisfy three principal objectives: accuracy, diversity, and\\nnovelty of recommendations. We integrate this framework with four\\nstate-of-the-art session-based recommendation models and compare it with a\\nsingle-objective RL agent that only focuses on accuracy. Our experimental\\nresults on two real-world datasets reveal a substantial increase in aggregate\\ndiversity, a moderate increase in accuracy, reduced repetitiveness of\\nrecommendations, and demonstrate the importance of reinforcing diversity and\\nnovelty as complementary objectives.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.15097v1.pdf'},\n",
       " {'id': '2203.05952v3',\n",
       "  'title': 'Balancing Consumer and Business Value of Recommender Systems: A\\n  Simulation-based Analysis',\n",
       "  'published': '2022-03-10T12:48:29Z',\n",
       "  'summary': \"Automated recommendations can nowadays be found on many e-commerce platforms,\\nand such recommendations can create substantial value for consumers and\\nproviders. Often, however, not all recommendable items have the same profit\\nmargin, and providers might thus be tempted to promote items that maximize\\ntheir profit. In the short run, consumers might accept non-optimal\\nrecommendations, but they may lose their trust in the long run. Ultimately,\\nthis leads to the problem of designing balanced recommendation strategies,\\nwhich consider both consumer and provider value and lead to sustained business\\nsuccess. This work proposes a simulation framework based on agent-based\\nmodeling designed to help providers explore longitudinal dynamics of different\\nrecommendation strategies. In our model, consumer agents receive\\nrecommendations from providers, and the perceived quality of the\\nrecommendations influences the consumers' trust over time. We design several\\nrecommendation strategies which either give more weight on provider profit or\\non consumer utility. Our simulations show that a hybrid strategy that puts more\\nweight on consumer utility but without ignoring profitability considerations\\nleads to the highest cumulative profit in the long run. This hybrid strategy\\nresults in a profit increase of about 20 % compared to pure consumer or profit\\noriented strategies. We also find that social media can reinforce the observed\\nphenomena. In case when consumers heavily rely on social media, the cumulative\\nprofit of the best strategy further increases. To ensure reproducibility and\\nfoster future research, we publicly share our flexible simulation framework.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2203.05952v3.pdf'},\n",
       " {'id': '1610.01546v1',\n",
       "  'title': 'Conversational Recommendation System with Unsupervised Learning',\n",
       "  'published': '2016-09-22T05:46:49Z',\n",
       "  'summary': 'We will demonstrate a conversational products recommendation agent. This\\nsystem shows how we combine research in personalized recommendation systems\\nwith research in dialogue systems to build a virtual sales agent. Based on new\\ndeep learning technologies we developed, the virtual agent is capable of\\nlearning how to interact with users, how to answer user questions, what is the\\nnext question to ask, and what to recommend when chatting with a human user.\\n  Normally a descent conversational agent for a particular domain requires tens\\nof thousands of hand labeled conversational data or hand written rules. This is\\na major barrier when launching a conversation agent for a new domain. We will\\nexplore and demonstrate the effectiveness of the learning solution even when\\nthere is no hand written rules or hand labeled training data.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1610.01546v1.pdf'},\n",
       " {'id': '2505.16429v1',\n",
       "  'title': 'Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform\\n  for Dynamic Recommender Systems',\n",
       "  'published': '2025-05-22T09:14:23Z',\n",
       "  'summary': 'Evaluating and iterating upon recommender systems is crucial, yet traditional\\nA/B testing is resource-intensive, and offline methods struggle with dynamic\\nuser-platform interactions. While agent-based simulation is promising, existing\\nplatforms often lack a mechanism for user actions to dynamically reshape the\\nenvironment. To bridge this gap, we introduce RecInter, a novel agent-based\\nsimulation platform for recommender systems featuring a robust interaction\\nmechanism. In RecInter platform, simulated user actions (e.g., likes, reviews,\\npurchases) dynamically update item attributes in real-time, and introduced\\nMerchant Agents can reply, fostering a more realistic and evolving ecosystem.\\nHigh-fidelity simulation is ensured through Multidimensional User Profiling\\nmodule, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought\\n(CoT) enriched interaction data. Our platform achieves significantly improved\\nsimulation credibility and successfully replicates emergent phenomena like\\nBrand Loyalty and the Matthew Effect. Experiments demonstrate that this\\ninteraction mechanism is pivotal for simulating realistic system evolution,\\nestablishing our platform as a credible testbed for recommender systems\\nresearch.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.16429v1.pdf'},\n",
       " {'id': '2406.11323v2',\n",
       "  'title': 'Transparency, Privacy, and Fairness in Recommender Systems',\n",
       "  'published': '2024-06-17T08:37:14Z',\n",
       "  'summary': \"Recommender systems have become a pervasive part of our daily online\\nexperience, and are one of the most widely used applications of artificial\\nintelligence and machine learning. Therefore, regulations and requirements for\\ntrustworthy artificial intelligence, for example, the European AI Act, which\\nincludes notions such as transparency, privacy, and fairness are also highly\\nrelevant for the design of recommender systems in practice. This habilitation\\nelaborates on aspects related to these three notions in the light of\\nrecommender systems, namely: (i) transparency and cognitive models, (ii)\\nprivacy and limited preference information, and (iii) fairness and popularity\\nbias in recommender systems. Specifically, with respect to aspect (i), we\\nhighlight the usefulness of incorporating psychological theories for a\\ntransparent design process of recommender systems. We term this type of systems\\npsychology-informed recommender systems. In aspect (ii), we study and address\\nthe trade-off between accuracy and privacy in differentially-private\\nrecommendations. We design a novel recommendation approach for collaborative\\nfiltering based on an efficient neighborhood reuse concept, which reduces the\\nnumber of users that need to be protected with differential privacy.\\nFurthermore, we address the related issue of limited availability of user\\npreference information, e.g., click data, in the settings of session-based and\\ncold-start recommendations. With respect to aspect (iii), we analyze popularity\\nbias in recommender systems. We find that the recommendation frequency of an\\nitem is positively correlated with this item's popularity. This also leads to\\nthe unfair treatment of users with little interest in popular content. Finally,\\nwe study long-term fairness dynamics in algorithmic decision support in the\\nlabor market using agent-based modeling techniques.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.11323v2.pdf'},\n",
       " {'id': '2502.14662v4',\n",
       "  'title': 'iAgent: LLM Agent as a Shield between User and Recommender Systems',\n",
       "  'published': '2025-02-20T15:58:25Z',\n",
       "  'summary': \"Traditional recommender systems usually take the user-platform paradigm,\\nwhere users are directly exposed under the control of the platform's\\nrecommendation algorithms. However, the defect of recommendation algorithms may\\nput users in very vulnerable positions under this paradigm. First, many\\nsophisticated models are often designed with commercial objectives in mind,\\nfocusing on the platform's benefits, which may hinder their ability to protect\\nand capture users' true interests. Second, these models are typically optimized\\nusing data from all users, which may overlook individual user's preferences.\\nDue to these shortcomings, users may experience several disadvantages under the\\ntraditional user-platform direct exposure paradigm, such as lack of control\\nover the recommender system, potential manipulation by the platform, echo\\nchamber effects, or lack of personalization for less active users due to the\\ndominance of active users during collaborative learning. Therefore, there is an\\nurgent need to develop a new paradigm to protect user interests and alleviate\\nthese issues. Recently, some researchers have introduced LLM agents to simulate\\nuser behaviors, these approaches primarily aim to optimize platform-side\\nperformance, leaving core issues in recommender systems unresolved. To address\\nthese limitations, we propose a new user-agent-platform paradigm, where agent\\nserves as the protective shield between user and recommender system that\\nenables indirect exposure.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.14662v4.pdf'},\n",
       " {'id': '2209.05063v1',\n",
       "  'title': 'Learning Affects Trust: Design Recommendations and Concepts for Teaching\\n  Children -- and Nearly Anyone -- about Conversational Agents',\n",
       "  'published': '2022-09-12T07:50:01Z',\n",
       "  'summary': \"Research has shown that human-agent relationships form in similar ways to\\nhuman-human relationships. Since children do not have the same critical\\nanalysis skills as adults (and may over-trust technology, for example), this\\nrelationship-formation is concerning. Nonetheless, little research investigates\\nchildren's perceptions of conversational agents in-depth, and even less\\ninvestigates how education might change these perceptions. We present K-12\\nworkshops with associated conversational AI concepts to encourage healthier\\nunderstanding and relationships with agents. Through studies with the\\ncurriculum, and children and parents from various countries, we found\\nparticipants' perceptions of agents -- specifically their partner models and\\ntrust -- changed. When participants discussed changes in trust of agents, we\\nfound they most often mentioned learning something. For example, they\\nfrequently mentioned learning where agents obtained information, what agents do\\nwith this information and how agents are programmed. Based on the results, we\\ndeveloped recommendations for teaching conversational agent concepts, including\\nemphasizing the concepts students found most challenging, like training,\\nturn-taking and terminology; supplementing agent development activities with\\nrelated learning activities; fostering appropriate levels of trust towards\\nagents; and fostering accurate partner models of agents. Through such pedagogy,\\nstudents can learn to better understand conversational AI and what it means to\\nhave it in the world.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.05063v1.pdf'},\n",
       " {'id': '2402.01135v1',\n",
       "  'title': 'A Multi-Agent Conversational Recommender System',\n",
       "  'published': '2024-02-02T04:20:13Z',\n",
       "  'summary': 'Due to strong capabilities in conducting fluent, multi-turn conversations\\nwith users, Large Language Models (LLMs) have the potential to further improve\\nthe performance of Conversational Recommender System (CRS). Unlike the aimless\\nchit-chat that LLM excels at, CRS has a clear target. So it is imperative to\\ncontrol the dialogue flow in the LLM to successfully recommend appropriate\\nitems to the users. Furthermore, user feedback in CRS can assist the system in\\nbetter modeling user preferences, which has been ignored by existing studies.\\nHowever, simply prompting LLM to conduct conversational recommendation cannot\\naddress the above two key challenges.\\n  In this paper, we propose Multi-Agent Conversational Recommender System\\n(MACRS) which contains two essential modules. First, we design a multi-agent\\nact planning framework, which can control the dialogue flow based on four\\nLLM-based agents. This cooperative multi-agent framework will generate various\\ncandidate responses based on different dialogue acts and then choose the most\\nappropriate response as the system response, which can help MACRS plan suitable\\ndialogue acts. Second, we propose a user feedback-aware reflection mechanism\\nwhich leverages user feedback to reason errors made in previous turns to adjust\\nthe dialogue act planning, and higher-level user information from implicit\\nsemantics. We conduct extensive experiments based on user simulator to\\ndemonstrate the effectiveness of MACRS in recommendation and user preferences\\ncollection. Experimental results illustrate that MACRS demonstrates an\\nimprovement in user interaction experience compared to directly using LLMs.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.01135v1.pdf'},\n",
       " {'id': '2506.03369v1',\n",
       "  'title': 'Impact of Rankings and Personalized Recommendations in Marketplaces',\n",
       "  'published': '2025-06-03T20:26:14Z',\n",
       "  'summary': \"Individuals often navigate several options with incomplete knowledge of their\\nown preferences. Information provisioning tools such as public rankings and\\npersonalized recommendations have become central to helping individuals make\\nchoices, yet their value proposition under different marketplace environments\\nremains unexplored. This paper studies a stylized model to explore the impact\\nof these tools in two marketplace settings: uncapacitated supply, where items\\ncan be selected by any number of agents, and capacitated supply, where each\\nitem is constrained to be matched to a single agent. We model the agents\\nutility as a weighted combination of a common term which depends only on the\\nitem, reflecting the item's population level quality, and an idiosyncratic\\nterm, which depends on the agent item pair capturing individual specific\\ntastes. Public rankings reveal the common term, while personalized\\nrecommendations reveal both terms. In the supply unconstrained settings, both\\npublic rankings and personalized recommendations improve welfare, with their\\nrelative value determined by the degree of preference heterogeneity. Public\\nrankings are effective when preferences are relatively homogeneous, while\\npersonalized recommendations become critical as heterogeneity increases. In\\ncontrast, in supply constrained settings, revealing just the common term, as\\ndone by public rankings, provides limited benefit since the total common value\\navailable is limited by capacity constraints, whereas personalized\\nrecommendations, by revealing both common and idiosyncratic terms,\\nsignificantly enhance welfare by enabling agents to match with items they\\nidiosyncratically value highly. These results illustrate the interplay between\\nsupply constraints and preference heterogeneity in determining the\\neffectiveness of information provisioning tools, offering insights for their\\ndesign and deployment in diverse settings.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.03369v1.pdf'},\n",
       " {'id': '2504.08742v1',\n",
       "  'title': 'Simulating Filter Bubble on Short-video Recommender System with Large\\n  Language Model Agents',\n",
       "  'published': '2025-03-23T10:35:58Z',\n",
       "  'summary': 'An increasing reliance on recommender systems has led to concerns about the\\ncreation of filter bubbles on social media, especially on short video platforms\\nlike TikTok. However, their formation is still not entirely understood due to\\nthe complex dynamics between recommendation algorithms and user feedback. In\\nthis paper, we aim to shed light on these dynamics using a large language\\nmodel-based simulation framework. Our work employs real-world short-video data\\ncontaining rich video content information and detailed user-agents to\\nrealistically simulate the recommendation-feedback cycle. Through large-scale\\nsimulations, we demonstrate that LLMs can replicate real-world user-recommender\\ninteractions, uncovering key mechanisms driving filter bubble formation. We\\nidentify critical factors, such as demographic features and category attraction\\nthat exacerbate content homogenization. To mitigate this, we design and test\\ninterventions including various cold-start and feedback weighting strategies,\\nshowing measurable reductions in filter bubble effects. Our framework enables\\nrapid prototyping of recommendation strategies, offering actionable solutions\\nto enhance content diversity in real-world systems. Furthermore, we analyze how\\nLLM-inherent biases may propagate through recommendations, proposing safeguards\\nto promote equity for vulnerable groups, such as women and low-income\\npopulations. By examining the interplay between recommendation and LLM agents,\\nthis work advances a deeper understanding of algorithmic bias and provides\\npractical tools to promote inclusive digital spaces.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.08742v1.pdf'},\n",
       " {'id': '1109.1093v1',\n",
       "  'title': 'Multi Agent Communication System for Online Auction with Decision\\n  Support System by JADE and TRACE',\n",
       "  'published': '2011-09-06T07:22:18Z',\n",
       "  'summary': 'The success of online auctions has given buyers access to greater product\\ndiversity with potentially lower prices. It has provided sellers with access to\\nlarge numbers of potential buyers and reduced transaction costs by enabling\\nauctions to take place without regard to time or place. However it is difficult\\nto spend more time period with system and closely monitor the auction until\\nauction participant wins the bid or closing of the auction. Determining which\\nitems to bid on or what may be the recommended bid and when to bid it are\\ndifficult questions to answer for online auction participants. The multi agent\\nauction advisor system JADE and TRACE, which is connected with decision support\\nsystem, gives the recommended bid to buyers for online auctions. The auction\\nadvisor system relies on intelligent agents both for the retrieval of relevant\\nauction data and for the processing of that data to enable meaningful\\nrecommendations, statistical reports and market prediction report to be made to\\nauction participants.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1109.1093v1.pdf'},\n",
       " {'id': '1901.00431v2',\n",
       "  'title': 'The Technological Gap Between Virtual Assistants and Recommendation\\n  Systems',\n",
       "  'published': '2018-12-21T00:50:03Z',\n",
       "  'summary': \"Virtual assistants, also known as intelligent conversational systems such as\\nGoogle's Virtual Assistant and Apple's Siri, interact with human-like responses\\nto users' queries and finish specific tasks. Meanwhile, existing recommendation\\ntechnologies model users' evolving, diverse and multi-aspect preferences to\\ngenerate recommendations in various domains/applications, aiming to improve the\\ncitizens' daily life by making suggestions. The repertoire of actions is no\\nlonger limited to the one-shot presentation of recommendation lists, which can\\nbe insufficient when the goal is to offer decision support for the user, by\\nquickly adapting to his/her preferences through conversations. Such an\\ninteractive mechanism is currently missing from recommendation systems. This\\narticle sheds light on the gap between virtual assistants and recommendation\\nsystems in terms of different technological aspects. In particular, we try to\\nanswer the most fundamental research question, which are the missing\\ntechnological factors to implement a personalized intelligent conversational\\nagent for producing accurate recommendations while taking into account how\\nusers behave under different conditions. The goal is, instead of adapting\\nhumans to machines, to actually provide users with better recommendation\\nservices so that machines will be adapted to humans in daily life.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1901.00431v2.pdf'},\n",
       " {'id': '2403.06465v1',\n",
       "  'title': 'RecAI: Leveraging Large Language Models for Next-Generation Recommender\\n  Systems',\n",
       "  'published': '2024-03-11T07:07:02Z',\n",
       "  'summary': 'This paper introduces RecAI, a practical toolkit designed to augment or even\\nrevolutionize recommender systems with the advanced capabilities of Large\\nLanguage Models (LLMs). RecAI provides a suite of tools, including Recommender\\nAI Agent, Recommendation-oriented Language Models, Knowledge Plugin,\\nRecExplainer, and Evaluator, to facilitate the integration of LLMs into\\nrecommender systems from multifaceted perspectives. The new generation of\\nrecommender systems, empowered by LLMs, are expected to be more versatile,\\nexplainable, conversational, and controllable, paving the way for more\\nintelligent and user-centric recommendation experiences. We hope the\\nopen-source of RecAI can help accelerate evolution of new advanced recommender\\nsystems. The source code of RecAI is available at\\n\\\\url{https://github.com/microsoft/RecAI}.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.06465v1.pdf'},\n",
       " {'id': '1806.01495v1',\n",
       "  'title': 'Dynamic optimal contract under parameter uncertainty with risk averse\\n  agent and principal',\n",
       "  'published': '2018-06-05T05:01:44Z',\n",
       "  'summary': \"We consider a continuous time Principal-Agent model on a finite time horizon,\\nwhere we look for the existence of an optimal contract both parties agreed on.\\nContrary to the main stream, where the principal is modelled as risk-neutral,\\nwe assume that both the principal and the agent have exponential utility, and\\nare risk averse with same risk awareness level. Moreover, the agent's quality\\nis unknown and modelled as a filtering term in the problem, which is revealed\\nas time passes by. The principal can not observe the agent's real action, but\\ncan only recommend action levels to the agent. Hence, we have a \\\\textit{moral\\nhazard} problem. In this setting, we give an explicit solution to the optimal\\ncontract problem.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1806.01495v1.pdf'},\n",
       " {'id': '1902.03987v3',\n",
       "  'title': 'Whole-Chain Recommendations',\n",
       "  'published': '2019-02-11T16:49:06Z',\n",
       "  'summary': \"With the recent prevalence of Reinforcement Learning (RL), there have been\\ntremendous interests in developing RL-based recommender systems. In practical\\nrecommendation sessions, users will sequentially access multiple scenarios,\\nsuch as the entrance pages and the item detail pages, and each scenario has its\\nspecific characteristics. However, the majority of existing RL-based\\nrecommender systems focus on optimizing one strategy for all scenarios or\\nseparately optimizing each strategy, which could lead to sub-optimal overall\\nperformance. In this paper, we study the recommendation problem with multiple\\n(consecutive) scenarios, i.e., whole-chain recommendations. We propose a\\nmulti-agent RL-based approach (DeepChain), which can capture the sequential\\ncorrelation among different scenarios and jointly optimize multiple\\nrecommendation strategies. To be specific, all recommender agents (RAs) share\\nthe same memory of users' historical behaviors, and they work collaboratively\\nto maximize the overall reward of a session. Note that optimizing multiple\\nrecommendation strategies jointly faces two challenges in the existing\\nmodel-free RL model - (i) it requires huge amounts of user behavior data, and\\n(ii) the distribution of reward (users' feedback) are extremely unbalanced. In\\nthis paper, we introduce model-based RL techniques to reduce the training data\\nrequirement and execute more accurate strategy updates. The experimental\\nresults based on a real e-commerce platform demonstrate the effectiveness of\\nthe proposed framework.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.03987v3.pdf'},\n",
       " {'id': '2105.04774v1',\n",
       "  'title': 'Learning to Ask Appropriate Questions in Conversational Recommendation',\n",
       "  'published': '2021-05-11T03:58:10Z',\n",
       "  'summary': \"Conversational recommender systems (CRSs) have revolutionized the\\nconventional recommendation paradigm by embracing dialogue agents to\\ndynamically capture the fine-grained user preference. In a typical\\nconversational recommendation scenario, a CRS firstly generates questions to\\nlet the user clarify her/his demands and then makes suitable recommendations.\\nHence, the ability to generate suitable clarifying questions is the key to\\ntimely tracing users' dynamic preferences and achieving successful\\nrecommendations. However, existing CRSs fall short in asking high-quality\\nquestions because: (1) system-generated responses heavily depends on the\\nperformance of the dialogue policy agent, which has to be trained with huge\\nconversation corpus to cover all circumstances; and (2) current CRSs cannot\\nfully utilize the learned latent user profiles for generating appropriate and\\npersonalized responses.\\n  To mitigate these issues, we propose the Knowledge-Based Question Generation\\nSystem (KBQG), a novel framework for conversational recommendation. Distinct\\nfrom previous conversational recommender systems, KBQG models a user's\\npreference in a finer granularity by identifying the most relevant relations\\nfrom a structured knowledge graph (KG). Conditioned on the varied importance of\\ndifferent relations, the generated clarifying questions could perform better in\\nimpelling users to provide more details on their preferences. Finially,\\naccurate recommendations can be generated in fewer conversational turns.\\nFurthermore, the proposed KBQG outperforms all baselines in our experiments on\\ntwo real-world datasets.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.04774v1.pdf'},\n",
       " {'id': '1911.05282v3',\n",
       "  'title': 'Getting recommendation is not always better',\n",
       "  'published': '2019-11-13T04:23:52Z',\n",
       "  'summary': \"We present an extended version of the Iterated Prisoner's Dilemma game in\\nwhich agents with limited memory receive recommendations about the unknown\\nopponent to decide whether to play with. Since agents can receive more than one\\nrecommendations about the same opponent, they have to evaluate the\\nrecommendations according to their disposition such as optimist, pessimist, or\\nrealist. They keep their firsthand experience in their memory. Since agents\\nhave limited memory, they have to use different forgetting strategies. Our\\nresults show that getting recommendations not always perform better. We observe\\nthat realist performs the best and optimist the worse.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1911.05282v3.pdf'},\n",
       " {'id': '2110.10850v1',\n",
       "  'title': 'Locality-Sensitive Experience Replay for Online Recommendation',\n",
       "  'published': '2021-10-21T01:49:16Z',\n",
       "  'summary': \"Online recommendation requires handling rapidly changing user preferences.\\nDeep reinforcement learning (DRL) is gaining interest as an effective means of\\ncapturing users' dynamic interest during interactions with recommender systems.\\nHowever, it is challenging to train a DRL agent, due to large state space\\n(e.g., user-item rating matrix and user profiles), action space (e.g.,\\ncandidate items), and sparse rewards. Existing studies encourage the agent to\\nlearn from past experience via experience replay (ER). They adapt poorly to the\\ncomplex environment of online recommender systems and are inefficient in\\ndetermining an optimal strategy from past experience. To address these issues,\\nwe design a novel state-aware experience replay model, which uses\\nlocality-sensitive hashing to map high dimensional data into low-dimensional\\nrepresentations and a prioritized reward-driven strategy to replay more\\nvaluable experience at a higher chance. Our model can selectively pick the most\\nrelevant and salient experiences and recommend the agent with the optimal\\npolicy. Experiments on three online simulation platforms demonstrate our model'\\nfeasibility and superiority toseveral existing experience replay methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.10850v1.pdf'},\n",
       " {'id': '2501.12573v1',\n",
       "  'title': \"Leveraging LLMs to Create a Haptic Devices' Recommendation System\",\n",
       "  'published': '2025-01-22T01:41:05Z',\n",
       "  'summary': 'Haptic technology has seen significant growth, yet a lack of awareness of\\nexisting haptic device design knowledge hinders development. This paper\\naddresses these limitations by leveraging advancements in Large Language Models\\n(LLMs) to develop a haptic agent, focusing specifically on Grounded Force\\nFeedback (GFF) devices recommendation. Our approach involves automating the\\ncreation of a structured haptic device database using information from research\\npapers and product specifications. This database enables the recommendation of\\nrelevant GFF devices based on user queries. To ensure precise and contextually\\nrelevant recommendations, the system employs a dynamic retrieval method that\\ncombines both conditional and semantic searches. Benchmarking against the\\nestablished UEQ and existing haptic device searching tools, the proposed haptic\\nrecommendation agent ranks in the top 10\\\\% across all UEQ categories with mean\\ndifferences favoring the agent in nearly all subscales, and maintains no\\nsignificant performance bias across different user groups, showcasing superior\\nusability and user satisfaction.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.12573v1.pdf'},\n",
       " {'id': '2508.11671v1',\n",
       "  'title': 'LLM-Based Intelligent Agents for Music Recommendation: A Comparison with\\n  Classical Content-Based Filtering',\n",
       "  'published': '2025-08-07T15:58:08Z',\n",
       "  'summary': 'The growing availability of music on streaming platforms has led to\\ninformation overload for users. To address this issue and enhance the user\\nexperience, increasingly sophisticated recommendation systems have been\\nproposed. This work investigates the use of Large Language Models (LLMs) from\\nthe Gemini and LLaMA families, combined with intelligent agents, in a\\nmulti-agent personalized music recommendation system. The results are compared\\nwith a traditional content-based recommendation model, considering user\\nsatisfaction, novelty, and computational efficiency. LLMs achieved satisfaction\\nrates of up to \\\\textit{89{,}32\\\\%}, indicating their promising potential in\\nmusic recommendation systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.11671v1.pdf'},\n",
       " {'id': '2504.03693v2',\n",
       "  'title': 'Agentic Business Process Management: Practitioner Perspectives on Agent\\n  Governance in Business Processes',\n",
       "  'published': '2025-03-23T20:15:24Z',\n",
       "  'summary': 'With the rise of generative AI, industry interest in software agents is\\ngrowing. Given the stochastic nature of generative AI-based agents, their\\neffective and safe deployment in organizations requires robust governance,\\nwhich can be facilitated by agentic business process management. However, given\\nthe nascence of this new-generation agent notion, it is not clear what BPM\\npractitioners consider to be an agent, and what benefits, risks and governance\\nchallenges they associate with agent deployments. To investigate how\\norganizations can effectively govern AI agents, we conducted a qualitative\\nstudy involving semi-structured interviews with 22 BPM practitioners from\\ndiverse industries. They anticipate that agents will enhance efficiency,\\nimprove data quality, ensure better compliance, and boost scalability through\\nautomation, while also cautioning against risks such as bias, over-reliance,\\ncybersecurity threats, job displacement, and ambiguous decision-making. To\\naddress these challenges, the study presents six key recommendations for the\\nresponsible adoption of AI agents: define clear business goals, set legal and\\nethical guardrails, establish human-agent collaboration, customize agent\\nbehavior, manage risks, and ensure safe integration with fallback options.\\nAdditionally, the paper outlines actions to align traditional BPM with agentic\\nAI, including balancing human and agent roles, redefining human involvement,\\nadapting process structures, and introducing performance metrics. These\\ninsights provide a practical foundation for integrating AI agents into business\\nprocesses while preserving oversight, flexibility, and trust.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.03693v2.pdf'},\n",
       " {'id': '0906.3769v1',\n",
       "  'title': 'Using Agent to Coordinate Web Services',\n",
       "  'published': '2009-06-20T02:46:20Z',\n",
       "  'summary': 'Traditionally, agent and web service are two separate research areas. We\\nfigure that, through agent communication, agent is suitable to coordinate web\\nservices. However, there exist agent communication problems due to the lack of\\nuniform, cross-platform vocabulary. Fortunately, ontology defines a vocabulary.\\nWe thus propose a new agent communication layer and present the web ontology\\nlanguage (OWL)-based operational ontologies that provides a declarative\\ndescription. It can be accessed by various engines to facilitate agent\\ncommunication. Further, in our operational ontologies, we define the mental\\nattitudes of agents that can be shared among other agents. Our architecture\\nenhanced the 3APL agent platform, and it is implemented as an agent\\ncommunication framework. Finally, we extended the framework to be compatible\\nwith the web ontology language for service (OWL-S), and then develop a movie\\nrecommendation system with four OWL-S semantic web services on the framework.\\nThe benefits of this work are: 1) dynamic web service coordination, 2)\\nontological reasoning through uniform representation, namely, the declarative\\ndescription, and 3) easy reuse and extension of both ontology and engine\\nthrough extending ontology.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0906.3769v1.pdf'},\n",
       " {'id': '1401.1880v2',\n",
       "  'title': 'DJ-MC: A Reinforcement-Learning Agent for Music Playlist Recommendation',\n",
       "  'published': '2014-01-09T01:50:09Z',\n",
       "  'summary': \"In recent years, there has been growing focus on the study of automated\\nrecommender systems. Music recommendation systems serve as a prominent domain\\nfor such works, both from an academic and a commercial perspective. A\\nfundamental aspect of music perception is that music is experienced in temporal\\ncontext and in sequence. In this work we present DJ-MC, a novel\\nreinforcement-learning framework for music recommendation that does not\\nrecommend songs individually but rather song sequences, or playlists, based on\\na model of preferences for both songs and song transitions. The model is\\nlearned online and is uniquely adapted for each listener. To reduce exploration\\ntime, DJ-MC exploits user feedback to initialize a model, which it subsequently\\nupdates by reinforcement. We evaluate our framework with human participants\\nusing both real song and playlist data. Our results indicate that DJ-MC's\\nability to recommend sequences of songs provides a significant improvement over\\nmore straightforward approaches, which do not take transitions into account.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1401.1880v2.pdf'},\n",
       " {'id': '1905.07043v3',\n",
       "  'title': 'Fiduciary Bandits',\n",
       "  'published': '2019-05-16T21:38:39Z',\n",
       "  'summary': \"Recommendation systems often face exploration-exploitation tradeoffs: the\\nsystem can only learn about the desirability of new options by recommending\\nthem to some user. Such systems can thus be modeled as multi-armed bandit\\nsettings; however, users are self-interested and cannot be made to follow\\nrecommendations. We ask whether exploration can nevertheless be performed in a\\nway that scrupulously respects agents' interests---i.e., by a system that acts\\nas a fiduciary. More formally, we introduce a model in which a recommendation\\nsystem faces an exploration-exploitation tradeoff under the constraint that it\\ncan never recommend any action that it knows yields lower reward in expectation\\nthan an agent would achieve if it acted alone. Our main contribution is a\\npositive result: an asymptotically optimal, incentive compatible, and ex-ante\\nindividually rational recommendation algorithm.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.07043v3.pdf'},\n",
       " {'id': '1902.00715v2',\n",
       "  'title': 'When Collaborative Filtering Meets Reinforcement Learning',\n",
       "  'published': '2019-02-02T13:22:35Z',\n",
       "  'summary': \"In this paper, we study a multi-step interactive recommendation problem,\\nwhere the item recommended at current step may affect the quality of future\\nrecommendations. To address the problem, we develop a novel and effective\\napproach, named CFRL, which seamlessly integrates the ideas of both\\ncollaborative filtering (CF) and reinforcement learning (RL). More\\nspecifically, we first model the recommender-user interactive recommendation\\nproblem as an agent-environment RL task, which is mathematically described by a\\nMarkov decision process (MDP). Further, to achieve collaborative\\nrecommendations for the entire user community, we propose a novel CF-based MDP\\nby encoding the states of all users into a shared latent vector space. Finally,\\nwe propose an effective Q-network learning method to learn the agent's optimal\\npolicy based on the CF-based MDP. The capability of CFRL is demonstrated by\\ncomparing its performance against a variety of existing methods on real-world\\ndatasets.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.00715v2.pdf'},\n",
       " {'id': '2201.07203v1',\n",
       "  'title': 'Emergent Instabilities in Algorithmic Feedback Loops',\n",
       "  'published': '2022-01-18T18:58:03Z',\n",
       "  'summary': \"Algorithms that aid human tasks, such as recommendation systems, are\\nubiquitous. They appear in everything from social media to streaming videos to\\nonline shopping. However, the feedback loop between people and algorithms is\\npoorly understood and can amplify cognitive and social biases (algorithmic\\nconfounding), leading to unexpected outcomes. In this work, we explore\\nalgorithmic confounding in collaborative filtering-based recommendation\\nalgorithms through teacher-student learning simulations. Namely, a student\\ncollaborative filtering-based model, trained on simulated choices, is used by\\nthe recommendation algorithm to recommend items to agents. Agents might choose\\nsome of these items, according to an underlying teacher model, with new choices\\nthen fed back into the student model as new training data (approximating online\\nmachine learning). These simulations demonstrate how algorithmic confounding\\nproduces erroneous recommendations which in turn lead to instability, i.e.,\\nwide variations in an item's popularity between each simulation realization. We\\nuse the simulations to demonstrate a novel approach to training collaborative\\nfiltering models that can create more stable and accurate recommendations. Our\\nmethodology is general enough that it can be extended to other socio-technical\\nsystems in order to better quantify and improve the stability of algorithms.\\nThese results highlight the need to account for emergent behaviors from\\ninteractions between people and algorithms.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.07203v1.pdf'},\n",
       " {'id': '2405.01847v1',\n",
       "  'title': 'A Model-based Multi-Agent Personalized Short-Video Recommender System',\n",
       "  'published': '2024-05-03T04:34:36Z',\n",
       "  'summary': 'Recommender selects and presents top-K items to the user at each online\\nrequest, and a recommendation session consists of several sequential requests.\\nFormulating a recommendation session as a Markov decision process and solving\\nit by reinforcement learning (RL) framework has attracted increasing attention\\nfrom both academic and industry communities. In this paper, we propose a\\nRL-based industrial short-video recommender ranking framework, which models and\\nmaximizes user watch-time in an environment of user multi-aspect preferences by\\na collaborative multi-agent formulization. Moreover, our proposed framework\\nadopts a model-based learning approach to alleviate the sample selection bias\\nwhich is a crucial but intractable problem in industrial recommender system.\\nExtensive offline evaluations and live experiments confirm the effectiveness of\\nour proposed method over alternatives. Our proposed approach has been deployed\\nin our real large-scale short-video sharing platform, successfully serving over\\nhundreds of millions users.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.01847v1.pdf'},\n",
       " {'id': '2504.12313v1',\n",
       "  'title': 'Exploring the Impact of Personality Traits on Conversational Recommender\\n  Systems: A Simulation with Large Language Models',\n",
       "  'published': '2025-04-09T13:21:17Z',\n",
       "  'summary': 'Conversational Recommender Systems (CRSs) engage users in multi-turn\\ninteractions to deliver personalized recommendations. The emergence of large\\nlanguage models (LLMs) further enhances these systems by enabling more natural\\nand dynamic user interactions. However, a key challenge remains in\\nunderstanding how personality traits shape conversational recommendation\\noutcomes. Psychological evidence highlights the influence of personality traits\\non user interaction behaviors. To address this, we introduce an LLM-based\\npersonality-aware user simulation for CRSs (PerCRS). The user agent induces\\ncustomizable personality traits and preferences, while the system agent\\npossesses the persuasion capability to simulate realistic interaction in CRSs.\\nWe incorporate multi-aspect evaluation to ensure robustness and conduct\\nextensive analysis from both user and system perspectives. Experimental results\\ndemonstrate that state-of-the-art LLMs can effectively generate diverse user\\nresponses aligned with specified personality traits, thereby prompting CRSs to\\ndynamically adjust their recommendation strategies. Our experimental analysis\\noffers empirical insights into the impact of personality traits on the outcomes\\nof conversational recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.12313v1.pdf'},\n",
       " {'id': '2409.11690v3',\n",
       "  'title': 'ID-Free Not Risk-Free: LLM-Powered Agents Unveil Risks in ID-Free\\n  Recommender Systems',\n",
       "  'published': '2024-09-18T04:10:44Z',\n",
       "  'summary': 'Recent advances in ID-free recommender systems have attracted significant\\nattention for effectively addressing the cold start problem. However, their\\nvulnerability to malicious attacks remains largely unexplored. In this paper,\\nwe unveil a critical yet overlooked risk: LLM-powered agents can be\\nstrategically deployed to attack ID-free recommenders, stealthily promoting\\nlow-quality items in black-box settings. This attack exploits a novel\\nrewriting-based deception strategy, where malicious agents synthesize deceptive\\ntextual descriptions by simulating the characteristics of popular items. To\\nachieve this, the attack mechanism integrates two primary components: (1) a\\npopularity extraction component that captures essential characteristics of\\npopular items and (2) a multi-agent collaboration mechanism that enables\\niterative refinement of promotional textual descriptions through independent\\nthinking and team discussion. To counter this risk, we further introduce a\\ndetection method to identify suspicious text generated by our discovered\\nattack. By unveiling this risk, our work aims to underscore the urgent need to\\nenhance the security of ID-free recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.11690v3.pdf'},\n",
       " {'id': '2409.13700v1',\n",
       "  'title': 'MAS4POI: a Multi-Agents Collaboration System for Next POI Recommendation',\n",
       "  'published': '2024-09-05T02:47:49Z',\n",
       "  'summary': 'LLM-based Multi-Agent Systems have potential benefits of complex\\ndecision-making tasks management across various domains but their applications\\nin the next Point-of-Interest (POI) recommendation remain underexplored. This\\npaper proposes a novel MAS4POI system designed to enhance next POI\\nrecommendations through multi-agent interactions. MAS4POI supports Large\\nLanguage Models (LLMs) specializing in distinct agents such as DataAgent,\\nManager, Analyst, and Navigator with each contributes to a collaborative\\nprocess of generating the next POI recommendations.The system is examined by\\nintegrating six distinct LLMs and evaluated by two real-world datasets for\\nrecommendation accuracy improvement in real-world scenarios. Our code is\\navailable at https://github.com/yuqian2003/MAS4POI.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.13700v1.pdf'},\n",
       " {'id': '2507.18993v1',\n",
       "  'title': 'Agent0: Leveraging LLM Agents to Discover Multi-value Features from Text\\n  for Enhanced Recommendations',\n",
       "  'published': '2025-07-25T06:45:10Z',\n",
       "  'summary': 'Large language models (LLMs) and their associated agent-based frameworks have\\nsignificantly advanced automated information extraction, a critical component\\nof modern recommender systems. While these multitask frameworks are widely used\\nin code generation, their application in data-centric research is still largely\\nuntapped. This paper presents Agent0, an LLM-driven, agent-based system\\ndesigned to automate information extraction and feature construction from raw,\\nunstructured text. Categorical features are crucial for large-scale recommender\\nsystems but are often expensive to acquire. Agent0 coordinates a group of\\ninteracting LLM agents to automatically identify the most valuable text aspects\\nfor subsequent tasks (such as models or AutoML pipelines). Beyond its feature\\nengineering capabilities, Agent0 also offers an automated prompt-engineering\\ntuning method that utilizes dynamic feedback loops from an oracle. Our findings\\ndemonstrate that this closed-loop methodology is both practical and effective\\nfor automated feature discovery, which is recognized as one of the most\\nchallenging phases in current recommender system development.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.18993v1.pdf'},\n",
       " {'id': '2507.21724v1',\n",
       "  'title': 'Agent-Based Exploration of Recommendation Systems in Misinformation\\n  Propagation',\n",
       "  'published': '2025-07-29T12:00:38Z',\n",
       "  'summary': 'This study uses agent-based modeling to examine the impact of various\\nrecommendation algorithms on the propagation of misinformation on online social\\nnetworks. We simulate a synthetic environment consisting of heterogeneous\\nagents, including regular users, bots, and influencers, interacting through a\\nsocial network with recommendation systems. We evaluate four recommendation\\nstrategies: popularity-based, collaborative filtering, and content-based\\nfiltering, along with a random baseline. Our results show that\\npopularity-driven algorithms significantly amplify misinformation, while\\nitem-based collaborative filtering and content-based approaches are more\\neffective in limiting exposure to fake content. Item-based collaborative\\nfiltering was found to perform better than previously reported in related\\nliterature. These findings highlight the role of algorithm design in shaping\\nonline information exposure and show that agent-based modeling can be used to\\ngain realistic insight into how misinformation spreads.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.21724v1.pdf'},\n",
       " {'id': '2509.01551v1',\n",
       "  'title': 'Cloud-Device Collaborative Agents for Sequential Recommendation',\n",
       "  'published': '2025-09-01T15:28:11Z',\n",
       "  'summary': \"Recent advances in large language models (LLMs) have enabled agent-based\\nrecommendation systems with strong semantic understanding and flexible\\nreasoning capabilities. While LLM-based agents deployed in the cloud offer\\npowerful personalization, they often suffer from privacy concerns, limited\\naccess to real-time signals, and scalability bottlenecks. Conversely, on-device\\nagents ensure privacy and responsiveness but lack the computational power for\\nglobal modeling and large-scale retrieval. To bridge these complementary\\nlimitations, we propose CDA4Rec, a novel Cloud-Device collaborative framework\\nfor sequential Recommendation, powered by dual agents: a cloud-side LLM and a\\ndevice-side small language model (SLM). CDA4Rec tackles the core challenge of\\ncloud-device coordination by decomposing the recommendation task into modular\\nsub-tasks including semantic modeling, candidate retrieval, structured user\\nmodeling, and final ranking, which are allocated to cloud or device based on\\ncomputational demands and privacy sensitivity. A strategy planning mechanism\\nleverages the cloud agent's reasoning ability to generate personalized\\nexecution plans, enabling context-aware task assignment and partial parallel\\nexecution across agents. This design ensures real-time responsiveness, improved\\nefficiency, and fine-grained personalization, even under diverse user states\\nand behavioral sparsity. Extensive experiments across multiple real-world\\ndatasets demonstrate that CDA4Rec consistently outperforms competitive\\nbaselines in both accuracy and efficiency, validating its effectiveness in\\nheterogeneous and resource-constrained environments.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.01551v1.pdf'},\n",
       " {'id': '2105.02377v1',\n",
       "  'title': 'Towards Content Provider Aware Recommender Systems: A Simulation Study\\n  on the Interplay between User and Provider Utilities',\n",
       "  'published': '2021-05-06T00:02:58Z',\n",
       "  'summary': 'Most existing recommender systems focus primarily on matching users to\\ncontent which maximizes user satisfaction on the platform. It is increasingly\\nobvious, however, that content providers have a critical influence on user\\nsatisfaction through content creation, largely determining the content pool\\navailable for recommendation. A natural question thus arises: can we design\\nrecommenders taking into account the long-term utility of both users and\\ncontent providers? By doing so, we hope to sustain more providers and a more\\ndiverse content pool for long-term user satisfaction. Understanding the full\\nimpact of recommendations on both user and provider groups is challenging. This\\npaper aims to serve as a research investigation of one approach toward building\\na provider-aware recommender, and evaluating its impact in a simulated setup.\\n  To characterize the user-recommender-provider interdependence, we complement\\nuser modeling by formalizing provider dynamics as well. The resulting joint\\ndynamical system gives rise to a weakly-coupled partially observable Markov\\ndecision process driven by recommender actions and user feedback to providers.\\nWe then build a REINFORCE recommender agent, coined EcoAgent, to optimize a\\njoint objective of user utility and the counterfactual utility lift of the\\nprovider associated with the recommended content, which we show to be\\nequivalent to maximizing overall user utility and the utilities of all\\nproviders on the platform under some mild assumptions. To evaluate our\\napproach, we introduce a simulation environment capturing the key interactions\\namong users, providers, and the recommender. We offer a number of simulated\\nexperiments that shed light on both the benefits and the limitations of our\\napproach. These results help understand how and when a provider-aware\\nrecommender agent is of benefit in building multi-stakeholder recommender\\nsystems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.02377v1.pdf'},\n",
       " {'id': '2410.17086v1',\n",
       "  'title': 'Exploration and Persuasion',\n",
       "  'published': '2024-10-22T15:13:13Z',\n",
       "  'summary': 'How to incentivize self-interested agents to explore when they prefer to\\nexploit? Consider a population of self-interested agents that make decisions\\nunder uncertainty. They \"explore\" to acquire new information and \"exploit\" this\\ninformation to make good decisions. Collectively they need to balance these two\\nobjectives, but their incentives are skewed toward exploitation. This is\\nbecause exploration is costly, but its benefits are spread over many agents in\\nthe future.\\n  \"Incentivized Exploration\" addresses this issue via strategic communication.\\nConsider a benign ``principal\" which can communicate with the agents and make\\nrecommendations, but cannot force the agents to comply. Moreover, suppose the\\nprincipal can observe the agents\\' decisions and the outcomes of these\\ndecisions. The goal is to design a communication and recommendation policy\\nwhich (i) achieves a desirable balance between exploration and exploitation,\\nand (ii) incentivizes the agents to follow recommendations. What makes it\\nfeasible is \"information asymmetry\": the principal knows more than any one\\nagent, as it collects information from many. It is essential that the principal\\ndoes not fully reveal all its knowledge to the agents.\\n  Incentivized exploration combines two important problems in, resp., machine\\nlearning and theoretical economics. First, if agents always follow\\nrecommendations, the principal faces a multi-armed bandit problem: essentially,\\ndesign an algorithm that balances exploration and exploitation. Second,\\ninteraction with a single agent corresponds to \"Bayesian persuasion\", where a\\nprincipal leverages information asymmetry to convince an agent to take a\\nparticular action. We provide a brief but self-contained introduction to each\\nproblem through the lens of incentivized exploration, solving a key special\\ncase of the former as a sub-problem of the latter.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.17086v1.pdf'},\n",
       " {'id': '2505.21154v1',\n",
       "  'title': 'GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware\\n  Recommender Simulation',\n",
       "  'published': '2025-05-27T13:09:21Z',\n",
       "  'summary': \"Current personalized recommender systems predominantly rely on static offline\\ndata for algorithm design and evaluation, significantly limiting their ability\\nto capture long-term user preference evolution and social influence dynamics in\\nreal-world scenarios. To address this fundamental challenge, we propose a\\nhigh-fidelity social simulation platform integrating human-like cognitive\\nagents and dynamic social interactions to realistically simulate user behavior\\nevolution under recommendation interventions. Specifically, the system\\ncomprises a population of Sim-User Agents, each equipped with a five-layer\\ncognitive architecture that encapsulates key psychological mechanisms,\\nincluding episodic memory, affective state transitions, adaptive preference\\nlearning, and dynamic trust-risk assessments. In particular, we innovatively\\nintroduce the Intimacy--Curiosity--Reciprocity--Risk (ICR2) motivational engine\\ngrounded in psychological and sociological theories, enabling more realistic\\nuser decision-making processes. Furthermore, we construct a multilayer\\nheterogeneous social graph (GGBond Graph) supporting dynamic relational\\nevolution, effectively modeling users' evolving social ties and trust dynamics\\nbased on interest similarity, personality alignment, and structural homophily.\\nDuring system operation, agents autonomously respond to recommendations\\ngenerated by typical recommender algorithms (e.g., Matrix Factorization,\\nMultVAE, LightGCN), deciding whether to consume, rate, and share content while\\ndynamically updating their internal states and social connections, thereby\\nforming a stable, multi-round feedback loop. This innovative design transcends\\nthe limitations of traditional static datasets, providing a controlled,\\nobservable environment for evaluating long-term recommender effects.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.21154v1.pdf'},\n",
       " {'id': '2208.00391v1',\n",
       "  'title': 'An Experimental Study on Learning Correlated Equilibrium in Routing\\n  Games',\n",
       "  'published': '2022-07-31T08:17:01Z',\n",
       "  'summary': 'We study route choice in a repeated routing game where an uncertain state of\\nnature determines link latency functions, and agents receive private route\\nrecommendation. The state is sampled in an i.i.d. manner in every round from a\\npublicly known distribution, and the recommendations are generated by a\\nrandomization policy whose mapping from the state is known publicly. In a\\none-shot setting, the agents are said to obey recommendation if it gives the\\nsmallest travel time in a posteriori expectation. A plausible extension to\\nrepeated setting is that the likelihood of following recommendation in a round\\nis related to regret from previous rounds. If the regret is of satisficing type\\nwith respect to a default choice and is averaged over past rounds and over all\\nagents, then the asymptotic outcome under an obedient recommendation policy\\ncoincides with the one-shot outcome. We report findings from an experiment with\\none participant at a time engaged in repeated route choice decision on\\ncomputer. In every round, the participant is shown travel time distribution for\\neach route, a route recommendation generated by an obedient policy, and a\\nrating suggestive of average experience of previous participants with the\\nquality of recommendation. Upon entering route choice, the actual travel times\\nare revealed. The participant evaluates the quality of recommendation by\\nsubmitting a review. This is combined with historical reviews to update rating\\nfor the next round. Data analysis from 33 participants each with 100 rounds\\nsuggests moderate negative correlation between the display rating and the\\naverage regret, and a strong positive correlation between the rating and the\\nlikelihood of following recommendation. Overall, under obedient recommendation\\npolicy, the rating converges close to its maximum value by the end of the\\nexperiments in conjunction with very high frequency of following\\nrecommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.00391v1.pdf'},\n",
       " {'id': '2307.14551v3',\n",
       "  'title': 'How to Train Your YouTube Recommender to Avoid Unwanted Videos',\n",
       "  'published': '2023-07-27T00:21:29Z',\n",
       "  'summary': 'YouTube provides features for users to indicate disinterest when presented\\nwith unwanted recommendations, such as the \"Not interested\" and \"Don\\'t\\nrecommend channel\" buttons. These buttons purportedly allow the user to correct\\n\"mistakes\" made by the recommendation system. Yet, relatively little is known\\nabout the empirical efficacy of these buttons. Neither is much known about\\nusers\\' awareness of and confidence in them. To address these gaps, we simulated\\nYouTube users with sock puppet agents. Each agent first executed a \"stain\\nphase\", where it watched many videos of an assigned topic; it then executed a\\n\"scrub phase\", where it tried to remove recommendations from the assigned\\ntopic. Each agent repeatedly applied a single scrubbing strategy, either\\nindicating disinterest in one of the videos visited in the stain phase\\n(disliking it or deleting it from the watch history), or indicating disinterest\\nin a video recommended on the homepage (clicking the \"not interested\" or \"don\\'t\\nrecommend channel\" button or opening the video and clicking the dislike\\nbutton). We found that the stain phase significantly increased the fraction of\\nthe recommended videos dedicated to the assigned topic on the user\\'s homepage.\\nFor the scrub phase, using the \"Not interested\" button worked best,\\nsignificantly reducing such recommendations in all topics tested, on average\\nremoving 88% of them. Neither the stain phase nor the scrub phase, however, had\\nmuch effect on videopage recommendations. We also ran a survey (N = 300) asking\\nadult YouTube users in the US whether they were aware of and used these buttons\\nbefore, as well as how effective they found these buttons to be. We found that\\n44% of participants were not aware that the \"Not interested\" button existed.\\nThose who were aware of it often used it to remove unwanted recommendations\\n(82.8%) and found it to be modestly effective (3.42 out of 5).',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.14551v3.pdf'},\n",
       " {'id': '2103.08057v1',\n",
       "  'title': 'RecSim NG: Toward Principled Uncertainty Modeling for Recommender\\n  Ecosystems',\n",
       "  'published': '2021-03-14T22:37:42Z',\n",
       "  'summary': 'The development of recommender systems that optimize multi-turn interaction\\nwith users, and model the interactions of different agents (e.g., users,\\ncontent providers, vendors) in the recommender ecosystem have drawn increasing\\nattention in recent years. Developing and training models and algorithms for\\nsuch recommenders can be especially difficult using static datasets, which\\noften fail to offer the types of counterfactual predictions needed to evaluate\\npolicies over extended horizons. To address this, we develop RecSim NG, a\\nprobabilistic platform for the simulation of multi-agent recommender systems.\\nRecSim NG is a scalable, modular, differentiable simulator implemented in\\nEdward2 and TensorFlow. It offers: a powerful, general probabilistic\\nprogramming language for agent-behavior specification; tools for probabilistic\\ninference and latent-variable model learning, backed by automatic\\ndifferentiation and tracing; and a TensorFlow-based runtime for running\\nsimulations on accelerated hardware. We describe RecSim NG and illustrate how\\nit can be used to create transparent, configurable, end-to-end models of a\\nrecommender ecosystem, complemented by a small set of simple use cases that\\ndemonstrate how RecSim NG can help both researchers and practitioners easily\\ndevelop and train novel algorithms for recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.08057v1.pdf'},\n",
       " {'id': '2505.12981v2',\n",
       "  'title': 'From Assistants to Adversaries: Exploring the Security Risks of Mobile\\n  LLM Agents',\n",
       "  'published': '2025-05-19T11:17:46Z',\n",
       "  'summary': 'The growing adoption of large language models (LLMs) has led to a new\\nparadigm in mobile computing--LLM-powered mobile AI agents--capable of\\ndecomposing and automating complex tasks directly on smartphones. However, the\\nsecurity implications of these agents remain largely unexplored. In this paper,\\nwe present the first comprehensive security analysis of mobile LLM agents,\\nencompassing three representative categories: System-level AI Agents developed\\nby original equipment manufacturers (e.g., YOYO Assistant), Third-party\\nUniversal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g.,\\nAlibaba Mobile Agent). We begin by analyzing the general workflow of mobile\\nagents and identifying security threats across three core capability\\ndimensions: language-based reasoning, GUI-based interaction, and system-level\\nexecution. Our analysis reveals 11 distinct attack surfaces, all rooted in the\\nunique capabilities and interaction patterns of mobile LLM agents, and spanning\\ntheir entire operational lifecycle. To investigate these threats in practice,\\nwe introduce AgentScan, a semi-automated security analysis framework that\\nsystematically evaluates mobile LLM agents across all 11 attack scenarios.\\nApplying AgentScan to nine widely deployed agents, we uncover a concerning\\ntrend: every agent is vulnerable to targeted attacks. In the most severe cases,\\nagents exhibit vulnerabilities across eight distinct attack vectors. These\\nattacks can cause behavioral deviations, privacy leakage, or even full\\nexecution hijacking. Based on these findings, we propose a set of defensive\\ndesign principles and practical recommendations for building secure mobile LLM\\nagents. Our disclosures have received positive feedback from two major device\\nvendors. Overall, this work highlights the urgent need for standardized\\nsecurity practices in the fast-evolving landscape of LLM-driven mobile\\nautomation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.12981v2.pdf'},\n",
       " {'id': '1703.00535v3',\n",
       "  'title': 'Human Interaction with Recommendation Systems',\n",
       "  'published': '2017-03-01T22:28:42Z',\n",
       "  'summary': 'Many recommendation algorithms rely on user data to generate recommendations.\\nHowever, these recommendations also affect the data obtained from future users.\\nThis work aims to understand the effects of this dynamic interaction. We\\npropose a simple model where users with heterogeneous preferences arrive over\\ntime. Based on this model, we prove that naive estimators, i.e. those which\\nignore this feedback loop, are not consistent. We show that consistent\\nestimators are efficient in the presence of myopic agents. Our results are\\nvalidated using extensive simulations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1703.00535v3.pdf'},\n",
       " {'id': '2008.09237v1',\n",
       "  'title': 'COOKIE: A Dataset for Conversational Recommendation over Knowledge\\n  Graphs in E-commerce',\n",
       "  'published': '2020-08-21T00:11:31Z',\n",
       "  'summary': 'In this work, we present a new dataset for conversational recommendation over\\nknowledge graphs in e-commerce platforms called COOKIE. The dataset is\\nconstructed from an Amazon review corpus by integrating both user-agent\\ndialogue and custom knowledge graphs for recommendation. Specifically, we first\\nconstruct a unified knowledge graph and extract key entities between\\nuser--product pairs, which serve as the skeleton of a conversation. Then we\\nsimulate conversations mirroring the human coarse-to-fine process of choosing\\npreferred items. The proposed baselines and experiments demonstrate that our\\ndataset is able to provide innovative opportunities for conversational\\nrecommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.09237v1.pdf'},\n",
       " {'id': '2412.18396v3',\n",
       "  'title': 'Contrastive Representation for Interactive Recommendation',\n",
       "  'published': '2024-12-24T12:39:23Z',\n",
       "  'summary': \"Interactive Recommendation (IR) has gained significant attention recently for\\nits capability to quickly capture dynamic interest and optimize both short and\\nlong term objectives. IR agents are typically implemented through Deep\\nReinforcement Learning (DRL), because DRL is inherently compatible with the\\ndynamic nature of IR. However, DRL is currently not perfect for IR. Due to the\\nlarge action space and sample inefficiency problem, training DRL recommender\\nagents is challenging. The key point is that useful features cannot be\\nextracted as high-quality representations for the recommender agent to optimize\\nits policy. To tackle this problem, we propose Contrastive Representation for\\nInteractive Recommendation (CRIR). CRIR efficiently extracts latent, high-level\\npreference ranking features from explicit interaction, and leverages the\\nfeatures to enhance users' representation. Specifically, the CRIR provides\\nrepresentation through one representation network, and refines it through our\\nproposed Preference Ranking Contrastive Learning (PRCL). The key insight of\\nPRCL is that it can perform contrastive learning without relying on\\ncomputations involving high-level representations or large potential action\\nsets. Furthermore, we also propose a data exploiting mechanism and an agent\\ntraining mechanism to better adapt CRIR to the DRL backbone. Extensive\\nexperiments have been carried out to show our method's superior improvement on\\nthe sample efficiency while training an DRL-based IR agent.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.18396v3.pdf'},\n",
       " {'id': '2503.16734v1',\n",
       "  'title': 'Towards Agentic Recommender Systems in the Era of Multimodal Large\\n  Language Models',\n",
       "  'published': '2025-03-20T22:37:15Z',\n",
       "  'summary': \"Recent breakthroughs in Large Language Models (LLMs) have led to the\\nemergence of agentic AI systems that extend beyond the capabilities of\\nstandalone models. By empowering LLMs to perceive external environments,\\nintegrate multimodal information, and interact with various tools, these\\nagentic systems exhibit greater autonomy and adaptability across complex tasks.\\nThis evolution brings new opportunities to recommender systems (RS): LLM-based\\nAgentic RS (LLM-ARS) can offer more interactive, context-aware, and proactive\\nrecommendations, potentially reshaping the user experience and broadening the\\napplication scope of RS. Despite promising early results, fundamental\\nchallenges remain, including how to effectively incorporate external knowledge,\\nbalance autonomy with controllability, and evaluate performance in dynamic,\\nmultimodal settings. In this perspective paper, we first present a systematic\\nanalysis of LLM-ARS: (1) clarifying core concepts and architectures; (2)\\nhighlighting how agentic capabilities -- such as planning, memory, and\\nmultimodal reasoning -- can enhance recommendation quality; and (3) outlining\\nkey research questions in areas such as safety, efficiency, and lifelong\\npersonalization. We also discuss open problems and future directions, arguing\\nthat LLM-ARS will drive the next wave of RS innovation. Ultimately, we foresee\\na paradigm shift toward intelligent, autonomous, and collaborative\\nrecommendation experiences that more closely align with users' evolving needs\\nand complex decision-making processes.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.16734v1.pdf'},\n",
       " {'id': '2205.02987v1',\n",
       "  'title': 'Tell Me Something That Will Help Me Trust You: A Survey of Trust\\n  Calibration in Human-Agent Interaction',\n",
       "  'published': '2022-05-06T02:41:08Z',\n",
       "  'summary': 'When a human receives a prediction or recommended course of action from an\\nintelligent agent, what additional information, beyond the prediction or\\nrecommendation itself, does the human require from the agent to decide whether\\nto trust or reject the prediction or recommendation? In this paper we survey\\nliterature in the area of trust between a single human supervisor and a single\\nagent subordinate to determine the nature and extent of this additional\\ninformation and to characterize it into a taxonomy that can be leveraged by\\nfuture researchers and intelligent agent practitioners. By examining this\\nquestion from a human-centered, information-focused point of view, we can begin\\nto compare and contrast different implementations and also provide insight and\\ndirections for future work.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.02987v1.pdf'},\n",
       " {'id': '2309.14156v2',\n",
       "  'title': 'Designing and evaluating an online reinforcement learning agent for\\n  physical exercise recommendations in N-of-1 trials',\n",
       "  'published': '2023-09-25T14:08:21Z',\n",
       "  'summary': \"Personalized adaptive interventions offer the opportunity to increase patient\\nbenefits, however, there are challenges in their planning and implementation.\\nOnce implemented, it is an important question whether personalized adaptive\\ninterventions are indeed clinically more effective compared to a fixed gold\\nstandard intervention. In this paper, we present an innovative N-of-1 trial\\nstudy design testing whether implementing a personalized intervention by an\\nonline reinforcement learning agent is feasible and effective. Throughout, we\\nuse a new study on physical exercise recommendations to reduce pain in\\nendometriosis for illustration. We describe the design of a contextual bandit\\nrecommendation agent and evaluate the agent in simulation studies. The results\\nshow that, first, implementing a personalized intervention by an online\\nreinforcement learning agent is feasible. Second, such adaptive interventions\\nhave the potential to improve patients' benefits even if only few observations\\nare available. As one challenge, they add complexity to the design and\\nimplementation process. In order to quantify the expected benefit, data from\\nprevious interventional studies is required. We expect our approach to be\\ntransferable to other interventions and clinical interventions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.14156v2.pdf'},\n",
       " {'id': '2508.15030v1',\n",
       "  'title': 'Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations\\n  in Tourism',\n",
       "  'published': '2025-08-20T19:49:06Z',\n",
       "  'summary': \"We propose Collab-REC, a multi-agent framework designed to counteract\\npopularity bias and enhance diversity in tourism recommendations. In our\\nsetting, three LLM-based agents -- Personalization, Popularity, and\\nSustainability generate city suggestions from complementary perspectives. A\\nnon-LLM moderator then merges and refines these proposals via multi-round\\nnegotiation, ensuring each agent's viewpoint is incorporated while penalizing\\nspurious or repeated responses. Experiments on European city queries show that\\nCollab-REC improves diversity and overall relevance compared to a single-agent\\nbaseline, surfacing lesser-visited locales that often remain overlooked. This\\nbalanced, context-aware approach addresses over-tourism and better aligns with\\nconstraints provided by the user, highlighting the promise of multi-stakeholder\\ncollaboration in LLM-driven recommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.15030v1.pdf'},\n",
       " {'id': '2509.06269v1',\n",
       "  'title': 'REMI: A Novel Causal Schema Memory Architecture for Personalized\\n  Lifestyle Recommendation Agents',\n",
       "  'published': '2025-09-08T01:17:46Z',\n",
       "  'summary': \"Personalized AI assistants often struggle to incorporate complex personal\\ndata and causal knowledge, leading to generic advice that lacks explanatory\\npower. We propose REMI, a Causal Schema Memory architecture for a multimodal\\nlifestyle agent that integrates a personal causal knowledge graph, a causal\\nreasoning engine, and a schema based planning module. The idea is to deliver\\nexplainable, personalized recommendations in domains like fashion, personal\\nwellness, and lifestyle planning. Our architecture uses a personal causal graph\\nof the user's life events and habits, performs goal directed causal traversals\\nenriched with external knowledge and hypothetical reasoning, and retrieves\\nadaptable plan schemas to generate tailored action plans. A Large Language\\nModel orchestrates these components, producing answers with transparent causal\\nexplanations. We outline the CSM system design and introduce new evaluation\\nmetrics for personalization and explainability, including Personalization\\nSalience Score and Causal Reasoning Accuracy, to rigorously assess its\\nperformance. Results indicate that CSM based agents can provide more context\\naware, user aligned recommendations compared to baseline LLM agents. This work\\ndemonstrates a novel approach to memory augmented, causal reasoning in\\npersonalized agents, advancing the development of transparent and trustworthy\\nAI lifestyle assistants.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.06269v1.pdf'},\n",
       " {'id': '2301.12255v1',\n",
       "  'title': 'The impact of surplus sharing on the outcomes of specific investments\\n  under negotiated transfer pricing: An agent-based simulation with fuzzy\\n  Q-learning agents',\n",
       "  'published': '2023-01-28T17:26:58Z',\n",
       "  'summary': \"This paper focuses on specific investments under negotiated transfer pricing.\\nReasons for transfer pricing studies are primarily to find conditions that\\nmaximize the firm's overall profit, especially in cases with bilateral trading\\nproblems with specific investments. However, the transfer pricing problem has\\nbeen developed in the context where managers are fully individual rational\\nutility maximizers. The underlying assumptions are rather heroic and, in\\nparticular, how managers process information under uncertainty, do not\\nperfectly match with human decision-making behavior. Therefore, this paper\\nrelaxes key assumptions and studies whether cognitively bounded agents achieve\\nthe same results as fully rational utility maximizers and, in particular,\\nwhether the recommendations on managerial-compensation arrangements and\\nbargaining infrastructures are designed to maximize headquarters' profit in\\nsuch a setting. Based on an agent-based simulation with fuzzy Q-learning\\nagents, it is shown that in case of symmetric marginal cost parameters, myopic\\nfuzzy Q-learning agents invest only as much as in the classic hold-up problem,\\nwhile non-myopic fuzzy Q-learning agents invest optimally. However, in\\nscenarios with non-symmetric marginal cost parameters, a deviation from the\\npreviously recommended surplus sharing rules can lead to higher investment\\ndecisions and, thus, to an increase in the firm's overall profit.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2301.12255v1.pdf'},\n",
       " {'id': '2508.07672v1',\n",
       "  'title': \"Towards Aligning Personalized Conversational Recommendation Agents with\\n  Users' Privacy Preferences\",\n",
       "  'published': '2025-08-11T06:51:44Z',\n",
       "  'summary': \"The proliferation of AI agents, with their complex and context-dependent\\nactions, renders conventional privacy paradigms obsolete. This position paper\\nargues that the current model of privacy management, rooted in a user's\\nunilateral control over a passive tool, is inherently mismatched with the\\ndynamic and interactive nature of AI agents. We contend that ensuring effective\\nprivacy protection necessitates that the agents proactively align with users'\\nprivacy preferences instead of passively waiting for the user to control. To\\nground this shift, and using personalized conversational recommendation agents\\nas a case, we propose a conceptual framework built on Contextual Integrity (CI)\\ntheory and Privacy Calculus theory. This synthesis first reframes automatically\\ncontrolling users' privacy as an alignment problem, where AI agents initially\\ndid not know users' preferences, and would learn their privacy preferences\\nthrough implicit or explicit feedback. Upon receiving the preference feedback,\\nthe agents used alignment and Pareto optimization for aligning preferences and\\nbalancing privacy and utility. We introduced formulations and instantiations,\\npotential applications, as well as five challenges.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.07672v1.pdf'},\n",
       " {'id': '1808.00720v2',\n",
       "  'title': 'RecoGym: A Reinforcement Learning Environment for the problem of Product\\n  Recommendation in Online Advertising',\n",
       "  'published': '2018-08-02T09:13:18Z',\n",
       "  'summary': 'Recommender Systems are becoming ubiquitous in many settings and take many\\nforms, from product recommendation in e-commerce stores, to query suggestions\\nin search engines, to friend recommendation in social networks. Current\\nresearch directions which are largely based upon supervised learning from\\nhistorical data appear to be showing diminishing returns with a lot of\\npractitioners report a discrepancy between improvements in offline metrics for\\nsupervised learning and the online performance of the newly proposed models.\\nOne possible reason is that we are using the wrong paradigm: when looking at\\nthe long-term cycle of collecting historical performance data, creating a new\\nversion of the recommendation model, A/B testing it and then rolling it out. We\\nsee that there a lot of commonalities with the reinforcement learning (RL)\\nsetup, where the agent observes the environment and acts upon it in order to\\nchange its state towards better states (states with higher rewards). To this\\nend we introduce RecoGym, an RL environment for recommendation, which is\\ndefined by a model of user traffic patterns on e-commerce and the users\\nresponse to recommendations on the publisher websites. We believe that this is\\nan important step forward for the field of recommendation systems research,\\nthat could open up an avenue of collaboration between the recommender systems\\nand reinforcement learning communities and lead to better alignment between\\noffline and online performance metrics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1808.00720v2.pdf'},\n",
       " {'id': '2112.00979v1',\n",
       "  'title': 'Recommending with Recommendations',\n",
       "  'published': '2021-12-02T04:30:15Z',\n",
       "  'summary': \"Recommendation systems are a key modern application of machine learning, but\\nthey have the downside that they often draw upon sensitive user information in\\nmaking their predictions. We show how to address this deficiency by basing a\\nservice's recommendation engine upon recommendations from other existing\\nservices, which contain no sensitive information by nature. Specifically, we\\nintroduce a contextual multi-armed bandit recommendation framework where the\\nagent has access to recommendations for other services. In our setting, the\\nuser's (potentially sensitive) information belongs to a high-dimensional latent\\nspace, and the ideal recommendations for the source and target tasks (which are\\nnon-sensitive) are given by unknown linear transformations of the user\\ninformation. So long as the tasks rely on similar segments of the user\\ninformation, we can decompose the target recommendation problem into systematic\\ncomponents that can be derived from the source recommendations, and\\nidiosyncratic components that are user-specific and cannot be derived from the\\nsource, but have significantly lower dimensionality. We propose an\\nexplore-then-refine approach to learning and utilizing this decomposition; then\\nusing ideas from perturbation theory and statistical concentration of measure,\\nwe prove our algorithm achieves regret comparable to a strong skyline that has\\nfull knowledge of the source and target transformations. We also consider a\\ngeneralization of our algorithm to a model with many simultaneous targets and\\nno source. Our methods obtain superior empirical results on synthetic\\nbenchmarks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.00979v1.pdf'},\n",
       " {'id': '2207.12628v1',\n",
       "  'title': 'Bundle MCR: Towards Conversational Bundle Recommendation',\n",
       "  'published': '2022-07-26T03:28:42Z',\n",
       "  'summary': 'Bundle recommender systems recommend sets of items (e.g., pants, shirt, and\\nshoes) to users, but they often suffer from two issues: significant interaction\\nsparsity and a large output space. In this work, we extend multi-round\\nconversational recommendation (MCR) to alleviate these issues. MCR, which uses\\na conversational paradigm to elicit user interests by asking user preferences\\non tags (e.g., categories or attributes) and handling user feedback across\\nmultiple rounds, is an emerging recommendation setting to acquire user feedback\\nand narrow down the output space, but has not been explored in the context of\\nbundle recommendation. In this work, we propose a novel recommendation task\\nnamed Bundle MCR. We first propose a new framework to formulate Bundle MCR as\\nMarkov Decision Processes (MDPs) with multiple agents, for user modeling,\\nconsultation and feedback handling in bundle contexts. Under this framework, we\\npropose a model architecture, called Bundle Bert (Bunt) to (1) recommend items,\\n(2) post questions and (3) manage conversations based on bundle-aware\\nconversation states. Moreover, to train Bunt effectively, we propose a\\ntwo-stage training strategy. In an offline pre-training stage, Bunt is trained\\nusing multiple cloze tasks to mimic bundle interactions in conversations. Then\\nin an online fine-tuning stage, Bunt agents are enhanced by user interactions.\\nOur experiments on multiple offline datasets as well as the human evaluation\\nshow the value of extending MCR frameworks to bundle settings and the\\neffectiveness of our Bunt design.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.12628v1.pdf'},\n",
       " {'id': '2505.00981v1',\n",
       "  'title': 'Multi-agents based User Values Mining for Recommendation',\n",
       "  'published': '2025-05-02T04:01:31Z',\n",
       "  'summary': \"Recommender systems have rapidly evolved and become integral to many online\\nservices. However, existing systems sometimes produce unstable and\\nunsatisfactory recommendations that fail to align with users' fundamental and\\nlong-term preferences. This is because they primarily focus on extracting\\nshallow and short-term interests from user behavior data, which is inherently\\ndynamic and challenging to model. Unlike these transient interests, user values\\nare more stable and play a crucial role in shaping user behaviors, such as\\npurchasing items and consuming content. Incorporating user values into\\nrecommender systems can help stabilize recommendation performance and ensure\\nresults better reflect users' latent preferences. However, acquiring user\\nvalues is typically difficult and costly. To address this challenge, we\\nleverage the strong language understanding, zero-shot inference, and\\ngeneralization capabilities of Large Language Models (LLMs) to extract user\\nvalues from users' historical interactions. Unfortunately, direct extraction\\nusing LLMs presents several challenges such as length constraints and\\nhallucination. To overcome these issues, we propose ZOOM, a zero-shot multi-LLM\\ncollaborative framework for effective and accurate user value extraction. In\\nZOOM, we apply text summarization techniques to condense item content while\\npreserving essential meaning. To mitigate hallucinations, ZOOM introduces two\\nspecialized agent roles: evaluators and supervisors, to collaboratively\\ngenerate accurate user values. Extensive experiments on two widely used\\nrecommendation datasets with two state-of-the-art recommendation models\\ndemonstrate the effectiveness and generalization of our framework in automatic\\nuser value mining and recommendation performance improvement.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.00981v1.pdf'},\n",
       " {'id': '0910.3490v2',\n",
       "  'title': 'Adaptive model for recommendation of news',\n",
       "  'published': '2009-10-19T09:43:12Z',\n",
       "  'summary': \"Most news recommender systems try to identify users' interests and news'\\nattributes and use them to obtain recommendations. Here we propose an adaptive\\nmodel which combines similarities in users' rating patterns with epidemic-like\\nspreading of news on an evolving network. We study the model by computer\\nagent-based simulations, measure its performance and discuss its robustness\\nagainst bias and malicious behavior. Subject to the approval fraction of news\\nrecommended, the proposed model outperforms the widely adopted recommendation\\nof news according to their absolute or relative popularity. This model provides\\na general social mechanism for recommender systems and may find its\\napplications also in other types of recommendation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0910.3490v2.pdf'},\n",
       " {'id': '2112.11854v1',\n",
       "  'title': 'Movie Recommender System using critic consensus',\n",
       "  'published': '2021-12-22T13:04:41Z',\n",
       "  'summary': 'Recommendation systems are perhaps one of the most important agents for\\nindustry growth through the modern Internet world. Previous approaches on\\nrecommendation systems include collaborative filtering and content based\\nfiltering recommendation systems. These 2 methods are disjointed in nature and\\nrequire the continuous storage of user preferences for a better recommendation.\\nTo provide better integration of the two processes, we propose a hybrid\\nrecommendation system based on the integration of collaborative and\\ncontent-based content, taking into account the top critic consensus and movie\\nrating score. We would like to present a novel model that recommends movies\\nbased on the combination of user preferences and critical consensus scores.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.11854v1.pdf'},\n",
       " {'id': '2009.07346v1',\n",
       "  'title': 'Reinforcement Learning for Strategic Recommendations',\n",
       "  'published': '2020-09-15T20:45:48Z',\n",
       "  'summary': 'Strategic recommendations (SR) refer to the problem where an intelligent\\nagent observes the sequential behaviors and activities of users and decides\\nwhen and how to interact with them to optimize some long-term objectives, both\\nfor the user and the business. These systems are in their infancy in the\\nindustry and in need of practical solutions to some fundamental research\\nchallenges. At Adobe research, we have been implementing such systems for\\nvarious use-cases, including points of interest recommendations, tutorial\\nrecommendations, next step guidance in multi-media editing software, and ad\\nrecommendation for optimizing lifetime value. There are many research\\nchallenges when building these systems, such as modeling the sequential\\nbehavior of users, deciding when to intervene and offer recommendations without\\nannoying the user, evaluating policies offline with high confidence, safe\\ndeployment, non-stationarity, building systems from passive data that do not\\ncontain past recommendations, resource constraint optimization in multi-user\\nsystems, scaling to large and dynamic actions spaces, and handling and\\nincorporating human cognitive biases. In this paper we cover various use-cases\\nand research challenges we solved to make these systems practical.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2009.07346v1.pdf'},\n",
       " {'id': '2109.03150v3',\n",
       "  'title': 'Recommendation Fairness: From Static to Dynamic',\n",
       "  'published': '2021-09-05T21:38:05Z',\n",
       "  'summary': \"Driven by the need to capture users' evolving interests and optimize their\\nlong-term experiences, more and more recommender systems have started to model\\nrecommendation as a Markov decision process and employ reinforcement learning\\nto address the problem. Shouldn't research on the fairness of recommender\\nsystems follow the same trend from static evaluation and one-shot intervention\\nto dynamic monitoring and non-stop control? In this paper, we portray the\\nrecent developments in recommender systems first and then discuss how fairness\\ncould be baked into the reinforcement learning techniques for recommendation.\\nMoreover, we argue that in order to make further progress in recommendation\\nfairness, we may want to consider multi-agent (game-theoretic) optimization,\\nmulti-objective (Pareto) optimization, and simulation-based optimization, in\\nthe general framework of stochastic games.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.03150v3.pdf'},\n",
       " {'id': '2208.08035v2',\n",
       "  'title': 'EGCR: Explanation Generation for Conversational Recommendation',\n",
       "  'published': '2022-08-17T02:30:41Z',\n",
       "  'summary': 'Growing attention has been paid in Conversational Recommendation System\\n(CRS), which works as a conversation-based and recommendation task-oriented\\ntool to provide items of interest and explore user preference. However,\\nexisting work in CRS fails to explicitly show the reasoning logic to users and\\nthe whole CRS still remains a black box. Therefore we propose a novel\\nend-to-end framework named Explanation Generation for Conversational\\nRecommendation (EGCR) based on generating explanations for conversational\\nagents to explain why they make the action. EGCR incorporates user reviews to\\nenhance the item representation and increase the informativeness of the whole\\nconversation. To the best of our knowledge, this is the first framework for\\nexplainable conversational recommendation on real-world datasets. Moreover, we\\nevaluate EGCR on one benchmark conversational recommendation datasets and\\nachieve better performance on both recommendation accuracy and conversation\\nquality than other state-of-the art models. Finally, extensive experiments\\ndemonstrate that generated explanations are not only having high quality and\\nexplainability, but also making CRS more trustworthy. We will make our code\\navailable to contribute to the CRS community',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.08035v2.pdf'},\n",
       " {'id': '2303.00968v3',\n",
       "  'title': 'Dynamic fairness-aware recommendation through multi-agent social choice',\n",
       "  'published': '2023-03-02T05:06:17Z',\n",
       "  'summary': 'Algorithmic fairness in the context of personalized recommendation presents\\nsignificantly different challenges to those commonly encountered in\\nclassification tasks. Researchers studying classification have generally\\nconsidered fairness to be a matter of achieving equality of outcomes between a\\nprotected and unprotected group, and built algorithmic interventions on this\\nbasis. We argue that fairness in real-world application settings in general,\\nand especially in the context of personalized recommendation, is much more\\ncomplex and multi-faceted, requiring a more general approach. We propose a\\nmodel to formalize multistakeholder fairness in recommender systems as a two\\nstage social choice problem. In particular, we express recommendation fairness\\nas a novel combination of an allocation and an aggregation problem, which\\nintegrate both fairness concerns and personalized recommendation provisions,\\nand derive new recommendation techniques based on this formulation. Simulations\\ndemonstrate the ability of the framework to integrate multiple fairness\\nconcerns in a dynamic way.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.00968v3.pdf'},\n",
       " {'id': '2310.18119v1',\n",
       "  'title': 'Towards a Unified Conversational Recommendation System: Multi-task\\n  Learning via Contextualized Knowledge Distillation',\n",
       "  'published': '2023-10-27T13:06:24Z',\n",
       "  'summary': 'In Conversational Recommendation System (CRS), an agent is asked to recommend\\na set of items to users within natural language conversations. To address the\\nneed for both conversational capability and personalized recommendations, prior\\nworks have utilized separate recommendation and dialogue modules. However, such\\napproach inevitably results in a discrepancy between recommendation results and\\ngenerated responses. To bridge the gap, we propose a multi-task learning for a\\nunified CRS, where a single model jointly learns both tasks via Contextualized\\nKnowledge Distillation (ConKD). We introduce two versions of ConKD: hard gate\\nand soft gate. The former selectively gates between two task-specific teachers,\\nwhile the latter integrates knowledge from both teachers. Our gates are\\ncomputed on-the-fly in a context-specific manner, facilitating flexible\\nintegration of relevant knowledge. Extensive experiments demonstrate that our\\nsingle model significantly improves recommendation performance while enhancing\\nfluency, and achieves comparable results in terms of diversity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.18119v1.pdf'},\n",
       " {'id': '2505.22979v1',\n",
       "  'title': 'Learning Recommender Mechanisms for Bayesian Stochastic Games',\n",
       "  'published': '2025-05-29T01:34:54Z',\n",
       "  'summary': 'An important challenge in non-cooperative game theory is coordinating on a\\nsingle (approximate) equilibrium from many possibilities - a challenge that\\nbecomes even more complex when players hold private information. Recommender\\nmechanisms tackle this problem by recommending strategies to players based on\\ntheir reported type profiles. A key consideration in such mechanisms is to\\nensure that players are incentivized to participate, report their private\\ninformation truthfully, and follow the recommendations. While previous work has\\nfocused on designing recommender mechanisms for one-shot and extensive-form\\ngames, these approaches cannot be effectively applied to stochastic games,\\nparticularly if we constrain recommendations to be Markov stationary policies.\\nTo bridge this gap, we introduce a novel bi-level reinforcement learning\\napproach for automatically designing recommender mechanisms in Bayesian\\nstochastic games. Our method produces a mechanism represented by a parametric\\nfunction (such as a neural network), and is therefore highly efficient at\\nexecution time. Experimental results on two repeated and two stochastic games\\ndemonstrate that our approach achieves social welfare levels competitive with\\ncooperative multi-agent reinforcement learning baselines, while also providing\\nsignificantly improved incentive properties.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.22979v1.pdf'},\n",
       " {'id': '2312.09950v2',\n",
       "  'title': 'Peer Learning: Learning Complex Policies in Groups from Scratch via\\n  Action Recommendations',\n",
       "  'published': '2023-12-15T17:01:35Z',\n",
       "  'summary': 'Peer learning is a novel high-level reinforcement learning framework for\\nagents learning in groups. While standard reinforcement learning trains an\\nindividual agent in trial-and-error fashion, all on its own, peer learning\\naddresses a related setting in which a group of agents, i.e., peers, learns to\\nmaster a task simultaneously together from scratch. Peers are allowed to\\ncommunicate only about their own states and actions recommended by others:\\n\"What would you do in my situation?\". Our motivation is to study the learning\\nbehavior of these agents. We formalize the teacher selection process in the\\naction advice setting as a multi-armed bandit problem and therefore highlight\\nthe need for exploration. Eventually, we analyze the learning behavior of the\\npeers and observe their ability to rank the agents\\' performance within the\\nstudy group and understand which agents give reliable advice. Further, we\\ncompare peer learning with single agent learning and a state-of-the-art action\\nadvice baseline. We show that peer learning is able to outperform single-agent\\nlearning and the baseline in several challenging discrete and continuous OpenAI\\nGym domains. Doing so, we also show that within such a framework complex\\npolicies from action recommendations beyond discrete action spaces can evolve.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.09950v2.pdf'},\n",
       " {'id': '2503.00566v3',\n",
       "  'title': 'Instructor-Worker Large Language Model System for Policy Recommendation:\\n  a Case Study on Air Quality Analysis of the January 2025 Los Angeles\\n  Wildfires',\n",
       "  'published': '2025-03-01T17:29:26Z',\n",
       "  'summary': \"The Los Angeles wildfires of January 2025 caused more than 250 billion\\ndollars in damage and lasted for nearly an entire month before containment.\\nFollowing our previous work, the Digital Twin Building, we modify and leverage\\nthe multi-agent large language model framework as well as the cloud-mapping\\nintegration to study the air quality during the Los Angeles wildfires. Recent\\nadvances in large language models have allowed for out-of-the-box automated\\nlarge-scale data analysis. We use a multi-agent large language system comprised\\nof an Instructor agent and Worker agents. Upon receiving the users'\\ninstructions, the Instructor agent retrieves the data from the cloud platform\\nand produces instruction prompts to the Worker agents. The Worker agents then\\nanalyze the data and provide summaries. The summaries are finally input back\\ninto the Instructor agent, which then provides the final data analysis. We test\\nthis system's capability for data-based policy recommendation by assessing our\\nInstructor-Worker LLM system's health recommendations based on air quality\\nduring the Los Angeles wildfires.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.00566v3.pdf'},\n",
       " {'id': '2411.12436v1',\n",
       "  'title': 'Coevolution of relationship-driven cooperation under recommendation\\n  protocol on multiplex networks',\n",
       "  'published': '2024-11-19T11:53:26Z',\n",
       "  'summary': \"While traditional game models often simplify interactions among agents as\\nstatic, real-world social relationships are inherently dynamic, influenced by\\nboth immediate payoffs and alternative information. Motivated by this fact, we\\nintroduce a coevolutionary multiplex network model that incorporates the\\nconcepts of a relationship threshold and a recommendation mechanism to explore\\nhow the strength of relationships among agents interacts with their strategy\\nchoices within the framework of weak prisoner's dilemma games. In the\\nrelationship layer, the relationship strength between agents varies based on\\ninteraction outcomes. In return, the strategy choice of agents in the game\\nlayer is influenced by both payoffs and relationship indices, and agents can\\ninteract with distant agents through a recommendation mechanism. Simulation of\\nvarious network topologies reveals that a higher average degree supports\\ncooperation, although increased randomness in interactions may inhibit its\\nformation. Interestingly, a higher threshold value of interaction quality is\\ndetrimental, while the applied recommendation protocol can improve global\\ncooperation. The best results are obtained when the relative weight of payoff\\nis minimal and the individual fitness is dominated by the relationship indices\\ngained from the quality of links to neighbors. As a consequence, the changes in\\nthe distribution of relationship indices are closely correlated with overall\\nlevels of cooperation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.12436v1.pdf'},\n",
       " {'id': '2503.23804v2',\n",
       "  'title': 'DrunkAgent: Stealthy Memory Corruption in LLM-Powered Recommender Agents',\n",
       "  'published': '2025-03-31T07:35:40Z',\n",
       "  'summary': 'Large language model (LLM)-powered agents are increasingly used in\\nrecommender systems (RSs) to achieve personalized behavior modeling, where the\\nmemory mechanism plays a pivotal role in enabling the agents to autonomously\\nexplore, learn and self-evolve from real-world interactions. However, this very\\nmechanism, serving as a contextual repository, inherently exposes an attack\\nsurface for potential adversarial manipulations. Despite its central role, the\\nrobustness of agentic RSs in the face of such threats remains largely\\nunderexplored. Previous works suffer from semantic mismatches or rely on static\\nembeddings or pre-defined prompts, all of which hinder their applicability to\\nsystems with dynamic memory states. This challenge is exacerbated by the\\nblack-box nature of commercial RSs.\\n  To tackle the above problems, in this paper, we present the first systematic\\ninvestigation of memory-based vulnerabilities in LLM-powered recommender\\nagents, revealing their security limitations and guiding efforts to strengthen\\nsystem resilience and trustworthiness. Specifically, we propose a novel\\nblack-box attack framework named DrunkAgent. DrunkAgent crafts semantically\\nmeaningful adversarial textual triggers for target item promotions and\\nintroduces a series of strategies to maximize the trigger effect by corrupting\\nthe memory updates during the interactions. The triggers and strategies are\\noptimized on a surrogate model, enabling DrunkAgent transferable and stealthy.\\nExtensive experiments on real-world datasets across diverse agentic RSs,\\nincluding collaborative filtering, retrieval augmentation and sequential\\nrecommendations, demonstrate the generalizability, transferability and\\nstealthiness of DrunkAgent.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.23804v2.pdf'},\n",
       " {'id': '2507.10911v1',\n",
       "  'title': 'Lessons Learned from Evaluation of LLM based Multi-agents in Safer\\n  Therapy Recommendation',\n",
       "  'published': '2025-07-15T02:01:38Z',\n",
       "  'summary': 'Therapy recommendation for chronic patients with multimorbidity is\\nchallenging due to risks of treatment conflicts. Existing decision support\\nsystems face scalability limitations. Inspired by the way in which general\\npractitioners (GP) manage multimorbidity patients, occasionally convening\\nmultidisciplinary team (MDT) collaboration, this study investigated the\\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\\na MAS framework simulating MDT decision-making by enabling discussion among LLM\\nagents to resolve medical conflicts. The systems were evaluated on therapy\\nplanning tasks for multimorbidity patients using benchmark cases. We compared\\nMAS performance with single-agent approaches and real-world benchmarks. An\\nimportant contribution of our study is the definition of evaluation metrics\\nthat go beyond the technical precision and recall and allow the inspection of\\nclinical goals met and medication burden of the proposed advices to a gold\\nstandard benchmark. Our results show that with current LLMs, a single agent GP\\nperforms as well as MDTs. The best-scoring models provide correct\\nrecommendations that address all clinical goals, yet the advices are\\nincomplete. Some models also present unnecessary medications, resulting in\\nunnecessary conflicts between medication and conditions or drug-drug\\ninteractions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.10911v1.pdf'},\n",
       " {'id': '1301.6728v1',\n",
       "  'title': 'The Decision-Theoretic Interactive Video Advisor',\n",
       "  'published': '2013-01-23T16:00:14Z',\n",
       "  'summary': \"The need to help people choose among large numbers of items and to filter\\nthrough large amounts of information has led to a flood of research in\\nconstruction of personal recommendation agents. One of the central issues in\\nconstructing such agents is the representation and elicitation of user\\npreferences or interests. This topic has long been studied in Decision Theory,\\nbut surprisingly little work in the area of recommender systems has made use of\\nformal decision-theoretic techniques. This paper describes DIVA, a\\ndecision-theoretic agent for recommending movies that contains a number of\\nnovel features. DIVA represents user preferences using pairwise comparisons\\namong items, rather than numeric ratings. It uses a novel similarity measure\\nbased on the concept of the probability of conflict between two orderings of\\nitems. The system has a rich representation of preference, distinguishing\\nbetween a user's general taste in movies and his immediate interests. It takes\\nan incremental approach to preference elicitation in which the user can provide\\nfeedback if not satisfied with the recommendation list. We empirically evaluate\\nthe performance of the system using the EachMovie collaborative filtering\\ndatabase.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1301.6728v1.pdf'},\n",
       " {'id': '1806.03277v1',\n",
       "  'title': 'Conversational Recommender System',\n",
       "  'published': '2018-06-08T17:15:28Z',\n",
       "  'summary': \"A personalized conversational sales agent could have much commercial\\npotential. E-commerce companies such as Amazon, eBay, JD, Alibaba etc. are\\npiloting such kind of agents with their users. However, the research on this\\ntopic is very limited and existing solutions are either based on single round\\nadhoc search engine or traditional multi round dialog system. They usually only\\nutilize user inputs in the current session, ignoring users' long term\\npreferences. On the other hand, it is well known that sales conversion rate can\\nbe greatly improved based on recommender systems, which learn user preferences\\nbased on past purchasing behavior and optimize business oriented metrics such\\nas conversion rate or expected revenue. In this work, we propose to integrate\\nresearch in dialog systems and recommender systems into a novel and unified\\ndeep reinforcement learning framework to build a personalized conversational\\nrecommendation agent that optimizes a per session based utility function.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1806.03277v1.pdf'},\n",
       " {'id': '1907.01101v1',\n",
       "  'title': 'A Simulation Study of Social-Networking-Driven Smart Recommendations for\\n  Internet of Vehicles',\n",
       "  'published': '2019-05-30T06:12:05Z',\n",
       "  'summary': 'Social aspects of connectivity and information dispersion are often ignored\\nwhile weighing the potential of Internet of Things (IoT). In the specialized\\ndomain of Internet of Vehicles (IoV), Social IoV (SIoV) is introduced\\nrealization its importance. Assuming a more commonly acceptable standardization\\nof Big Data generated by IoV, the social dimensions enabling its fruitful usage\\nremains a challenge. In this paper, an agent-based model of information sharing\\nbetween vehicles for context-aware recommendations is presented. The model\\nadheres to social dimensions as that of human society. Some important\\nhypotheses are tested under reasonable connectivity and data constraints. The\\nsimulation results reveal that closure of social ties and its timing impacts\\ndispersion of novel information (necessary for a recommender system)\\nsubstantially. It was also observed that as the network evolves as a result of\\nincremental interactions, recommendations guaranteeing a fair distribution of\\nvehicles across equally good competitors is not possible.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.01101v1.pdf'},\n",
       " {'id': '2209.08228v1',\n",
       "  'title': 'Intrinsically Motivated Reinforcement Learning based Recommendation with\\n  Counterfactual Data Augmentation',\n",
       "  'published': '2022-09-17T03:09:06Z',\n",
       "  'summary': \"Deep reinforcement learning (DRL) has been proven its efficiency in capturing\\nusers' dynamic interests in recent literature. However, training a DRL agent is\\nchallenging, because of the sparse environment in recommender systems (RS), DRL\\nagents could spend times either exploring informative user-item interaction\\ntrajectories or using existing trajectories for policy learning. It is also\\nknown as the exploration and exploitation trade-off which affects the\\nrecommendation performance significantly when the environment is sparse. It is\\nmore challenging to balance the exploration and exploitation in DRL RS where RS\\nagent need to deeply explore the informative trajectories and exploit them\\nefficiently in the context of recommender systems. As a step to address this\\nissue, We design a novel intrinsically ,otivated reinforcement learning method\\nto increase the capability of exploring informative interaction trajectories in\\nthe sparse environment, which are further enriched via a counterfactual\\naugmentation strategy for more efficient exploitation. The extensive\\nexperiments on six offline datasets and three online simulation platforms\\ndemonstrate the superiority of our model to a set of existing state-of-the-art\\nmethods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.08228v1.pdf'},\n",
       " {'id': '2409.07416v2',\n",
       "  'title': 'Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise\\n  Recommendation',\n",
       "  'published': '2024-09-11T17:01:06Z',\n",
       "  'summary': 'Modern listwise recommendation systems need to consider both long-term user\\nperceptions and short-term interest shifts. Reinforcement learning can be\\napplied on recommendation to study such a problem but is also subject to large\\nsearch space, sparse user feedback and long interactive latency. Motivated by\\nrecent progress in hierarchical reinforcement learning, we propose a novel\\nframework called mccHRL to provide different levels of temporal abstraction on\\nlistwise recommendation. Within the hierarchical framework, the high-level\\nagent studies the evolution of user perception, while the low-level agent\\nproduces the item selection policy by modeling the process as a sequential\\ndecision-making problem. We argue that such framework has a well-defined\\ndecomposition of the outra-session context and the intra-session context, which\\nare encoded by the high-level and low-level agents, respectively. To verify\\nthis argument, we implement both a simulator-based environment and an\\nindustrial dataset-based experiment. Results observe significant performance\\nimprovement by our method, compared with several well-known baselines. Data and\\ncodes have been made public.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.07416v2.pdf'},\n",
       " {'id': '2509.09685v1',\n",
       "  'title': 'TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal\\n  Conversational Music Recommendation',\n",
       "  'published': '2025-08-18T05:06:58Z',\n",
       "  'summary': 'We present TalkPlayData 2, a synthetic dataset for multimodal conversational\\nmusic recommendation generated by an agentic data pipeline. In TalkPlayData 2\\npipeline, multiple large language model (LLM) agents are created under various\\nroles with specialized prompts and access to different parts of information,\\nand the chat data is acquired by logging the conversation between the Listener\\nLLM and the Recsys LLM. To cover various conversation scenarios, for each\\nconversation, the Listener LLM is conditioned on a finetuned conversation goal.\\nFinally, all the LLMs are multimodal with audio and images, allowing a\\nsimulation of multimodal recommendation and conversation. In the LLM-as-a-judge\\nand subjective evaluation experiments, TalkPlayData 2 achieved the proposed\\ngoal in various aspects related to training a generative recommendation model\\nfor music. TalkPlayData 2 and its generation code are open-sourced at\\nhttps://talkpl.ai/talkplaydata2.html.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.09685v1.pdf'},\n",
       " {'id': '1301.4417v1',\n",
       "  'title': 'The role of taste affinity in agent-based models for social\\n  recommendation',\n",
       "  'published': '2013-01-18T16:14:09Z',\n",
       "  'summary': \"In the Internet era, online social media emerged as the main tool for sharing\\nopinions and information among individuals. In this work we study an adaptive\\nmodel of a social network where directed links connect users with similar\\ntastes, and over which information propagates through social recommendation.\\nAgent-based simulations of two different artificial settings for modeling user\\ntastes are compared with patterns seen in real data, suggesting that users\\ndiffering in their scope of interests is a more realistic assumption than users\\ndiffering only in their particular interests. We further introduce an extensive\\nset of similarity metrics based on users' past assessments, and evaluate their\\nuse in the given social recommendation model with both artificial simulations\\nand real data. Superior recommendation performance is observed for similarity\\nmetrics that give preference to users with small scope---who thus act as\\nselective filters in social recommendation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1301.4417v1.pdf'},\n",
       " {'id': '2011.02248v1',\n",
       "  'title': 'Generative Inverse Deep Reinforcement Learning for Online Recommendation',\n",
       "  'published': '2020-11-04T12:12:25Z',\n",
       "  'summary': \"Deep reinforcement learning enables an agent to capture user's interest\\nthrough interactions with the environment dynamically. It has attracted great\\ninterest in the recommendation research. Deep reinforcement learning uses a\\nreward function to learn user's interest and to control the learning process.\\nHowever, most reward functions are manually designed; they are either\\nunrealistic or imprecise to reflect the high variety, dimensionality, and\\nnon-linearity properties of the recommendation problem. That makes it difficult\\nfor the agent to learn an optimal policy to generate the most satisfactory\\nrecommendations. To address the above issue, we propose a novel generative\\ninverse reinforcement learning approach, namely InvRec, which extracts the\\nreward function from user's behaviors automatically, for online recommendation.\\nWe conduct experiments on an online platform, VirtualTB, and compare with\\nseveral state-of-the-art methods to demonstrate the feasibility and\\neffectiveness of our proposed approach.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2011.02248v1.pdf'},\n",
       " {'id': '2402.11627v1',\n",
       "  'title': 'Interactive Garment Recommendation with User in the Loop',\n",
       "  'published': '2024-02-18T16:01:28Z',\n",
       "  'summary': 'Recommending fashion items often leverages rich user profiles and makes\\ntargeted suggestions based on past history and previous purchases. In this\\npaper, we work under the assumption that no prior knowledge is given about a\\nuser. We propose to build a user profile on the fly by integrating user\\nreactions as we recommend complementary items to compose an outfit. We present\\na reinforcement learning agent capable of suggesting appropriate garments and\\ningesting user feedback so to improve its recommendations and maximize user\\nsatisfaction. To train such a model, we resort to a proxy model to be able to\\nsimulate having user feedback in the training loop. We experiment on the\\nIQON3000 fashion dataset and we find that a reinforcement learning-based agent\\nbecomes capable of improving its recommendations by taking into account\\npersonal preferences. Furthermore, such task demonstrated to be hard for\\nnon-reinforcement models, that cannot exploit exploration during training.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.11627v1.pdf'},\n",
       " {'id': '2404.04906v1',\n",
       "  'title': 'Balancing Information Perception with Yin-Yang: Agent-Based Information\\n  Neutrality Model for Recommendation Systems',\n",
       "  'published': '2024-04-07T10:16:22Z',\n",
       "  'summary': \"While preference-based recommendation algorithms effectively enhance user\\nengagement by recommending personalized content, they often result in the\\ncreation of ``filter bubbles''. These bubbles restrict the range of information\\nusers interact with, inadvertently reinforcing their existing viewpoints.\\nPrevious research has focused on modifying these underlying algorithms to\\ntackle this issue. Yet, approaches that maintain the integrity of the original\\nalgorithms remain largely unexplored. This paper introduces an Agent-based\\nInformation Neutrality model grounded in the Yin-Yang theory, namely, AbIN.\\nThis innovative approach targets the imbalance in information perception within\\nexisting recommendation systems. It is designed to integrate with these\\npreference-based systems, ensuring the delivery of recommendations with neutral\\ninformation. Our empirical evaluation of this model proved its efficacy,\\nshowcasing its capacity to expand information diversity while respecting user\\npreferences. Consequently, AbIN emerges as an instrumental tool in mitigating\\nthe negative impact of filter bubbles on information consumption.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.04906v1.pdf'},\n",
       " {'id': '2405.01868v1',\n",
       "  'title': 'Incorporating External Knowledge and Goal Guidance for LLM-based\\n  Conversational Recommender Systems',\n",
       "  'published': '2024-05-03T05:42:57Z',\n",
       "  'summary': 'This paper aims to efficiently enable large language models (LLMs) to use\\nexternal knowledge and goal guidance in conversational recommender system (CRS)\\ntasks. Advanced LLMs (e.g., ChatGPT) are limited in domain-specific CRS tasks\\nfor 1) generating grounded responses with recommendation-oriented knowledge, or\\n2) proactively leading the conversations through different dialogue goals. In\\nthis work, we first analyze those limitations through a comprehensive\\nevaluation, showing the necessity of external knowledge and goal guidance which\\ncontribute significantly to the recommendation accuracy and language quality.\\nIn light of this finding, we propose a novel ChatCRS framework to decompose the\\ncomplex CRS task into several sub-tasks through the implementation of 1) a\\nknowledge retrieval agent using a tool-augmented approach to reason over\\nexternal Knowledge Bases and 2) a goal-planning agent for dialogue goal\\nprediction. Experimental results on two multi-goal CRS datasets reveal that\\nChatCRS sets new state-of-the-art benchmarks, improving language quality of\\ninformativeness by 17% and proactivity by 27%, and achieving a tenfold\\nenhancement in recommendation accuracy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.01868v1.pdf'},\n",
       " {'id': '1907.00710v1',\n",
       "  'title': 'Deep Conversational Recommender in Travel',\n",
       "  'published': '2019-06-25T04:39:26Z',\n",
       "  'summary': 'When traveling to a foreign country, we are often in dire need of an\\nintelligent conversational agent to provide instant and informative responses\\nto our various queries. However, to build such a travel agent is non-trivial.\\nFirst of all, travel naturally involves several sub-tasks such as hotel\\nreservation, restaurant recommendation and taxi booking etc, which invokes the\\nneed for global topic control. Secondly, the agent should consider various\\nconstraints like price or distance given by the user to recommend an\\nappropriate venue. In this paper, we present a Deep Conversational Recommender\\n(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)\\nmodels with a neural latent topic component to better guide response generation\\nand make the training easier. To consider the various constraints for venue\\nrecommendation, we leverage a graph convolutional network (GCN) based approach\\nto capture the relationships between different venues and the match between\\nvenue and dialog context. For response generation, we combine the topic-based\\ncomponent with the idea of pointer networks, which allows us to effectively\\nincorporate recommendation results. We perform extensive evaluation on a\\nmulti-turn task-oriented dialog dataset in travel domain and the results show\\nthat our method achieves superior performance as compared to a wide range of\\nbaselines.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.00710v1.pdf'},\n",
       " {'id': '2504.16420v1',\n",
       "  'title': 'A Survey of Foundation Model-Powered Recommender Systems: From\\n  Feature-Based, Generative to Agentic Paradigms',\n",
       "  'published': '2025-04-23T05:02:51Z',\n",
       "  'summary': 'Recommender systems (RS) have become essential in filtering information and\\npersonalizing content for users. RS techniques have traditionally relied on\\nmodeling interactions between users and items as well as the features of\\ncontent using models specific to each task. The emergence of foundation models\\n(FMs), large scale models trained on vast amounts of data such as GPT, LLaMA\\nand CLIP, is reshaping the recommendation paradigm. This survey provides a\\ncomprehensive overview of the Foundation Models for Recommender Systems\\n(FM4RecSys), covering their integration in three paradigms: (1) Feature-Based\\naugmentation of representations, (2) Generative recommendation approaches, and\\n(3) Agentic interactive systems. We first review the data foundations of RS,\\nfrom traditional explicit or implicit feedback to multimodal content sources.\\nWe then introduce FMs and their capabilities for representation learning,\\nnatural language understanding, and multi-modal reasoning in RS contexts. The\\ncore of the survey discusses how FMs enhance RS under different paradigms.\\nAfterward, we examine FM applications in various recommendation tasks. Through\\nan analysis of recent research, we highlight key opportunities that have been\\nrealized as well as challenges encountered. Finally, we outline open research\\ndirections and technical challenges for next-generation FM4RecSys. This survey\\nnot only reviews the state-of-the-art methods but also provides a critical\\nanalysis of the trade-offs among the feature-based, the generative, and the\\nagentic paradigms, outlining key open issues and future research directions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.16420v1.pdf'},\n",
       " {'id': '1507.00819v1',\n",
       "  'title': 'Improving package recommendations through query relaxation',\n",
       "  'published': '2015-07-03T05:33:04Z',\n",
       "  'summary': 'Recommendation systems aim to identify items that are likely to be of\\ninterest to users. In many cases, users are interested in package\\nrecommendations as collections of items. For example, a dietitian may wish to\\nderive a dietary plan as a collection of recipes that is nutritionally\\nbalanced, and a travel agent may want to produce a vacation package as a\\ncoordinated collection of travel and hotel reservations. Recent work has\\nexplored extending recommendation systems to support packages of items. These\\nsystems need to solve complex combinatorial problems, enforcing various\\nproperties and constraints defined on sets of items. Introducing constraints on\\npackages makes recommendation queries harder to evaluate, but also harder to\\nexpress: Queries that are under-specified produce too many answers, whereas\\nqueries that are over-specified frequently miss interesting solutions.\\n  In this paper, we study query relaxation techniques that target package\\nrecommendation systems. Our work offers three key insights: First, even when\\nthe original query result is not empty, relaxing constraints can produce\\npreferable solutions. Second, a solution due to relaxation can only be\\npreferred if it improves some property specified by the query. Third,\\nrelaxation should not treat all constraints as equals: some constraints are\\nmore important to the users than others. Our contributions are threefold: (a)\\nwe define the problem of deriving package recommendations through query\\nrelaxation, (b) we design and experimentally evaluate heuristics that relax\\nquery constraints to derive interesting packages, and (c) we present a crowd\\nstudy that evaluates the sensitivity of real users to different kinds of\\nconstraints and demonstrates that query relaxation is a powerful tool in\\ndiversifying package recommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1507.00819v1.pdf'},\n",
       " {'id': '2006.05779v2',\n",
       "  'title': 'Self-Supervised Reinforcement Learning for Recommender Systems',\n",
       "  'published': '2020-06-10T11:18:57Z',\n",
       "  'summary': 'In session-based or sequential recommendation, it is important to consider a\\nnumber of factors like long-term user engagement, multiple types of user-item\\ninteractions such as clicks, purchases etc. The current state-of-the-art\\nsupervised approaches fail to model them appropriately. Casting sequential\\nrecommendation task as a reinforcement learning (RL) problem is a promising\\ndirection. A major component of RL approaches is to train the agent through\\ninteractions with the environment. However, it is often problematic to train a\\nrecommender in an on-line fashion due to the requirement to expose users to\\nirrelevant recommendations. As a result, learning the policy from logged\\nimplicit feedback is of vital importance, which is challenging due to the pure\\noff-policy setting and lack of negative rewards (feedback). In this paper, we\\npropose self-supervised reinforcement learning for sequential recommendation\\ntasks. Our approach augments standard recommendation models with two output\\nlayers: one for self-supervised learning and the other for RL. The RL part acts\\nas a regularizer to drive the supervised layer focusing on specific\\nrewards(e.g., recommending items which may lead to purchases rather than\\nclicks) while the self-supervised layer with cross-entropy loss provides strong\\ngradient signals for parameter updates. Based on such an approach, we propose\\ntwo frameworks namely Self-Supervised Q-learning(SQN) and Self-Supervised\\nActor-Critic(SAC). We integrate the proposed frameworks with four\\nstate-of-the-art recommendation models. Experimental results on two real-world\\ndatasets demonstrate the effectiveness of our approach.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.05779v2.pdf'},\n",
       " {'id': '2101.03392v1',\n",
       "  'title': 'Generate Natural Language Explanations for Recommendation',\n",
       "  'published': '2021-01-09T17:00:41Z',\n",
       "  'summary': 'Providing personalized explanations for recommendations can help users to\\nunderstand the underlying insight of the recommendation results, which is\\nhelpful to the effectiveness, transparency, persuasiveness and trustworthiness\\nof recommender systems. Current explainable recommendation models mostly\\ngenerate textual explanations based on pre-defined sentence templates. However,\\nthe expressiveness power of template-based explanation sentences are limited to\\nthe pre-defined expressions, and manually defining the expressions require\\nsignificant human efforts. Motivated by this problem, we propose to generate\\nfree-text natural language explanations for personalized recommendation. In\\nparticular, we propose a hierarchical sequence-to-sequence model (HSS) for\\npersonalized explanation generation. Different from conventional sentence\\ngeneration in NLP research, a great challenge of explanation generation in\\ne-commerce recommendation is that not all sentences in user reviews are of\\nexplanation purpose. To solve the problem, we further propose an auto-denoising\\nmechanism based on topical item feature words for sentence generation.\\nExperiments on various e-commerce product domains show that our approach can\\nnot only improve the recommendation accuracy, but also the explanation quality\\nin terms of the offline measures and feature words coverage. This research is\\none of the initial steps to grant intelligent agents with the ability to\\nexplain itself based on natural language sentences.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.03392v1.pdf'},\n",
       " {'id': '2308.16505v3',\n",
       "  'title': 'Recommender AI Agent: Integrating Large Language Models for Interactive\\n  Recommendations',\n",
       "  'published': '2023-08-31T07:36:44Z',\n",
       "  'summary': 'Recommender models excel at providing domain-specific item recommendations by\\nleveraging extensive user behavior data. Despite their ability to act as\\nlightweight domain experts, they struggle to perform versatile tasks such as\\nproviding explanations and engaging in conversations. On the other hand, large\\nlanguage models (LLMs) represent a significant step towards artificial general\\nintelligence, showcasing remarkable capabilities in instruction comprehension,\\ncommonsense reasoning, and human interaction. However, LLMs lack the knowledge\\nof domain-specific item catalogs and behavioral patterns, particularly in areas\\nthat diverge from general world knowledge, such as online e-commerce.\\nFinetuning LLMs for each domain is neither economic nor efficient.\\n  In this paper, we bridge the gap between recommender models and LLMs,\\ncombining their respective strengths to create a versatile and interactive\\nrecommender system. We introduce an efficient framework called\\n\\\\textbf{InteRecAgent}, which employs LLMs as the brain and recommender models\\nas tools. We first outline a minimal set of essential tools required to\\ntransform LLMs into InteRecAgent. We then propose an efficient workflow within\\nInteRecAgent for task execution, incorporating key components such as memory\\ncomponents, dynamic demonstration-augmented task planning, and reflection.\\nInteRecAgent enables traditional recommender systems, such as those ID-based\\nmatrix factorization models, to become interactive systems with a natural\\nlanguage interface through the integration of LLMs. Experimental results on\\nseveral public datasets show that InteRecAgent achieves satisfying performance\\nas a conversational recommender system, outperforming general-purpose LLMs. The\\nsource code of InteRecAgent is released at https://aka.ms/recagent.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.16505v3.pdf'},\n",
       " {'id': '2504.05322v1',\n",
       "  'title': 'Balancing Benefits and Risks: RL Approaches for Addiction-Aware Social\\n  Media Recommenders',\n",
       "  'published': '2025-02-25T09:43:25Z',\n",
       "  'summary': \"Social media platforms provide valuable opportunities for users to gather\\ninformation, interact with friends, and enjoy entertainment. However, their\\naddictive potential poses significant challenges, including overuse and\\nnegative psycho-logical or behavioral impacts [4, 2, 8]. This study explores\\nstrategies to mitigate compulsive social media usage while preserving its\\nbenefits and ensuring economic sustainability, focusing on recommenders that\\npromote balanced usage.\\n  We analyze user behaviors arising from intrinsic diversities and\\nenvironmental interactions, offering insights for next-generation social media\\nrecommenders that prioritize well-being. Specifically, we examine the temporal\\npredictability of overuse and addiction using measures available to\\nrecommenders, aiming to inform mechanisms that prevent addiction while avoiding\\nuser disengagement [7].\\n  Building on RL-based computational frameworks for addiction modelling [6],\\nour study introduces: - A recommender system adapting to user preferences,\\nintroducing non-stationary and non-Markovian dynamics.\\n  - Differentiated state representations for users and recommenders to capture\\nnuanced interactions.\\n  - Distinct usage conditions-light and heavy use-addressing RL's limitations\\nin distinguishing prolonged from healthy engagement.\\n  - Complexity in overuse impacts, highlighting their role in user adaptation\\n[7].\\n  Simulations demonstrate how model-based (MB) and model-free (MF)\\ndecision-making interact with environmental dynamics to influence user behavior\\nand addiction. Results reveal the significant role of recommender systems in\\nshaping addiction tendencies or fostering healthier engagement. These findings\\nsupport ethical, adaptive recommender design, advancing sustainable social\\nmedia ecosystems [9, 1].\\n  Keywords: multi-agent systems, recommender systems, addiction, social media\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.05322v1.pdf'},\n",
       " {'id': '2504.03759v1',\n",
       "  'title': 'Emerging Cyber Attack Risks of Medical AI Agents',\n",
       "  'published': '2025-04-02T08:04:53Z',\n",
       "  'summary': \"Large language models (LLMs)-powered AI agents exhibit a high level of\\nautonomy in addressing medical and healthcare challenges. With the ability to\\naccess various tools, they can operate within an open-ended action space.\\nHowever, with the increase in autonomy and ability, unforeseen risks also\\narise. In this work, we investigated one particular risk, i.e., cyber attack\\nvulnerability of medical AI agents, as agents have access to the Internet\\nthrough web browsing tools. We revealed that through adversarial prompts\\nembedded on webpages, cyberattackers can: i) inject false information into the\\nagent's response; ii) they can force the agent to manipulate recommendation\\n(e.g., healthcare products and services); iii) the attacker can also steal\\nhistorical conversations between the user and agent, resulting in the leak of\\nsensitive/private medical information; iv) furthermore, the targeted agent can\\nalso cause a computer system hijack by returning a malicious URL in its\\nresponse. Different backbone LLMs were examined, and we found such cyber\\nattacks can succeed in agents powered by most mainstream LLMs, with the\\nreasoning models such as DeepSeek-R1 being the most vulnerable.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.03759v1.pdf'},\n",
       " {'id': '2505.19205v2',\n",
       "  'title': 'OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter\\n  Optimization',\n",
       "  'published': '2025-05-25T16:05:41Z',\n",
       "  'summary': \"Hyperparameter optimization (HPO) is a critical yet challenging aspect of\\nmachine learning model development, significantly impacting model performance\\nand generalization. Traditional HPO methods often struggle with high\\ndimensionality, complex interdependencies, and computational expense. This\\npaper introduces OptiMindTune, a novel multi-agent framework designed to\\nintelligently and efficiently optimize hyperparameters. OptiMindTune leverages\\nthe collaborative intelligence of three specialized AI agents -- a Recommender\\nAgent, an Evaluator Agent, and a Decision Agent -- each powered by Google's\\nGemini models. These agents address distinct facets of the HPO problem, from\\nmodel selection and hyperparameter suggestion to robust evaluation and\\nstrategic decision-making. By fostering dynamic interactions and knowledge\\nsharing, OptiMindTune aims to converge to optimal hyperparameter configurations\\nmore rapidly and robustly than existing single-agent or monolithic approaches.\\nOur framework integrates principles from advanced large language models, and\\nadaptive search to achieve scalable and intelligent AutoML. We posit that this\\nmulti-agent paradigm offers a promising avenue for tackling the increasing\\ncomplexity of modern machine learning model tuning.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.19205v2.pdf'},\n",
       " {'id': '2201.13448v4',\n",
       "  'title': 'Warmth and competence in human-agent cooperation',\n",
       "  'published': '2022-01-31T18:57:08Z',\n",
       "  'summary': 'Interaction and cooperation with humans are overarching aspirations of\\nartificial intelligence (AI) research. Recent studies demonstrate that AI\\nagents trained with deep reinforcement learning are capable of collaborating\\nwith humans. These studies primarily evaluate human compatibility through\\n\"objective\" metrics such as task performance, obscuring potential variation in\\nthe levels of trust and subjective preference that different agents garner. To\\nbetter understand the factors shaping subjective preferences in human-agent\\ncooperation, we train deep reinforcement learning agents in Coins, a two-player\\nsocial dilemma. We recruit $N = 501$ participants for a human-agent cooperation\\nstudy and measure their impressions of the agents they encounter. Participants\\'\\nperceptions of warmth and competence predict their stated preferences for\\ndifferent agents, above and beyond objective performance metrics. Drawing\\ninspiration from social science and biology research, we subsequently implement\\na new ``partner choice\\'\\' framework to elicit revealed preferences: after\\nplaying an episode with an agent, participants are asked whether they would\\nlike to play the next episode with the same agent or to play alone. As with\\nstated preferences, social perception better predicts participants\\' revealed\\npreferences than does objective performance. Given these results, we recommend\\nhuman-agent interaction researchers routinely incorporate the measurement of\\nsocial perception and subjective preferences into their studies.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.13448v4.pdf'},\n",
       " {'id': '2312.15536v1',\n",
       "  'title': 'Harnessing Pre-trained Generalist Agents for Software Engineering Tasks',\n",
       "  'published': '2023-12-24T18:39:58Z',\n",
       "  'summary': 'Nowadays, we are witnessing an increasing adoption of Artificial Intelligence\\n(AI) to develop techniques aimed at improving the reliability, effectiveness,\\nand overall quality of software systems. Deep reinforcement learning (DRL) has\\nrecently been successfully used for automation in complex tasks such as game\\ntesting and solving the job-shop scheduling problem. However, these specialized\\nDRL agents, trained from scratch on specific tasks, suffer from a lack of\\ngeneralizability to other tasks and they need substantial time to be developed\\nand re-trained effectively. Recently, DRL researchers have begun to develop\\ngeneralist agents, able to learn a policy from various environments and capable\\nof achieving performances similar to or better than specialist agents in new\\ntasks. In the Natural Language Processing or Computer Vision domain, these\\ngeneralist agents are showing promising adaptation capabilities to\\nnever-before-seen tasks after a light fine-tuning phase and achieving high\\nperformance. This paper investigates the potential of generalist agents for\\nsolving SE tasks. Specifically, we conduct an empirical study aimed at\\nassessing the performance of two generalist agents on two important SE tasks:\\nthe detection of bugs in games (for two games) and the minimization of makespan\\nin a scheduling task, to solve the job-shop scheduling problem (for two\\ninstances). Our results show that the generalist agents outperform the\\nspecialist agents with very little effort for fine-tuning, achieving a 20%\\nreduction of the makespan over specialized agent performance on task-based\\nscheduling. In the context of game testing, some generalist agent\\nconfigurations detect 85% more bugs than the specialist agents. Building on our\\nanalysis, we provide recommendations for researchers and practitioners looking\\nto select generalist agents for SE tasks, to ensure that they perform\\neffectively.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.15536v1.pdf'},\n",
       " {'id': '2507.21206v1',\n",
       "  'title': 'Agentic Web: Weaving the Next Web with AI Agents',\n",
       "  'published': '2025-07-28T17:58:12Z',\n",
       "  'summary': 'The emergence of AI agents powered by large language models (LLMs) marks a\\npivotal shift toward the Agentic Web, a new phase of the internet defined by\\nautonomous, goal-driven interactions. In this paradigm, agents interact\\ndirectly with one another to plan, coordinate, and execute complex tasks on\\nbehalf of users. This transition from human-driven to machine-to-machine\\ninteraction allows intent to be delegated, relieving users from routine digital\\noperations and enabling a more interactive, automated web experience. In this\\npaper, we present a structured framework for understanding and building the\\nAgentic Web. We trace its evolution from the PC and Mobile Web eras and\\nidentify the core technological foundations that support this shift. Central to\\nour framework is a conceptual model consisting of three key dimensions:\\nintelligence, interaction, and economics. These dimensions collectively enable\\nthe capabilities of AI agents, such as retrieval, recommendation, planning, and\\ncollaboration. We analyze the architectural and infrastructural challenges\\ninvolved in creating scalable agentic systems, including communication\\nprotocols, orchestration strategies, and emerging paradigms such as the Agent\\nAttention Economy. We conclude by discussing the potential applications,\\nsocietal risks, and governance issues posed by agentic systems, and outline\\nresearch directions for developing open, secure, and intelligent ecosystems\\nshaped by both human intent and autonomous agent behavior. A continuously\\nupdated collection of relevant studies for agentic web is available at:\\nhttps://github.com/SafeRL-Lab/agentic-web.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.21206v1.pdf'},\n",
       " {'id': '2210.07773v2',\n",
       "  'title': 'Diversified Recommendations for Agents with Adaptive Preferences',\n",
       "  'published': '2022-09-20T16:12:22Z',\n",
       "  'summary': \"When an Agent visits a platform recommending a menu of content to select\\nfrom, their choice of item depends not only on fixed preferences, but also on\\ntheir prior engagements with the platform. The Recommender's primary objective\\nis typically to encourage content consumption which optimizes some reward, such\\nas ad revenue, but they often also aim to ensure that a wide variety of content\\nis consumed by the Agent over time. We formalize this problem as an adversarial\\nbandit task. At each step, the Recommender presents a menu of $k$ (out of $n$)\\nitems to the Agent, who selects one item in the menu according to their unknown\\npreference model, which maps their history of past items to relative selection\\nprobabilities. The Recommender then observes the Agent's chosen item and\\nreceives bandit feedback of the item's reward. In addition to optimizing reward\\nfrom selected items, the Recommender must also ensure that the total\\ndistribution of chosen items has sufficiently high entropy.\\n  We define a class of preference models which are locally learnable, i.e.\\nbehavior over the entire domain can be estimated by only observing behavior in\\na small region; this includes models representable by bounded-degree\\npolynomials as well as functions with a sparse Fourier basis. For this class,\\nwe give an algorithm for the Recommender which obtains $\\\\tilde{O}(T^{3/4})$\\nregret against all item distributions satisfying two conditions: they are\\nsufficiently diversified, and they are instantaneously realizable at any\\nhistory by some distribution over menus. We show that these conditions are\\nclosely connected: all sufficiently high-entropy distributions are\\ninstantaneously realizable at any item history. We also give a set of negative\\nresults justifying our assumptions, in the form of a runtime lower bound for\\nnon-local learning and linear regret lower bounds for alternate benchmarks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.07773v2.pdf'},\n",
       " {'id': '2209.15166v1',\n",
       "  'title': 'Reward Shaping for User Satisfaction in a REINFORCE Recommender',\n",
       "  'published': '2022-09-30T01:29:12Z',\n",
       "  'summary': 'How might we design Reinforcement Learning (RL)-based recommenders that\\nencourage aligning user trajectories with the underlying user satisfaction?\\nThree research questions are key: (1) measuring user satisfaction, (2)\\ncombatting sparsity of satisfaction signals, and (3) adapting the training of\\nthe recommender agent to maximize satisfaction. For measurement, it has been\\nfound that surveys explicitly asking users to rate their experience with\\nconsumed items can provide valuable orthogonal information to the\\nengagement/interaction data, acting as a proxy to the underlying user\\nsatisfaction. For sparsity, i.e, only being able to observe how satisfied users\\nare with a tiny fraction of user-item interactions, imputation models can be\\nuseful in predicting satisfaction level for all items users have consumed. For\\nlearning satisfying recommender policies, we postulate that reward shaping in\\nRL recommender agents is powerful for driving satisfying user experiences.\\nPutting everything together, we propose to jointly learn a policy network and a\\nsatisfaction imputation network: The role of the imputation network is to learn\\nwhich actions are satisfying to the user; while the policy network, built on\\ntop of REINFORCE, decides which items to recommend, with the reward utilizing\\nthe imputed satisfaction. We use both offline analysis and live experiments in\\nan industrial large-scale recommendation platform to demonstrate the promise of\\nour approach for satisfying user experiences.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.15166v1.pdf'},\n",
       " {'id': '2501.09493v3',\n",
       "  'title': 'Evaluating Conversational Recommender Systems via Large Language Models:\\n  A User-Centric Framework',\n",
       "  'published': '2025-01-16T12:06:56Z',\n",
       "  'summary': \"Conversational recommender systems (CRSs) integrate both recommendation and\\ndialogue tasks, making their evaluation uniquely challenging. Existing\\napproaches primarily assess CRS performance by separately evaluating item\\nrecommendation and dialogue management using rule-based metrics. However, these\\nmethods fail to capture the real human experience, and they cannot draw direct\\nconclusions about the system's overall performance. As conversational\\nrecommender systems become increasingly vital in e-commerce, social media, and\\ncustomer support, the ability to evaluate both recommendation accuracy and\\ndialogue management quality using a single metric, thereby authentically\\nreflecting user experience, has become the principal challenge impeding\\nprogress in this field.\\n  In this work, we propose a user-centric evaluation framework based on large\\nlanguage models (LLMs) for CRSs, namely Conversational Recommendation Evaluator\\n(CoRE). CoRE consists of two main components: (1) LLM-As-Evaluator. Firstly, we\\ncomprehensively summarize 12 key factors influencing user experience in CRSs\\nand directly leverage LLM as an evaluator to assign a score to each factor. (2)\\nMulti-Agent Debater. Secondly, we design a multi-agent debate framework with\\nfour distinct roles (common user, domain expert, linguist, and HCI expert) to\\ndiscuss and synthesize the 12 evaluation factors into a unified overall\\nperformance score.\\n  Furthermore, we apply the proposed framework to evaluate four CRSs on two\\nbenchmark datasets. The experimental results show that CoRE aligns well with\\nhuman evaluation in most of the 12 factors and the overall assessment.\\nEspecially, CoRE's overall evaluation scores demonstrate significantly better\\nalignment with human feedback compared to existing rule-based metrics.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.09493v3.pdf'},\n",
       " {'id': '1811.06026v7',\n",
       "  'title': 'Incentivizing Exploration with Selective Data Disclosure',\n",
       "  'published': '2018-11-14T19:29:16Z',\n",
       "  'summary': 'We propose and design recommendation systems that incentivize efficient\\nexploration. Agents arrive sequentially, choose actions and receive rewards,\\ndrawn from fixed but unknown action-specific distributions. The recommendation\\nsystem presents each agent with actions and rewards from a subsequence of past\\nagents, chosen ex ante. Thus, the agents engage in sequential social learning,\\nmoderated by these subsequences. We asymptotically attain optimal regret rate\\nfor exploration, using a flexible frequentist behavioral model and mitigating\\nrationality and commitment assumptions inherent in prior work. We suggest three\\ncomponents of effective recommendation systems: independent focus groups, group\\naggregators, and interlaced information structures.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.06026v7.pdf'},\n",
       " {'id': '2401.04429v2',\n",
       "  'title': 'i-Rebalance: Personalized Vehicle Repositioning for Supply Demand\\n  Balance',\n",
       "  'published': '2024-01-09T08:51:56Z',\n",
       "  'summary': \"Ride-hailing platforms have been facing the challenge of balancing demand and\\nsupply. Existing vehicle reposition techniques often treat drivers as\\nhomogeneous agents and relocate them deterministically, assuming compliance\\nwith the reposition. In this paper, we consider a more realistic and\\ndriver-centric scenario where drivers have unique cruising preferences and can\\ndecide whether to take the recommendation or not on their own. We propose\\ni-Rebalance, a personalized vehicle reposition technique with deep\\nreinforcement learning (DRL). i-Rebalance estimates drivers' decisions on\\naccepting reposition recommendations through an on-field user study involving\\n99 real drivers. To optimize supply-demand balance and enhance preference\\nsatisfaction simultaneously, i-Rebalance has a sequential reposition strategy\\nwith dual DRL agents: Grid Agent to determine the reposition order of idle\\nvehicles, and Vehicle Agent to provide personalized recommendations to each\\nvehicle in the pre-defined order. This sequential learning strategy facilitates\\nmore effective policy training within a smaller action space compared to\\ntraditional joint-action methods. Evaluation of real-world trajectory data\\nshows that i-Rebalance improves driver acceptance rate by 38.07% and total\\ndriver income by 9.97%.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.04429v2.pdf'},\n",
       " {'id': '2107.10093v2',\n",
       "  'title': 'Incentivizing Compliance with Algorithmic Instruments',\n",
       "  'published': '2021-07-21T14:10:08Z',\n",
       "  'summary': \"Randomized experiments can be susceptible to selection bias due to potential\\nnon-compliance by the participants. While much of the existing work has studied\\ncompliance as a static behavior, we propose a game-theoretic model to study\\ncompliance as dynamic behavior that may change over time. In rounds, a social\\nplanner interacts with a sequence of heterogeneous agents who arrive with their\\nunobserved private type that determines both their prior preferences across the\\nactions (e.g., control and treatment) and their baseline rewards without taking\\nany treatment. The planner provides each agent with a randomized recommendation\\nthat may alter their beliefs and their action selection. We develop a novel\\nrecommendation mechanism that views the planner's recommendation as a form of\\ninstrumental variable (IV) that only affects an agents' action selection, but\\nnot the observed rewards. We construct such IVs by carefully mapping the\\nhistory -- the interactions between the planner and the previous agents -- to a\\nrandom recommendation. Even though the initial agents may be completely\\nnon-compliant, our mechanism can incentivize compliance over time, thereby\\nenabling the estimation of the treatment effect of each treatment, and\\nminimizing the cumulative regret of the planner whose goal is to identify the\\noptimal treatment.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2107.10093v2.pdf'},\n",
       " {'id': '2503.02398v2',\n",
       "  'title': 'PersonaX: A Recommendation Agent Oriented User Modeling Framework for\\n  Long Behavior Sequence',\n",
       "  'published': '2025-03-04T08:41:40Z',\n",
       "  'summary': 'User profile embedded in the prompt template of personalized recommendation\\nagents play a crucial role in shaping their decision-making process.\\nHigh-quality user profiles are essential for aligning agent behavior with real\\nuser interests. Typically, these profiles are constructed by leveraging LLMs\\nfor user profile modeling (LLM-UM). However, this process faces several\\nchallenges: (1) LLMs struggle with long user behaviors due to context length\\nlimitations and performance degradation. (2) Existing methods often extract\\nonly partial segments from full historical behavior sequence, inevitably\\ndiscarding diverse user interests embedded in the omitted content, leading to\\nincomplete modeling and suboptimal profiling. (3) User profiling is often\\ntightly coupled with the inference context, requiring online processing, which\\nintroduces significant latency overhead. In this paper, we propose PersonaX, an\\nagent-agnostic LLM-UM framework to address these challenges. It augments\\ndownstream recommendation agents to achieve better recommendation performance\\nand inference efficiency. PersonaX (a) segments complete historical behaviors\\ninto clustered groups, (b) selects multiple sub behavior sequences (SBS) with a\\nbalance of prototypicality and diversity to form a high quality core set, (c)\\nperforms offline multi-persona profiling to capture diverse user interests and\\ngenerate fine grained, cached textual personas, and (d) decouples user\\nprofiling from online inference, enabling profile retrieval instead of real\\ntime generation. Extensive experiments demonstrate its effectiveness: using\\nonly 30 to 50% of behavioral data (sequence length 480), PersonaX enhances\\nAgentCF by 3 to 11% and Agent4Rec by 10 to 50%. As a scalable and\\nmodel-agnostic LLM-UM solution, PersonaX sets a new benchmark in scalable user\\nmodeling.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.02398v2.pdf'},\n",
       " {'id': '2508.18812v1',\n",
       "  'title': 'STARec: An Efficient Agent Framework for Recommender Systems via\\n  Autonomous Deliberate Reasoning',\n",
       "  'published': '2025-08-26T08:47:58Z',\n",
       "  'summary': 'While modern recommender systems are instrumental in navigating information\\nabundance, they remain fundamentally limited by static user modeling and\\nreactive decision-making paradigms. Current large language model (LLM)-based\\nagents inherit these shortcomings through their overreliance on heuristic\\npattern matching, yielding recommendations prone to shallow correlation bias,\\nlimited causal inference, and brittleness in sparse-data scenarios. We\\nintroduce STARec, a slow-thinking augmented agent framework that endows\\nrecommender systems with autonomous deliberative reasoning capabilities. Each\\nuser is modeled as an agent with parallel cognitions: fast response for\\nimmediate interactions and slow reasoning that performs chain-of-thought\\nrationales. To cultivate intrinsic slow thinking, we develop anchored\\nreinforcement training - a two-stage paradigm combining structured knowledge\\ndistillation from advanced reasoning models with preference-aligned reward\\nshaping. This hybrid approach scaffolds agents in acquiring foundational\\ncapabilities (preference summarization, rationale generation) while enabling\\ndynamic policy adaptation through simulated feedback loops. Experiments on\\nMovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves\\nsubstantial performance gains compared with state-of-the-art baselines, despite\\nusing only 0.4% of the full training data.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.18812v1.pdf'},\n",
       " {'id': '2101.10431v5',\n",
       "  'title': 'Optimal Disclosure of Information to a Privately Informed Receiver',\n",
       "  'published': '2021-01-25T21:42:31Z',\n",
       "  'summary': \"We study information design settings where the designer controls information\\nabout a state, and there are multiple agents interacting in a game who are\\nprivately informed about their types. Each agent's utility depends on all\\nagents' types and actions, as well as (linearly) on the state. To optimally\\nscreen the agents, the designer first asks agents to report their types and\\nthen sends a private action recommendation to each agent whose distribution\\ndepends on all reported types and the state. We show that there always exists\\nan optimal mechanism which is laminar partitional. Such a mechanism partitions\\nthe state space for each type profile and recommends the same action profile\\nfor states that belong to the same partition element. Furthermore, the convex\\nhulls of any two partition elements are such that either one contains the other\\nor they have an empty intersection. In the single-agent case, each state is\\neither perfectly revealed or lies in an interval in which the number of\\ndifferent signal realizations is at most the number of different types of the\\nagent plus two. A similar result is established for the multi-agent case.\\n  We also highlight the value of screening: without screening the best\\nachievable payoff could be as low as one over the number of types fraction of\\nthe optimal payoff. Along the way, we shed light on the solutions of\\noptimization problems over distributions subject to a mean-preserving\\ncontraction constraint and additional side constraints, which might be of\\nindependent interest.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.10431v5.pdf'},\n",
       " {'id': '2411.16031v1',\n",
       "  'title': 'Agent-Based Modelling Meets Generative AI in Social Network Simulations',\n",
       "  'published': '2024-11-25T01:18:49Z',\n",
       "  'summary': \"Agent-Based Modelling (ABM) has emerged as an essential tool for simulating\\nsocial networks, encompassing diverse phenomena such as information\\ndissemination, influence dynamics, and community formation. However, manually\\nconfiguring varied agent interactions and information flow dynamics poses\\nchallenges, often resulting in oversimplified models that lack real-world\\ngeneralizability. Integrating modern Large Language Models (LLMs) with ABM\\npresents a promising avenue to address these challenges and enhance simulation\\nfidelity, leveraging LLMs' human-like capabilities in sensing, reasoning, and\\nbehavior. In this paper, we propose a novel framework utilizing LLM-empowered\\nagents to simulate social network users based on their interests and\\npersonality traits. The framework allows for customizable agent interactions\\nresembling various social network platforms, including mechanisms for content\\nresharing and personalized recommendations. We validate our framework using a\\ncomprehensive Twitter dataset from the 2020 US election, demonstrating that\\nLLM-agents accurately replicate real users' behaviors, including linguistic\\npatterns and political inclinations. These agents form homogeneous ideological\\nclusters and retain the main themes of their community. Notably,\\npreference-based recommendations significantly influence agent behavior,\\npromoting increased engagement, network homophily and the formation of echo\\nchambers. Overall, our findings underscore the potential of LLM-agents in\\nadvancing social media simulations and unraveling intricate online dynamics.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.16031v1.pdf'},\n",
       " {'id': '0812.4460v1',\n",
       "  'title': 'Emergence of Spontaneous Order Through Neighborhood Formation in\\n  Peer-to-Peer Recommender Systems',\n",
       "  'published': '2008-12-23T23:26:27Z',\n",
       "  'summary': \"The advent of the Semantic Web necessitates paradigm shifts away from\\ncentralized client/server architectures towards decentralization and\\npeer-to-peer computation, making the existence of central authorities\\nsuperfluous and even impossible. At the same time, recommender systems are\\ngaining considerable impact in e-commerce, providing people with\\nrecommendations that are personalized and tailored to their very needs. These\\nrecommender systems have traditionally been deployed with stark centralized\\nscenarios in mind, operating in closed communities detached from their host\\nnetwork's outer perimeter. We aim at marrying these two worlds, i.e.,\\ndecentralized peer-to-peer computing and recommender systems, in one\\nagent-based framework. Our architecture features an epidemic-style protocol\\nmaintaining neighborhoods of like-minded peers in a robust, selforganizing\\nfashion. In order to demonstrate our architecture's ability to retain\\nscalability, robustness and to allow for convergence towards high-quality\\nrecommendations, we conduct offline experiments on top of the popular MovieLens\\ndataset.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0812.4460v1.pdf'},\n",
       " {'id': '1210.1441v1',\n",
       "  'title': 'Adaptive social recommendation in a multiple category landscape',\n",
       "  'published': '2012-10-04T13:48:41Z',\n",
       "  'summary': \"People in the Internet era have to cope with the information overload,\\nstriving to find what they are interested in, and usually face this situation\\nby following a limited number of sources or friends that best match their\\ninterests. A recent line of research, namely adaptive social recommendation,\\nhas therefore emerged to optimize the information propagation in social\\nnetworks and provide users with personalized recommendations. Validation of\\nthese methods by agent-based simulations often assumes that the tastes of users\\nand can be represented by binary vectors, with entries denoting users'\\npreferences. In this work we introduce a more realistic assumption that users'\\ntastes are modeled by multiple vectors. We show that within this framework the\\nsocial recommendation process has a poor outcome. Accordingly, we design novel\\nmeasures of users' taste similarity that can substantially improve the\\nprecision of the recommender system. Finally, we discuss the issue of enhancing\\nthe recommendations' diversity while preserving their accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1210.1441v1.pdf'},\n",
       " {'id': '2111.01911v1',\n",
       "  'title': 'Parameterized Explanations for Investor / Company Matching',\n",
       "  'published': '2021-10-27T17:41:43Z',\n",
       "  'summary': 'Matching companies and investors is usually considered a highly specialized\\ndecision making process. Building an AI agent that can automate such\\nrecommendation process can significantly help reduce costs, and eliminate human\\nbiases and errors. However, limited sample size of financial data-sets and the\\nneed for not only good recommendations, but also explaining why a particular\\nrecommendation is being made, makes this a challenging problem. In this work we\\npropose a representation learning based recommendation engine that works\\nextremely well with small datasets and demonstrate how it can be coupled with a\\nparameterized explanation generation engine to build an explainable\\nrecommendation system for investor-company matching. We compare the performance\\nof our system with human generated recommendations and demonstrate the ability\\nof our algorithm to perform extremely well on this task. We also highlight how\\nexplainability helps with real-life adoption of our system.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.01911v1.pdf'},\n",
       " {'id': '2412.18416v2',\n",
       "  'title': 'Muse: A Multimodal Conversational Recommendation Dataset with\\n  Scenario-Grounded User Profiles',\n",
       "  'published': '2024-12-24T13:08:34Z',\n",
       "  'summary': \"Current conversational recommendation systems focus predominantly on text.\\nHowever, real-world recommendation settings are generally multimodal, causing a\\nsignificant gap between existing research and practical applications. To\\naddress this issue, we propose Muse, the first multimodal conversational\\nrecommendation dataset. Muse comprises 83,148 utterances from 7,000\\nconversations centered around the Clothing domain. Each conversation contains\\ncomprehensive multimodal interactions, rich elements, and natural dialogues.\\nData in Muse are automatically synthesized by a multi-agent framework powered\\nby multimodal large language models (MLLMs). It innovatively derives user\\nprofiles from real-world scenarios rather than depending on manual design and\\nhistory data for better scalability, and then it fulfills conversation\\nsimulation and optimization. Both human and LLM evaluations demonstrate the\\nhigh quality of conversations in Muse. Additionally, fine-tuning experiments on\\nthree MLLMs demonstrate Muse's learnable patterns for recommendations and\\nresponses, confirming its value for multimodal conversational recommendation.\\nOur dataset and codes are available at\\nhttps://anonymous.4open.science/r/Muse-0086.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.18416v2.pdf'},\n",
       " {'id': '2501.02727v1',\n",
       "  'title': 'Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test\\n  Data',\n",
       "  'published': '2025-01-06T02:50:51Z',\n",
       "  'summary': 'We present HiRMed (Hierarchical RAG-enhanced Medical Test Recommendation), a\\nnovel tree-structured recommendation system that leverages Retrieval-Augmented\\nGeneration (RAG) for intelligent medical test recommendations. Unlike\\ntraditional vector similarity-based approaches, our system performs medical\\nreasoning at each tree node through a specialized RAG process. Starting from\\nthe root node with initial symptoms, the system conducts step-wise medical\\nanalysis to identify potential underlying conditions and their corresponding\\ndiagnostic requirements. At each level, instead of simple matching, our\\nRAG-enhanced nodes analyze retrieved medical knowledge to understand\\nsymptom-disease relationships and determine the most appropriate diagnostic\\npath. The system dynamically adjusts its recommendation strategy based on\\nmedical reasoning results, considering factors such as urgency levels and\\ndiagnostic uncertainty. Experimental results demonstrate that our approach\\nachieves superior performance in terms of coverage rate, accuracy, and miss\\nrate compared to conventional retrieval-based methods. This work represents a\\nsignificant advance in medical test recommendation by introducing medical\\nreasoning capabilities into the traditional tree-based retrieval structure.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.02727v1.pdf'},\n",
       " {'id': '2307.06210v1',\n",
       "  'title': 'Online Information Acquisition: Hiring Multiple Agents',\n",
       "  'published': '2023-07-12T14:56:44Z',\n",
       "  'summary': \"We investigate the mechanism design problem faced by a principal who hires\\n\\\\emph{multiple} agents to gather and report costly information. Then, the\\nprincipal exploits the information to make an informed decision. We model this\\nproblem as a game, where the principal announces a mechanism consisting in\\naction recommendations and a payment function, a.k.a. scoring rule. Then, each\\nagent chooses an effort level and receives partial information about an\\nunderlying state of nature based on the effort. Finally, the agents report the\\ninformation (possibly non-truthfully), the principal takes a decision based on\\nthis information, and the agents are paid according to the scoring rule. While\\nprevious work focuses on single-agent problems, we consider multi-agents\\nsettings. This poses the challenge of coordinating the agents' efforts and\\naggregating correlated information. Indeed, we show that optimal mechanisms\\nmust correlate agents' efforts, which introduces externalities among the\\nagents, and hence complex incentive compatibility constraints and equilibrium\\nselection problems. First, we design a polynomial-time algorithm to find an\\noptimal incentive compatible mechanism. Then, we study an online problem, where\\nthe principal repeatedly interacts with a group of unknown agents. We design a\\nno-regret algorithm that provides $\\\\widetilde{\\\\mathcal{O}}(T^{2/3})$ regret\\nwith respect to an optimal mechanism, matching the state-of-the-art bound for\\nsingle-agent settings.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.06210v1.pdf'},\n",
       " {'id': '2504.19678v1',\n",
       "  'title': 'From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review',\n",
       "  'published': '2025-04-28T11:08:22Z',\n",
       "  'summary': 'Large language models and autonomous AI agents have evolved rapidly,\\nresulting in a diverse array of evaluation benchmarks, frameworks, and\\ncollaboration protocols. However, the landscape remains fragmented and lacks a\\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\\nmodels and agents across multiple domains. In addition, we propose a taxonomy\\nof approximately 60 benchmarks that cover general and academic knowledge\\nreasoning, mathematical problem-solving, code generation and software\\nengineering, factual grounding and retrieval, domain-specific evaluations,\\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\\nthat integrate large language models with modular toolkits to enable autonomous\\ndecision-making and multi-step reasoning. Moreover, we present real-world\\napplications of autonomous AI agents in materials science, biomedical research,\\nacademic ideation, software engineering, synthetic data generation, chemical\\nreasoning, mathematical problem-solving, geographic information systems,\\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\\nwe discuss recommendations for future research, focusing on advanced reasoning\\nstrategies, failure modes in multi-agent LLM systems, automated scientific\\ndiscovery, dynamic tool integration via reinforcement learning, integrated\\nsearch capabilities, and security vulnerabilities in agent protocols.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.19678v1.pdf'},\n",
       " {'id': '1209.1428v1',\n",
       "  'title': 'Challenges and Directions for Engineering Multi-agent Systems',\n",
       "  'published': '2012-09-07T00:27:39Z',\n",
       "  'summary': 'In this talk I review where we stand regarding the engineering of multi-agent\\nsystems. There is both good news and bad news. The good news is that over the\\npast decade we\\'ve made considerable progress on techniques for engineering\\nmulti-agent systems: we have good, usable methodologies, and mature tools.\\nFurthermore, we\\'ve seen a wide range of demonstrated applications, and have\\neven begun to quantify the advantages of agent technology. However, industry\\ninvolvement in AAMAS appears to be declining (as measured by industry\\nsponsorship of the conference), and industry affiliated attendants at AAMAS\\n2012 were few (1-2%). Furthermore, looking at the applications of agents being\\nreported at recent AAMAS, usage of Agent Oriented Software Engineering (AOSE)\\nand of Agent Oriented Programming Languages (AOPLs) is quite limited. This\\nobservation is corroborated by the results of a 2008 survey by Frank and\\nVirginia Dignum. Based on these observations, I make five recommendations: (1)\\nRe-engage with industry; (2) Stop designing AOPLs and AOSE methodologies ...\\nand instead ... (3) Move to the \"macro\" level: develop techniques for designing\\nand implementing interaction, integrate micro (single cognitive agent) and\\nmacro (MAS) design and implementation; (4) Develop techniques for the Assurance\\nof MAS; and (5) Re-engage with the US.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1209.1428v1.pdf'},\n",
       " {'id': '2108.01413v1',\n",
       "  'title': 'IASelect: Finding Best-fit Agent Practices in Industrial CPS Using Graph\\n  Databases',\n",
       "  'published': '2021-08-03T11:10:02Z',\n",
       "  'summary': 'The ongoing fourth Industrial Revolution depends mainly on robust Industrial\\nCyber-Physical Systems (ICPS). ICPS includes computing (software and hardware)\\nabilities to control complex physical processes in distributed industrial\\nenvironments. Industrial agents, originating from the well-established\\nmulti-agent systems field, provide complex and cooperative control mechanisms\\nat the software level, allowing us to develop larger and more feature-rich\\nICPS. The IEEE P2660.1 standardisation project, \"Recommended Practices on\\nIndustrial Agents: Integration of Software Agents and Low Level Automation\\nFunctions\" focuses on identifying Industrial Agent practices that can benefit\\nICPS systems of the future. A key problem within this project is identifying\\nthe best-fit industrial agent practices for a given ICPS. This paper reports on\\nthe design and development of a tool to address this challenge. This tool,\\ncalled IASelect, is built using graph databases and provides the ability to\\nflexibly and visually query a growing repository of industrial agent practices\\nrelevant to ICPS. IASelect includes a front-end that allows industry\\npractitioners to interactively identify best-fit practices without having to\\nwrite manual queries.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2108.01413v1.pdf'},\n",
       " {'id': '2007.01442v4',\n",
       "  'title': 'Multi-Agent Low-Dimensional Linear Bandits',\n",
       "  'published': '2020-07-02T23:54:56Z',\n",
       "  'summary': 'We study a multi-agent stochastic linear bandit with side information,\\nparameterized by an unknown vector $\\\\theta^* \\\\in \\\\mathbb{R}^d$. The side\\ninformation consists of a finite collection of low-dimensional subspaces, one\\nof which contains $\\\\theta^*$. In our setting, agents can collaborate to reduce\\nregret by sending recommendations across a communication graph connecting them.\\nWe present a novel decentralized algorithm, where agents communicate subspace\\nindices with each other and each agent plays a projected variant of LinUCB on\\nthe corresponding (low-dimensional) subspace. By distributing the search for\\nthe optimal subspace across users and learning of the unknown vector by each\\nagent in the corresponding low-dimensional subspace, we show that the per-agent\\nfinite-time regret is much smaller than the case when agents do not\\ncommunicate. We finally complement these results through simulations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.01442v4.pdf'},\n",
       " {'id': '2106.03927v1',\n",
       "  'title': 'Improving Social Welfare While Preserving Autonomy via a Pareto Mediator',\n",
       "  'published': '2021-06-07T19:34:42Z',\n",
       "  'summary': 'Machine learning algorithms often make decisions on behalf of agents with\\nvaried and sometimes conflicting interests. In domains where agents can choose\\nto take their own action or delegate their action to a central mediator, an\\nopen question is how mediators should take actions on behalf of delegating\\nagents. The main existing approach uses delegating agents to punish\\nnon-delegating agents in an attempt to get all agents to delegate, which tends\\nto be costly for all. We introduce a Pareto Mediator which aims to improve\\noutcomes for delegating agents without making any of them worse off. Our\\nexperiments in random normal form games, a restaurant recommendation game, and\\na reinforcement learning sequential social dilemma show that the Pareto\\nMediator greatly increases social welfare. Also, even when the Pareto Mediator\\nis based on an incorrect model of agent utility, performance gracefully\\ndegrades to the pre-intervention level, due to the individual autonomy\\npreserved by the voluntary mediator.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2106.03927v1.pdf'},\n",
       " {'id': '2504.08739v1',\n",
       "  'title': 'Enhancing Product Search Interfaces with Sketch-Guided Diffusion and\\n  Language Agents',\n",
       "  'published': '2025-03-21T05:44:15Z',\n",
       "  'summary': \"The rapid progress in diffusion models, transformers, and language agents has\\nunlocked new possibilities, yet their potential in user interfaces and\\ncommercial applications remains underexplored. We present Sketch-Search Agent,\\na novel framework that transforms the image search experience by integrating a\\nmultimodal language agent with freehand sketches as control signals for\\ndiffusion models. Using the T2I-Adapter, Sketch-Search Agent combines sketches\\nand text prompts to generate high-quality query images, encoded via a CLIP\\nimage encoder for efficient matching against an image corpus. Unlike existing\\nmethods, Sketch-Search Agent requires minimal setup, no additional training,\\nand excels in sketch-based image retrieval and natural language interactions.\\nThe multimodal agent enhances user experience by dynamically retaining\\npreferences, ranking results, and refining queries for personalized\\nrecommendations. This interactive design empowers users to create sketches and\\nreceive tailored product suggestions, showcasing the potential of diffusion\\nmodels in user-centric image retrieval. Experiments confirm Sketch-Search\\nAgent's high accuracy in delivering relevant product search results.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.08739v1.pdf'},\n",
       " {'id': '2508.02421v1',\n",
       "  'title': 'Emergence of Fair Leaders via Mediators in Multi-Agent Reinforcement\\n  Learning',\n",
       "  'published': '2025-08-04T13:42:45Z',\n",
       "  'summary': \"Stackelberg games and their resulting equilibria have received increasing\\nattention in the multi-agent reinforcement learning literature. Each stage of a\\ntraditional Stackelberg game involves a leader(s) acting first, followed by the\\nfollowers. In situations where the roles of leader(s) and followers can be\\ninterchanged, the designated role can have considerable advantages, for\\nexample, in first-mover advantage settings. Then the question arises: Who\\nshould be the leader and when? A bias in the leader selection process can lead\\nto unfair outcomes. This problem is aggravated if the agents are\\nself-interested and care only about their goals and rewards. We formally define\\nthis leader selection problem and show its relation to fairness in agents'\\nreturns. Furthermore, we propose a multi-agent reinforcement learning framework\\nthat maximizes fairness by integrating mediators. Mediators have previously\\nbeen used in the simultaneous action setting with varying levels of control,\\nsuch as directly performing agents' actions or just recommending them. Our\\nframework integrates mediators in the Stackelberg setting with minimal control\\n(leader selection). We show that the presence of mediators leads to\\nself-interested agents taking fair actions, resulting in higher overall\\nfairness in agents' returns.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.02421v1.pdf'},\n",
       " {'id': 'nlin/0609033v2',\n",
       "  'title': 'Fame Emerges as a Result of Small Memory',\n",
       "  'published': '2006-09-12T21:47:21Z',\n",
       "  'summary': \"A dynamic memory model is proposed in which an agent ``learns'' a new agent\\nby means of recommendation. The agents can also ``remember'' and ``forget''.\\nThe memory size is decreased while the population size is kept constant.\\n``Fame'' emerged as a few agents become very well known in expense of the\\nmajority being completely forgotten. The minimum and the maximum of fame change\\nlinearly with the relative memory size. The network properties of the\\nwho-knows-who graph, which represents the state of the system, are\\ninvestigated.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/nlin/0609033v2.pdf'},\n",
       " {'id': '1008.1324v1',\n",
       "  'title': 'Statistical Trading Using Target Oriented Trading Agent',\n",
       "  'published': '2010-08-07T11:29:41Z',\n",
       "  'summary': 'In this article we briefly present our contributions toward Trading Agent\\nCompetition (TAC); an international forum for promotion of research into the\\ntrading agent problems. Moreover, we present some strategies proposed and used\\nin the development of our TAC Agent and resultant brief information after its\\nparticipation in a real time trading environment. In the end we conclude with\\nneeded improvements and future recommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1008.1324v1.pdf'},\n",
       " {'id': '2307.00660v1',\n",
       "  'title': 'Minimum Levels of Interpretability for Artificial Moral Agents',\n",
       "  'published': '2023-07-02T20:27:55Z',\n",
       "  'summary': \"As artificial intelligence (AI) models continue to scale up, they are\\nbecoming more capable and integrated into various forms of decision-making\\nsystems. For models involved in moral decision-making, also known as artificial\\nmoral agents (AMA), interpretability provides a way to trust and understand the\\nagent's internal reasoning mechanisms for effective use and error correction.\\nIn this paper, we provide an overview of this rapidly-evolving sub-field of AI\\ninterpretability, introduce the concept of the Minimum Level of\\nInterpretability (MLI) and recommend an MLI for various types of agents, to aid\\ntheir safe deployment in real-world settings.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.00660v1.pdf'},\n",
       " {'id': '2102.07359v1',\n",
       "  'title': 'Intelligent Electric Vehicle Charging Recommendation Based on\\n  Multi-Agent Reinforcement Learning',\n",
       "  'published': '2021-02-15T06:23:59Z',\n",
       "  'summary': 'Electric Vehicle (EV) has become a preferable choice in the modern\\ntransportation system due to its environmental and energy sustainability.\\nHowever, in many large cities, EV drivers often fail to find the proper spots\\nfor charging, because of the limited charging infrastructures and the\\nspatiotemporally unbalanced charging demands. Indeed, the recent emergence of\\ndeep reinforcement learning provides great potential to improve the charging\\nexperience from various aspects over a long-term horizon. In this paper, we\\npropose a framework, named Multi-Agent Spatio-Temporal Reinforcement Learning\\n(Master), for intelligently recommending public accessible charging stations by\\njointly considering various long-term spatiotemporal factors. Specifically, by\\nregarding each charging station as an individual agent, we formulate this\\nproblem as a multi-objective multi-agent reinforcement learning task. We first\\ndevelop a multi-agent actor-critic framework with the centralized attentive\\ncritic to coordinate the recommendation between geo-distributed agents.\\nMoreover, to quantify the influence of future potential charging competition,\\nwe introduce a delayed access strategy to exploit the knowledge of future\\ncharging competition during training. After that, to effectively optimize\\nmultiple learning objectives, we extend the centralized attentive critic to\\nmulti-critics and develop a dynamic gradient re-weighting strategy to\\nadaptively guide the optimization direction. Finally, extensive experiments on\\ntwo real-world datasets demonstrate that Master achieves the best comprehensive\\nperformance compared with nine baseline approaches.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.07359v1.pdf'},\n",
       " {'id': '2302.06014v2',\n",
       "  'title': 'Online Recommendations for Agents with Discounted Adaptive Preferences',\n",
       "  'published': '2023-02-12T22:04:27Z',\n",
       "  'summary': 'We consider a bandit recommendations problem in which an agent\\'s preferences\\n(representing selection probabilities over recommended items) evolve as a\\nfunction of past selections, according to an unknown $\\\\textit{preference\\nmodel}$. In each round, we show a menu of $k$ items (out of $n$ total) to the\\nagent, who then chooses a single item, and we aim to minimize regret with\\nrespect to some $\\\\textit{target set}$ (a subset of the item simplex) for\\nadversarial losses over the agent\\'s choices. Extending the setting from Agarwal\\nand Brown (2022), where uniform-memory agents were considered, here we allow\\nfor non-uniform memory in which a discount factor is applied to the agent\\'s\\nmemory vector at each subsequent round. In the \"long-term memory\" regime (when\\nthe effective memory horizon scales with $T$ sublinearly), we show that\\nefficient sublinear regret is obtainable with respect to the set of\\n$\\\\textit{everywhere instantaneously realizable distributions}$ (the \"EIRD set\",\\nas formulated in prior work) for any $\\\\textit{smooth}$ preference model.\\nFurther, for preferences which are bounded above and below by linear functions\\nof memory weight (we call these \"scale-bounded\" preferences) we give an\\nalgorithm which obtains efficient sublinear regret with respect to nearly the\\n$\\\\textit{entire}$ item simplex. We show an NP-hardness result for expanding to\\ntargets beyond EIRD in general. In the \"short-term memory\" regime (when the\\nmemory horizon is constant), we show that scale-bounded preferences again\\nenable efficient sublinear regret for nearly the entire simplex even without\\nsmoothness if losses do not change too frequently, yet we show an\\ninformation-theoretic barrier for competing against the EIRD set under\\narbitrary smooth preference models even when losses are constant.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.06014v2.pdf'},\n",
       " {'id': '2310.16566v1',\n",
       "  'title': 'Model-enhanced Contrastive Reinforcement Learning for Sequential\\n  Recommendation',\n",
       "  'published': '2023-10-25T11:43:29Z',\n",
       "  'summary': 'Reinforcement learning (RL) has been widely applied in recommendation systems\\ndue to its potential in optimizing the long-term engagement of users. From the\\nperspective of RL, recommendation can be formulated as a Markov decision\\nprocess (MDP), where recommendation system (agent) can interact with users\\n(environment) and acquire feedback (reward signals).However, it is impractical\\nto conduct online interactions with the concern on user experience and\\nimplementation complexity, and we can only train RL recommenders with offline\\ndatasets containing limited reward signals and state transitions. Therefore,\\nthe data sparsity issue of reward signals and state transitions is very severe,\\nwhile it has long been overlooked by existing RL recommenders.Worse still, RL\\nmethods learn through the trial-and-error mode, but negative feedback cannot be\\nobtained in implicit feedback recommendation tasks, which aggravates the\\noverestimation problem of offline RL recommender. To address these challenges,\\nwe propose a novel RL recommender named model-enhanced contrastive\\nreinforcement learning (MCRL). On the one hand, we learn a value function to\\nestimate the long-term engagement of users, together with a conservative value\\nlearning mechanism to alleviate the overestimation problem.On the other hand,\\nwe construct some positive and negative state-action pairs to model the reward\\nfunction and state transition function with contrastive learning to exploit the\\ninternal structure information of MDP. Experiments demonstrate that the\\nproposed method significantly outperforms existing offline RL and\\nself-supervised RL methods with different representative backbone networks on\\ntwo real-world datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.16566v1.pdf'},\n",
       " {'id': '2508.13209v2',\n",
       "  'title': 'Research on Conversational Recommender System Considering Consumer Types',\n",
       "  'published': '2025-08-16T15:15:52Z',\n",
       "  'summary': \"Conversational Recommender Systems (CRS) provide personalized services\\nthrough multi-turn interactions, yet most existing methods overlook users'\\nheterogeneous decision-making styles and knowledge levels, which constrains\\nboth accuracy and efficiency. To address this gap, we propose CT-CRS (Consumer\\nType-Enhanced Conversational Recommender System), a framework that integrates\\nconsumer type modeling into dialogue recommendation. Based on consumer type\\ntheory, we define four user categories--dependent, efficient, cautious, and\\nexpert--derived from two dimensions: decision-making style (maximizers vs.\\nsatisficers) and knowledge level (high vs. low). CT-CRS employs interaction\\nhistories and fine-tunes the large language model to automatically infer user\\ntypes in real time, avoiding reliance on static questionnaires. We incorporate\\nuser types into state representation and design a type-adaptive policy that\\ndynamically adjusts recommendation granularity, diversity, and attribute query\\ncomplexity. To further optimize the dialogue policy, we adopt Inverse\\nReinforcement Learning (IRL), enabling the agent to approximate expert-like\\nstrategies conditioned on consumer type. Experiments on LastFM, Amazon-Book,\\nand Yelp show that CTCRS improves recommendation success rate and reduces\\ninteraction turns compared to strong baselines. Ablation studies confirm that\\nboth consumer type modeling and IRL contribute significantly to performance\\ngains. These results demonstrate that CT-CRS offers a scalable and\\ninterpretable solution for enhancing CRS personalization through the\\nintegration of psychological modeling and advanced policy optimization.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.13209v2.pdf'},\n",
       " {'id': '2408.16032v1',\n",
       "  'title': 'An Extremely Data-efficient and Generative LLM-based Reinforcement\\n  Learning Agent for Recommenders',\n",
       "  'published': '2024-08-28T10:31:50Z',\n",
       "  'summary': 'Recent advancements in large language models (LLMs) have enabled\\nunderstanding webpage contexts, product details, and human instructions.\\nUtilizing LLMs as the foundational architecture for either reward models or\\npolicies in reinforcement learning has gained popularity -- a notable\\nachievement is the success of InstructGPT. RL algorithms have been instrumental\\nin maximizing long-term customer satisfaction and avoiding short-term, myopic\\ngoals in industrial recommender systems, which often rely on deep learning\\nmodels to predict immediate clicks or purchases.\\n  In this project, several RL methods are implemented and evaluated using the\\nWebShop benchmark environment, data, simulator, and pre-trained model\\ncheckpoints. The goal is to train an RL agent to maximize the purchase reward\\ngiven a detailed human instruction describing a desired product. The RL agents\\nare developed by fine-tuning a pre-trained BERT model with various objectives,\\nlearning from preferences without a reward model, and employing contemporary\\ntraining techniques such as Proximal Policy Optimization (PPO) as used in\\nInstructGPT, and Direct Preference Optimization (DPO). This report also\\nevaluates the RL agents trained using generative trajectories. Evaluations were\\nconducted using Thompson sampling in the WebShop simulator environment.\\n  The simulated online experiments demonstrate that agents trained on generated\\ntrajectories exhibited comparable task performance to those trained using human\\ntrajectories. This has demonstrated an example of an extremely low-cost\\ndata-efficient way of training reinforcement learning agents. Also, with\\nlimited training time (<2hours), without utilizing any images, a DPO agent\\nachieved a 19% success rate after approximately 3000 steps or 30 minutes of\\ntraining on T4 GPUs, compared to a PPO agent, which reached a 15% success rate.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.16032v1.pdf'},\n",
       " {'id': '2412.02057v2',\n",
       "  'title': 'Comparative Analysis of Multi-Agent Reinforcement Learning Policies for\\n  Crop Planning Decision Support',\n",
       "  'published': '2024-12-03T00:30:19Z',\n",
       "  'summary': \"In India, the majority of farmers are classified as small or marginal, making\\ntheir livelihoods particularly vulnerable to economic losses due to market\\nsaturation and climate risks. Effective crop planning can significantly impact\\ntheir expected income, yet existing decision support systems (DSS) often\\nprovide generic recommendations that fail to account for real-time market\\ndynamics and the interactions among multiple farmers. In this paper, we\\nevaluate the viability of three multi-agent reinforcement learning (MARL)\\napproaches for optimizing total farmer income and promoting fairness in crop\\nplanning: Independent Q-Learning (IQL), where each farmer acts independently\\nwithout coordination, Agent-by-Agent (ABA), which sequentially optimizes each\\nfarmer's policy in relation to the others, and the Multi-agent Rollout Policy,\\nwhich jointly optimizes all farmers' actions for global reward maximization.\\nOur results demonstrate that while IQL offers computational efficiency with\\nlinear runtime, it struggles with coordination among agents, leading to lower\\ntotal rewards and an unequal distribution of income. Conversely, the\\nMulti-agent Rollout policy achieves the highest total rewards and promotes\\nequitable income distribution among farmers but requires significantly more\\ncomputational resources, making it less practical for large numbers of agents.\\nABA strikes a balance between runtime efficiency and reward optimization,\\noffering reasonable total rewards with acceptable fairness and scalability.\\nThese findings highlight the importance of selecting appropriate MARL\\napproaches in DSS to provide personalized and equitable crop planning\\nrecommendations, advancing the development of more adaptive and farmer-centric\\nagricultural decision-making systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.02057v2.pdf'},\n",
       " {'id': '2106.08298v1',\n",
       "  'title': 'StockBabble: A Conversational Financial Agent to support Stock Market\\n  Investors',\n",
       "  'published': '2021-06-15T17:19:30Z',\n",
       "  'summary': \"We introduce StockBabble, a conversational agent designed to support\\nunderstanding and engagement with the stock market. StockBabble's value and\\nnovelty is in its ability to empower retail investors -- many of which may be\\nnew to investing -- and supplement their informational needs using a\\nuser-friendly agent. Users have the ability to query information on companies\\nto retrieve a general and financial overview of a stock, including accessing\\nthe latest news and trading recommendations. They can also request charts which\\ncontain live prices and technical investment indicators, and add shares to a\\npersonal portfolio to allow performance monitoring over time. To evaluate our\\nagent's potential, we conducted a user study with 15 participants. In total,\\n73% (11/15) of respondents said that they felt more confident in investing\\nafter using StockBabble, and all 15 would consider recommending it to others.\\nThese results are encouraging and suggest a wider appeal for such agents.\\nMoreover, we believe this research can help to inform the design and\\ndevelopment of future intelligent, financial personal assistants.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2106.08298v1.pdf'},\n",
       " {'id': '2207.11415v1',\n",
       "  'title': 'Convergence in a Repeated Non-atomic Routing Game with Partial Signaling',\n",
       "  'published': '2022-07-23T04:41:27Z',\n",
       "  'summary': \"We study the following repeated non-atomic routing game. In every round,\\nnature chooses a state in an i.i.d. manner according to a publicly known\\ndistribution, which influences link latency functions. The system planner makes\\nprivate route recommendations to participating agents, which constitute a fixed\\nfraction, according to a publicly known signaling strategy. The participating\\nagents choose between obeying or not obeying the recommendation according to\\ncumulative regret of the participating agent population in the previous round.\\nThe non-participating agents choose route according to myopic best response to\\na calibrated forecast of the routing decisions of the participating agents. We\\nshow that, for parallel networks, if the planner's signal strategy satisfies\\nthe obedience condition, then, almost surely, the link flows are asymptotically\\nconsistent with the Bayes correlated equilibrium induced by the signaling\\nstrategy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.11415v1.pdf'},\n",
       " {'id': '2503.21760v2',\n",
       "  'title': 'MemInsight: Autonomous Memory Augmentation for LLM Agents',\n",
       "  'published': '2025-03-27T17:57:28Z',\n",
       "  'summary': 'Large language model (LLM) agents have evolved to intelligently process\\ninformation, make decisions, and interact with users or tools. A key capability\\nis the integration of long-term memory capabilities, enabling these agents to\\ndraw upon historical interactions and knowledge. However, the growing memory\\nsize and need for semantic structuring pose significant challenges. In this\\nwork, we propose an autonomous memory augmentation approach, MemInsight, to\\nenhance semantic data representation and retrieval mechanisms. By leveraging\\nautonomous augmentation to historical interactions, LLM agents are shown to\\ndeliver more accurate and contextualized responses. We empirically validate the\\nefficacy of our proposed approach in three task scenarios; conversational\\nrecommendation, question answering and event summarization. On the LLM-REDIAL\\ndataset, MemInsight boosts persuasiveness of recommendations by up to 14%.\\nMoreover, it outperforms a RAG baseline by 34% in recall for LoCoMo retrieval.\\nOur empirical results show the potential of MemInsight to enhance the\\ncontextual performance of LLM agents across multiple tasks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.21760v2.pdf'},\n",
       " {'id': '2001.07853v1',\n",
       "  'title': 'Incentivising Exploration and Recommendations for Contextual Bandits\\n  with Payments',\n",
       "  'published': '2020-01-22T02:26:22Z',\n",
       "  'summary': 'We propose a contextual bandit based model to capture the learning and social\\nwelfare goals of a web platform in the presence of myopic users. By using\\npayments to incentivize these agents to explore different\\nitems/recommendations, we show how the platform can learn the inherent\\nattributes of items and achieve a sublinear regret while maximizing cumulative\\nsocial welfare. We also calculate theoretical bounds on the cumulative costs of\\nincentivization to the platform. Unlike previous works in this domain, we\\nconsider contexts to be completely adversarial, and the behavior of the\\nadversary is unknown to the platform. Our approach can improve various\\nengagement metrics of users on e-commerce stores, recommendation engines and\\nmatching platforms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2001.07853v1.pdf'},\n",
       " {'id': '2506.06334v1',\n",
       "  'title': 'Preference-based learning for news headline recommendation',\n",
       "  'published': '2025-05-31T12:57:56Z',\n",
       "  'summary': 'This study explores strategies for optimizing news headline recommendations\\nthrough preference-based learning. Using real-world data of user interactions\\nwith French-language online news posts, we learn a headline recommender agent\\nunder a contextual bandit setting. This allows us to explore the impact of\\ntranslation on engagement predictions, as well as the benefits of different\\ninteractive strategies on user engagement during data collection. Our results\\nshow that explicit exploration may not be required in the presence of noisy\\ncontexts, opening the door to simpler but efficient strategies in practice.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.06334v1.pdf'},\n",
       " {'id': '1703.10672v1',\n",
       "  'title': 'Learning and Trust in Auction Markets',\n",
       "  'published': '2017-03-30T20:57:39Z',\n",
       "  'summary': \"In this paper, we study behavior of bidders in an experimental launch of a\\nnew advertising auction platform by Zillow, as Zillow switched from negotiated\\ncontracts to using auctions in several geographically isolated markets. A\\nunique feature of this experiment is that the bidders in this market are real\\nestate agents that bid on their own behalf, not using third-party\\nintermediaries. To help bidders, Zillow also provided a recommendation tool\\nthat suggested a bid for each bidder.\\n  Our main focus in this paper is on the decisions of bidders whether or not to\\nadopt the platform-provided bid recommendation. We observe that a significant\\nproportion of bidders do not use the recommended bid. Using the bid history of\\nthe agents we infer their value, and compare the agents' regret with their\\nactual bidding history with results they would have obtained following the\\nrecommendation. We find that for half of the agents not following the\\nrecommendation, the increased effort of experimenting with alternate bids\\nresults in increased regret, i.e., they get decreased net value out of the\\nsystem. The proportion of agents not following the recommendation slowly\\ndeclines as markets mature, but it remains large in most markets that we\\nobserve. We argue that the main reason for this phenomenon is the lack of trust\\nin the platform-provided tool.\\n  Our work provides an empirical insight into possible design choices for\\nauction-based online advertising platforms. While search advertising platforms\\n(such as Google or Bing) allow bidders to submit bids on their own, many\\ndisplay advertising platforms (such as Facebook) optimize bids on bidders'\\nbehalf and eliminate the need for bids. Our empirical analysis shows that the\\nlatter approach is preferred for markets where bidders are individuals, who\\ndon't have access to third party tools, and who may question the fairness of\\nplatform-provided suggestions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1703.10672v1.pdf'},\n",
       " {'id': '1807.01732v1',\n",
       "  'title': 'Recommendation Systems and Self Motivated Users',\n",
       "  'published': '2018-07-04T18:23:56Z',\n",
       "  'summary': \"Modern recommendation systems rely on the wisdom of the crowd to learn the\\noptimal course of action. This induces an inherent mis-alignment of incentives\\nbetween the system's objective to learn (explore) and the individual users'\\nobjective to take the contemporaneous optimal action (exploit). The design of\\nsuch systems must account for this and also for additional information\\navailable to the users. A prominent, yet simple, example is when agents arrive\\nsequentially and each agent observes the action and reward of his predecessor.\\nWe provide an incentive compatible and asymptotically optimal mechanism for\\nthat setting. The complexity of the mechanism suggests that the design of such\\nsystems for general settings is a challenging task.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.01732v1.pdf'},\n",
       " {'id': '2402.13338v1',\n",
       "  'title': 'Incentivized Exploration via Filtered Posterior Sampling',\n",
       "  'published': '2024-02-20T19:30:55Z',\n",
       "  'summary': 'We study \"incentivized exploration\" (IE) in social learning problems where\\nthe principal (a recommendation algorithm) can leverage information asymmetry\\nto incentivize sequentially-arriving agents to take exploratory actions. We\\nidentify posterior sampling, an algorithmic approach that is well known in the\\nmulti-armed bandits literature, as a general-purpose solution for IE. In\\nparticular, we expand the existing scope of IE in several practically-relevant\\ndimensions, from private agent types to informative recommendations to\\ncorrelated Bayesian priors. We obtain a general analysis of posterior sampling\\nin IE which allows us to subsume these extended settings as corollaries, while\\nalso recovering existing results as special cases.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.13338v1.pdf'},\n",
       " {'id': '1602.07570v4',\n",
       "  'title': 'Bayesian Exploration: Incentivizing Exploration in Bayesian Games',\n",
       "  'published': '2016-02-24T15:57:28Z',\n",
       "  'summary': \"We consider a ubiquitous scenario in the Internet economy when individual\\ndecision-makers (henceforth, agents) both produce and consume information as\\nthey make strategic choices in an uncertain environment. This creates a\\nthree-way tradeoff between exploration (trying out insufficiently explored\\nalternatives to help others in the future), exploitation (making optimal\\ndecisions given the information discovered by other agents), and incentives of\\nthe agents (who are myopically interested in exploitation, while preferring the\\nothers to explore). We posit a principal who controls the flow of information\\nfrom agents that came before, and strives to coordinate the agents towards a\\nsocially optimal balance between exploration and exploitation, not using any\\nmonetary transfers. The goal is to design a recommendation policy for the\\nprincipal which respects agents' incentives and minimizes a suitable notion of\\nregret.\\n  We extend prior work in this direction to allow the agents to interact with\\none another in a shared environment: at each time step, multiple agents arrive\\nto play a Bayesian game, receive recommendations, choose their actions, receive\\ntheir payoffs, and then leave the game forever. The agents now face two sources\\nof uncertainty: the actions of the other agents and the parameters of the\\nuncertain game environment.\\n  Our main contribution is to show that the principal can achieve constant\\nregret when the utilities are deterministic (where the constant depends on the\\nprior distribution, but not on the time horizon), and logarithmic regret when\\nthe utilities are stochastic. As a key technical tool, we introduce the concept\\nof explorable actions, the actions which some incentive-compatible policy can\\nrecommend with non-zero probability. We show how the principal can identify\\n(and explore) all explorable actions, and use the revealed information to\\nperform optimally.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1602.07570v4.pdf'},\n",
       " {'id': '2310.07320v2',\n",
       "  'title': 'Byzantine-Resilient Decentralized Multi-Armed Bandits',\n",
       "  'published': '2023-10-11T09:09:50Z',\n",
       "  'summary': \"In decentralized cooperative multi-armed bandits (MAB), each agent observes a\\ndistinct stream of rewards, and seeks to exchange information with others to\\nselect a sequence of arms so as to minimize its regret. Agents in the\\ncooperative setting can outperform a single agent running a MAB method such as\\nUpper-Confidence Bound (UCB) independently. In this work, we study how to\\nrecover such salient behavior when an unknown fraction of the agents can be\\nByzantine, that is, communicate arbitrarily wrong information in the form of\\nreward mean-estimates or confidence sets. This framework can be used to model\\nattackers in computer networks, instigators of offensive content into\\nrecommender systems, or manipulators of financial markets. Our key contribution\\nis the development of a fully decentralized resilient upper confidence bound\\n(UCB) algorithm that fuses an information mixing step among agents with a\\ntruncation of inconsistent and extreme values. This truncation step enables us\\nto establish that the performance of each normal agent is no worse than the\\nclassic single-agent UCB1 algorithm in terms of regret, and more importantly,\\nthe cumulative regret of all normal agents is strictly better than the\\nnon-cooperative case, provided that each agent has at least 3f+1 neighbors\\nwhere f is the maximum possible Byzantine agents in each agent's neighborhood.\\nExtensions to time-varying neighbor graphs, and minimax lower bounds are\\nfurther established on the achievable regret. Experiments corroborate the\\nmerits of this framework in practice.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.07320v2.pdf'},\n",
       " {'id': '2210.10638v4',\n",
       "  'title': 'Digital Human Interactive Recommendation Decision-Making Based on\\n  Reinforcement Learning',\n",
       "  'published': '2022-10-06T16:01:26Z',\n",
       "  'summary': 'Digital human recommendation system has been developed to help customers find\\ntheir favorite products and is playing an active role in various recommendation\\ncontexts. How to timely catch and learn the dynamics of the preferences of the\\ncustomers, while meeting their exact requirements, becomes crucial in the\\ndigital human recommendation domain. We design a novel practical digital human\\ninteractive recommendation agent framework based on Reinforcement Learning(RL)\\nto improve the efficiency of the interactive recommendation decision-making by\\nleveraging both the digital human features and the superior flexibility of RL.\\nOur proposed framework learns through real-time interactions between the\\ndigital human and customers dynamically through the state-of-art RL algorithms,\\ncombined with multimodal embedding and graph embedding, to improve the accuracy\\nof personalization and thus enable the digital human agent to timely catch the\\nattention of the customer. Experiments on real business data demonstrate that\\nour framework can provide better personalized customer engagement and better\\ncustomer experiences.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.10638v4.pdf'},\n",
       " {'id': '2507.17080v1',\n",
       "  'title': 'VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and\\n  LLM-Augmented CLIP Embeddings',\n",
       "  'published': '2025-07-22T23:45:43Z',\n",
       "  'summary': 'Multimodal learning plays a critical role in e-commerce recommendation\\nplatforms today, enabling accurate recommendations and product understanding.\\nHowever, existing vision-language models, such as CLIP, face key challenges in\\ne-commerce recommendation systems: 1) Weak object-level alignment, where global\\nimage embeddings fail to capture fine-grained product attributes, leading to\\nsuboptimal retrieval performance; 2) Ambiguous textual representations, where\\nproduct descriptions often lack contextual clarity, affecting cross-modal\\nmatching; and 3) Domain mismatch, as generic vision-language models may not\\ngeneralize well to e-commerce-specific data. To address these limitations, we\\npropose a framework, VL-CLIP, that enhances CLIP embeddings by integrating\\nVisual Grounding for fine-grained visual understanding and an LLM-based agent\\nfor generating enriched text embeddings. Visual Grounding refines image\\nrepresentations by localizing key products, while the LLM agent enhances\\ntextual features by disambiguating product descriptions. Our approach\\nsignificantly improves retrieval accuracy, multimodal retrieval effectiveness,\\nand recommendation quality across tens of millions of items on one of the\\nlargest e-commerce platforms in the U.S., increasing CTR by 18.6%, ATC by\\n15.5%, and GMV by 4.0%. Additional experimental results show that our framework\\noutperforms vision-language models, including CLIP, FashionCLIP, and GCL, in\\nboth precision and semantic alignment, demonstrating the potential of combining\\nobject-aware visual grounding and LLM-enhanced text representation for robust\\nmultimodal recommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.17080v1.pdf'},\n",
       " {'id': '0902.1475v2',\n",
       "  'title': 'Personalised and Dynamic Trust in Social Networks',\n",
       "  'published': '2009-02-09T16:53:01Z',\n",
       "  'summary': 'We propose a novel trust metric for social networks which is suitable for\\napplication in recommender systems. It is personalised and dynamic and allows\\nto compute the indirect trust between two agents which are not neighbours based\\non the direct trust between agents that are neighbours. In analogy to some\\npersonalised versions of PageRank, this metric makes use of the concept of\\nfeedback centrality and overcomes some of the limitations of other trust\\nmetrics.In particular, it does not neglect cycles and other patterns\\ncharacterising social networks, as some other algorithms do. In order to apply\\nthe metric to recommender systems, we propose a way to make trust dynamic over\\ntime. We show by means of analytical approximations and computer simulations\\nthat the metric has the desired properties. Finally, we carry out an empirical\\nvalidation on a dataset crawled from an Internet community and compare the\\nperformance of a recommender system using our metric to one using collaborative\\nfiltering.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0902.1475v2.pdf'},\n",
       " {'id': '2205.02704v1',\n",
       "  'title': 'Utility-Based Context-Aware Multi-Agent Recommendation System for Energy\\n  Efficiency in Residential Buildings',\n",
       "  'published': '2022-05-05T15:22:56Z',\n",
       "  'summary': \"A significant part of CO2 emissions is due to high electricity consumption in\\nresidential buildings. Using load shifting can help to improve the households'\\nenergy efficiency. To nudge changes in energy consumption behavior, simple but\\npowerful architectures are vital. This paper presents a novel algorithm of a\\nrecommendation system generating device usage recommendations and suggests a\\nframework for evaluating its performance by analyzing potential energy cost\\nsavings. As a utility-based recommender system, it models user preferences\\ndepending on habitual device usage patterns, user availability, and device\\nusage costs. As a context-aware system, it requires an external hourly\\nelectricity price signal and appliance-level energy consumption data. Due to a\\nmulti-agent architecture, it provides flexibility and allows for adjustments\\nand further enhancements. Empirical results show that the system can provide\\nenergy cost savings of 18% and more for most studied households.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.02704v1.pdf'},\n",
       " {'id': '2008.00104v2',\n",
       "  'title': 'Optimizing Long-term Social Welfare in Recommender Systems: A\\n  Constrained Matching Approach',\n",
       "  'published': '2020-07-31T22:40:47Z',\n",
       "  'summary': \"Most recommender systems (RS) research assumes that a user's utility can be\\nmaximized independently of the utility of the other agents (e.g., other users,\\ncontent providers). In realistic settings, this is often not true---the\\ndynamics of an RS ecosystem couple the long-term utility of all agents. In this\\nwork, we explore settings in which content providers cannot remain viable\\nunless they receive a certain level of user engagement. We formulate the\\nrecommendation problem in this setting as one of equilibrium selection in the\\ninduced dynamical system, and show that it can be solved as an optimal\\nconstrained matching problem. Our model ensures the system reaches an\\nequilibrium with maximal social welfare supported by a sufficiently diverse set\\nof viable providers. We demonstrate that even in a simple, stylized dynamical\\nRS model, the standard myopic approach to recommendation---always matching a\\nuser to the best provider---performs poorly. We develop several scalable\\ntechniques to solve the matching problem, and also draw connections to various\\nnotions of user regret and fairness, arguing that these outcomes are fairer in\\na utilitarian sense.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.00104v2.pdf'},\n",
       " {'id': '2011.08090v1',\n",
       "  'title': 'Explainable Artificial Intelligence Recommendation System by Leveraging\\n  the Semantics of Adverse Childhood Experiences: Proof-of-Concept Prototype\\n  Development',\n",
       "  'published': '2020-11-06T17:45:15Z',\n",
       "  'summary': 'The study of adverse childhood experiences and their consequences has emerged\\nover the past 20 years. In this study, we aimed to leverage explainable\\nartificial intelligence, and propose a proof-of-concept prototype for a\\nknowledge-driven evidence-based recommendation system to improve surveillance\\nof adverse childhood experiences. We used concepts from an ontology that we\\nhave developed to build and train a question-answering agent using the Google\\nDialogFlow engine. In addition to the question-answering agent, the initial\\nprototype includes knowledge graph generation and recommendation components\\nthat leverage third-party graph technology. To showcase the framework\\nfunctionalities, we here present a prototype design and demonstrate the main\\nfeatures through four use case scenarios motivated by an initiative currently\\nimplemented at a children hospital in Memphis, Tennessee. Ongoing development\\nof the prototype requires implementing an optimization algorithm of the\\nrecommendations, incorporating a privacy layer through a personal health\\nlibrary, and conducting a clinical trial to assess both usability and\\nusefulness of the implementation. This semantic-driven explainable artificial\\nintelligence prototype can enhance health care practitioners ability to provide\\nexplanations for the decisions they make.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2011.08090v1.pdf'},\n",
       " {'id': '2310.17749v1',\n",
       "  'title': 'Salespeople vs SalesBot: Exploring the Role of Educational Value in\\n  Conversational Recommender Systems',\n",
       "  'published': '2023-10-26T19:44:06Z',\n",
       "  'summary': \"Making big purchases requires consumers to research or consult a salesperson\\nto gain domain expertise. However, existing conversational recommender systems\\n(CRS) often overlook users' lack of background knowledge, focusing solely on\\ngathering preferences. In this work, we define a new problem space for\\nconversational agents that aim to provide both product recommendations and\\neducational value through mixed-type mixed-initiative dialog. We introduce\\nSalesOps, a framework that facilitates the simulation and evaluation of such\\nsystems by leveraging recent advancements in large language models (LLMs). We\\nbuild SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate\\neither side of the framework. A comprehensive human study compares SalesBot\\nagainst professional salespeople, revealing that although SalesBot approaches\\nprofessional performance in terms of fluency and informativeness, it lags\\nbehind in recommendation quality. We emphasize the distinct limitations both\\nface in providing truthful information, highlighting the challenges of ensuring\\nfaithfulness in the CRS context. We release our code and make all data\\navailable.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.17749v1.pdf'},\n",
       " {'id': '2503.23374v1',\n",
       "  'title': 'RuleAgent: Discovering Rules for Recommendation Denoising with\\n  Autonomous Language Agents',\n",
       "  'published': '2025-03-30T09:19:03Z',\n",
       "  'summary': 'The implicit feedback (e.g., clicks) in real-world recommender systems is\\noften prone to severe noise caused by unintentional interactions, such as\\nmisclicks or curiosity-driven behavior. A common approach to denoising this\\nfeedback is manually crafting rules based on observations of training loss\\npatterns. However, this approach is labor-intensive and the resulting rules\\noften lack generalization across diverse scenarios. To overcome these\\nlimitations, we introduce RuleAgent, a language agent based framework which\\nmimics real-world data experts to autonomously discover rules for\\nrecommendation denoising. Unlike the high-cost process of manual rule mining,\\nRuleAgent offers rapid and dynamic rule discovery, ensuring adaptability to\\nevolving data and varying scenarios. To achieve this, RuleAgent is equipped\\nwith tailored profile, memory, planning, and action modules and leverages\\nreflection mechanisms to enhance its reasoning capabilities for rule discovery.\\nFurthermore, to avoid the frequent retraining in rule discovery, we propose\\nLossEraser-an unlearning strategy that streamlines training without\\ncompromising denoising performance. Experiments on benchmark datasets\\ndemonstrate that, compared with existing denoising methods, RuleAgent not only\\nderives the optimal recommendation performance but also produces generalizable\\ndenoising rules, assisting researchers in efficient data cleaning.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.23374v1.pdf'},\n",
       " {'id': '2504.08754v5',\n",
       "  'title': 'Towards Personalized Conversational Sales Agents: Contextual User\\n  Profiling for Strategic Action',\n",
       "  'published': '2025-03-28T15:49:52Z',\n",
       "  'summary': 'Conversational Recommender Systems (CRSs)aim to engage users in dialogue to\\nprovide tailored recommendations. While traditional CRSs focus on eliciting\\npreferences and retrieving items, real-world e-commerce interactions involve\\nmore complex decision-making, where users consider multiple factors beyond\\nsimple attributes. To capture this complexity, we introduce Conversational\\nSales (CSALES), a novel task that integrates preference elicitation,\\nrecommendation, and persuasion within a unified conversational framework. To\\nsupport realistic and systematic evaluation, we present CSUSER, an evaluation\\nprotocol with LLM-based user simulator grounded in real-world behavioral data\\nby modeling fine-grained user profiles for personalized interaction. We also\\npropose CSI, a conversational sales agent that proactively infers contextual\\nuser profiles and strategically selects actions through conversation.\\nComprehensive experiments show that CSI significantly improves both\\nrecommendation success and persuasive effectiveness across diverse user\\nprofiles.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.08754v5.pdf'},\n",
       " {'id': '2505.07257v1',\n",
       "  'title': 'DARLR: Dual-Agent Offline Reinforcement Learning for Recommender Systems\\n  with Dynamic Reward',\n",
       "  'published': '2025-05-12T06:18:31Z',\n",
       "  'summary': 'Model-based offline reinforcement learning (RL) has emerged as a promising\\napproach for recommender systems, enabling effective policy learning by\\ninteracting with frozen world models. However, the reward functions in these\\nworld models, trained on sparse offline logs, often suffer from inaccuracies.\\nSpecifically, existing methods face two major limitations in addressing this\\nchallenge: (1) deterministic use of reward functions as static look-up tables,\\nwhich propagates inaccuracies during policy learning, and (2) static\\nuncertainty designs that fail to effectively capture decision risks and\\nmitigate the impact of these inaccuracies. In this work, a dual-agent\\nframework, DARLR, is proposed to dynamically update world models to enhance\\nrecommendation policies. To achieve this, a \\\\textbf{\\\\textit{selector}} is\\nintroduced to identify reference users by balancing similarity and diversity so\\nthat the \\\\textbf{\\\\textit{recommender}} can aggregate information from these\\nusers and iteratively refine reward estimations for dynamic reward shaping.\\nFurther, the statistical features of the selected users guide the dynamic\\nadaptation of an uncertainty penalty to better align with evolving\\nrecommendation requirements. Extensive experiments on four benchmark datasets\\ndemonstrate the superior performance of DARLR, validating its effectiveness.\\nThe code is available at https://github.com/ArronDZhang/DARLR.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.07257v1.pdf'},\n",
       " {'id': '2111.12899v1',\n",
       "  'title': 'Recommending Multiple Positive Citations for Manuscript via\\n  Content-Dependent Modeling and Multi-Positive Triplet',\n",
       "  'published': '2021-11-25T04:09:31Z',\n",
       "  'summary': \"Considering the rapidly increasing number of academic papers, searching for\\nand citing appropriate references has become a non-trial task during the wiring\\nof papers. Recommending a handful of candidate papers to a manuscript before\\npublication could ease the burden of the authors, and help the reviewers to\\ncheck the completeness of the cited resources. Conventional approaches on\\ncitation recommendation generally consider recommending one ground-truth\\ncitation for a query context from an input manuscript, but lack of\\nconsideration on co-citation recommendations. However, a piece of context often\\nneeds to be supported by two or more co-citation pairs. Here, we propose a\\nnovel scientific paper modeling for citation recommendations, namely\\nMulti-Positive BERT Model for Citation Recommendation (MP-BERT4CR), complied\\nwith a series of Multi-Positive Triplet objectives to recommend multiple\\npositive citations for a query context. The proposed approach has the following\\nadvantages: First, the proposed multi-positive objectives are effective to\\nrecommend multiple positive candidates. Second, we adopt noise distributions\\nwhich are built based on the historical co-citation frequencies, so that\\nMP-BERT4CR is not only effective on recommending high-frequent co-citation\\npairs; but also the performances on retrieving the low-frequent ones are\\nsignificantly improved. Third, we propose a dynamic context sampling strategy\\nwhich captures the ``macro-scoped'' citing intents from a manuscript and\\nempowers the citation embeddings to be content-dependent, which allow the\\nalgorithm to further improve the performances. Single and multiple positive\\nrecommendation experiments testified that MP-BERT4CR delivered significant\\nimprovements. In addition, MP-BERT4CR are also effective in retrieving the full\\nlist of co-citations, and historically low-frequent co-citation pairs compared\\nwith the prior works.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.12899v1.pdf'},\n",
       " {'id': '1906.07358v1',\n",
       "  'title': 'Knowledge Network System (KNS) by Evolutionary Collective Intelligence\\n  (ECI): Model, Algorithm and Applications',\n",
       "  'published': '2019-06-18T03:05:52Z',\n",
       "  'summary': 'Aiming at overcoming some inherent drawbacks and bottlenecks encountered by\\nthe conventional Knowledge, Recommendation, Search, and Social Systems, in this\\narticle we introduce the Knowledge Network System (KNS), a novel type of\\nknowledge graph which is constructed by a new proposed algorithm, the\\nEvolutionary Collective Intelligence (ECI) algorithm. The ECI, an agent-machine\\ninteractive algorithm, constructs the KNS by iteratively recommending\\ninteresting/matched samples/files to the agents, and meanwhile taking\\nadvantages of the collective intelligence of the agents. The ECI based KNS, to\\nthe best of our knowledge, is the first attempt in literature that integrates\\nthe functions of knowledge network construction, high-quality recommendation,\\nnew types of search and social in a same framework. Some real and potential\\napplications of KNS and ECI are discussed, and a real system named VISVA is\\nprovided to demonstrate their efficacy. Some open problems for future works are\\nalso summarized in the end.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1906.07358v1.pdf'},\n",
       " {'id': '1904.11412v1',\n",
       "  'title': 'Assistive System in Conversational Agent for Health Coaching: The\\n  CoachAI Approach',\n",
       "  'published': '2019-04-25T15:39:49Z',\n",
       "  'summary': \"With increasing physicians' workload and patients' needs for care, there is a\\nneed for technology that facilitates physicians work and performs continues\\nfollow-up with patients. Existing approaches focus merely on improving\\npatient's condition, and none have considered managing physician's workload.\\nThis paper presents an initial evaluation of a conversational agent assisted\\ncoaching platform intended to manage physicians' fatigue and provide continuous\\nfollow-up to patients. We highlight the approach adapted to build the chatbot\\ndialogue and the coaching platform. We will particularly discuss the activity\\nrecommender algorithms used to suggest insights about patients' condition and\\nactivities based on previously collected data. The paper makes three\\ncontributions: (1) present the conversational agent as an assistive virtual\\ncoach, (2) decrease physicians workload and continuous follow up with patients,\\nall by handling some repetitive physician tasks and performing initial follow\\nup with the patient, (3) present the activity recommender that tracks previous\\nactivities and patient information and provides useful insights about possible\\nactivity and patient match to the coach. Future work focuses on integrating the\\nrecommender model with the CoachAI platform and test the prototype with\\npatient's in collaboration with an ambulatory clinic.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1904.11412v1.pdf'},\n",
       " {'id': '2006.13171v2',\n",
       "  'title': 'ObjectNav Revisited: On Evaluation of Embodied Agents Navigating to\\n  Objects',\n",
       "  'published': '2020-06-23T17:18:54Z',\n",
       "  'summary': \"We revisit the problem of Object-Goal Navigation (ObjectNav). In its simplest\\nform, ObjectNav is defined as the task of navigating to an object, specified by\\nits label, in an unexplored environment. In particular, the agent is\\ninitialized at a random location and pose in an environment and asked to find\\nan instance of an object category, e.g., find a chair, by navigating to it.\\n  As the community begins to show increased interest in semantic goal\\nspecification for navigation tasks, a number of different often-inconsistent\\ninterpretations of this task are emerging. This document summarizes the\\nconsensus recommendations of this working group on ObjectNav. In particular, we\\nmake recommendations on subtle but important details of evaluation criteria\\n(for measuring success when navigating towards a target object), the agent's\\nembodiment parameters, and the characteristics of the environments within which\\nthe task is carried out. Finally, we provide a detailed description of the\\ninstantiation of these recommendations in challenges organized at the Embodied\\nAI workshop at CVPR 2020 http://embodied-ai.org .\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.13171v2.pdf'},\n",
       " {'id': '2406.17475v1',\n",
       "  'title': 'Performative Debias with Fair-exposure Optimization Driven by Strategic\\n  Agents in Recommender Systems',\n",
       "  'published': '2024-06-25T11:41:50Z',\n",
       "  'summary': 'Data bias, e.g., popularity impairs the dynamics of two-sided markets within\\nrecommender systems. This overshadows the less visible but potentially\\nintriguing long-tail items that could capture user interest. Despite the\\nabundance of research surrounding this issue, it still poses challenges and\\nremains a hot topic in academic circles. Along this line, in this paper, we\\ndeveloped a re-ranking approach in dynamic settings with fair-exposure\\noptimization driven by strategic agents. Designed for the producer side, the\\nexecution of agents assumes content creators can modify item features based on\\nstrategic incentives to maximize their exposure. This iterative process entails\\nan end-to-end optimization, employing differentiable ranking operators that\\nsimultaneously target accuracy and fairness. Joint objectives ensure the\\nperformance of recommendations while enhancing the visibility of tail items. We\\nalso leveraged the performativity nature of predictions to illustrate how\\nstrategic learning influences content creators to shift towards fairness\\nefficiently, thereby incentivizing features of tail items. Through\\ncomprehensive experiments on both public and industrial datasets, we have\\nsubstantiated the effectiveness and dominance of the proposed method especially\\non unveiling the potential of tail items.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.17475v1.pdf'},\n",
       " {'id': '2506.14302v1',\n",
       "  'title': 'Expectation Confirmation Preference Optimization for Multi-Turn\\n  Conversational Recommendation Agent',\n",
       "  'published': '2025-06-17T08:29:04Z',\n",
       "  'summary': \"Recent advancements in Large Language Models (LLMs) have significantly\\npropelled the development of Conversational Recommendation Agents (CRAs).\\nHowever, these agents often generate short-sighted responses that fail to\\nsustain user guidance and meet expectations. Although preference optimization\\nhas proven effective in aligning LLMs with user expectations, it remains costly\\nand performs poorly in multi-turn dialogue. To address this challenge, we\\nintroduce a novel multi-turn preference optimization (MTPO) paradigm ECPO,\\nwhich leverages Expectation Confirmation Theory to explicitly model the\\nevolution of user satisfaction throughout multi-turn dialogues, uncovering the\\nunderlying causes of dissatisfaction. These causes can be utilized to support\\ntargeted optimization of unsatisfactory responses, thereby achieving turn-level\\npreference optimization. ECPO ingeniously eliminates the significant sampling\\noverhead of existing MTPO methods while ensuring the optimization process\\ndrives meaningful improvements. To support ECPO, we introduce an LLM-based user\\nsimulator, AILO, to simulate user feedback and perform expectation confirmation\\nduring conversational recommendations. Experimental results show that ECPO\\nsignificantly enhances CRA's interaction capabilities, delivering notable\\nimprovements in both efficiency and effectiveness over existing MTPO methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.14302v1.pdf'},\n",
       " {'id': '2508.02342v1',\n",
       "  'title': 'Agentic Personalized Fashion Recommendation in the Age of Generative AI:\\n  Challenges, Opportunities, and Evaluation',\n",
       "  'published': '2025-08-04T12:22:25Z',\n",
       "  'summary': 'Fashion recommender systems (FaRS) face distinct challenges due to rapid\\ntrend shifts, nuanced user preferences, intricate item-item compatibility, and\\nthe complex interplay among consumers, brands, and influencers. Traditional\\nrecommendation approaches, largely static and retrieval-focused, struggle to\\neffectively capture these dynamic elements, leading to decreased user\\nsatisfaction and elevated return rates. This paper synthesizes both academic\\nand industrial viewpoints to map the distinctive output space and stakeholder\\necosystem of modern FaRS, identifying the complex interplay among users,\\nbrands, platforms, and influencers, and highlighting the unique data and\\nmodeling challenges that arise.\\n  We outline a research agenda for industrial FaRS, centered on five\\nrepresentative scenarios spanning static queries, outfit composition, and\\nmulti-turn dialogue, and argue that mixed-modality refinement-the ability to\\ncombine image-based references (anchors) with nuanced textual constraints-is a\\nparticularly critical task for real-world deployment. To this end, we propose\\nan Agentic Mixed-Modality Refinement (AMMR) pipeline, which fuses multimodal\\nencoders with agentic LLM planners and dynamic retrieval, bridging the gap\\nbetween expressive user intent and fast-changing fashion inventories. Our work\\nshows that moving beyond static retrieval toward adaptive, generative, and\\nstakeholder-aware systems is essential to satisfy the evolving expectations of\\nfashion consumers and brands.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.02342v1.pdf'},\n",
       " {'id': '2004.10439v1',\n",
       "  'title': 'Tactical Decision-Making in Autonomous Driving by Reinforcement Learning\\n  with Uncertainty Estimation',\n",
       "  'published': '2020-04-22T08:22:28Z',\n",
       "  'summary': \"Reinforcement learning (RL) can be used to create a tactical decision-making\\nagent for autonomous driving. However, previous approaches only output\\ndecisions and do not provide information about the agent's confidence in the\\nrecommended actions. This paper investigates how a Bayesian RL technique, based\\non an ensemble of neural networks with additional randomized prior functions\\n(RPF), can be used to estimate the uncertainty of decisions in autonomous\\ndriving. A method for classifying whether or not an action should be considered\\nsafe is also introduced. The performance of the ensemble RPF method is\\nevaluated by training an agent on a highway driving scenario. It is shown that\\nthe trained agent can estimate the uncertainty of its decisions and indicate an\\nunacceptable level when the agent faces a situation that is far from the\\ntraining distribution. Furthermore, within the training distribution, the\\nensemble RPF agent outperforms a standard Deep Q-Network agent. In this study,\\nthe estimated uncertainty is used to choose safe actions in unknown situations.\\nHowever, the uncertainty information could also be used to identify situations\\nthat should be added to the training process.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2004.10439v1.pdf'},\n",
       " {'id': '2103.07746v2',\n",
       "  'title': 'A Simulation Study Evaluating Phase I Clinical Trial Designs for\\n  Combinational Agents',\n",
       "  'published': '2021-03-13T16:37:22Z',\n",
       "  'summary': \"Nowadays, more and more clinical trials choose combinational agents as the\\nintervention to achieve better therapeutic responses. However, dose-finding for\\ncombinational agents is much more complicated than single agent as the full\\norder of combination dose toxicity is unknown. Therefore, regular phase I\\ndesigns are not able to identify the maximum tolerated dose (MTD) of\\ncombinational agents. Motivated by such needs, plenty of novel phase I clinical\\ntrial designs for combinational agents were proposed. With so many available\\ndesigns, research that compare their performances, explore parameters' impacts,\\nand provide recommendations is very limited. Therefore, we conducted a\\nsimulation study to evaluate multiple phase I designs that proposed to identify\\nsingle MTD for combinational agents under various scenarios. We also explored\\ninfluences of different design parameters. In the end, we summarized the pros\\nand cons of each design, and provided a general guideline in design selection.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.07746v2.pdf'},\n",
       " {'id': '2206.05030v1',\n",
       "  'title': \"Explanation as Question Answering based on a Task Model of the Agent's\\n  Design\",\n",
       "  'published': '2022-06-08T08:52:47Z',\n",
       "  'summary': \"We describe a stance towards the generation of explanations in AI agents that\\nis both human-centered and design-based. We collect questions about the working\\nof an AI agent through participatory design by focus groups. We capture an\\nagent's design through a Task-Method-Knowledge model that explicitly specifies\\nthe agent's tasks and goals, as well as the mechanisms, knowledge and\\nvocabulary it uses for accomplishing the tasks. We illustrate our approach\\nthrough the generation of explanations in Skillsync, an AI agent that links\\ncompanies and colleges for worker upskilling and reskilling. In particular, we\\nembed a question-answering agent called AskJill in Skillsync, where AskJill\\ncontains a TMK model of Skillsync's design. AskJill presently answers\\nhuman-generated questions about Skillsync's tasks and vocabulary, and thereby\\nhelps explain how it produces its recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.05030v1.pdf'},\n",
       " {'id': '2309.16144v1',\n",
       "  'title': 'Scalable Exact Output Synchronization of Discrete-Time Multi-Agent\\n  Systems in the Presence of Disturbances and Measurement Noise With Known\\n  Frequencies',\n",
       "  'published': '2023-09-28T03:48:57Z',\n",
       "  'summary': \"This paper aims to achieve scalable exact output and regulated output\\nsynchronization for discrete-time multi-agent systems in presence of\\ndisturbances and measurement noise with known frequencies. Both homogeneous and\\nheterogeneous multi-agent systems are considered, with parts of agents' states\\naccessible in the latter case. The key contribution of this paper is on the\\ndistributed protocol that only uses the information of agent models, rather\\nthan the communication network information and the agent number, so as to\\nachieve the scalable exact synchronization under disturbances and measurement\\nnoise. The validity of the protocol is verified by numerical simulations with\\narbitrarily chosen number of agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.16144v1.pdf'},\n",
       " {'id': '2402.00064v1',\n",
       "  'title': 'Merging plans with incomplete knowledge about actions and goals through\\n  an agent-based reputation system',\n",
       "  'published': '2024-01-29T11:34:59Z',\n",
       "  'summary': 'Managing transition plans is one of the major problems of people with\\ncognitive disabilities. Therefore, finding an automated way to generate such\\nplans would be a helpful tool for this community. In this paper we have\\nspecifically proposed and compared different alternative ways to merge plans\\nformed by sequences of actions of unknown similarities between goals and\\nactions executed by several operator agents which cooperate between them\\napplying such actions over some passive elements (node agents) that require\\nadditional executions of another plan after some time of use. Such ignorance of\\nthe similarities between plan actions and goals would justify the use of a\\ndistributed recommendation system that would provide an useful plan to be\\napplied for a certain goal to a given operator agent, generated from the known\\nresults of previous executions of different plans by other operator agents.\\nHere we provide the general framework of execution (agent system), and the\\ndifferent merging algorithms applied to this problem. The proposed agent system\\nwould act as an useful cognitive assistant for people with intelectual\\ndisabilities such as autism.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.00064v1.pdf'},\n",
       " {'id': '2504.01963v1',\n",
       "  'title': 'LLMs Working in Harmony: A Survey on the Technological Aspects of\\n  Building Effective LLM-Based Multi Agent Systems',\n",
       "  'published': '2025-03-13T06:17:50Z',\n",
       "  'summary': 'This survey investigates foundational technologies essential for developing\\neffective Large Language Model (LLM)-based multi-agent systems. Aiming to\\nanswer how best to optimize these systems for collaborative, dynamic\\nenvironments, we focus on four critical areas: Architecture, Memory, Planning,\\nand Technologies/Frameworks. By analyzing recent advancements and their\\nlimitations - such as scalability, real-time response challenges, and agent\\ncoordination constraints, we provide a detailed view of the technological\\nlandscape. Frameworks like the Mixture of Agents architecture and the ReAct\\nplanning model exemplify current innovations, showcasing improvements in role\\nassignment and decision-making. This review synthesizes key strengths and\\npersistent challenges, offering practical recommendations to enhance system\\nscalability, agent collaboration, and adaptability. Our findings provide a\\nroadmap for future research, supporting the creation of robust, efficient\\nmulti-agent systems that advance both individual agent performance and\\ncollective system resilience.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.01963v1.pdf'},\n",
       " {'id': '2505.12594v1',\n",
       "  'title': 'AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection',\n",
       "  'published': '2025-05-19T01:14:57Z',\n",
       "  'summary': 'Anomaly detection (AD) is essential in areas such as fraud detection, network\\nmonitoring, and scientific research. However, the diversity of data modalities\\nand the increasing number of specialized AD libraries pose challenges for\\nnon-expert users who lack in-depth library-specific knowledge and advanced\\nprogramming skills. To tackle this, we present AD-AGENT, an LLM-driven\\nmulti-agent framework that turns natural-language instructions into fully\\nexecutable AD pipelines. AD-AGENT coordinates specialized agents for intent\\nparsing, data preparation, library and model selection, documentation mining,\\nand iterative code generation and debugging. Using a shared short-term\\nworkspace and a long-term cache, the agents integrate popular AD libraries like\\nPyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that\\nAD-AGENT produces reliable scripts and recommends competitive models across\\nlibraries. The system is open-sourced to support further research and practical\\napplications in AD.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.12594v1.pdf'},\n",
       " {'id': '2507.08149v2',\n",
       "  'title': 'Code with Me or for Me? How Increasing AI Automation Transforms\\n  Developer Workflows',\n",
       "  'published': '2025-07-10T20:12:54Z',\n",
       "  'summary': 'Developers now have access to a growing array of increasingly autonomous AI\\ntools for software development. While many studies examine copilots that\\nprovide chat assistance or code completions, evaluations of coding agents --\\nwhich can automatically write files and run code -- still rely on static\\nbenchmarks. We present the first controlled study of developer interactions\\nwith coding agents, characterizing how more autonomous AI tools affect\\nproductivity and experience. We evaluate two leading copilot and agentic coding\\nassistants, recruiting participants who regularly use the former. Our results\\nshow agents can assist developers in ways that surpass copilots (e.g.,\\ncompleting tasks humans may not have accomplished) and reduce the effort\\nrequired to finish tasks. Yet challenges remain for broader adoption, including\\nensuring users adequately understand agent behaviors. Our findings reveal how\\nworkflows shift with coding agents and how interactions differ from copilots,\\nmotivating recommendations for researchers and highlighting challenges in\\nadopting agentic systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.08149v2.pdf'},\n",
       " {'id': '2502.10978v1',\n",
       "  'title': 'Agentic LLM Framework for Adaptive Decision Discourse',\n",
       "  'published': '2025-02-16T03:46:37Z',\n",
       "  'summary': \"Effective decision-making in complex systems requires synthesizing diverse\\nperspectives to address multifaceted challenges under uncertainty. This study\\nintroduces a real-world inspired agentic Large Language Models (LLMs)\\nframework, to simulate and enhance decision discourse-the deliberative process\\nthrough which actionable strategies are collaboratively developed. Unlike\\ntraditional decision-support tools, the framework emphasizes dialogue,\\ntrade-off exploration, and the emergent synergies generated by interactions\\namong agents embodying distinct personas. These personas simulate diverse\\nstakeholder roles, each bringing unique priorities, expertise, and value-driven\\nreasoning to the table. The framework incorporates adaptive and self-governing\\nmechanisms, enabling agents to dynamically summon additional expertise and\\nrefine their assembly to address evolving challenges. An illustrative\\nhypothetical example focused on extreme flooding in a Midwestern township\\ndemonstrates the framework's ability to navigate uncertainty, balance competing\\npriorities, and propose mitigation and adaptation strategies by considering\\nsocial, economic, and environmental dimensions. Results reveal how the\\nbreadth-first exploration of alternatives fosters robust and equitable\\nrecommendation pathways. This framework transforms how decisions are approached\\nin high-stakes scenarios and can be incorporated in digital environments. It\\nnot only augments decision-makers' capacity to tackle complexity but also sets\\na foundation for scalable and context-aware AI-driven recommendations. This\\nresearch explores novel and alternate routes leveraging agentic LLMs for\\nadaptive, collaborative, and equitable recommendation processes, with\\nimplications across domains where uncertainty and complexity converge.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.10978v1.pdf'},\n",
       " {'id': '1507.07191v2',\n",
       "  'title': 'Economic Recommendation Systems',\n",
       "  'published': '2015-07-26T11:43:00Z',\n",
       "  'summary': \"In the on-line Explore and Exploit literature, central to Machine Learning, a\\ncentral planner is faced with a set of alternatives, each yielding some unknown\\nreward. The planner's goal is to learn the optimal alternative as soon as\\npossible, via experimentation. A typical assumption in this model is that the\\nplanner has full control over the experiment design and implementation. When\\nexperiments are implemented by a society of self-motivated agents the planner\\ncan only recommend experimentation but has no power to enforce it. Kremer et al\\n(JPE, 2014) introduce the first study of explore and exploit schemes that\\naccount for agents' incentives. In their model it is implicitly assumed that\\nagents do not see nor communicate with each other. Their main result is a\\ncharacterization of an optimal explore and exploit scheme. In this work we\\nextend Kremer et al (JPE, 2014) by adding a layer of a social network according\\nto which agents can observe each other. It turns out that when observability is\\nfactored in the scheme proposed by Kremer et al (JPE, 2014) is no longer\\nincentive compatible. In our main result we provide a tight bound on how many\\nother agents can each agent observe and still have an incentive-compatible\\nalgorithm and asymptotically optimal outcome. More technically, for a setting\\nwith N agents where the number of nodes with degree greater than N^alpha is\\nbounded by N^beta and 2*alpha+beta < 1 we construct incentive-compatible\\nasymptotically optimal mechanism. The bound 2*alpha+beta < 1 is shown to be\\ntight.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1507.07191v2.pdf'},\n",
       " {'id': '2406.04219v2',\n",
       "  'title': 'Multi-Agent Imitation Learning: Value is Easy, Regret is Hard',\n",
       "  'published': '2024-06-06T16:18:20Z',\n",
       "  'summary': \"We study a multi-agent imitation learning (MAIL) problem where we take the\\nperspective of a learner attempting to coordinate a group of agents based on\\ndemonstrations of an expert doing so. Most prior work in MAIL essentially\\nreduces the problem to matching the behavior of the expert within the support\\nof the demonstrations. While doing so is sufficient to drive the value gap\\nbetween the learner and the expert to zero under the assumption that agents are\\nnon-strategic, it does not guarantee robustness to deviations by strategic\\nagents. Intuitively, this is because strategic deviations can depend on a\\ncounterfactual quantity: the coordinator's recommendations outside of the state\\ndistribution their recommendations induce. In response, we initiate the study\\nof an alternative objective for MAIL in Markov Games we term the regret gap\\nthat explicitly accounts for potential deviations by agents in the group. We\\nfirst perform an in-depth exploration of the relationship between the value and\\nregret gaps. First, we show that while the value gap can be efficiently\\nminimized via a direct extension of single-agent IL algorithms, even value\\nequivalence can lead to an arbitrarily large regret gap. This implies that\\nachieving regret equivalence is harder than achieving value equivalence in\\nMAIL. We then provide a pair of efficient reductions to no-regret online convex\\noptimization that are capable of minimizing the regret gap (a) under a coverage\\nassumption on the expert (MALICE) or (b) with access to a queryable expert\\n(BLADES).\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.04219v2.pdf'},\n",
       " {'id': '2301.00993v1',\n",
       "  'title': 'Offline Evaluation for Reinforcement Learning-based Recommendation: A\\n  Critical Issue and Some Alternatives',\n",
       "  'published': '2023-01-03T08:03:37Z',\n",
       "  'summary': 'In this paper, we argue that the paradigm commonly adopted for offline\\nevaluation of sequential recommender systems is unsuitable for evaluating\\nreinforcement learning-based recommenders. We find that most of the existing\\noffline evaluation practices for reinforcement learning-based recommendation\\nare based on a next-item prediction protocol, and detail three shortcomings of\\nsuch an evaluation protocol. Notably, it cannot reflect the potential benefits\\nthat reinforcement learning (RL) is expected to bring while it hides critical\\ndeficiencies of certain offline RL agents. Our suggestions for alternative ways\\nto evaluate RL-based recommender systems aim to shed light on the existing\\npossibilities and inspire future research on reliable evaluation protocols.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2301.00993v1.pdf'},\n",
       " {'id': '2305.18212v1',\n",
       "  'title': 'Multimodal Recommendation Dialog with Subjective Preference: A New\\n  Challenge and Benchmark',\n",
       "  'published': '2023-05-26T08:43:46Z',\n",
       "  'summary': 'Existing multimodal task-oriented dialog data fails to demonstrate the\\ndiverse expressions of user subjective preferences and recommendation acts in\\nthe real-life shopping scenario. This paper introduces a new dataset SURE\\n(Multimodal Recommendation Dialog with SUbjective PREference), which contains\\n12K shopping dialogs in complex store scenes. The data is built in two phases\\nwith human annotations to ensure quality and diversity. SURE is well-annotated\\nwith subjective preferences and recommendation acts proposed by sales experts.\\nA comprehensive analysis is given to reveal the distinguishing features of\\nSURE. Three benchmark tasks are then proposed on the data to evaluate the\\ncapability of multimodal recommendation agents. Based on the SURE, we propose a\\nbaseline model, powered by a state-of-the-art multimodal model, for these\\ntasks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.18212v1.pdf'},\n",
       " {'id': '2501.15048v1',\n",
       "  'title': 'YouTube Recommendations Reinforce Negative Emotions: Auditing\\n  Algorithmic Bias with Emotionally-Agentic Sock Puppets',\n",
       "  'published': '2025-01-25T03:04:53Z',\n",
       "  'summary': \"Personalized recommendation algorithms, like those on YouTube, significantly\\nshape online content consumption. These systems aim to maximize engagement by\\nlearning users' preferences and aligning content accordingly but may\\nunintentionally reinforce impulsive and emotional biases. Using a sock-puppet\\naudit methodology, this study examines YouTube's capacity to recognize and\\nreinforce emotional preferences. Simulated user accounts with assigned\\nemotional preferences navigate the platform, selecting videos that align with\\ntheir assigned preferences and recording subsequent recommendations. Our\\nfindings reveal reveal that YouTube amplifies negative emotions, such as anger\\nand grievance, by increasing their prevalence and prominence in\\nrecommendations. This reinforcement intensifies over time and persists across\\ncontexts. Surprisingly, contextual recommendations often exceed personalized\\nones in reinforcing emotional alignment. These findings suggest the algorithm\\namplifies user biases, contributing to emotional filter bubbles and raising\\nconcerns about user well-being and societal impacts. The study emphasizes the\\nneed for balancing personalization with content diversity and user agency.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.15048v1.pdf'},\n",
       " {'id': '2001.05452v4',\n",
       "  'title': 'The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits',\n",
       "  'published': '2020-01-15T17:49:29Z',\n",
       "  'summary': \"We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup\\nconsisting of $N$ agents, solving the same MAB instance to minimize individual\\ncumulative regret. In our model, agents collaborate by exchanging messages\\nthrough pairwise gossip style communications on an arbitrary connected graph.\\nWe develop two novel algorithms, where each agent only plays from a subset of\\nall the arms. Agents use the communication medium to recommend only arm-IDs\\n(not samples), and thus update the set of arms from which they play. We\\nestablish that, if agents communicate $\\\\Omega(\\\\log(T))$ times through any\\nconnected pairwise gossip mechanism, then every agent's regret is a factor of\\norder $N$ smaller compared to the case of no collaborations. Furthermore, we\\nshow that the communication constraints only have a second order effect on the\\nregret of our algorithm. We then analyze this second order term of the regret\\nto derive bounds on the regret-communication tradeoffs. Finally, we empirically\\nevaluate our algorithm and conclude that the insights are fundamental and not\\nartifacts of our bounds. We also show a lower bound which gives that the regret\\nscaling obtained by our algorithm cannot be improved even in the absence of any\\ncommunication constraints. Our results thus demonstrate that even a minimal\\nlevel of collaboration among agents greatly reduces regret for all agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2001.05452v4.pdf'},\n",
       " {'id': '2009.09118v1',\n",
       "  'title': 'Multi-contrast K-edge imaging on a bench-top photon-counting CT system:\\n  Acquisition parameter study',\n",
       "  'published': '2020-09-18T23:26:32Z',\n",
       "  'summary': 'Purpose: Photon-counting computed tomography (PCCT) shows promise for medical\\nimaging in regards to material separation and imaging of multiple contrast\\nagents. However, many PCCT setups are under development and are not optimized\\nfor specific contrast agents or use cases. Here, we demonstrate how\\nexperimental system parameters may be varied in order to enhance performance\\nand we propose a set of recommendations to achieve this based on contrast\\nagent.\\n  Approach: A table-top PCCT system with a cadmium zinc telluride (CZT)\\ndetector capable of separating six energy bins was used to image multiple\\ncontrast agents in a small phantom. The contrast agents were separated and the\\nconcentration was quantified using K-edge subtraction. To increase system\\nperformance, we investigated three parameters: beam filter type and thickness,\\nprojection acquisition time, and energy bin width. The results from the\\nparameters were compared based on PCCT signal and contrast to noise ratio (CNR)\\nor noise in K-edge images. The concentrations of the contrast agents were\\nquantified in K-edge images and compared to known concentrations.\\n  Results: The bench-top PCCT system was able to successfully quantify the\\ncontrast agents through K-edge subtraction. Decreasing projection acquisition\\ntime showed a decrease in K-edge CNR. However, it did not scale as the square\\nroot of time. Filter type and bin width demonstrated a dependence on the\\nspecific contrast agent.\\n  Conclusions: The presented bench-top system demonstrated the ability to\\nseparate contrast agents using K-edge subtraction and accurately determine\\ncontrast concentration in K-edge images. Specific parameters for future use\\nwill be chosen based on contrast agent.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2009.09118v1.pdf'},\n",
       " {'id': '2403.00188v2',\n",
       "  'title': 'Impact of Decentralized Learning on Player Utilities in Stackelberg\\n  Games',\n",
       "  'published': '2024-02-29T23:38:28Z',\n",
       "  'summary': \"When deployed in the world, a learning agent such as a recommender system or\\na chatbot often repeatedly interacts with another learning agent (such as a\\nuser) over time. In many such two-agent systems, each agent learns separately\\nand the rewards of the two agents are not perfectly aligned. To better\\nunderstand such cases, we examine the learning dynamics of the two-agent system\\nand the implications for each agent's objective. We model these systems as\\nStackelberg games with decentralized learning and show that standard regret\\nbenchmarks (such as Stackelberg equilibrium payoffs) result in worst-case\\nlinear regret for at least one player. To better capture these systems, we\\nconstruct a relaxed regret benchmark that is tolerant to small learning errors\\nby agents. We show that standard learning algorithms fail to provide sublinear\\nregret, and we develop algorithms to achieve near-optimal $O(T^{2/3})$ regret\\nfor both players with respect to these benchmarks. We further design relaxed\\nenvironments under which faster learning ($O(\\\\sqrt{T})$) is possible.\\nAltogether, our results take a step towards assessing how two-agent\\ninteractions in sequential and decentralized learning environments affect the\\nutility of both agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.00188v2.pdf'},\n",
       " {'id': '2508.14231v1',\n",
       "  'title': 'Incident Analysis for AI Agents',\n",
       "  'published': '2025-08-19T19:39:37Z',\n",
       "  'summary': \"As AI agents become more widely deployed, we are likely to see an increasing\\nnumber of incidents: events involving AI agent use that directly or indirectly\\ncause harm. For example, agents could be prompt-injected to exfiltrate private\\ninformation or make unauthorized purchases. Structured information about such\\nincidents (e.g., user prompts) can help us understand their causes and prevent\\nfuture occurrences. However, existing incident reporting processes are not\\nsufficient for understanding agent incidents. In particular, such processes are\\nlargely based on publicly available data, which excludes useful, but\\npotentially sensitive, information such as an agent's chain of thought or\\nbrowser history. To inform the development of new, emerging incident reporting\\nprocesses, we propose an incident analysis framework for agents. Drawing on\\nsystems safety approaches, our framework proposes three types of factors that\\ncan cause incidents: system-related (e.g., CBRN training data), contextual\\n(e.g., prompt injections), and cognitive (e.g., misunderstanding a user\\nrequest). We also identify specific information that could help clarify which\\nfactors are relevant to a given incident: activity logs, system documentation\\nand access, and information about the tools an agent uses. We provide\\nrecommendations for 1) what information incident reports should include and 2)\\nwhat information developers and deployers should retain and make available to\\nincident investigators upon request. As we transition to a world with more\\nagents, understanding agent incidents will become increasingly crucial for\\nmanaging risks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.14231v1.pdf'},\n",
       " {'id': '2007.02095v1',\n",
       "  'title': 'Neural Interactive Collaborative Filtering',\n",
       "  'published': '2020-07-04T13:35:39Z',\n",
       "  'summary': \"In this paper, we study collaborative filtering in an interactive setting, in\\nwhich the recommender agents iterate between making recommendations and\\nupdating the user profile based on the interactive feedback. The most\\nchallenging problem in this scenario is how to suggest items when the user\\nprofile has not been well established, i.e., recommend for cold-start users or\\nwarm-start users with taste drifting. Existing approaches either rely on overly\\npessimistic linear exploration strategy or adopt meta-learning based algorithms\\nin a full exploitation way. In this work, to quickly catch up with the user's\\ninterests, we propose to represent the exploration policy with a neural network\\nand directly learn it from the feedback data. Specifically, the exploration\\npolicy is encoded in the weights of multi-channel stacked self-attention neural\\nnetworks and trained with efficient Q-learning by maximizing users' overall\\nsatisfaction in the recommender systems. The key insight is that the satisfied\\nrecommendations triggered by the exploration recommendation can be viewed as\\nthe exploration bonus (delayed reward) for its contribution on improving the\\nquality of the user profile. Therefore, the proposed exploration policy, to\\nbalance between learning the user profile and making accurate recommendations,\\ncan be directly optimized by maximizing users' long-term satisfaction with\\nreinforcement learning. Extensive experiments and analysis conducted on three\\nbenchmark collaborative filtering datasets have demonstrated the advantage of\\nour method over state-of-the-art methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.02095v1.pdf'},\n",
       " {'id': '2208.07626v3',\n",
       "  'title': 'Algorithmic Assistance with Recommendation-Dependent Preferences',\n",
       "  'published': '2022-08-16T09:24:47Z',\n",
       "  'summary': 'When an algorithm provides risk assessments, we typically think of them as\\nhelpful inputs to human decisions, such as when risk scores are presented to\\njudges or doctors. However, a decision-maker may not only react to the\\ninformation provided by the algorithm. The decision-maker may also view the\\nalgorithmic recommendation as a default action, making it costly for them to\\ndeviate, such as when a judge is reluctant to overrule a high-risk assessment\\nfor a defendant or a doctor fears the consequences of deviating from\\nrecommended procedures. To address such unintended consequences of algorithmic\\nassistance, we propose a principal-agent model of joint human-machine\\ndecision-making. Within this model, we consider the effect and design of\\nalgorithmic recommendations when they affect choices not just by shifting\\nbeliefs, but also by altering preferences. We motivate this assumption from\\ninstitutional factors, such as a desire to avoid audits, as well as from\\nwell-established models in behavioral science that predict loss aversion\\nrelative to a reference point, which here is set by the algorithm. We show that\\nrecommendation-dependent preferences create inefficiencies where the\\ndecision-maker is overly responsive to the recommendation. As a potential\\nremedy, we discuss algorithms that strategically withhold recommendations, and\\nshow how they can improve the quality of final decisions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.07626v3.pdf'},\n",
       " {'id': '2303.06611v1',\n",
       "  'title': 'AutoDenoise: Automatic Data Instance Denoising for Recommendations',\n",
       "  'published': '2023-03-12T08:36:15Z',\n",
       "  'summary': 'Historical user-item interaction datasets are essential in training modern\\nrecommender systems for predicting user preferences. However, the arbitrary\\nuser behaviors in most recommendation scenarios lead to a large volume of noisy\\ndata instances being recorded, which cannot fully represent their true\\ninterests. While a large number of denoising studies are emerging in the\\nrecommender system community, all of them suffer from highly dynamic data\\ndistributions. In this paper, we propose a Deep Reinforcement Learning (DRL)\\nbased framework, AutoDenoise, with an Instance Denoising Policy Network, for\\ndenoising data instances with an instance selection manner in deep recommender\\nsystems. To be specific, AutoDenoise serves as an agent in DRL to adaptively\\nselect noise-free and predictive data instances, which can then be utilized\\ndirectly in training representative recommendation models. In addition, we\\ndesign an alternate two-phase optimization strategy to train and validate the\\nAutoDenoise properly. In the searching phase, we aim to train the policy\\nnetwork with the capacity of instance denoising; in the validation phase, we\\nfind out and evaluate the denoised subset of data instances selected by the\\ntrained policy network, so as to validate its denoising ability. We conduct\\nextensive experiments to validate the effectiveness of AutoDenoise combined\\nwith multiple representative recommender system models.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.06611v1.pdf'},\n",
       " {'id': '2305.11081v1',\n",
       "  'title': 'Contrastive State Augmentations for Reinforcement Learning-Based\\n  Recommender Systems',\n",
       "  'published': '2023-05-18T16:08:34Z',\n",
       "  'summary': 'Learning reinforcement learning (RL)-based recommenders from historical\\nuser-item interaction sequences is vital to generate high-reward\\nrecommendations and improve long-term cumulative benefits. However, existing RL\\nrecommendation methods encounter difficulties (i) to estimate the value\\nfunctions for states which are not contained in the offline training data, and\\n(ii) to learn effective state representations from user implicit feedback due\\nto the lack of contrastive signals. In this work, we propose contrastive state\\naugmentations (CSA) for the training of RL-based recommender systems. To tackle\\nthe first issue, we propose four state augmentation strategies to enlarge the\\nstate space of the offline data. The proposed method improves the\\ngeneralization capability of the recommender by making the RL agent visit the\\nlocal state regions and ensuring the learned value functions are similar\\nbetween the original and augmented states. For the second issue, we propose\\nintroducing contrastive signals between augmented states and the state randomly\\nsampled from other sessions to improve the state representation learning\\nfurther. To verify the effectiveness of the proposed CSA, we conduct extensive\\nexperiments on two publicly accessible datasets and one dataset collected from\\na real-life e-commerce platform. We also conduct experiments on a simulated\\nenvironment as the online evaluation setting. Experimental results demonstrate\\nthat CSA can effectively improve recommendation performance.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.11081v1.pdf'},\n",
       " {'id': '2305.14103v1',\n",
       "  'title': 'Simulating News Recommendation Ecosystem for Fun and Profit',\n",
       "  'published': '2023-05-23T14:25:37Z',\n",
       "  'summary': 'Understanding the evolution of online news communities is essential for\\ndesigning more effective news recommender systems. However, due to the lack of\\nappropriate datasets and platforms, the existing literature is limited in\\nunderstanding the impact of recommender systems on this evolutionary process\\nand the underlying mechanisms, resulting in sub-optimal system designs that may\\naffect long-term utilities. In this work, we propose SimuLine, a simulation\\nplatform to dissect the evolution of news recommendation ecosystems and present\\na detailed analysis of the evolutionary process and underlying mechanisms.\\nSimuLine first constructs a latent space well reflecting the human behaviors,\\nand then simulates the news recommendation ecosystem via agent-based modeling.\\nBased on extensive simulation experiments and the comprehensive analysis\\nframework consisting of quantitative metrics, visualization, and textual\\nexplanations, we analyze the characteristics of each evolutionary phase from\\nthe perspective of life-cycle theory, and propose a relationship graph\\nillustrating the key factors and affecting mechanisms. Furthermore, we explore\\nthe impacts of recommender system designing strategies, including the\\nutilization of cold-start news, breaking news, and promotion, on the\\nevolutionary process, which shed new light on the design of recommender\\nsystems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.14103v1.pdf'},\n",
       " {'id': '2306.01476v1',\n",
       "  'title': 'Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking\\n  Intent in Recommender Systems',\n",
       "  'published': '2023-06-02T12:02:23Z',\n",
       "  'summary': \"Recommending novel content, which expands user horizons by introducing them\\nto new interests, has been shown to improve users' long-term experience on\\nrecommendation platforms \\\\cite{chen2021values}. Users however are not\\nconstantly looking to explore novel content. It is therefore crucial to\\nunderstand their novelty-seeking intent and adjust the recommendation policy\\naccordingly. Most existing literature models a user's propensity to choose\\nnovel content or to prefer a more diverse set of recommendations at individual\\ninteractions. Hierarchical structure, on the other hand, exists in a user's\\nnovelty-seeking intent, which is manifested as a static and intrinsic user\\npreference for seeking novelty along with a dynamic session-based propensity.\\nTo this end, we propose a novel hierarchical reinforcement learning-based\\nmethod to model the hierarchical user novelty-seeking intent, and to adapt the\\nrecommendation policy accordingly based on the extracted user novelty-seeking\\npropensity. We further incorporate diversity and novelty-related measurement in\\nthe reward function of the hierarchical RL (HRL) agent to encourage user\\nexploration \\\\cite{chen2021values}. We demonstrate the benefits of explicitly\\nmodeling hierarchical user novelty-seeking intent in recommendations through\\nextensive experiments on simulated and real-world datasets. In particular, we\\ndemonstrate that the effectiveness of our proposed hierarchical RL-based method\\nlies in its ability to capture such hierarchically-structured intent. As a\\nresult, the proposed HRL model achieves superior performance on several public\\ndatasets, compared with state-of-art baselines.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.01476v1.pdf'},\n",
       " {'id': '2402.15013v2',\n",
       "  'title': 'Filter Bubble or Homogenization? Disentangling the Long-Term Effects of\\n  Recommendations on User Consumption Patterns',\n",
       "  'published': '2024-02-22T23:12:20Z',\n",
       "  'summary': \"Recommendation algorithms play a pivotal role in shaping our media choices,\\nwhich makes it crucial to comprehend their long-term impact on user behavior.\\nThese algorithms are often linked to two critical outcomes: homogenization,\\nwherein users consume similar content despite disparate underlying preferences,\\nand the filter bubble effect, wherein individuals with differing preferences\\nonly consume content aligned with their preferences (without much overlap with\\nother users). Prior research assumes a trade-off between homogenization and\\nfilter bubble effects and then shows that personalized recommendations mitigate\\nfilter bubbles by fostering homogenization. However, because of this assumption\\nof a tradeoff between these two effects, prior work cannot develop a more\\nnuanced view of how recommendation systems may independently impact\\nhomogenization and filter bubble effects. We develop a more refined definition\\nof homogenization and the filter bubble effect by decomposing them into two key\\nmetrics: how different the average consumption is between users (inter-user\\ndiversity) and how varied an individual's consumption is (intra-user\\ndiversity). We then use a novel agent-based simulation framework that enables a\\nholistic view of the impact of recommendation systems on homogenization and\\nfilter bubble effects. Our simulations show that traditional recommendation\\nalgorithms (based on past behavior) mainly reduce filter bubbles by affecting\\ninter-user diversity without significantly impacting intra-user diversity.\\nBuilding on these findings, we introduce two new recommendation algorithms that\\ntake a more nuanced approach by accounting for both types of diversity.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.15013v2.pdf'},\n",
       " {'id': '2508.10401v1',\n",
       "  'title': 'Proxy Model-Guided Reinforcement Learning for Client Selection in\\n  Federated Recommendation',\n",
       "  'published': '2025-08-14T07:03:39Z',\n",
       "  'summary': \"Federated recommender systems have emerged as a promising privacy-preserving\\nparadigm, enabling personalized recommendation services without exposing users'\\nraw data. By keeping data local and relying on a central server to coordinate\\ntraining across distributed clients, FedRSs protect user privacy while\\ncollaboratively learning global models. However, most existing FedRS frameworks\\nadopt fully random client selection strategy in each training round,\\noverlooking the statistical heterogeneity of user data arising from diverse\\npreferences and behavior patterns, thereby resulting in suboptimal model\\nperformance. While some client selection strategies have been proposed in the\\nbroader federated learning literature, these methods are typically designed for\\ngeneric tasks and fail to address the unique challenges of recommendation\\nscenarios, such as expensive contribution evaluation due to the large number of\\nclients, and sparse updates resulting from long-tail item distributions. To\\nbridge this gap, we propose ProxyRL-FRS, a proxy model-guided reinforcement\\nlearning framework tailored for client selection in federated recommendation.\\nSpecifically, we first introduce ProxyNCF, a dual-branch model deployed on each\\nclient, which augments standard Neural Collaborative Filtering with an\\nadditional proxy model branch that provides lightweight contribution\\nestimation, thus eliminating the need for expensive per-round local training\\ntraditionally required to evaluate a client's contribution. Furthermore, we\\ndesign a staleness-aware SA reinforcement learning agent that selects clients\\nbased on the proxy-estimated contribution, and is guided by a reward function\\nbalancing recommendation accuracy and embedding staleness, thereby enriching\\nthe update coverage of item embeddings. Experiments conducted on public\\nrecommendation datasets demonstrate the effectiveness of ProxyRL-FRS.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.10401v1.pdf'},\n",
       " {'id': '2508.20587v1',\n",
       "  'title': 'SemSR: Semantics aware robust Session-based Recommendations',\n",
       "  'published': '2025-08-28T09:25:54Z',\n",
       "  'summary': 'Session-based recommendation (SR) models aim to recommend items to anonymous\\nusers based on their behavior during the current session. While various SR\\nmodels in the literature utilize item sequences to predict the next item, they\\noften fail to leverage semantic information from item titles or descriptions\\nimpeding session intent identification and interpretability. Recent research\\nhas explored Large Language Models (LLMs) as promising approaches to enhance\\nsession-based recommendations, with both prompt-based and fine-tuning based\\nmethods being widely investigated. However, prompt-based methods struggle to\\nidentify optimal prompts that elicit correct reasoning and lack task-specific\\nfeedback at test time, resulting in sub-optimal recommendations. Fine-tuning\\nmethods incorporate domain-specific knowledge but incur significant\\ncomputational costs for implementation and maintenance. In this paper, we\\npresent multiple approaches to utilize LLMs for session-based recommendation:\\n(i) in-context LLMs as recommendation agents, (ii) LLM-generated\\nrepresentations for semantic initialization of deep learning SR models, and\\n(iii) integration of LLMs with data-driven SR models. Through comprehensive\\nexperiments on two real-world publicly available datasets, we demonstrate that\\nLLM-based methods excel at coarse-level retrieval (high recall values), while\\ntraditional data-driven techniques perform well at fine-grained ranking (high\\nMean Reciprocal Rank values). Furthermore, the integration of LLMs with\\ndata-driven SR models significantly out performs both standalone LLM approaches\\nand data-driven deep learning models, as well as baseline SR models, in terms\\nof both Recall and MRR metrics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.20587v1.pdf'},\n",
       " {'id': '2507.18115v1',\n",
       "  'title': 'Agentic AI framework for End-to-End Medical Data Inference',\n",
       "  'published': '2025-07-24T05:56:25Z',\n",
       "  'summary': 'Building and deploying machine learning solutions in healthcare remains\\nexpensive and labor-intensive due to fragmented preprocessing workflows, model\\ncompatibility issues, and stringent data privacy constraints. In this work, we\\nintroduce an Agentic AI framework that automates the entire clinical data\\npipeline, from ingestion to inference, through a system of modular,\\ntask-specific agents. These agents handle both structured and unstructured\\ndata, enabling automatic feature selection, model selection, and preprocessing\\nrecommendation without manual intervention. We evaluate the system on publicly\\navailable datasets from geriatrics, palliative care, and colonoscopy imaging.\\nFor example, in the case of structured data (anxiety data) and unstructured\\ndata (colonoscopy polyps data), the pipeline begins with file-type detection by\\nthe Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring\\nprivacy compliance, where we first identify the data type and then anonymize\\nit. The Feature Extraction Agent identifies features using an embedding-based\\napproach for tabular data, extracting all column names, and a multi-stage\\nMedGemma-based approach for image data, which infers modality and disease name.\\nThese features guide the Model-Data Feature Matcher Agent in selecting the\\nbest-fit model from a curated repository. The Preprocessing Recommender Agent\\nand Preprocessing Implementor Agent then apply tailored preprocessing based on\\ndata type and model requirements. Finally, the ``Model Inference Agent\" runs\\nthe selected model on the uploaded data and generates interpretable outputs\\nusing tools like SHAP, LIME, and DETR attention maps. By automating these\\nhigh-friction stages of the ML lifecycle, the proposed framework reduces the\\nneed for repeated expert intervention, offering a scalable, cost-efficient\\npathway for operationalizing AI in clinical environments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.18115v1.pdf'},\n",
       " {'id': '1811.10686v1',\n",
       "  'title': 'Beyond \"How may I help you?\": Assisting Customer Service Agents with\\n  Proactive Responses',\n",
       "  'published': '2018-11-26T20:56:38Z',\n",
       "  'summary': 'We study the problem of providing recommended responses to customer service\\nagents in live-chat dialogue systems. Smart-reply systems have been widely\\napplied in real-world applications (e.g. Gmail, LinkedIn Messaging), where most\\nof them can successfully recommend reactive responses. However, we observe a\\nmajor limitation of current methods is that they generally have difficulties in\\nsuggesting proactive investigation act (e.g. \"Do you perhaps have another\\naccount with us?\") due to the lack of long-term context information, which\\nindeed act as critical steps for customer service agents to collect information\\nand resolve customers\\' issues. Thus in this work, we propose an end-to-end\\nmethod with special focus on suggesting proactive investigative questions to\\ncustomer agents in Airbnb\\'s customer service live-chat system. Effectiveness of\\nour proposed method can be validated through qualitative and quantitative\\nresults.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.10686v1.pdf'},\n",
       " {'id': '1810.10304v2',\n",
       "  'title': 'Optimal Algorithm for Bayesian Incentive-Compatible Exploration',\n",
       "  'published': '2018-10-24T11:47:54Z',\n",
       "  'summary': 'We consider a social planner faced with a stream of myopic selfish agents.\\nThe goal of the social planner is to maximize the social welfare, however, it\\nis limited to using only information asymmetry (regarding previous outcomes)\\nand cannot use any monetary incentives. The planner recommends actions to\\nagents, but her recommendations need to be Bayesian Incentive Compatible to be\\nfollowed by the agents. Our main result is an optimal algorithm for the\\nplanner, in the case that the actions realizations are deterministic and have\\nlimited support, making significant important progress on this open problem.\\nOur optimal protocol has two interesting features. First, it always completes\\nthe exploration of a priori more beneficial actions before exploring a priori\\nless beneficial actions. Second, the randomization in the protocol is\\ncorrelated across agents and actions (and not independent at each decision\\ntime).',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1810.10304v2.pdf'},\n",
       " {'id': '2110.00673v1',\n",
       "  'title': 'Multi-Agent Algorithmic Recourse',\n",
       "  'published': '2021-10-01T22:54:47Z',\n",
       "  'summary': 'The recent adoption of machine learning as a tool in real world decision\\nmaking has spurred interest in understanding how these decisions are being\\nmade. Counterfactual Explanations are a popular interpretable machine learning\\ntechnique that aims to understand how a machine learning model would behave if\\ngiven alternative inputs. Many explanations attempt to go further and recommend\\nactions an individual could take to obtain a more desirable output from the\\nmodel. These recommendations are known as algorithmic recourse. Past work has\\nlargely focused on the effect algorithmic recourse has on a single agent. In\\nthis work, we show that when the assumption of a single agent environment is\\nrelaxed, current approaches to algorithmic recourse fail to guarantee certain\\nethically desirable properties. Instead, we propose a new game theory inspired\\nframework for providing algorithmic recourse in a multi-agent environment that\\ndoes guarantee these properties.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.00673v1.pdf'},\n",
       " {'id': '2307.07746v1',\n",
       "  'title': 'Optimal Queue Design',\n",
       "  'published': '2023-07-15T08:55:37Z',\n",
       "  'summary': \"We study the optimal method for rationing scarce resources through a queue\\nsystem. The designer controls agents' entry into a queue and their exit, their\\nservice priority -- or queueing discipline -- as well as their information\\nabout queue priorities, while providing them with the incentive to join the\\nqueue and, importantly, to stay in the queue, when recommended by the designer.\\nUnder a mild condition, the optimal mechanism induces agents to enter up to a\\ncertain queue length and never removes any agents from the queue; serves them\\naccording to a first-come-first-served (FCFS) rule; and provides them with no\\ninformation throughout the process beyond the recommendations they receive.\\nFCFS is also necessary for optimality in a rich domain. We identify a novel\\nrole for queueing disciplines in regulating agents' beliefs and their dynamic\\nincentives and uncover a hitherto unrecognized virtue of FCFS in this regard.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.07746v1.pdf'},\n",
       " {'id': '2407.02759v1',\n",
       "  'title': 'Multi-Scenario Combination Based on Multi-Agent Reinforcement Learning\\n  to Optimize the Advertising Recommendation System',\n",
       "  'published': '2024-07-03T02:33:20Z',\n",
       "  'summary': \"This paper explores multi-scenario optimization on large platforms using\\nmulti-agent reinforcement learning (MARL). We address this by treating\\nscenarios like search, recommendation, and advertising as a cooperative,\\npartially observable multi-agent decision problem. We introduce the Multi-Agent\\nRecurrent Deterministic Policy Gradient (MARDPG) algorithm, which aligns\\ndifferent scenarios under a shared objective and allows for strategy\\ncommunication to boost overall performance. Our results show marked\\nimprovements in metrics such as click-through rate (CTR), conversion rate, and\\ntotal sales, confirming our method's efficacy in practical settings.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.02759v1.pdf'},\n",
       " {'id': '2508.04025v1',\n",
       "  'title': 'Uncertainty-Aware GUI Agent: Adaptive Perception through Component\\n  Recommendation and Human-in-the-Loop Refinement',\n",
       "  'published': '2025-08-06T02:38:02Z',\n",
       "  'summary': 'Graphical user interface (GUI) agents have shown promise in automating mobile\\ntasks but still struggle with input redundancy and decision ambiguity. In this\\npaper, we present \\\\textbf{RecAgent}, an uncertainty-aware agent that addresses\\nthese issues through adaptive perception. We distinguish two types of\\nuncertainty in GUI navigation: (1) perceptual uncertainty, caused by input\\nredundancy and noise from comprehensive screen information, and (2) decision\\nuncertainty, arising from ambiguous tasks and complex reasoning. To reduce\\nperceptual uncertainty, RecAgent employs a component recommendation mechanism\\nthat identifies and focuses on the most relevant UI elements. For decision\\nuncertainty, it uses an interactive module to request user feedback in\\nambiguous situations, enabling intent-aware decisions. These components are\\nintegrated into a unified framework that proactively reduces input complexity\\nand reacts to high-uncertainty cases via human-in-the-loop refinement.\\nAdditionally, we propose a dataset called \\\\textbf{ComplexAction} to evaluate\\nthe success rate of GUI agents in executing specified single-step actions\\nwithin complex scenarios. Extensive experiments validate the effectiveness of\\nour approach. The dataset and code will be available at\\nhttps://github.com/Fanye12/RecAgent.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.04025v1.pdf'},\n",
       " {'id': '2010.07035v1',\n",
       "  'title': 'MARS-Gym: A Gym framework to model, train, and evaluate Recommender\\n  Systems for Marketplaces',\n",
       "  'published': '2020-09-30T16:39:31Z',\n",
       "  'summary': 'Recommender Systems are especially challenging for marketplaces since they\\nmust maximize user satisfaction while maintaining the healthiness and fairness\\nof such ecosystems. In this context, we observed a lack of resources to design,\\ntrain, and evaluate agents that learn by interacting within these environments.\\nFor this matter, we propose MARS-Gym, an open-source framework to empower\\nresearchers and engineers to quickly build and evaluate Reinforcement Learning\\nagents for recommendations in marketplaces. MARS-Gym addresses the whole\\ndevelopment pipeline: data processing, model design and optimization, and\\nmulti-sided evaluation. We also provide the implementation of a diverse set of\\nbaseline agents, with a metrics-driven analysis of them in the Trivago\\nmarketplace dataset, to illustrate how to conduct a holistic assessment using\\nthe available metrics of recommendation, off-policy estimation, and fairness.\\nWith MARS-Gym, we expect to bridge the gap between academic research and\\nproduction systems, as well as to facilitate the design of new algorithms and\\napplications.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.07035v1.pdf'},\n",
       " {'id': '2102.13073v2',\n",
       "  'title': 'Where to go next: Learning a Subgoal Recommendation Policy for\\n  Navigation Among Pedestrians',\n",
       "  'published': '2021-02-25T18:41:58Z',\n",
       "  'summary': 'Robotic navigation in environments shared with other robots or humans remains\\nchallenging because the intentions of the surrounding agents are not directly\\nobservable and the environment conditions are continuously changing. Local\\ntrajectory optimization methods, such as model predictive control (MPC), can\\ndeal with those changes but require global guidance, which is not trivial to\\nobtain in crowded scenarios. This paper proposes to learn, via deep\\nReinforcement Learning (RL), an interaction-aware policy that provides\\nlong-term guidance to the local planner. In particular, in simulations with\\ncooperative and non-cooperative agents, we train a deep network to recommend a\\nsubgoal for the MPC planner. The recommended subgoal is expected to help the\\nrobot in making progress towards its goal and accounts for the expected\\ninteraction with other agents. Based on the recommended subgoal, the MPC\\nplanner then optimizes the inputs for the robot satisfying its kinodynamic and\\ncollision avoidance constraints. Our approach is shown to substantially improve\\nthe navigation performance in terms of number of collisions as compared to\\nprior MPC frameworks, and in terms of both travel time and number of collisions\\ncompared to deep RL methods in cooperative, competitive and mixed multiagent\\nscenarios.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.13073v2.pdf'},\n",
       " {'id': '2203.13769v1',\n",
       "  'title': 'An Audit of Misinformation Filter Bubbles on YouTube: Bubble Bursting\\n  and Recent Behavior Changes',\n",
       "  'published': '2022-03-25T16:49:57Z',\n",
       "  'summary': 'The negative effects of misinformation filter bubbles in adaptive systems\\nhave been known to researchers for some time. Several studies investigated,\\nmost prominently on YouTube, how fast a user can get into a misinformation\\nfilter bubble simply by selecting wrong choices from the items offered. Yet, no\\nstudies so far have investigated what it takes to burst the bubble, i.e.,\\nrevert the bubble enclosure. We present a study in which pre-programmed agents\\n(acting as YouTube users) delve into misinformation filter bubbles by watching\\nmisinformation promoting content (for various topics). Then, by watching\\nmisinformation debunking content, the agents try to burst the bubbles and reach\\nmore balanced recommendation mixes. We recorded the search results and\\nrecommendations, which the agents encountered, and analyzed them for the\\npresence of misinformation. Our key finding is that bursting of a filter bubble\\nis possible, albeit it manifests differently from topic to topic. Moreover, we\\nobserve that filter bubbles do not truly appear in some situations. We also\\ndraw a direct comparison with a previous study. Sadly, we did not find much\\nimprovements in misinformation occurrences, despite recent pledges by YouTube.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2203.13769v1.pdf'},\n",
       " {'id': '2310.19536v1',\n",
       "  'title': 'Adversarial Batch Inverse Reinforcement Learning: Learn to Reward from\\n  Imperfect Demonstration for Interactive Recommendation',\n",
       "  'published': '2023-10-30T13:43:20Z',\n",
       "  'summary': 'Rewards serve as a measure of user satisfaction and act as a limiting factor\\nin interactive recommender systems. In this research, we focus on the problem\\nof learning to reward (LTR), which is fundamental to reinforcement learning.\\nPrevious approaches either introduce additional procedures for learning to\\nreward, thereby increasing the complexity of optimization, or assume that\\nuser-agent interactions provide perfect demonstrations, which is not feasible\\nin practice. Ideally, we aim to employ a unified approach that optimizes both\\nthe reward and policy using compositional demonstrations. However, this\\nrequirement presents a challenge since rewards inherently quantify user\\nfeedback on-policy, while recommender agents approximate off-policy future\\ncumulative valuation. To tackle this challenge, we propose a novel batch\\ninverse reinforcement learning paradigm that achieves the desired properties.\\nOur method utilizes discounted stationary distribution correction to combine\\nLTR and recommender agent evaluation. To fulfill the compositional requirement,\\nwe incorporate the concept of pessimism through conservation. Specifically, we\\nmodify the vanilla correction using Bellman transformation and enforce KL\\nregularization to constrain consecutive policy updates. We use two real-world\\ndatasets which represent two compositional coverage to conduct empirical\\nstudies, the results also show that the proposed method relatively improves\\nboth effectiveness (2.3\\\\%) and efficiency (11.53\\\\%)',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.19536v1.pdf'},\n",
       " {'id': 'nlin/0410034v1',\n",
       "  'title': 'Size-Distribution Scaling in Clusters of Allelomimetic Agents',\n",
       "  'published': '2004-10-19T13:22:55Z',\n",
       "  'summary': 'The allelomimesis clustering model is based on only two parameters: a local\\nparameter $\\\\alpha$ that represents the probability of nearest-neighbor copying\\nand a global parameter $p$ that represents the fraction of unresponsive agents.\\nThe model results into the formation of clusters of agents, the sizes of which\\nobey a distribution that is determined by the values of $\\\\alpha$ and $p$.\\nSeveral experimental data are fitted by tuning the two parameters. In\\nparticular, the significance of the value of $\\\\alpha$ that corresponds to an\\nexperimental data is discussed and is justified according to behavioral\\ncontext. Recommendations for possible extensions of the model are also\\nenumerated.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/nlin/0410034v1.pdf'},\n",
       " {'id': '2112.01146v1',\n",
       "  'title': 'Conversational Agents in Therapeutic Interventions for\\n  Neurodevelopmental Disorders: A Survey',\n",
       "  'published': '2021-12-02T11:51:13Z',\n",
       "  'summary': 'Neurodevelopmental Disorders (NDD) are a group of conditions with onset in\\nthe developmental period characterized by deficits in the cognitive and social\\nareas. Conversational agents have been increasingly explored to support\\ntherapeutic interventions for people with NDD. This survey provides a\\nstructured view of the crucial design features of these systems, the types of\\ntherapeutic goals they address, and the empirical methods adopted for their\\nevaluation. From this analysis, we elaborate a set of recommendations and\\nhighlight the gaps left unsolved in the state of the art, upon which we ground\\na research agenda on conversational agents for NDD.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.01146v1.pdf'},\n",
       " {'id': '2502.07393v1',\n",
       "  'title': 'FinRL-DeepSeek: LLM-Infused Risk-Sensitive Reinforcement Learning for\\n  Trading Agents',\n",
       "  'published': '2025-02-11T09:23:14Z',\n",
       "  'summary': 'This paper presents a novel risk-sensitive trading agent combining\\nreinforcement learning and large language models (LLMs). We extend the\\nConditional Value-at-Risk Proximal Policy Optimization (CPPO) algorithm, by\\nadding risk assessment and trading recommendation signals generated by a LLM\\nfrom financial news. Our approach is backtested on the Nasdaq-100 index\\nbenchmark, using financial news data from the FNSPID dataset and the DeepSeek\\nV3, Qwen 2.5 and Llama 3.3 language models. The code, data, and trading agents\\nare available at: https://github.com/benstaf/FinRL_DeepSeek',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.07393v1.pdf'},\n",
       " {'id': '2201.10983v3',\n",
       "  'title': 'Online POI Recommendation: Learning Dynamic Geo-Human Interactions in\\n  Streams',\n",
       "  'published': '2022-01-19T16:49:49Z',\n",
       "  'summary': 'In this paper, we focus on the problem of modeling dynamic geo-human\\ninteractions in streams for online POI recommendations. Specifically, we\\nformulate the in-stream geo-human interaction modeling problem into a novel\\ndeep interactive reinforcement learning framework, where an agent is a\\nrecommender and an action is a next POI to visit. We uniquely model the\\nreinforcement learning environment as a joint and connected composition of\\nusers and geospatial contexts (POIs, POI categories, functional zones). An\\nevent that a user visits a POI in stream updates the states of both users and\\ngeospatial contexts; the agent perceives the updated environment state to make\\nonline recommendations. Specifically, we model a mixed-user event stream by\\nunifying all users, visits, and geospatial contexts as a dynamic knowledge\\ngraph stream, in order to model human-human, geo-human, geo-geo interactions.\\nWe design an exit mechanism to address the expired information challenge,\\ndevise a meta-path method to address the recommendation candidate generation\\nchallenge, and develop a new deep policy network structure to address the\\nvarying action space challenge, and, finally, propose an effective adversarial\\ntraining method for optimization. Finally, we present extensive experiments to\\ndemonstrate the enhanced performance of our method.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.10983v3.pdf'},\n",
       " {'id': '2212.05173v1',\n",
       "  'title': 'Activity-Based Recommendations for Demand Response in Smart Sustainable\\n  Buildings',\n",
       "  'published': '2022-12-10T01:44:37Z',\n",
       "  'summary': 'The energy consumption of private households amounts to approximately 30% of\\nthe total global energy consumption, causing a large share of the CO2 emissions\\nthrough energy production. An intelligent demand response via load shifting\\nincreases the energy efficiency of residential buildings by nudging residents\\nto change their energy consumption behavior. This paper introduces an activity\\nprediction-based framework for the utility-based context-aware multi-agent\\nrecommendation system that generates an activity shifting schedule for a\\n24-hour time horizon to either focus on CO2 emissions or energy cost savings.\\nIn particular, we design and implement an Activity Agent that uses hourly\\nenergy consumption data. It does not require further sensorial data or activity\\nlabels which reduces implementation costs and the need for extensive user\\ninput. Moreover, the system enhances the utility option of saving energy costs\\nby saving CO2 emissions and provides the possibility to focus on both\\ndimensions. The empirical results show that while setting the focus on CO2\\nemissions savings, the system provides an average of 12% of emissions savings\\nand 7% of cost savings. When focusing on energy cost savings, 20% of energy\\ncosts and 6% of emissions savings are possible for the studied households in\\ncase of accepting all recommendations. Recommending an activity schedule, the\\nsystem uses the same terms residents describe their domestic life. Therefore,\\nrecommendations can be more easily integrated into daily life supporting the\\nacceptance of the system in a long-term perspective.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2212.05173v1.pdf'},\n",
       " {'id': '2312.06853v2',\n",
       "  'title': 'LLF-Bench: Benchmark for Interactive Learning from Language Feedback',\n",
       "  'published': '2023-12-11T21:49:04Z',\n",
       "  'summary': 'We introduce a new benchmark, LLF-Bench (Learning from Language Feedback\\nBenchmark; pronounced as \"elf-bench\"), to evaluate the ability of AI agents to\\ninteractively learn from natural language feedback and instructions. Learning\\nfrom language feedback (LLF) is essential for people, largely because the rich\\ninformation this feedback provides can help a learner avoid much of trial and\\nerror and thereby speed up the learning process. Large Language Models (LLMs)\\nhave recently enabled AI agents to comprehend natural language -- and hence AI\\nagents can potentially benefit from language feedback during learning like\\nhumans do. But existing interactive benchmarks do not assess this crucial\\ncapability: they either use numeric reward feedback or require no learning at\\nall (only planning or information retrieval). LLF-Bench is designed to fill\\nthis omission. LLF-Bench is a diverse collection of sequential decision-making\\ntasks that includes user recommendation, poem writing, navigation, and robot\\ncontrol. The objective of an agent is to interactively solve these tasks based\\non their natural-language instructions and the feedback received after taking\\nactions. Crucially, to ensure that the agent actually \"learns\" from the\\nfeedback, LLF-Bench implements several randomization techniques (such as\\nparaphrasing and environment randomization) to ensure that the task isn\\'t\\nfamiliar to the agent and that the agent is robust to various verbalizations.\\nIn addition, LLF-Bench provides a unified OpenAI Gym interface for all its\\ntasks and allows the users to easily configure the information the feedback\\nconveys (among suggestion, explanation, and instantaneous performance) to study\\nhow agents respond to different types of feedback. Together, these features\\nmake LLF-Bench a unique research platform for developing and testing LLF\\nagents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.06853v2.pdf'},\n",
       " {'id': '2504.15304v1',\n",
       "  'title': 'Can Machine Learning Agents Deal with Hard Choices?',\n",
       "  'published': '2025-04-18T14:38:27Z',\n",
       "  'summary': 'Machine Learning ML agents have been increasingly used in decision-making\\nacross a wide range of tasks and environments. These ML agents are typically\\ndesigned to balance multiple objectives when making choices. Understanding how\\ntheir decision-making processes align with or diverge from human reasoning is\\nessential. Human agents often encounter hard choices, that is, situations where\\noptions are incommensurable; neither option is preferred, yet the agent is not\\nindifferent between them. In such cases, human agents can identify hard choices\\nand resolve them through deliberation. In contrast, current ML agents, due to\\nfundamental limitations in Multi-Objective Optimisation or MOO methods, cannot\\nidentify hard choices, let alone resolve them. Neither Scalarised Optimisation\\nnor Pareto Optimisation, the two principal MOO approaches, can capture\\nincommensurability. This limitation generates three distinct alignment\\nproblems: the alienness of ML decision-making behaviour from a human\\nperspective; the unreliability of preference-based alignment strategies for\\nhard choices; and the blockage of alignment strategies pursuing multiple\\nobjectives. Evaluating two potential technical solutions, I recommend an\\nensemble solution that appears most promising for enabling ML agents to\\nidentify hard choices and mitigate alignment problems. However, no known\\ntechnique allows ML agents to resolve hard choices through deliberation, as\\nthey cannot autonomously change their goals. This underscores the\\ndistinctiveness of human agency and urges ML researchers to reconceptualise\\nmachine autonomy and develop frameworks and methods that can better address\\nthis fundamental gap.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.15304v1.pdf'},\n",
       " {'id': '2206.13960v1',\n",
       "  'title': 'Dynamic Memory for Interpretable Sequential Optimisation',\n",
       "  'published': '2022-06-28T12:29:13Z',\n",
       "  'summary': 'Real-world applications of reinforcement learning for recommendation and\\nexperimentation faces a practical challenge: the relative reward of different\\nbandit arms can evolve over the lifetime of the learning agent. To deal with\\nthese non-stationary cases, the agent must forget some historical knowledge, as\\nit may no longer be relevant to minimise regret. We present a solution to\\nhandling non-stationarity that is suitable for deployment at scale, to provide\\nbusiness operators with automated adaptive optimisation. Our solution aims to\\nprovide interpretable learning that can be trusted by humans, whilst responding\\nto non-stationarity to minimise regret. To this end, we develop an adaptive\\nBayesian learning agent that employs a novel form of dynamic memory. It enables\\ninterpretability through statistical hypothesis testing, by targeting a set\\npoint of statistical power when comparing rewards and adjusting its memory\\ndynamically to achieve this power. By design, the agent is agnostic to\\ndifferent kinds of non-stationarity. Using numerical simulations, we compare\\nits performance against an existing proposal and show that, under multiple\\nnon-stationary scenarios, our agent correctly adapts to real changes in the\\ntrue rewards. In all bandit solutions, there is an explicit trade-off between\\nlearning and achieving maximal performance. Our solution sits on a different\\npoint on this trade-off when compared to another similarly robust approach: we\\nprioritise interpretability, which relies on more learning, at the cost of some\\nregret. We describe the architecture of a large-scale deployment of automatic\\noptimisation-as-a-service where our agent achieves interpretability whilst\\nadapting to changing circumstances.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.13960v1.pdf'},\n",
       " {'id': '2404.13954v1',\n",
       "  'title': 'A survey of air combat behavior modeling using machine learning',\n",
       "  'published': '2024-04-22T07:54:56Z',\n",
       "  'summary': 'With the recent advances in machine learning, creating agents that behave\\nrealistically in simulated air combat has become a growing field of interest.\\nThis survey explores the application of machine learning techniques for\\nmodeling air combat behavior, motivated by the potential to enhance\\nsimulation-based pilot training. Current simulated entities tend to lack\\nrealistic behavior, and traditional behavior modeling is labor-intensive and\\nprone to loss of essential domain knowledge between development steps.\\nAdvancements in reinforcement learning and imitation learning algorithms have\\ndemonstrated that agents may learn complex behavior from data, which could be\\nfaster and more scalable than manual methods. Yet, making adaptive agents\\ncapable of performing tactical maneuvers and operating weapons and sensors\\nstill poses a significant challenge. The survey examines applications, behavior\\nmodel types, prevalent machine learning methods, and the technical and human\\nchallenges in developing adaptive and realistically behaving agents. Another\\nchallenge is the transfer of agents from learning environments to military\\nsimulation systems and the consequent demand for standardization. Four primary\\nrecommendations are presented regarding increased emphasis on\\nbeyond-visual-range scenarios, multi-agent machine learning and cooperation,\\nutilization of hierarchical behavior models, and initiatives for\\nstandardization and research collaboration. These recommendations aim to\\naddress current issues and guide the development of more comprehensive,\\nadaptable, and realistic machine learning-based behavior models for air combat\\napplications.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.13954v1.pdf'},\n",
       " {'id': 'cs/0511011v1',\n",
       "  'title': 'The Impact of Social Networks on Multi-Agent Recommender Systems',\n",
       "  'published': '2005-11-02T23:44:34Z',\n",
       "  'summary': \"Awerbuch et al.'s approach to distributed recommender systems (DRSs) is to\\nhave agents sample products at random while randomly querying one another for\\nthe best item they have found; we improve upon this by adding a communication\\nnetwork. Agents can only communicate with their immediate neighbors in the\\nnetwork, but neighboring agents may or may not represent users with common\\ninterests. We define two network structures: in the ``mailing-list model,''\\nagents representing similar users form cliques, while in the ``word-of-mouth\\nmodel'' the agents are distributed randomly in a scale-free network (SFN). In\\nboth models, agents tell their neighbors about satisfactory products as they\\nare found. In the word-of-mouth model, knowledge of items propagates only\\nthrough interested agents, and the SFN parameters affect the system's\\nperformance. We include a summary of our new results on the character and\\nparameters of random subgraphs of SFNs, in particular SFNs with power-law\\ndegree distributions down to minimum degree 1. These networks are not as\\nresilient as Cohen et al. originally suggested. In the case of the widely-cited\\n``Internet resilience'' result, high failure rates actually lead to the\\norphaning of half of the surviving nodes after 60% of the network has failed\\nand the complete disintegration of the network at 90%. We show that given an\\nappropriate network, the communication network reduces the number of sampled\\nitems, the number of messages sent, and the amount of ``spam.'' We conclude\\nthat in many cases DRSs will be useful for sharing information in a multi-agent\\nlearning system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/cs/0511011v1.pdf'},\n",
       " {'id': '2107.06720v2',\n",
       "  'title': 'Fairness in Ranking under Uncertainty',\n",
       "  'published': '2021-07-14T14:10:16Z',\n",
       "  'summary': \"Fairness has emerged as an important consideration in algorithmic\\ndecision-making. Unfairness occurs when an agent with higher merit obtains a\\nworse outcome than an agent with lower merit. Our central point is that a\\nprimary cause of unfairness is uncertainty. A principal or algorithm making\\ndecisions never has access to the agents' true merit, and instead uses proxy\\nfeatures that only imperfectly predict merit (e.g., GPA, star ratings,\\nrecommendation letters). None of these ever fully capture an agent's merit; yet\\nexisting approaches have mostly been defining fairness notions directly based\\non observed features and outcomes.\\n  Our primary point is that it is more principled to acknowledge and model the\\nuncertainty explicitly. The role of observed features is to give rise to a\\nposterior distribution of the agents' merits. We use this viewpoint to define a\\nnotion of approximate fairness in ranking. We call an algorithm $\\\\phi$-fair\\n(for $\\\\phi \\\\in [0,1]$) if it has the following property for all agents $x$ and\\nall $k$: if agent $x$ is among the top $k$ agents with respect to merit with\\nprobability at least $\\\\rho$ (according to the posterior merit distribution),\\nthen the algorithm places the agent among the top $k$ agents in its ranking\\nwith probability at least $\\\\phi \\\\rho$.\\n  We show how to compute rankings that optimally trade off approximate fairness\\nagainst utility to the principal. In addition to the theoretical\\ncharacterization, we present an empirical analysis of the potential impact of\\nthe approach in simulation studies. For real-world validation, we applied the\\napproach in the context of a paper recommendation system that we built and\\nfielded at the KDD 2020 conference.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2107.06720v2.pdf'},\n",
       " {'id': '1510.02049v1',\n",
       "  'title': 'Assisting Composition of Email Responses: a Topic Prediction Approach',\n",
       "  'published': '2015-10-07T18:08:45Z',\n",
       "  'summary': 'We propose an approach for helping agents compose email replies to customer\\nrequests. To enable that, we use LDA to extract latent topics from a collection\\nof email exchanges. We then use these latent topics to label our data,\\nobtaining a so-called \"silver standard\" topic labelling. We exploit this\\nlabelled set to train a classifier to: (i) predict the topic distribution of\\nthe entire agent\\'s email response, based on features of the customer\\'s email;\\nand (ii) predict the topic distribution of the next sentence in the agent\\'s\\nreply, based on the customer\\'s email features and on features of the agent\\'s\\ncurrent sentence. The experimental results on a large email collection from a\\ncontact center in the tele- com domain show that the proposed ap- proach is\\neffective in predicting the best topic of the agent\\'s next sentence. In 80% of\\nthe cases, the correct topic is present among the top five recommended topics\\n(out of fifty possible ones). This shows the potential of this method to be\\napplied in an interactive setting, where the agent is presented a small list of\\nlikely topics to choose from for the next sentence.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1510.02049v1.pdf'},\n",
       " {'id': '1912.01741v1',\n",
       "  'title': 'A Dataset Schema for Cooperative Learning from Demonstration in\\n  Multi-robots Systems',\n",
       "  'published': '2019-12-03T23:42:24Z',\n",
       "  'summary': \"Multi-Agent Systems (MASs) have been used to solve complex problems that\\ndemand intelligent agents working together to reach the desired goals. These\\nAgents should effectively synchronize their individual behaviors so that they\\ncan act as a team in a coordinated manner to achieve the common goal of the\\nwhole system. One of the main issues in MASs is the agents' coordination, being\\ncommon domain experts observing MASs execution disapprove agents' decisions.\\nEven if the MAS was designed using the best methods and tools for agents'\\ncoordination, this difference of decisions between experts and MAS is\\nconfirmed. Therefore, this paper proposes a new dataset schema to support\\nlearning the coordinated behavior in MASs from demonstration. The results of\\nthe proposed solution are validated in a Multi-Robot System (MRS) organizing a\\ncollection of new cooperative plans recommendations from the demonstration by\\ndomain experts.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1912.01741v1.pdf'},\n",
       " {'id': '2007.09645v3',\n",
       "  'title': 'Design and Analysis of a Multi-Agent E-Learning System Using Prometheus\\n  Design Tool',\n",
       "  'published': '2020-07-19T10:37:52Z',\n",
       "  'summary': 'Agent unified modeling languages (AUML) are agent-oriented approaches that\\nsupports the specification, design, visualization and documentation of an\\nagent-based system. This paper presents the use of Prometheus AUML approach for\\nthe modeling of a Pre-assessment System of five interactive agents. The\\nPre-assessment System, as previously reported, is a multi-agent based\\ne-learning system that is developed to support the assessment of prior learning\\nskills in students so as to classify their skills and make recommendation for\\ntheir learning. This paper discusses the detailed design approach of the system\\nin a step-by-step manner; and domain knowledge abstraction and organization in\\nthe system. In addition, the analysis of the data collated and models of\\nprediction for future pre-assessment results are also presented.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.09645v3.pdf'},\n",
       " {'id': '2303.06935v1',\n",
       "  'title': 'Importance Filtering with Risk Models for Complex Driving Situations',\n",
       "  'published': '2023-03-13T09:03:10Z',\n",
       "  'summary': 'Self-driving cars face complex driving situations with a large amount of\\nagents when moving in crowded cities. However, some of the agents are actually\\nnot influencing the behavior of the self-driving car. Filtering out unimportant\\nagents would inherently simplify the behavior or motion planning task for the\\nsystem. The planning system can then focus on fewer agents to find optimal\\nbehavior solutions for the ego~agent. This is helpful especially in terms of\\ncomputational efficiency. In this paper, therefore, the research topic of\\nimportance filtering with driving risk models is introduced. We give an\\noverview of state-of-the-art risk models and present newly adapted risk models\\nfor filtering. Their capability to filter out surrounding unimportant agents is\\ncompared in a large-scale experiment. As it turns out, the novel trajectory\\ndistance balances performance, robustness and efficiency well. Based on the\\nresults, we can further derive a novel filter architecture with multiple filter\\nsteps, for which risk models are recommended for each step, to further improve\\nthe robustness. We are confident that this will enable current behavior\\nplanning systems to better solve complex situations in everyday driving.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.06935v1.pdf'},\n",
       " {'id': '2404.08630v1',\n",
       "  'title': 'A Conceptual Framework for Conversational Search and Recommendation:\\n  Conceptualizing Agent-Human Interactions During the Conversational Search\\n  Process',\n",
       "  'published': '2024-04-12T17:48:18Z',\n",
       "  'summary': 'The conversational search task aims to enable a user to resolve information\\nneeds via natural language dialogue with an agent. In this paper, we aim to\\ndevelop a conceptual framework of the actions and intents of users and agents\\nexplaining how these actions enable the user to explore the search space and\\nresolve their information need. We outline the different actions and intents,\\nbefore discussing key decision points in the conversation where the agent needs\\nto decide how to steer the conversational search process to a successful and/or\\nsatisfactory conclusion. Essentially, this paper provides a conceptualization\\nof the conversational search process between an agent and user, which provides\\na framework and a starting point for research, development and evaluation of\\nconversational search agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.08630v1.pdf'},\n",
       " {'id': '2504.09855v1',\n",
       "  'title': 'PestMA: LLM-based Multi-Agent System for Informed Pest Management',\n",
       "  'published': '2025-04-14T03:53:59Z',\n",
       "  'summary': 'Effective pest management is complex due to the need for accurate,\\ncontext-specific decisions. Recent advancements in large language models (LLMs)\\nopen new possibilities for addressing these challenges by providing\\nsophisticated, adaptive knowledge acquisition and reasoning. However, existing\\nLLM-based pest management approaches often rely on a single-agent paradigm,\\nwhich can limit their capacity to incorporate diverse external information,\\nengage in systematic validation, and address complex, threshold-driven\\ndecisions. To overcome these limitations, we introduce PestMA, an LLM-based\\nmulti-agent system (MAS) designed to generate reliable and evidence-based pest\\nmanagement advice. Building on an editorial paradigm, PestMA features three\\nspecialized agents, an Editor for synthesizing pest management recommendations,\\na Retriever for gathering relevant external data, and a Validator for ensuring\\ncorrectness. Evaluations on real-world pest scenarios demonstrate that PestMA\\nachieves an initial accuracy of 86.8% for pest management decisions, which\\nincreases to 92.6% after validation. These results underscore the value of\\ncollaborative agent-based workflows in refining and validating decisions,\\nhighlighting the potential of LLM-based multi-agent systems to automate and\\nenhance pest management processes.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.09855v1.pdf'},\n",
       " {'id': '2505.23720v1',\n",
       "  'title': 'COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic\\n  Agents',\n",
       "  'published': '2025-05-29T17:53:12Z',\n",
       "  'summary': \"This paper considers a contextual bandit problem involving multiple agents,\\nwhere a learner sequentially observes the contexts and the agent's reported\\narms, and then selects the arm that maximizes the system's overall reward.\\nExisting work in contextual bandits assumes that agents truthfully report their\\narms, which is unrealistic in many real-life applications. For instance,\\nconsider an online platform with multiple sellers; some sellers may\\nmisrepresent product quality to gain an advantage, such as having the platform\\npreferentially recommend their products to online users. To address this\\nchallenge, we propose an algorithm, COBRA, for contextual bandit problems\\ninvolving strategic agents that disincentivize their strategic behavior without\\nusing any monetary incentives, while having incentive compatibility and a\\nsub-linear regret guarantee. Our experimental results also validate the\\ndifferent performance aspects of our proposed algorithm.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.23720v1.pdf'},\n",
       " {'id': '2211.00779v1',\n",
       "  'title': 'Reinforcement Learning in Education: A Multi-Armed Bandit Approach',\n",
       "  'published': '2022-11-01T22:47:17Z',\n",
       "  'summary': 'Advances in reinforcement learning research have demonstrated the ways in\\nwhich different agent-based models can learn how to optimally perform a task\\nwithin a given environment. Reinforcement leaning solves unsupervised problems\\nwhere agents move through a state-action-reward loop to maximize the overall\\nreward for the agent, which in turn optimizes the solving of a specific problem\\nin a given environment. However, these algorithms are designed based on our\\nunderstanding of actions that should be taken in a real-world environment to\\nsolve a specific problem. One such problem is the ability to identify,\\nrecommend and execute an action within a system where the users are the\\nsubject, such as in education. In recent years, the use of blended learning\\napproaches integrating face-to-face learning with online learning in the\\neducation context, has in-creased. Additionally, online platforms used for\\neducation require the automation of certain functions such as the\\nidentification, recommendation or execution of actions that can benefit the\\nuser, in this sense, the student or learner. As promising as these scientific\\nadvances are, there is still a need to conduct research in a variety of\\ndifferent areas to ensure the successful deployment of these agents within\\neducation systems. Therefore, the aim of this study was to contextualise and\\nsimulate the cumulative reward within an environment for an intervention\\nrecommendation problem in the education context.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.00779v1.pdf'},\n",
       " {'id': '2310.09412v1',\n",
       "  'title': 'Hybrid Reinforcement Learning for Optimizing Pump Sustainability in\\n  Real-World Water Distribution Networks',\n",
       "  'published': '2023-10-13T21:26:16Z',\n",
       "  'summary': 'This article addresses the pump-scheduling optimization problem to enhance\\nreal-time control of real-world water distribution networks (WDNs). Our primary\\nobjectives are to adhere to physical operational constraints while reducing\\nenergy consumption and operational costs. Traditional optimization techniques,\\nsuch as evolution-based and genetic algorithms, often fall short due to their\\nlack of convergence guarantees. Conversely, reinforcement learning (RL) stands\\nout for its adaptability to uncertainties and reduced inference time, enabling\\nreal-time responsiveness. However, the effective implementation of RL is\\ncontingent on building accurate simulation models for WDNs, and prior\\napplications have been limited by errors in simulation training data. These\\nerrors can potentially cause the RL agent to learn misleading patterns and\\nactions and recommend suboptimal operational strategies. To overcome these\\nchallenges, we present an improved \"hybrid RL\" methodology. This method\\nintegrates the benefits of RL while anchoring it in historical data, which\\nserves as a baseline to incrementally introduce optimal control\\nrecommendations. By leveraging operational data as a foundation for the agent\\'s\\nactions, we enhance the explainability of the agent\\'s actions, foster more\\nrobust recommendations, and minimize error. Our findings demonstrate that the\\nhybrid RL agent can significantly improve sustainability, operational\\nefficiency, and dynamically adapt to emerging scenarios in real-world WDNs.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.09412v1.pdf'},\n",
       " {'id': '2502.15698v1',\n",
       "  'title': 'Developing an Artificial Intelligence Tool for Personalized Breast\\n  Cancer Treatment Plans based on the NCCN Guidelines',\n",
       "  'published': '2025-01-06T02:16:20Z',\n",
       "  'summary': \"Cancer treatments require personalized approaches based on a patient's\\nclinical condition, medical history, and evidence-based guidelines. The\\nNational Comprehensive Cancer Network (NCCN) provides frequently updated,\\ncomplex guidelines through visuals like flowcharts and diagrams, which can be\\ntime consuming for oncologists to stay current with treatment protocols. This\\nstudy presents an AI (Artificial Intelligence)-driven methodology to accurately\\nautomate treatment regimens following NCCN guidelines for breast cancer\\npatients.\\n  We proposed two AI-driven methods: Agentic-RAG (Retrieval-Augmented\\nGeneration) and Graph-RAG. Agentic-RAG used a three-step Large Language Model\\n(LLM) process to select clinical titles from NCCN guidelines, retrieve matching\\nJSON content, and iteratively refine recommendations based on insufficiency\\nchecks. Graph-RAG followed a Microsoft-developed framework with proprietary\\nprompts, where JSON data was converted to text via an LLM, summarized, and\\nmapped into graph structures representing key treatment relationships. Final\\nrecommendations were generated by querying relevant graph summaries. Both were\\nevaluated using a set of patient descriptions, each with four associated\\nquestions.\\n  As shown in Table 1, Agentic RAG achieved a 100% adherence (24/24) with no\\nhallucinations or incorrect treatments. Graph-RAG had 95.8% adherence (23/24)\\nwith one incorrect treatment and no hallucinations. Chat GPT-4 showed 91.6%\\nadherence (22/24) with two wrong treatments and no hallucinations. Both Agentic\\nRAG and Graph-RAG provided detailed treatment recommendations with accurate\\nreferences to relevant NCCN document page numbers.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.15698v1.pdf'},\n",
       " {'id': '2502.18754v1',\n",
       "  'title': 'AgentSociety Challenge: Designing LLM Agents for User Modeling and\\n  Recommendation on Web Platforms',\n",
       "  'published': '2025-02-26T02:10:25Z',\n",
       "  'summary': 'The AgentSociety Challenge is the first competition in the Web Conference\\nthat aims to explore the potential of Large Language Model (LLM) agents in\\nmodeling user behavior and enhancing recommender systems on web platforms. The\\nChallenge consists of two tracks: the User Modeling Track and the\\nRecommendation Track. Participants are tasked to utilize a combined dataset\\nfrom Yelp, Amazon, and Goodreads, along with an interactive environment\\nsimulator, to develop innovative LLM agents. The Challenge has attracted 295\\nteams across the globe and received over 1,400 submissions in total over the\\ncourse of 37 official competition days. The participants have achieved 21.9%\\nand 20.3% performance improvement for Track 1 and Track 2 in the Development\\nPhase, and 9.1% and 15.9% in the Final Phase, representing a significant\\naccomplishment. This paper discusses the detailed designs of the Challenge,\\nanalyzes the outcomes, and highlights the most successful LLM agent designs. To\\nsupport further research and development, we have open-sourced the benchmark\\nenvironment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.18754v1.pdf'},\n",
       " {'id': '2309.08621v2',\n",
       "  'title': 'Exploring Social Choice Mechanisms for Recommendation Fairness in SCRUF',\n",
       "  'published': '2023-09-10T17:47:21Z',\n",
       "  'summary': 'Fairness problems in recommender systems often have a complexity in practice\\nthat is not adequately captured in simplified research formulations. A social\\nchoice formulation of the fairness problem, operating within a multi-agent\\narchitecture of fairness concerns, offers a flexible and multi-aspect\\nalternative to fairness-aware recommendation approaches. Leveraging social\\nchoice allows for increased generality and the possibility of tapping into\\nwell-studied social choice algorithms for resolving the tension between\\nmultiple, competing fairness concerns. This paper explores a range of options\\nfor choice mechanisms in multi-aspect fairness applications using both real and\\nsynthetic data and shows that different classes of choice and allocation\\nmechanisms yield different but consistent fairness / accuracy tradeoffs. We\\nalso show that a multi-agent formulation offers flexibility in adapting to user\\npopulation dynamics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.08621v2.pdf'},\n",
       " {'id': '2403.00832v1',\n",
       "  'title': 'Explainable Session-based Recommendation via Path Reasoning',\n",
       "  'published': '2024-02-28T12:11:08Z',\n",
       "  'summary': 'This paper explores providing explainability for session-based recommendation\\n(SR) by path reasoning. Current SR models emphasize accuracy but lack\\nexplainability, while traditional path reasoning prioritizes knowledge graph\\nexploration, ignoring sequential patterns present in the session history.\\nTherefore, we propose a generalized hierarchical reinforcement learning\\nframework for SR, which improves the explainability of existing SR models via\\nPath Reasoning, namely PR4SR. Considering the different importance of items to\\nthe session, we design the session-level agent to select the items in the\\nsession as the starting point for path reasoning and the path-level agent to\\nperform path reasoning. In particular, we design a multi-target reward\\nmechanism to adapt to the skip behaviors of sequential patterns in SR, and\\nintroduce path midpoint reward to enhance the exploration efficiency in\\nknowledge graphs. To improve the completeness of the knowledge graph and to\\ndiversify the paths of explanation, we incorporate extracted feature\\ninformation from images into the knowledge graph. We instantiate PR4SR in five\\nstate-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and\\ncompare it with other explainable SR frameworks, to demonstrate the\\neffectiveness of PR4SR for recommendation and explanation tasks through\\nextensive experiments with these approaches on four datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.00832v1.pdf'},\n",
       " {'id': '2409.16558v1',\n",
       "  'title': 'Bias Reduction in Social Networks through Agent-Based Simulations',\n",
       "  'published': '2024-09-25T02:16:20Z',\n",
       "  'summary': \"Online social networks use recommender systems to suggest relevant\\ninformation to their users in the form of personalized timelines. Studying how\\nthese systems expose people to information at scale is difficult to do as one\\ncannot assume each user is subject to the same timeline condition and building\\nappropriate evaluation infrastructure is costly. We show that a simple\\nagent-based model where users have fixed preferences affords us the ability to\\ncompare different recommender systems (and thus different personalized\\ntimelines) in their ability to skew users' perception of their network.\\nImportantly, we show that a simple greedy algorithm that constructs a feed\\nbased on network properties reduces such perception biases comparable to a\\nrandom feed. This underscores the influence network structure has in\\ndetermining the effectiveness of recommender systems in the social network\\ncontext and offers a tool for mitigating perception biases through algorithmic\\nfeed construction.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.16558v1.pdf'},\n",
       " {'id': '2410.09580v3',\n",
       "  'title': 'SAPIENT: Mastering Multi-turn Conversational Recommendation with\\n  Strategic Planning and Monte Carlo Tree Search',\n",
       "  'published': '2024-10-12T16:21:33Z',\n",
       "  'summary': 'Conversational Recommender Systems (CRS) proactively engage users in\\ninteractive dialogues to elicit user preferences and provide personalized\\nrecommendations. Existing methods train Reinforcement Learning (RL)-based agent\\nwith greedy action selection or sampling strategy, and may suffer from\\nsuboptimal conversational planning. To address this, we present a novel Monte\\nCarlo Tree Search (MCTS)-based CRS framework SAPIENT. SAPIENT consists of a\\nconversational agent (S-agent) and a conversational planner (S-planner).\\nS-planner builds a conversational search tree with MCTS based on the initial\\nactions proposed by S-agent to find conversation plans. The best conversation\\nplans from S-planner are used to guide the training of S-agent, creating a\\nself-training loop where S-agent can iteratively improve its capability for\\nconversational planning. Furthermore, we propose an efficient variant SAPIENT\\nfor trade-off between training efficiency and performance. Extensive\\nexperiments on four benchmark datasets validate the effectiveness of our\\napproach, showing that SAPIENT outperforms the state-of-the-art baselines. Our\\ncode and data are accessible through https://github.com/ninglab/SAPIENT.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.09580v3.pdf'},\n",
       " {'id': '2505.13528v1',\n",
       "  'title': 'LLM-Based User Simulation for Low-Knowledge Shilling Attacks on\\n  Recommender Systems',\n",
       "  'published': '2025-05-18T04:40:34Z',\n",
       "  'summary': 'Recommender systems (RS) are increasingly vulnerable to shilling attacks,\\nwhere adversaries inject fake user profiles to manipulate system outputs.\\nTraditional attack strategies often rely on simplistic heuristics, require\\naccess to internal RS data, and overlook the manipulation potential of textual\\nreviews. In this work, we introduce Agent4SR, a novel framework that leverages\\nLarge Language Model (LLM)-based agents to perform low-knowledge, high-impact\\nshilling attacks through both rating and review generation. Agent4SR simulates\\nrealistic user behavior by orchestrating adversarial interactions, selecting\\nitems, assigning ratings, and crafting reviews, while maintaining behavioral\\nplausibility. Our design includes targeted profile construction, hybrid memory\\nretrieval, and a review attack strategy that propagates target item features\\nacross unrelated reviews to amplify manipulation. Extensive experiments on\\nmultiple datasets and RS architectures demonstrate that Agent4SR outperforms\\nexisting low-knowledge baselines in both effectiveness and stealth. Our\\nfindings reveal a new class of emergent threats posed by LLM-driven agents,\\nunderscoring the urgent need for enhanced defenses in modern recommender\\nsystems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.13528v1.pdf'},\n",
       " {'id': '2506.11563v1',\n",
       "  'title': 'Learn to Preserve Personality: Federated Foundation Models in\\n  Recommendations',\n",
       "  'published': '2025-06-13T08:17:07Z',\n",
       "  'summary': 'A core learning challenge for existed Foundation Models (FM) is striking the\\ntradeoff between generalization with personalization, which is a dilemma that\\nhas been highlighted by various parameter-efficient adaptation techniques.\\nFederated foundation models (FFM) provide a structural means to decouple shared\\nknowledge from individual specific adaptations via decentralized processes.\\nRecommendation systems offer a perfect testbed for FFMs, given their reliance\\non rich implicit feedback reflecting unique user characteristics. This position\\npaper discusses a novel learning paradigm where FFMs not only harness their\\ngeneralization capabilities but are specifically designed to preserve the\\nintegrity of user personality, illustrated thoroughly within the recommendation\\ncontexts. We envision future personal agents, powered by personalized adaptive\\nFMs, guiding user decisions on content. Such an architecture promises a user\\ncentric, decentralized system where individuals maintain control over their\\npersonalized agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.11563v1.pdf'},\n",
       " {'id': '2507.11049v2',\n",
       "  'title': 'Journalism-Guided Agentic In-Context Learning for News Stance Detection',\n",
       "  'published': '2025-07-15T07:22:04Z',\n",
       "  'summary': \"As online news consumption grows, personalized recommendation systems have\\nbecome integral to digital journalism. However, these systems risk reinforcing\\nfilter bubbles and political polarization by failing to incorporate diverse\\nperspectives. Stance detection -- identifying a text's position on a target --\\ncan help mitigate this by enabling viewpoint-aware recommendations and\\ndata-driven analyses of media bias. Yet, existing stance detection research\\nremains largely limited to short texts and high-resource languages. To address\\nthese gaps, we introduce \\\\textsc{K-News-Stance}, the first Korean dataset for\\narticle-level stance detection, comprising 2,000 news articles with\\narticle-level and 19,650 segment-level stance annotations across 47 societal\\nissues. We also propose \\\\textsc{JoA-ICL}, a \\\\textbf{Jo}urnalism-guided\\n\\\\textbf{A}gentic \\\\textbf{I}n-\\\\textbf{C}ontext \\\\textbf{L}earning framework that\\nemploys a language model agent to predict the stances of key structural\\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\\narticle stance. Experiments show that \\\\textsc{JoA-ICL} outperforms existing\\nstance detection methods, highlighting the benefits of segment-level agency in\\ncapturing the overall position of long-form news articles. Two case studies\\nfurther demonstrate its broader utility in promoting viewpoint diversity in\\nnews recommendations and uncovering patterns of media bias.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.11049v2.pdf'},\n",
       " {'id': '2106.02708v1',\n",
       "  'title': 'On the Design of Strategic Task Recommendations for Sustainable\\n  Crowdsourcing-Based Content Moderation',\n",
       "  'published': '2021-06-04T20:35:14Z',\n",
       "  'summary': \"Crowdsourcing-based content moderation is a platform that hosts content\\nmoderation tasks for crowd workers to review user submissions (e.g. text,\\nimages and videos) and make decisions regarding the admissibility of the posted\\ncontent, along with a gamut of other tasks such as image labeling and\\nspeech-to-text conversion. In an attempt to reduce cognitive overload at the\\nworkers and improve system efficiency, these platforms offer personalized task\\nrecommendations according to the worker's preferences. However, the current\\nstate-of-the-art recommendation systems disregard the effects on worker's\\nmental health, especially when they are repeatedly exposed to content\\nmoderation tasks with extreme content (e.g. violent images, hate-speech). In\\nthis paper, we propose a novel, strategic recommendation system for the\\ncrowdsourcing platform that recommends jobs based on worker's mental status.\\nSpecifically, this paper models interaction between the crowdsourcing\\nplatform's recommendation system (leader) and the worker (follower) as a\\nBayesian Stackelberg game where the type of the follower corresponds to the\\nworker's cognitive atrophy rate and task preferences. We discuss how rewards\\nand costs should be designed to steer the game towards desired outcomes in\\nterms of maximizing the platform's productivity, while simultaneously improving\\nthe working conditions of crowd workers.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2106.02708v1.pdf'},\n",
       " {'id': '2301.08632v2',\n",
       "  'title': 'Generative Slate Recommendation with Reinforcement Learning',\n",
       "  'published': '2023-01-20T15:28:09Z',\n",
       "  'summary': 'Recent research has employed reinforcement learning (RL) algorithms to\\noptimize long-term user engagement in recommender systems, thereby avoiding\\ncommon pitfalls such as user boredom and filter bubbles. They capture the\\nsequential and interactive nature of recommendations, and thus offer a\\nprincipled way to deal with long-term rewards and avoid myopic behaviors.\\nHowever, RL approaches are intractable in the slate recommendation scenario -\\nwhere a list of items is recommended at each interaction turn - due to the\\ncombinatorial action space. In that setting, an action corresponds to a slate\\nthat may contain any combination of items.\\n  While previous work has proposed well-chosen decompositions of actions so as\\nto ensure tractability, these rely on restrictive and sometimes unrealistic\\nassumptions. Instead, in this work we propose to encode slates in a continuous,\\nlow-dimensional latent space learned by a variational auto-encoder. Then, the\\nRL agent selects continuous actions in this latent space, which are ultimately\\ndecoded into the corresponding slates. By doing so, we are able to (i) relax\\nassumptions required by previous work, and (ii) improve the quality of the\\naction selection by modeling full slates instead of independent items, in\\nparticular by enabling diversity. Our experiments performed on a wide array of\\nsimulated environments confirm the effectiveness of our generative modeling of\\nslates over baselines in practical scenarios where the restrictive assumptions\\nunderlying the baselines are lifted. Our findings suggest that representation\\nlearning using generative models is a promising direction towards generalizable\\nRL-based slate recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2301.08632v2.pdf'},\n",
       " {'id': '2403.16427v4',\n",
       "  'title': 'Re2LLM: Reflective Reinforcement Large Language Model for Session-based\\n  Recommendation',\n",
       "  'published': '2024-03-25T05:12:18Z',\n",
       "  'summary': 'Large Language Models (LLMs) are emerging as promising approaches to enhance\\nsession-based recommendation (SBR), where both prompt-based and\\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\\nHowever, the former methods struggle with optimal prompts to elicit the correct\\nreasoning of LLMs due to the lack of task-specific feedback, leading to\\nunsatisfactory recommendations. Although the latter methods attempt to\\nfine-tune LLMs with domain-specific knowledge, they face limitations such as\\nhigh computational costs and reliance on open-source backbones. To address such\\nissues, we propose a Reflective Reinforcement Large Language Model (Re2LLM) for\\nSBR, guiding LLMs to focus on specialized knowledge essential for more accurate\\nrecommendations effectively and efficiently. In particular, we first design the\\nReflective Exploration Module to effectively extract knowledge that is readily\\nunderstandable and digestible by LLMs. To be specific, we direct LLMs to\\nexamine recommendation errors through self-reflection and construct a knowledge\\nbase (KB) comprising hints capable of rectifying these errors. To efficiently\\nelicit the correct reasoning of LLMs, we further devise the Reinforcement\\nUtilization Module to train a lightweight retrieval agent. It learns to select\\nhints from the constructed KB based on the task-specific feedback, where the\\nhints can serve as guidance to help correct LLMs reasoning for better\\nrecommendations. Extensive experiments on multiple real-world datasets\\ndemonstrate that our method consistently outperforms state-of-the-art methods.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.16427v4.pdf'},\n",
       " {'id': '2407.17115v2',\n",
       "  'title': 'Reinforced Prompt Personalization for Recommendation with Large Language\\n  Models',\n",
       "  'published': '2024-07-24T09:24:49Z',\n",
       "  'summary': \"Designing effective prompts can empower LLMs to understand user preferences\\nand provide recommendations with intent comprehension and knowledge utilization\\ncapabilities. Nevertheless, recent studies predominantly concentrate on\\ntask-wise prompting, developing fixed prompt templates shared across all users\\nin a given recommendation task (e.g., rating or ranking). Although convenient,\\ntask-wise prompting overlooks individual user differences, leading to\\ninaccurate analysis of user interests. In this work, we introduce the concept\\nof instance-wise prompting, aiming at personalizing discrete prompts for\\nindividual users. Toward this end, we propose Reinforced Prompt Personalization\\n(RPP) to realize it automatically. To improve efficiency and quality, RPP\\npersonalizes prompts at the sentence level rather than searching in the vast\\nvocabulary word-by-word. Specifically, RPP breaks down the prompt into four\\npatterns, tailoring patterns based on multi-agent and combining them. Then the\\npersonalized prompts interact with LLMs (environment) iteratively, to boost\\nLLMs' recommending performance (reward). In addition to RPP, to improve the\\nscalability of action space, our proposal of RPP+ dynamically refines the\\nselected actions with LLMs throughout the iterative process. Extensive\\nexperiments on various datasets demonstrate the superiority of RPP/RPP+ over\\ntraditional recommender models, few-shot methods, and other prompt-based\\nmethods, underscoring the significance of instance-wise prompting in LLMs for\\nrecommendation. Our code is available at https://github.com/maowenyu-11/RPP.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.17115v2.pdf'},\n",
       " {'id': '2502.00055v1',\n",
       "  'title': 'Towards Recommender Systems LLMs Playground (RecSysLLMsP): Exploring\\n  Polarization and Engagement in Simulated Social Networks',\n",
       "  'published': '2025-01-29T14:23:34Z',\n",
       "  'summary': \"Given the exponential advancement in AI technologies and the potential\\nescalation of harmful effects from recommendation systems, it is crucial to\\nsimulate and evaluate these effects early on. Doing so can help prevent\\npossible damage to both societies and technology companies. This paper\\nintroduces the Recommender Systems LLMs Playground (RecSysLLMsP), a novel\\nsimulation framework leveraging Large Language Models (LLMs) to explore the\\nimpacts of different content recommendation setups on user engagement and\\npolarization in social networks. By creating diverse AI agents (AgentPrompts)\\nwith descriptive, static, and dynamic attributes, we assess their autonomous\\nbehaviour across three scenarios: Plurality, Balanced, and Similarity. Our\\nfindings reveal that the Similarity Scenario, which aligns content with user\\npreferences, maximizes engagement while potentially fostering echo chambers.\\nConversely, the Plurality Scenario promotes diverse interactions but produces\\nmixed engagement results. Our study emphasizes the need for a careful balance\\nin recommender system designs to enhance user satisfaction while mitigating\\nsocietal polarization. It underscores the unique value and challenges of\\nincorporating LLMs into simulation environments. The benefits of RecSysLLMsP\\nlie in its potential to calculate polarization effects, which is crucial for\\nassessing societal impacts and determining user engagement levels with diverse\\nrecommender system setups. This advantage is essential for developing and\\nmaintaining a successful business model for social media companies. However,\\nthe study's limitations revolve around accurately emulating reality. Future\\nefforts should validate the similarity in behaviour between real humans and\\nAgentPrompts and establish metrics for measuring polarization scores.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.00055v1.pdf'},\n",
       " {'id': '1909.12723v1',\n",
       "  'title': 'Information Design in Spatial Resource Competition',\n",
       "  'published': '2019-09-27T14:54:41Z',\n",
       "  'summary': \"We consider the information design problem in spatial resource competition\\nsettings. Agents gather at a location deciding whether to move to another\\nlocation for possibly higher level of resources, and the utility each agent\\ngets by moving to the other location decreases as more agents move there. The\\nagents do not observe the resource level at the other location while a\\nprincipal does and the principal would like to carefully release this\\ninformation to attract a proper number of agents to move. We adopt the Bayesian\\npersuasion framework and analyze the principal's optimal signaling mechanism\\ndesign problem. We study both private and public signaling mechanisms. For\\nprivate signaling, we show the optimal mechanism can be computed in polynomial\\ntime with respect to the number of agents. Obtaining the optimal private\\nmechanism involves two steps: first, solve a linear program to get the marginal\\nprobability each agent should be recommended to move; second, sample the moving\\nagents satisfying the marginal probabilities with a sequential sampling\\nprocedure. For public signaling, we show the sender preferred equilibrium has a\\nsimple threshold structure and the optimal public mechanism with respect to the\\nsender preferred equilibrium can be computed in polynomial time. We support our\\nanalytical results with numerical computations that show the optimal private\\nand public signaling mechanisms achieve substantially higher social welfare\\ncompared with no information or full information benchmarks in many settings.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1909.12723v1.pdf'},\n",
       " {'id': '2112.07774v2',\n",
       "  'title': 'Assessing Human Interaction in Virtual Reality With Continually Learning\\n  Prediction Agents Based on Reinforcement Learning Algorithms: A Pilot Study',\n",
       "  'published': '2021-12-14T22:46:44Z',\n",
       "  'summary': \"Artificial intelligence systems increasingly involve continual learning to\\nenable flexibility in general situations that are not encountered during system\\ntraining. Human interaction with autonomous systems is broadly studied, but\\nresearch has hitherto under-explored interactions that occur while the system\\nis actively learning, and can noticeably change its behaviour in minutes. In\\nthis pilot study, we investigate how the interaction between a human and a\\ncontinually learning prediction agent develops as the agent develops\\ncompetency. Additionally, we compare two different agent architectures to\\nassess how representational choices in agent design affect the human-agent\\ninteraction. We develop a virtual reality environment and a time-based\\nprediction task wherein learned predictions from a reinforcement learning (RL)\\nalgorithm augment human predictions. We assess how a participant's performance\\nand behaviour in this task differs across agent types, using both quantitative\\nand qualitative analyses. Our findings suggest that human trust of the system\\nmay be influenced by early interactions with the agent, and that trust in turn\\naffects strategic behaviour, but limitations of the pilot study rule out any\\nconclusive statement. We identify trust as a key feature of interaction to\\nfocus on when considering RL-based technologies, and make several\\nrecommendations for modification to this study in preparation for a\\nlarger-scale investigation. A video summary of this paper can be found at\\nhttps://youtu.be/oVYJdnBqTwQ .\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.07774v2.pdf'},\n",
       " {'id': '2306.06087v1',\n",
       "  'title': 'Learning Not to Spoof',\n",
       "  'published': '2023-06-09T17:49:56Z',\n",
       "  'summary': \"As intelligent trading agents based on reinforcement learning (RL) gain\\nprevalence, it becomes more important to ensure that RL agents obey laws,\\nregulations, and human behavioral expectations. There is substantial literature\\nconcerning the aversion of obvious catastrophes like crashing a helicopter or\\nbankrupting a trading account, but little around the avoidance of subtle\\nnon-normative behavior for which there are examples, but no programmable\\ndefinition. Such behavior may violate legal or regulatory, rather than physical\\nor monetary, constraints.\\n  In this article, I consider a series of experiments in which an intelligent\\nstock trading agent maximizes profit but may also inadvertently learn to spoof\\nthe market in which it participates. I first inject a hand-coded spoofing agent\\nto a multi-agent market simulation and learn to recognize spoofing activity\\nsequences. Then I replace the hand-coded spoofing trader with a simple\\nprofit-maximizing RL agent and observe that it independently discovers spoofing\\nas the optimal strategy. Finally, I introduce a method to incorporate the\\nrecognizer as normative guide, shaping the agent's perceived rewards and\\naltering its selected actions. The agent remains profitable while avoiding\\nspoofing behaviors that would result in even higher profit. After presenting\\nthe empirical results, I conclude with some recommendations. The method should\\ngeneralize to the reduction of any unwanted behavior for which a recognizer can\\nbe learned.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.06087v1.pdf'},\n",
       " {'id': '2507.08440v1',\n",
       "  'title': 'Finding Common Ground: Using Large Language Models to Detect Agreement\\n  in Multi-Agent Decision Conferences',\n",
       "  'published': '2025-07-11T09:31:10Z',\n",
       "  'summary': 'Decision conferences are structured, collaborative meetings that bring\\ntogether experts from various fields to address complex issues and reach a\\nconsensus on recommendations for future actions or policies. These conferences\\noften rely on facilitated discussions to ensure productive dialogue and\\ncollective agreement. Recently, Large Language Models (LLMs) have shown\\nsignificant promise in simulating real-world scenarios, particularly through\\ncollaborative multi-agent systems that mimic group interactions. In this work,\\nwe present a novel LLM-based multi-agent system designed to simulate decision\\nconferences, specifically focusing on detecting agreement among the participant\\nagents. To achieve this, we evaluate six distinct LLMs on two tasks: stance\\ndetection, which identifies the position an agent takes on a given issue, and\\nstance polarity detection, which identifies the sentiment as positive,\\nnegative, or neutral. These models are further assessed within the multi-agent\\nsystem to determine their effectiveness in complex simulations. Our results\\nindicate that LLMs can reliably detect agreement even in dynamic and nuanced\\ndebates. Incorporating an agreement-detection agent within the system can also\\nimprove the efficiency of group debates and enhance the overall quality and\\ncoherence of deliberations, making them comparable to real-world decision\\nconferences regarding outcome and decision-making. These findings demonstrate\\nthe potential for LLM-based multi-agent systems to simulate group\\ndecision-making processes. They also highlight that such systems could be\\ninstrumental in supporting decision-making with expert elicitation workshops\\nacross various domains.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.08440v1.pdf'},\n",
       " {'id': '1012.1099v1',\n",
       "  'title': 'Heterogeneity, quality, and reputation in an adaptive recommendation\\n  model',\n",
       "  'published': '2010-12-06T09:24:52Z',\n",
       "  'summary': 'Recommender systems help people cope with the problem of information\\noverload. A recently proposed adaptive news recommender model [Medo et al.,\\n2009] is based on epidemic-like spreading of news in a social network. By means\\nof agent-based simulations we study a \"good get richer\" feature of the model\\nand determine which attributes are necessary for a user to play a leading role\\nin the network. We further investigate the filtering efficiency of the model as\\nwell as its robustness against malicious and spamming behaviour. We show that\\nincorporating user reputation in the recommendation process can substantially\\nimprove the outcome.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1012.1099v1.pdf'},\n",
       " {'id': '1905.05851v1',\n",
       "  'title': 'Exploring Interactions with Voice-Controlled TV',\n",
       "  'published': '2019-05-14T21:31:47Z',\n",
       "  'summary': 'Intelligent agents such as Alexa, Siri, and Google Assistant are now built\\ninto streaming TV systems, allowing people to use voice input to navigate the\\nincreasingly complex set of apps available on a TV. However, these systems\\ntypically support a narrow range of control- and search-oriented commands, and\\ndo not support deeper recommendation or exploration queries. To learn about how\\npeople interact with a recommendation-oriented voice-controlled TV, we use\\nresearch through design methods to explore an early prototype movie\\nrecommendation system where the only input modality is voice. We describe\\nin-depth qualitative research sessions with 11 participants. We contribute\\nimplications for designers of voice-controlled TV: mitigating the drawbacks of\\nvoice-only interactions, navigating the tension between expressiveness and\\nefficiency, and building voice-driven recommendation interfaces that facilitate\\nexploration.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.05851v1.pdf'},\n",
       " {'id': '2012.06052v1',\n",
       "  'title': 'Interactive Search Based on Deep Reinforcement Learning',\n",
       "  'published': '2020-12-09T15:23:53Z',\n",
       "  'summary': \"With the continuous development of machine learning technology, major\\ne-commerce platforms have launched recommendation systems based on it to serve\\na large number of customers with different needs more efficiently. Compared\\nwith traditional supervised learning, reinforcement learning can better capture\\nthe user's state transition in the decision-making process, and consider a\\nseries of user actions, not just the static characteristics of the user at a\\ncertain moment. In theory, it will have a long-term perspective, producing a\\nmore effective recommendation. The special requirements of reinforcement\\nlearning for data make it need to rely on an offline virtual system for\\ntraining. Our project mainly establishes a virtual user environment for offline\\ntraining. At the same time, we tried to improve a reinforcement learning\\nalgorithm based on bi-clustering to expand the action space and recommended\\npath space of the recommendation agent.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.06052v1.pdf'},\n",
       " {'id': '2303.09601v1',\n",
       "  'title': 'Psychotherapy AI Companion with Reinforcement Learning Recommendations\\n  and Interpretable Policy Dynamics',\n",
       "  'published': '2023-03-16T19:01:29Z',\n",
       "  'summary': \"We introduce a Reinforcement Learning Psychotherapy AI Companion that\\ngenerates topic recommendations for therapists based on patient responses. The\\nsystem uses Deep Reinforcement Learning (DRL) to generate multi-objective\\npolicies for four different psychiatric conditions: anxiety, depression,\\nschizophrenia, and suicidal cases. We present our experimental results on the\\naccuracy of recommended topics using three different scales of working alliance\\nratings: task, bond, and goal. We show that the system is able to capture the\\nreal data (historical topics discussed by the therapists) relatively well, and\\nthat the best performing models vary by disorder and rating scale. To gain\\ninterpretable insights into the learned policies, we visualize policy\\ntrajectories in a 2D principal component analysis space and transition\\nmatrices. These visualizations reveal distinct patterns in the policies trained\\nwith different reward signals and trained on different clinical diagnoses. Our\\nsystem's success in generating DIsorder-Specific Multi-Objective Policies\\n(DISMOP) and interpretable policy dynamics demonstrates the potential of DRL in\\nproviding personalized and efficient therapeutic recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.09601v1.pdf'},\n",
       " {'id': '2403.19831v1',\n",
       "  'title': 'TASR: A Novel Trust-Aware Stackelberg Routing Algorithm to Mitigate\\n  Traffic Congestion',\n",
       "  'published': '2024-03-28T20:47:36Z',\n",
       "  'summary': \"Stackelberg routing platforms (SRP) reduce congestion in one-shot traffic\\nnetworks by proposing optimal route recommendations to selfish travelers.\\nTraditionally, Stackelberg routing is cast as a partial control problem where a\\nfraction of traveler flow complies with route recommendations, while the\\nremaining respond as selfish travelers. In this paper, a novel Stackelberg\\nrouting framework is formulated where the agents exhibit \\\\emph{probabilistic\\ncompliance} by accepting SRP's route recommendations with a \\\\emph{trust}\\nprobability. A greedy \\\\emph{\\\\textbf{T}rust-\\\\textbf{A}ware \\\\textbf{S}tackelberg\\n\\\\textbf{R}outing} algorithm (in short, TASR) is proposed for SRP to compute\\nunique path recommendations to each traveler flow with a unique demand.\\nSimulation experiments are designed with random travel demands with diverse\\ntrust values on real road networks such as Sioux Falls, Chicago Sketch, and\\nSydney networks for both single-commodity and multi-commodity flows. The\\nperformance of TASR is compared with state-of-the-art Stackelberg routing\\nmethods in terms of traffic congestion and trust dynamics over repeated\\ninteraction between the SRP and the travelers. Results show that TASR improves\\nnetwork congestion without causing a significant reduction in trust towards the\\nSRP, when compared to most well-known Stackelberg routing strategies.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.19831v1.pdf'},\n",
       " {'id': '2502.11721v1',\n",
       "  'title': 'Enhancing Recommendation Explanations through User-Centric Refinement',\n",
       "  'published': '2025-02-17T12:08:18Z',\n",
       "  'summary': 'Generating natural language explanations for recommendations has become\\nincreasingly important in recommender systems. Traditional approaches typically\\ntreat user reviews as ground truth for explanations and focus on improving\\nreview prediction accuracy by designing various model architectures. However,\\ndue to limitations in data scale and model capability, these explanations often\\nfail to meet key user-centric aspects such as factuality, personalization, and\\nsentiment coherence, significantly reducing their overall helpfulness to users.\\nIn this paper, we propose a novel paradigm that refines initial explanations\\ngenerated by existing explainable recommender models during the inference stage\\nto enhance their quality in multiple aspects. Specifically, we introduce a\\nmulti-agent collaborative refinement framework based on large language models.\\nTo ensure alignment between the refinement process and user demands, we employ\\na plan-then-refine pattern to perform targeted modifications. To enable\\ncontinuous improvements, we design a hierarchical reflection mechanism that\\nprovides feedback on the refinement process from both strategic and content\\nperspectives. Extensive experiments on three datasets demonstrate the\\neffectiveness of our framework.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.11721v1.pdf'},\n",
       " {'id': '2504.12722v1',\n",
       "  'title': 'SimUSER: Simulating User Behavior with Large Language Models for\\n  Recommender System Evaluation',\n",
       "  'published': '2025-04-17T07:57:23Z',\n",
       "  'summary': 'Recommender systems play a central role in numerous real-life applications,\\nyet evaluating their performance remains a significant challenge due to the gap\\nbetween offline metrics and online behaviors. Given the scarcity and limits\\n(e.g., privacy issues) of real user data, we introduce SimUSER, an agent\\nframework that serves as believable and cost-effective human proxies. SimUSER\\nfirst identifies self-consistent personas from historical data, enriching user\\nprofiles with unique backgrounds and personalities. Then, central to this\\nevaluation are users equipped with persona, memory, perception, and brain\\nmodules, engaging in interactions with the recommender system. SimUSER exhibits\\ncloser alignment with genuine humans than prior work, both at micro and macro\\nlevels. Additionally, we conduct insightful experiments to explore the effects\\nof thumbnails on click rates, the exposure effect, and the impact of reviews on\\nuser engagement. Finally, we refine recommender system parameters based on\\noffline A/B test results, resulting in improved user engagement in the real\\nworld.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.12722v1.pdf'},\n",
       " {'id': '1702.02367v1',\n",
       "  'title': 'Iterative Multi-document Neural Attention for Multiple Answer Prediction',\n",
       "  'published': '2017-02-08T10:58:02Z',\n",
       "  'summary': 'People have information needs of varying complexity, which can be solved by\\nan intelligent agent able to answer questions formulated in a proper way,\\neventually considering user context and preferences. In a scenario in which the\\nuser profile can be considered as a question, intelligent agents able to answer\\nquestions can be used to find the most relevant answers for a given user. In\\nthis work we propose a novel model based on Artificial Neural Networks to\\nanswer questions with multiple answers by exploiting multiple facts retrieved\\nfrom a knowledge base. The model is evaluated on the factoid Question Answering\\nand top-n recommendation tasks of the bAbI Movie Dialog dataset. After\\nassessing the performance of the model on both tasks, we try to define the\\nlong-term goal of a conversational recommender system able to interact using\\nnatural language and to support users in their information seeking processes in\\na personalized way.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1702.02367v1.pdf'},\n",
       " {'id': '2008.09369v2',\n",
       "  'title': 'Learning to Collaborate in Multi-Module Recommendation via Multi-Agent\\n  Reinforcement Learning without Communication',\n",
       "  'published': '2020-08-21T08:23:33Z',\n",
       "  'summary': \"With the rise of online e-commerce platforms, more and more customers prefer\\nto shop online. To sell more products, online platforms introduce various\\nmodules to recommend items with different properties such as huge discounts. A\\nweb page often consists of different independent modules. The ranking policies\\nof these modules are decided by different teams and optimized individually\\nwithout cooperation, which might result in competition between modules. Thus,\\nthe global policy of the whole page could be sub-optimal. In this paper, we\\npropose a novel multi-agent cooperative reinforcement learning approach with\\nthe restriction that different modules cannot communicate. Our contributions\\nare three-fold. Firstly, inspired by a solution concept in game theory named\\ncorrelated equilibrium, we design a signal network to promote cooperation of\\nall modules by generating signals (vectors) for different modules. Secondly, an\\nentropy-regularized version of the signal network is proposed to coordinate\\nagents' exploration of the optimal global policy. Furthermore, experiments\\nbased on real-world e-commerce data demonstrate that our algorithm obtains\\nsuperior performance over baselines.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.09369v2.pdf'},\n",
       " {'id': '2009.05653v1',\n",
       "  'title': 'Teaching Tech to Talk: K-12 Conversational Artificial Intelligence\\n  Literacy Curriculum and Development Tools',\n",
       "  'published': '2020-09-11T20:52:46Z',\n",
       "  'summary': 'With children talking to smart-speakers, smart-phones and even\\nsmart-microwaves daily, it is increasingly important to educate students on how\\nthese agents work-from underlying mechanisms to societal implications.\\nResearchers are developing tools and curriculum to teach K-12 students broadly\\nabout artificial intelligence (AI); however, few studies have evaluated these\\ntools with respect to AI-specific learning outcomes, and even fewer have\\naddressed student learning about AI-based conversational agents. We evaluate\\nour Conversational Agent Interface for MIT App Inventor and workshop curriculum\\nwith respect to eight AI competencies from the literature. Furthermore, we\\nanalyze teacher (n=9) and student (n=47) feedback from workshops with the\\ninterface and recommend that future work leverages design considerations from\\nthe literature to optimize engagement, collaborates with teachers, and\\naddresses a range of student abilities through pacing and opportunities for\\nextension. We found students struggled most with the concepts of AI ethics and\\nlearning, and recommend emphasizing these topics when teaching.\\n  The appendix, including a demo video, can be found here:\\nhttps://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2009.05653v1.pdf'},\n",
       " {'id': '2304.02233v1',\n",
       "  'title': 'Ericson: An Interactive Open-Domain Conversational Search Agent',\n",
       "  'published': '2023-04-05T05:28:31Z',\n",
       "  'summary': 'Open-domain conversational search (ODCS) aims to provide valuable, up-to-date\\ninformation, while maintaining natural conversations to help users refine and\\nultimately answer information needs. However, creating an effective and robust\\nODCS agent is challenging. In this paper, we present a fully functional ODCS\\nsystem, Ericson, which includes state-of-the-art question answering and\\ninformation retrieval components, as well as intent inference and dialogue\\nmanagement models for proactive question refinement and recommendations. Our\\nsystem was stress-tested in the Amazon Alexa Prize, by engaging in live\\nconversations with thousands of Alexa users, thus providing empirical basis for\\nthe analysis of the ODCS system in real settings. Our interaction data analysis\\nrevealed that accurate intent classification, encouraging user engagement, and\\ncareful proactive recommendations contribute most to the users satisfaction.\\nOur study further identifies limitations of the existing search techniques, and\\ncan serve as a building block for the next generation of ODCS agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.02233v1.pdf'},\n",
       " {'id': '2305.17619v1',\n",
       "  'title': 'AI Coach Assist: An Automated Approach for Call Recommendation in\\n  Contact Centers for Agent Coaching',\n",
       "  'published': '2023-05-28T03:29:59Z',\n",
       "  'summary': 'In recent years, the utilization of Artificial Intelligence (AI) in the\\ncontact center industry is on the rise. One area where AI can have a\\nsignificant impact is in the coaching of contact center agents. By analyzing\\ncall transcripts using Natural Language Processing (NLP) techniques, it would\\nbe possible to quickly determine which calls are most relevant for coaching\\npurposes. In this paper, we present AI Coach Assist, which leverages the\\npre-trained transformer-based language models to determine whether a given call\\nis coachable or not based on the quality assurance (QA) questions asked by the\\ncontact center managers or supervisors. The system was trained and evaluated on\\na large dataset collected from real-world contact centers and provides an\\neffective way to recommend calls to the contact center managers that are more\\nlikely to contain coachable moments. Our experimental findings demonstrate the\\npotential of AI Coach Assist to improve the coaching process, resulting in\\nenhancing the performance of contact center agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.17619v1.pdf'},\n",
       " {'id': '2406.00551v2',\n",
       "  'title': 'Strategic Linear Contextual Bandits',\n",
       "  'published': '2024-06-01T20:46:40Z',\n",
       "  'summary': 'Motivated by the phenomenon of strategic agents gaming a recommender system\\nto maximize the number of times they are recommended to users, we study a\\nstrategic variant of the linear contextual bandit problem, where the arms can\\nstrategically misreport privately observed contexts to the learner. We treat\\nthe algorithm design problem as one of mechanism design under uncertainty and\\npropose the Optimistic Grim Trigger Mechanism (OptGTM) that incentivizes the\\nagents (i.e., arms) to report their contexts truthfully while simultaneously\\nminimizing regret. We also show that failing to account for the strategic\\nnature of the agents results in linear regret. However, a trade-off between\\nmechanism design and regret minimization appears to be unavoidable. More\\nbroadly, this work aims to provide insight into the intersection of online\\nlearning and mechanism design.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.00551v2.pdf'},\n",
       " {'id': '2502.13843v2',\n",
       "  'title': 'AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware\\n  Cross-domain Recommendations',\n",
       "  'published': '2025-02-19T16:02:59Z',\n",
       "  'summary': \"LLM-based user agents, which simulate user interaction behavior, are emerging\\nas a promising approach to enhancing recommender systems. In real-world\\nscenarios, users' interactions often exhibit cross-domain characteristics and\\nare influenced by others. However, the memory design in current methods causes\\nuser agents to introduce significant irrelevant information during\\ndecision-making in cross-domain scenarios and makes them unable to recognize\\nthe influence of other users' interactions, such as popularity factors. To\\ntackle this issue, we propose a dual-layer memory architecture combined with a\\ntwo-step fusion mechanism. This design avoids irrelevant information during\\ndecision-making while ensuring effective integration of cross-domain\\npreferences. We also introduce the concepts of interest groups and group-shared\\nmemory to better capture the influence of popularity factors on users with\\nsimilar interests. Comprehensive experiments validate the effectiveness of\\nAgentCF++. Our code is available at https://github.com/jhliu0807/AgentCF-plus.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.13843v2.pdf'},\n",
       " {'id': '2504.13897v1',\n",
       "  'title': 'Show Me How: Benefits and Challenges of Agent-Augmented Counterfactual\\n  Explanations for Non-Expert Users',\n",
       "  'published': '2025-04-06T09:31:02Z',\n",
       "  'summary': 'Counterfactual explanations offer actionable insights by illustrating how\\nchanges to inputs can lead to different outcomes. However, these explanations\\noften suffer from ambiguity and impracticality, limiting their utility for\\nnon-expert users with limited AI knowledge. Augmenting counterfactual\\nexplanations with Large Language Models (LLMs) has been proposed as a solution,\\nbut little research has examined their benefits and challenges for non-experts.\\nTo address this gap, we developed a healthcare-focused system that leverages\\nconversational AI agents to enhance counterfactual explanations, offering\\nclear, actionable recommendations to help patients at high risk of\\ncardiovascular disease (CVD) reduce their risk. Evaluated through a\\nmixed-methods study with 34 participants, our findings highlight the\\neffectiveness of agent-augmented counterfactuals in improving actionable\\nrecommendations. Results further indicate that users with prior experience\\nusing conversational AI demonstrated greater effectiveness in utilising these\\nexplanations compared to novices. Furthermore, this paper introduces a set of\\ngeneric guidelines for creating augmented counterfactual explanations,\\nincorporating safeguards to mitigate common LLM pitfalls, such as\\nhallucinations, and ensuring the explanations are both actionable and\\ncontextually relevant for non-expert users.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.13897v1.pdf'},\n",
       " {'id': '2505.01115v1',\n",
       "  'title': 'Exploring Equity of Climate Policies using Multi-Agent Multi-Objective\\n  Reinforcement Learning',\n",
       "  'published': '2025-05-02T08:52:56Z',\n",
       "  'summary': 'Addressing climate change requires coordinated policy efforts of nations\\nworldwide. These efforts are informed by scientific reports, which rely in part\\non Integrated Assessment Models (IAMs), prominent tools used to assess the\\neconomic impacts of climate policies. However, traditional IAMs optimize\\npolicies based on a single objective, limiting their ability to capture the\\ntrade-offs among economic growth, temperature goals, and climate justice. As a\\nresult, policy recommendations have been criticized for perpetuating\\ninequalities, fueling disagreements during policy negotiations. We introduce\\nJustice, the first framework integrating IAM with Multi-Objective Multi-Agent\\nReinforcement Learning (MOMARL). By incorporating multiple objectives, Justice\\ngenerates policy recommendations that shed light on equity while balancing\\nclimate and economic goals. Further, using multiple agents can provide a\\nrealistic representation of the interactions among the diverse policy actors.\\nWe identify equitable Pareto-optimal policies using our framework, which\\nfacilitates deliberative decision-making by presenting policymakers with the\\ninherent trade-offs in climate and economic policy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.01115v1.pdf'},\n",
       " {'id': '2506.04571v2',\n",
       "  'title': 'OpenAg: Democratizing Agricultural Intelligence',\n",
       "  'published': '2025-06-05T02:44:38Z',\n",
       "  'summary': 'Agriculture is undergoing a major transformation driven by artificial\\nintelligence (AI), machine learning, and knowledge representation technologies.\\nHowever, current agricultural intelligence systems often lack contextual\\nunderstanding, explainability, and adaptability, especially for smallholder\\nfarmers with limited resources. General-purpose large language models (LLMs),\\nwhile powerful, typically lack the domain-specific knowledge and contextual\\nreasoning needed for practical decision support in farming. They tend to\\nproduce recommendations that are too generic or unrealistic for real-world\\napplications. To address these challenges, we present OpenAg, a comprehensive\\nframework designed to advance agricultural artificial general intelligence\\n(AGI). OpenAg combines domain-specific foundation models, neural knowledge\\ngraphs, multi-agent reasoning, causal explainability, and adaptive transfer\\nlearning to deliver context-aware, explainable, and actionable insights. The\\nsystem includes: (i) a unified agricultural knowledge base that integrates\\nscientific literature, sensor data, and farmer-generated knowledge; (ii) a\\nneural agricultural knowledge graph for structured reasoning and inference;\\n(iii) an adaptive multi-agent reasoning system where AI agents specialize and\\ncollaborate across agricultural domains; and (iv) a causal transparency\\nmechanism that ensures AI recommendations are interpretable, scientifically\\ngrounded, and aligned with real-world constraints. OpenAg aims to bridge the\\ngap between scientific knowledge and the tacit expertise of experienced farmers\\nto support scalable and locally relevant agricultural decision-making.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.04571v2.pdf'},\n",
       " {'id': '2505.15935v2',\n",
       "  'title': 'MAPS: A Multilingual Benchmark for Global Agent Performance and Security',\n",
       "  'published': '2025-05-21T18:42:00Z',\n",
       "  'summary': \"Agentic AI systems, which build on Large Language Models (LLMs) and interact\\nwith tools and memory, have rapidly advanced in capability and scope. Yet,\\nsince LLMs have been shown to struggle in multilingual settings, typically\\nresulting in lower performance and reduced safety, agentic systems risk\\ninheriting these limitations. This raises concerns about the accessibility of\\nsuch systems, as users interacting in languages other than English may\\nencounter unreliable or security-critical agent behavior. Despite growing\\ninterest in evaluating agentic AI, existing benchmarks focus exclusively on\\nEnglish, leaving multilingual settings unexplored. To address this gap, we\\npropose MAPS, a multilingual benchmark suite designed to evaluate agentic AI\\nsystems across diverse languages and tasks. MAPS builds on four widely used\\nagentic benchmarks - GAIA (real-world tasks), SWE-bench (code generation), MATH\\n(mathematical reasoning), and the Agent Security Benchmark (security). We\\ntranslate each dataset into eleven diverse languages, resulting in 805 unique\\ntasks and 9,660 total language-specific instances - enabling a systematic\\nanalysis of the multilingual effect on AI agents' performance and robustness.\\nEmpirically, we observe degradation in both performance and security when\\ntransitioning from English to other languages, with severity varying by task\\nand correlating with the amount of translated input. Building on these\\nfindings, we provide actionable recommendations to guide agentic AI systems\\ndevelopment and assessment under multilingual settings. This work establishes\\nthe first standardized evaluation framework for multilingual agentic AI,\\nencouraging future research towards equitable, reliable, and accessible agentic\\nAI. MAPS benchmark suite is publicly available at\\nhttps://huggingface.co/datasets/Fujitsu-FRE/MAPS\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.15935v2.pdf'},\n",
       " {'id': '1909.04421v4',\n",
       "  'title': 'Privacy-Preserving Bandits',\n",
       "  'published': '2019-09-10T11:39:58Z',\n",
       "  'summary': \"Contextual bandit algorithms~(CBAs) often rely on personal data to provide\\nrecommendations. Centralized CBA agents utilize potentially sensitive data from\\nrecent interactions to provide personalization to end-users. Keeping the\\nsensitive data locally, by running a local agent on the user's device, protects\\nthe user's privacy, however, the agent requires longer to produce useful\\nrecommendations, as it does not leverage feedback from other users. This paper\\nproposes a technique we call Privacy-Preserving Bandits (P2B); a system that\\nupdates local agents by collecting feedback from other local agents in a\\ndifferentially-private manner. Comparisons of our proposed approach with a\\nnon-private, as well as a fully-private (local) system, show competitive\\nperformance on both synthetic benchmarks and real-world data. Specifically, we\\nobserved only a decrease of 2.6% and 3.6% in multi-label classification\\naccuracy, and a CTR increase of 0.0025 in online advertising for a privacy\\nbudget $\\\\epsilon \\\\approx 0.693$. These results suggest P2B is an effective\\napproach to challenges arising in on-device privacy-preserving personalization.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1909.04421v4.pdf'},\n",
       " {'id': '2005.13803v1',\n",
       "  'title': 'Would you Like to Talk about Sports Now? Towards Contextual Topic\\n  Suggestion for Open-Domain Conversational Agents',\n",
       "  'published': '2020-05-28T06:41:18Z',\n",
       "  'summary': 'To hold a true conversation, an intelligent agent should be able to\\noccasionally take initiative and recommend the next natural conversation topic.\\nThis is a challenging task. A topic suggested by the agent should be relevant\\nto the person, appropriate for the conversation context, and the agent should\\nhave something interesting to say about it. Thus, a scripted, or\\none-size-fits-all, popularity-based topic suggestion is doomed to fail.\\nInstead, we explore different methods for a personalized, contextual topic\\nsuggestion for open-domain conversations. We formalize the Conversational Topic\\nSuggestion problem (CTS) to more clearly identify the assumptions and\\nrequirements. We also explore three possible approaches to solve this problem:\\n(1) model-based sequential topic suggestion to capture the conversation context\\n(CTS-Seq), (2) Collaborative Filtering-based suggestion to capture previous\\nsuccessful conversations from similar users (CTS-CF), and (3) a hybrid approach\\ncombining both conversation context and collaborative filtering. To evaluate\\nthe effectiveness of these methods, we use real conversations collected as part\\nof the Amazon Alexa Prize 2018 Conversational AI challenge. The results are\\npromising: the CTS-Seq model suggests topics with 23% higher accuracy than the\\nbaseline, and incorporating collaborative filtering signals into a hybrid\\nCTS-Seq-CF model further improves recommendation accuracy by 12%. Together, our\\nproposed models, experiments, and analysis significantly advance the study of\\nopen-domain conversational agents, and suggest promising directions for future\\nimprovements.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.13803v1.pdf'},\n",
       " {'id': '2105.06718v2',\n",
       "  'title': 'Modeling the interplay between epidemics and regional socio-economics',\n",
       "  'published': '2021-05-14T08:55:18Z',\n",
       "  'summary': \"In this study we present a dynamical agent-based model to investigate the\\ninterplay between the socio-economy of and SEIRS-type epidemic spreading over a\\ngeographical area, divided to smaller area districts and further to smallest\\narea cells. The model treats the populations of cells and authorities of\\ndistricts as agents, such that the former can reduce their economic activity\\nand the latter can recommend economic activity reduction both with the overall\\ngoal to slow down the epidemic spreading. The agents make decisions with the\\naim of attaining as high socio-economic standings as possible relative to other\\nagents of the same type by evaluating their standings based on the local and\\nregional infection rates, compliance to the authorities' regulations, regional\\ndrops in economic activity, and efforts to mitigate the spread of epidemic. We\\nfind that the willingness of population to comply with authorities'\\nrecommendations has the most drastic effect on the epidemic spreading: periodic\\nwaves spread almost unimpeded in non-compliant populations, while in compliant\\nones the spread is minimal with chaotic spreading pattern and significantly\\nlower infection rates. Health and economic concerns of agents turn out to have\\nlesser roles, the former increasing their efforts and the latter decreasing\\nthem.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.06718v2.pdf'},\n",
       " {'id': '2405.20254v2',\n",
       "  'title': 'Conversational Agents to Facilitate Deliberation on Harmful Content in\\n  WhatsApp Groups',\n",
       "  'published': '2024-05-30T17:07:07Z',\n",
       "  'summary': \"WhatsApp groups have become a hotbed for the propagation of harmful content\\nincluding misinformation, hate speech, polarizing content, and rumors,\\nespecially in Global South countries. Given the platform's end-to-end\\nencryption, moderation responsibilities lie on group admins and members, who\\nrarely contest such content. Another approach is fact-checking, which is\\nunscalable, and can only contest factual content (e.g., misinformation) but not\\nsubjective content (e.g., hate speech). Drawing on recent literature, we\\nexplore deliberation -- open and inclusive discussion -- as an alternative. We\\ninvestigate the role of a conversational agent in facilitating deliberation on\\nharmful content in WhatsApp groups. We conducted semi-structured interviews\\nwith 21 Indian WhatsApp users, employing a design probe to showcase an example\\nagent. Participants expressed the need for anonymity and recommended AI\\nassistance to reduce the effort required in deliberation. They appreciated the\\nagent's neutrality but pointed out the futility of deliberation in echo chamber\\ngroups. Our findings highlight design tensions for such an agent, including\\nprivacy versus group dynamics and freedom of speech in private spaces. We\\ndiscuss the efficacy of deliberation using deliberative theory as a lens,\\ncompare deliberation with moderation and fact-checking, and provide design\\nrecommendations for future such systems. Ultimately, this work advances CSCW by\\noffering insights into designing deliberative systems for combating harmful\\ncontent in private group chats on social media.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.20254v2.pdf'},\n",
       " {'id': '2410.11683v1',\n",
       "  'title': 'Optimal Mediation Mechanisms in Bilateral Trade',\n",
       "  'published': '2024-10-15T15:20:40Z',\n",
       "  'summary': \"Consider a bilateral trade scenario where a seller seeks to sell an item to a\\nbuyer through a trusted mediator. The item's quality is the seller's private\\ninformation, and the buyer's valuation of the item depends on both the quality\\nand the buyer's type. The mediator, who is uninformed about the private\\ninformation of both the seller and buyer, aims to design a mechanism that\\nelicits and reveals information to facilitate communication between two agents.\\nThe mediator can also charge a fee for providing such services.\\n  In this work, we study the problem of designing mechanisms that maximize\\nrevenue for the mediator. We formulate this mechanism design problem as an\\noptimization problem that involves non-linear constraints. Interestingly, under\\nthe monotone hazard rate assumption, we can bypass this issue by considering a\\nrelaxed problem and showing that the solution to the relaxed problem remains\\noptimal to the original one. In optimal mechanisms, the mediator directly\\nrecommends whether to trade after eliciting the agents' types. The mediator\\nprivately offers a price to each agent if a trade is recommended. The optimal\\nmechanism adopts a threshold information structure, i.e., it only reveals to\\nthe agent whether the other agent's type exceeds a certain threshold. The\\noptimal payment function of buyer is monotone decreasing to their type, which\\ndiffers from most existing works. Finally, we discuss some interesting\\nobservations revealed by the optimal mechanism.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.11683v1.pdf'},\n",
       " {'id': '2504.13192v2',\n",
       "  'title': 'CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent',\n",
       "  'published': '2025-04-13T05:31:37Z',\n",
       "  'summary': \"Recently, Large Language Model (LLM)-empowered recommender systems (RecSys)\\nhave brought significant advances in personalized user experience and have\\nattracted considerable attention. Despite the impressive progress, the research\\nquestion regarding the safety vulnerability of LLM-empowered RecSys still\\nremains largely under-investigated. Given the security and privacy concerns, it\\nis more practical to focus on attacking the black-box RecSys, where attackers\\ncan only observe the system's inputs and outputs. However, traditional attack\\napproaches employing reinforcement learning (RL) agents are not effective for\\nattacking LLM-empowered RecSys due to the limited capabilities in processing\\ncomplex textual inputs, planning, and reasoning. On the other hand, LLMs\\nprovide unprecedented opportunities to serve as attack agents to attack RecSys\\nbecause of their impressive capability in simulating human-like decision-making\\nprocesses. Therefore, in this paper, we propose a novel attack framework called\\nCheatAgent by harnessing the human-like capabilities of LLMs, where an\\nLLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our\\nmethod first identifies the insertion position for maximum impact with minimal\\ninput modification. After that, the LLM agent is designed to generate\\nadversarial perturbations to insert at target positions. To further improve the\\nquality of generated perturbations, we utilize the prompt tuning technique to\\nimprove attacking strategies via feedback from the victim RecSys iteratively.\\nExtensive experiments across three real-world datasets demonstrate the\\neffectiveness of our proposed attacking method.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.13192v2.pdf'},\n",
       " {'id': '2508.16044v2',\n",
       "  'title': 'AMAZe: A Multi-Agent Zero-shot Index Advisor for Relational Databases',\n",
       "  'published': '2025-08-22T02:42:21Z',\n",
       "  'summary': 'Index recommendation is one of the most important problems in database\\nmanagement system (DBMS) optimization. Given queries and certain index-related\\nconstraints, traditional methods rely on heuristic optimization or\\nlearning-based models to select effective indexes and improve query\\nperformance. However, heuristic optimization suffers from high computation\\ntime, and learning-based models lose generalisability due to training for\\ndifferent workloads and database schemas. With the recent rapid development of\\nlarge language models (LLMs), methods using prompt tuning have been proposed to\\nenhance the efficiency of index selection. However, such methods still can not\\nachieve the state-of-the-art (SOTA) results, and preparing the index selection\\ndemonstrations is also resource-intensive. To address these issues, we propose\\nAMAZe, a zero-shot LLM-based index advisor with a multi-agent framework. We\\ndecompose the index recommendation problem into sub-steps, including planning,\\nselection, combination, revision, and reflection. A set of LLM-embedded agents\\nis designed to handle each one of the different sub-steps. Our method utilizes\\nhigh-level agents to control the index selection process and low-level agents\\nto select and revise indexes. Through extensive experiments, we show that our\\nproposed AMAZe not only achieves the SOTA performance compared to the heuristic\\nmethods, but also outperforms learning-based and prompt-based methods with\\nhigher efficiency and better zero-shot inference ability.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.16044v2.pdf'},\n",
       " {'id': '1906.06437v1',\n",
       "  'title': 'A Strategy for Expert Recommendation From Open Data Available on the\\n  Lattes Platform',\n",
       "  'published': '2019-06-14T23:36:53Z',\n",
       "  'summary': 'With the increasing volume of data and users of curriculum systems, the\\ndifficulty of finding specialists is increasing.This work proposes an open data\\nextraction methodology of the Lattes Platform curricula, a treatment for this\\ndata and investigates a Recommendation Agent approach based on deep neural\\nnetworks with autoencoder.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1906.06437v1.pdf'},\n",
       " {'id': '1802.09100v1',\n",
       "  'title': 'Can a Chatbot Determine My Diet?: Addressing Challenges of Chatbot\\n  Application for Meal Recommendation',\n",
       "  'published': '2018-02-25T22:30:10Z',\n",
       "  'summary': 'Poor nutrition can lead to reduced immunity, increased susceptibility to\\ndisease, impaired physical and mental development, and reduced productivity. A\\nconversational agent can support people as a virtual coach, however building\\nsuch systems still have its associated challenges and limitations. This paper\\ndescribes the background and motivation for chatbot systems in the context of\\nhealthy nutrition recommendation. We discuss current challenges associated with\\nchatbot application, we tackled technical, theoretical, behavioural, and social\\naspects of the challenges. We then propose a pipeline to be used as guidelines\\nby developers to implement theoretically and technically robust chatbot\\nsystems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1802.09100v1.pdf'},\n",
       " {'id': '1804.02657v1',\n",
       "  'title': 'Emotion Orientated Recommendation System for Hiroshima Tourist by Fuzzy\\n  Petri Net',\n",
       "  'published': '2018-04-08T09:18:56Z',\n",
       "  'summary': \"We developed an Android Smartophone application software for tourist\\ninformation system. Especially, the agent system recommends the sightseeing\\nspot and local hospitality corresponding to the current feelings. The system\\nsuch as concierge can estimate user's emotion and mood by Emotion Generating\\nCalculations and Mental State Transition Network. In this paper, the system\\ndecides the next candidates for spots and foods by the reasoning of fuzzy Petri\\nNet in order to make more smooth communication between human and smartphone.\\nThe system was developed for Hiroshima Tourist Information and described some\\nhospitality about the concierge system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1804.02657v1.pdf'},\n",
       " {'id': '2112.14480v1',\n",
       "  'title': 'On some Foundational Aspects of Human-Centered Artificial Intelligence',\n",
       "  'published': '2021-12-29T09:58:59Z',\n",
       "  'summary': 'The burgeoning of AI has prompted recommendations that AI techniques should\\nbe \"human-centered\". However, there is no clear definition of what is meant by\\nHuman Centered Artificial Intelligence, or for short, HCAI. This paper aims to\\nimprove this situation by addressing some foundational aspects of HCAI. To do\\nso, we introduce the term HCAI agent to refer to any physical or software\\ncomputational agent equipped with AI components and that interacts and/or\\ncollaborates with humans. This article identifies five main conceptual\\ncomponents that participate in an HCAI agent: Observations, Requirements,\\nActions, Explanations and Models. We see the notion of HCAI agent, together\\nwith its components and functions, as a way to bridge the technical and\\nnon-technical discussions on human-centered AI. In this paper, we focus our\\nanalysis on scenarios consisting of a single agent operating in dynamic\\nenvironments in presence of humans.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.14480v1.pdf'},\n",
       " {'id': '1402.3044v2',\n",
       "  'title': 'Finding a Collective Set of Items: From Proportional Multirepresentation\\n  to Group Recommendation',\n",
       "  'published': '2014-02-13T07:14:28Z',\n",
       "  'summary': \"We consider the following problem: There is a set of items (e.g., movies) and\\na group of agents (e.g., passengers on a plane); each agent has some intrinsic\\nutility for each of the items. Our goal is to pick a set of $K$ items that\\nmaximize the total derived utility of all the agents (i.e., in our example we\\nare to pick $K$ movies that we put on the plane's entertainment system).\\nHowever, the actual utility that an agent derives from a given item is only a\\nfraction of its intrinsic one, and this fraction depends on how the agent ranks\\nthe item among the chosen, available, ones. We provide a formal specification\\nof the model and provide concrete examples and settings where it is applicable.\\nWe show that the problem is hard in general, but we show a number of\\ntractability results for its natural special cases.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1402.3044v2.pdf'},\n",
       " {'id': '2005.10619v1',\n",
       "  'title': 'A Survey of Reinforcement Learning Algorithms for Dynamically Varying\\n  Environments',\n",
       "  'published': '2020-05-19T09:42:42Z',\n",
       "  'summary': 'Reinforcement learning (RL) algorithms find applications in inventory\\ncontrol, recommender systems, vehicular traffic management, cloud computing and\\nrobotics. The real-world complications of many tasks arising in these domains\\nmakes them difficult to solve with the basic assumptions underlying classical\\nRL algorithms. RL agents in these applications often need to react and adapt to\\nchanging operating conditions. A significant part of research on single-agent\\nRL techniques focuses on developing algorithms when the underlying assumption\\nof stationary environment model is relaxed. This paper provides a survey of RL\\nmethods developed for handling dynamically varying environment models. The goal\\nof methods not limited by the stationarity assumption is to help autonomous\\nagents adapt to varying operating conditions. This is possible either by\\nminimizing the rewards lost during learning by RL agent or by finding a\\nsuitable policy for the RL agent which leads to efficient operation of the\\nunderlying system. A representative collection of these algorithms is discussed\\nin detail in this work along with their categorization and their relative\\nmerits and demerits. Additionally we also review works which are tailored to\\napplication domains. Finally, we discuss future enhancements for this field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.10619v1.pdf'},\n",
       " {'id': '2102.11592v3',\n",
       "  'title': 'Strategic Classification in the Dark',\n",
       "  'published': '2021-02-23T10:13:54Z',\n",
       "  'summary': \"Strategic classification studies the interaction between a classification\\nrule and the strategic agents it governs. Under the assumption that the\\nclassifier is known, rational agents respond to it by manipulating their\\nfeatures. However, in many real-life scenarios of high-stake classification\\n(e.g., credit scoring), the classifier is not revealed to the agents, which\\nleads agents to attempt to learn the classifier and game it too. In this paper\\nwe generalize the strategic classification model to such scenarios. We define\\nthe price of opacity as the difference in prediction error between opaque and\\ntransparent strategy-robust classifiers, characterize it, and give a sufficient\\ncondition for this price to be strictly positive, in which case transparency is\\nthe recommended policy. Our experiments show how Hardt et al.'s robust\\nclassifier is affected by keeping agents in the dark.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.11592v3.pdf'},\n",
       " {'id': '2111.01570v1',\n",
       "  'title': 'Privacy-Preserving Communication-Efficient Federated Multi-Armed Bandits',\n",
       "  'published': '2021-11-02T12:56:12Z',\n",
       "  'summary': 'Communication bottleneck and data privacy are two critical concerns in\\nfederated multi-armed bandit (MAB) problems, such as situations in\\ndecision-making and recommendations of connected vehicles via wireless. In this\\npaper, we design the privacy-preserving communication-efficient algorithm in\\nsuch problems and study the interactions among privacy, communication and\\nlearning performance in terms of the regret. To be specific, we design\\nprivacy-preserving learning algorithms and communication protocols and derive\\nthe learning regret when networked private agents are performing online bandit\\nlearning in a master-worker, a decentralized and a hybrid structure. Our bandit\\nlearning algorithms are based on epoch-wise sub-optimal arm eliminations at\\neach agent and agents exchange learning knowledge with the server/each other at\\nthe end of each epoch. Furthermore, we adopt the differential privacy (DP)\\napproach to protect the data privacy at each agent when exchanging information;\\nand we curtail communication costs by making less frequent communications with\\nfewer agents participation. By analyzing the regret of our proposed algorithmic\\nframework in the master-worker, decentralized and hybrid structures, we\\ntheoretically show tradeoffs between regret and communication costs/privacy.\\nFinally, we empirically show these trade-offs which are consistent with our\\ntheoretical analysis.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.01570v1.pdf'},\n",
       " {'id': '2310.17017v1',\n",
       "  'title': 'An Integrative Survey on Mental Health Conversational Agents to Bridge\\n  Computer Science and Medical Perspectives',\n",
       "  'published': '2023-10-25T21:37:57Z',\n",
       "  'summary': 'Mental health conversational agents (a.k.a. chatbots) are widely studied for\\ntheir potential to offer accessible support to those experiencing mental health\\nchallenges. Previous surveys on the topic primarily consider papers published\\nin either computer science or medicine, leading to a divide in understanding\\nand hindering the sharing of beneficial knowledge between both domains. To\\nbridge this gap, we conduct a comprehensive literature review using the PRISMA\\nframework, reviewing 534 papers published in both computer science and\\nmedicine. Our systematic review reveals 136 key papers on building mental\\nhealth-related conversational agents with diverse characteristics of modeling\\nand experimental design techniques. We find that computer science papers focus\\non LLM techniques and evaluating response quality using automated metrics with\\nlittle attention to the application while medical papers use rule-based\\nconversational agents and outcome metrics to measure the health outcomes of\\nparticipants. Based on our findings on transparency, ethics, and cultural\\nheterogeneity in this review, we provide a few recommendations to help bridge\\nthe disciplinary divide and enable the cross-disciplinary development of mental\\nhealth conversational agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.17017v1.pdf'},\n",
       " {'id': '2403.09883v1',\n",
       "  'title': 'Influence of Personality and Communication Behavior of a Conversational\\n  Agent on User Experience and Social Presence in Augmented Reality',\n",
       "  'published': '2024-03-14T21:32:04Z',\n",
       "  'summary': 'A virtual embodiment can benefit conversational agents, but it is unclear how\\ntheir personalities and non-verbal behavior influence the User Experience and\\nSocial Presence in Augmented Reality (AR). We asked 30 users to converse with a\\nvirtual assistant who gives recommendations about city activities. The\\nparticipants interacted with two different personalities: Sammy, a cheerful\\nblue mouse, and Olive, a serious green human-like agent. Each was presented\\nwith two body languages - happy/friendly and annoyed/unfriendly. We conclude\\nhow agent representation and humor affect User Experience aspects, and that\\nbody language is significant in the evaluation and perception of the AR agent.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.09883v1.pdf'},\n",
       " {'id': '2403.15524v2',\n",
       "  'title': 'PPA-Game: Characterizing and Learning Competitive Dynamics Among Online\\n  Content Creators',\n",
       "  'published': '2024-03-22T14:13:11Z',\n",
       "  'summary': \"In this paper, we present the Proportional Payoff Allocation Game (PPA-Game),\\nwhich characterizes situations where agents compete for divisible resources. In\\nthe PPA-game, agents select from available resources, and their payoffs are\\nproportionately determined based on heterogeneous weights attributed to them.\\nSuch dynamics simulate content creators on online recommender systems like\\nYouTube and TikTok, who compete for finite consumer attention, with content\\nexposure reliant on inherent and distinct quality. We first conduct a\\ngame-theoretical analysis of the PPA-Game. While the PPA-Game does not always\\nguarantee the existence of a pure Nash equilibrium (PNE), we identify prevalent\\nscenarios ensuring its existence. Simulated experiments further prove that the\\ncases where PNE does not exist rarely happen. Beyond analyzing static payoffs,\\nwe further discuss the agents' online learning about resource payoffs by\\nintegrating a multi-player multi-armed bandit framework. We propose an online\\nalgorithm facilitating each agent's maximization of cumulative payoffs over $T$\\nrounds. Theoretically, we establish that the regret of any agent is bounded by\\n$O(\\\\log^{1 + \\\\eta} T)$ for any $\\\\eta > 0$. Empirical results further validate\\nthe effectiveness of our online learning approach.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.15524v2.pdf'},\n",
       " {'id': '2501.13648v3',\n",
       "  'title': 'Revisiting Online Learning Approach to Inverse Linear Optimization: A\\n  Fenchel$-$Young Loss Perspective and Gap-Dependent Regret Analysis',\n",
       "  'published': '2025-01-23T13:27:14Z',\n",
       "  'summary': 'This paper revisits the online learning approach to inverse linear\\noptimization studied by B\\\\\"armann et al. (2017), where the goal is to infer an\\nunknown linear objective function of an agent from sequential observations of\\nthe agent\\'s input-output pairs. First, we provide a simple understanding of the\\nonline learning approach through its connection to online convex optimization\\nof \\\\emph{Fenchel--Young losses}. As a byproduct, we present an offline\\nguarantee on the \\\\emph{suboptimality loss}, which measures how well predicted\\nobjectives explain the agent\\'s choices, without assuming the optimality of the\\nagent\\'s choices. Second, assuming that there is a gap between optimal and\\nsuboptimal objective values in the agent\\'s decision problems, we obtain an\\nupper bound independent of the time horizon $T$ on the sum of suboptimality and\\n\\\\emph{estimate losses}, where the latter measures the quality of solutions\\nrecommended by predicted objectives. Interestingly, our gap-dependent analysis\\nachieves a faster rate than the standard $O(\\\\sqrt{T})$ regret bound by\\nexploiting structures specific to inverse linear optimization, even though\\nneither the loss functions nor their domains enjoy desirable properties, such\\nas strong convexity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.13648v3.pdf'},\n",
       " {'id': '2502.15865v2',\n",
       "  'title': 'Standard Benchmarks Fail -- Auditing LLM Agents in Finance Must\\n  Prioritize Risk',\n",
       "  'published': '2025-02-21T12:56:15Z',\n",
       "  'summary': \"Standard benchmarks fixate on how well large language model (LLM) agents\\nperform in finance, yet say little about whether they are safe to deploy. We\\nargue that accuracy metrics and return-based scores provide an illusion of\\nreliability, overlooking vulnerabilities such as hallucinated facts, stale\\ndata, and adversarial prompt manipulation. We take a firm position: financial\\nLLM agents should be evaluated first and foremost on their risk profile, not on\\ntheir point-estimate performance. Drawing on risk-engineering principles, we\\noutline a three-level agenda: model, workflow, and system, for stress-testing\\nLLM agents under realistic failure modes. To illustrate why this shift is\\nurgent, we audit six API-based and open-weights LLM agents on three high-impact\\ntasks and uncover hidden weaknesses that conventional benchmarks miss. We\\nconclude with actionable recommendations for researchers, practitioners, and\\nregulators: audit risk-aware metrics in future studies, publish stress\\nscenarios alongside datasets, and treat ``safety budget'' as a primary success\\ncriterion. Only by redefining what ``good'' looks like can the community\\nresponsibly advance AI-driven finance.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.15865v2.pdf'},\n",
       " {'id': '2503.04750v2',\n",
       "  'title': 'AI Agents Should be Regulated Based on the Extent of Their Autonomous\\n  Operations',\n",
       "  'published': '2025-02-07T09:40:48Z',\n",
       "  'summary': \"This position paper argues that AI agents should be regulated by the extent\\nto which they operate autonomously. AI agents with long-term planning and\\nstrategic capabilities can pose significant risks of human extinction and\\nirreversible global catastrophes. While existing regulations often focus on\\ncomputational scale as a proxy for potential harm, we argue that such measures\\nare insufficient for assessing the risks posed by agents whose capabilities\\narise primarily from inference-time computation. To support our position, we\\ndiscuss relevant regulations and recommendations from scientists regarding\\nexistential risks, as well as the advantages of using action sequences -- which\\nreflect the degree of an agent's autonomy -- as a more suitable measure of\\npotential impact than existing metrics that rely on observing environmental\\nstates.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.04750v2.pdf'},\n",
       " {'id': '2508.00400v1',\n",
       "  'title': 'Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents',\n",
       "  'published': '2025-08-01T08:01:38Z',\n",
       "  'summary': 'We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store\\nsimulation for benchmarking embodied agents against human performance in\\nshopping tasks. Addressing a gap in retail-specific sim environments for\\nembodied agent training, Sari Sandbox features over 250 interactive grocery\\nitems across three store configurations, controlled via an API. It supports\\nboth virtual reality (VR) for human interaction and a vision language model\\n(VLM)-powered embodied agent. We also introduce SariBench, a dataset of\\nannotated human demonstrations across varied task difficulties. Our sandbox\\nenables embodied agents to navigate, inspect, and manipulate retail items,\\nproviding baselines against human performance. We conclude with benchmarks,\\nperformance analysis, and recommendations for enhancing realism and\\nscalability. The source code can be accessed via\\nhttps://github.com/upeee/sari-sandbox-env.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.00400v1.pdf'},\n",
       " {'id': '2508.03095v1',\n",
       "  'title': 'A Survey of AI Agent Registry Solutions',\n",
       "  'published': '2025-08-05T05:17:18Z',\n",
       "  'summary': \"As As autonomous AI agents scale across cloud, enterprise, and decentralized\\nenvironments, the need for standardized registry systems to support discovery,\\nidentity, and capability sharing has become essential. This paper surveys three\\nprominent registry approaches each defined by a unique metadata model: MCP's\\nmcp.json, A2A's Agent Card, and NANDA's AgentFacts. MCP uses a centralized\\nmetaregistry with GitHub authenticated publishing and structured metadata for\\nserver discovery. A2A enables decentralized interaction via JSON-based Agent\\nCards, discoverable through well-known URIs, curated catalogs, or direct\\nconfiguration. NANDA Index introduces AgentFacts, a cryptographically\\nverifiable and privacy-preserving metadata model designed for dynamic\\ndiscovery, credentialed capabilities, and cross-domain interoperability. These\\napproaches are compared across four dimensions: security, scalability,\\nauthentication, and maintainability. The paper concludes with suggestions and\\nrecommendations to guide future design and adoption of registry systems for the\\nInternet of AI Agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.03095v1.pdf'},\n",
       " {'id': '2509.10993v1',\n",
       "  'title': 'When Your Boss Is an AI Bot: Exploring Opportunities and Risks of\\n  Manager Clone Agents in the Future Workplace',\n",
       "  'published': '2025-09-13T22:11:23Z',\n",
       "  'summary': \"As Generative AI (GenAI) becomes increasingly embedded in the workplace,\\nmanagers are beginning to create Manager Clone Agents - AI-powered digital\\nsurrogates that are trained on their work communications and decision patterns\\nto perform managerial tasks on their behalf. To investigate this emerging\\nphenomenon, we conducted six design fiction workshops (n = 23) with managers\\nand workers, in which participants co-created speculative scenarios and\\ndiscussed how Manager Clone Agents might transform collaborative work. We\\nidentified four potential roles that participants envisioned for Manager Clone\\nAgents: proxy presence, informational conveyor belt, productivity engine, and\\nleadership amplifier, while highlighting concerns spanning individual,\\ninterpersonal, and organizational levels. We provide design recommendations\\nenvisioned by both parties for integrating Manager Clone Agents responsibly\\ninto the future workplace, emphasizing the need to prioritize workers'\\nperspectives, strengthen interpersonal bonds, and enable flexible clone\\nconfiguration.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.10993v1.pdf'},\n",
       " {'id': '1902.07119v1',\n",
       "  'title': 'Bayesian Exploration with Heterogeneous Agents',\n",
       "  'published': '2019-02-19T16:22:43Z',\n",
       "  'summary': 'It is common in recommendation systems that users both consume and produce\\ninformation as they make strategic choices under uncertainty. While a social\\nplanner would balance \"exploration\" and \"exploitation\" using a multi-armed\\nbandit algorithm, users\\' incentives may tilt this balance in favor of\\nexploitation. We consider Bayesian Exploration: a simple model in which the\\nrecommendation system (the \"principal\") controls the information flow to the\\nusers (the \"agents\") and strives to incentivize exploration via information\\nasymmetry. A single round of this model is a version of a well-known \"Bayesian\\nPersuasion game\" from [Kamenica and Gentzkow]. We allow heterogeneous users,\\nrelaxing a major assumption from prior work that users have the same\\npreferences from one time step to another. The goal is now to learn the best\\npersonalized recommendations. One particular challenge is that it may be\\nimpossible to incentivize some of the user types to take some of the actions,\\nno matter what the principal does or how much time she has. We consider several\\nversions of the model, depending on whether and when the user types are\\nreported to the principal, and design a near-optimal \"recommendation policy\"\\nfor each version. We also investigate how the model choice and the diversity of\\nuser types impact the set of actions that can possibly be \"explored\" by each\\ntype.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.07119v1.pdf'},\n",
       " {'id': '2304.07920v2',\n",
       "  'title': 'Causal Decision Transformer for Recommender Systems via Offline\\n  Reinforcement Learning',\n",
       "  'published': '2023-04-17T00:05:52Z',\n",
       "  'summary': \"Reinforcement learning-based recommender systems have recently gained\\npopularity. However, the design of the reward function, on which the agent\\nrelies to optimize its recommendation policy, is often not straightforward.\\nExploring the causality underlying users' behavior can take the place of the\\nreward function in guiding the agent to capture the dynamic interests of users.\\nMoreover, due to the typical limitations of simulation environments (e.g., data\\ninefficiency), most of the work cannot be broadly applied in large-scale\\nsituations. Although some works attempt to convert the offline dataset into a\\nsimulator, data inefficiency makes the learning process even slower. Because of\\nthe nature of reinforcement learning (i.e., learning by interaction), it cannot\\ncollect enough data to train during a single interaction. Furthermore,\\ntraditional reinforcement learning algorithms do not have a solid capability\\nlike supervised learning methods to learn from offline datasets directly. In\\nthis paper, we propose a new model named the causal decision transformer for\\nrecommender systems (CDT4Rec). CDT4Rec is an offline reinforcement learning\\nsystem that can learn from a dataset rather than from online interaction.\\nMoreover, CDT4Rec employs the transformer architecture, which is capable of\\nprocessing large offline datasets and capturing both short-term and long-term\\ndependencies within the data to estimate the causal relationship between\\naction, state, and reward. To demonstrate the feasibility and superiority of\\nour model, we have conducted experiments on six real-world offline datasets and\\none online simulator.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.07920v2.pdf'},\n",
       " {'id': '2308.06965v1',\n",
       "  'title': 'AutoAssign+: Automatic Shared Embedding Assignment in Streaming\\n  Recommendation',\n",
       "  'published': '2023-08-14T06:43:59Z',\n",
       "  'summary': 'In the domain of streaming recommender systems, conventional methods for\\naddressing new user IDs or item IDs typically involve assigning initial ID\\nembeddings randomly. However, this practice results in two practical\\nchallenges: (i) Items or users with limited interactive data may yield\\nsuboptimal prediction performance. (ii) Embedding new IDs or low-frequency IDs\\nnecessitates consistently expanding the embedding table, leading to unnecessary\\nmemory consumption. In light of these concerns, we introduce a reinforcement\\nlearning-driven framework, namely AutoAssign+, that facilitates Automatic\\nShared Embedding Assignment Plus. To be specific, AutoAssign+ utilizes an\\nIdentity Agent as an actor network, which plays a dual role: (i) Representing\\nlow-frequency IDs field-wise with a small set of shared embeddings to enhance\\nthe embedding initialization, and (ii) Dynamically determining which ID\\nfeatures should be retained or eliminated in the embedding table. The policy of\\nthe agent is optimized with the guidance of a critic network. To evaluate the\\neffectiveness of our approach, we perform extensive experiments on three\\ncommonly used benchmark datasets. Our experiment results demonstrate that\\nAutoAssign+ is capable of significantly enhancing recommendation performance by\\nmitigating the cold-start problem. Furthermore, our framework yields a\\nreduction in memory usage of approximately 20-30%, verifying its practical\\neffectiveness and efficiency for streaming recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.06965v1.pdf'},\n",
       " {'id': '2410.14586v1',\n",
       "  'title': 'Neural Combinatorial Clustered Bandits for Recommendation Systems',\n",
       "  'published': '2024-10-18T16:37:28Z',\n",
       "  'summary': 'We consider the contextual combinatorial bandit setting where in each round,\\nthe learning agent, e.g., a recommender system, selects a subset of \"arms,\"\\ne.g., products, and observes rewards for both the individual base arms, which\\nare a function of known features (called \"context\"), and the super arm (the\\nsubset of arms), which is a function of the base arm rewards. The agent\\'s goal\\nis to simultaneously learn the unknown reward functions and choose the\\nhighest-reward arms. For example, the \"reward\" may represent a user\\'s\\nprobability of clicking on one of the recommended products. Conventional bandit\\nmodels, however, employ restrictive reward function models in order to obtain\\nperformance guarantees. We make use of deep neural networks to estimate and\\nlearn the unknown reward functions and propose Neural UCB Clustering\\n(NeUClust), which adopts a clustering approach to select the super arm in every\\nround by exploiting underlying structure in the context space. Unlike prior\\nneural bandit works, NeUClust uses a neural network to estimate the super arm\\nreward and select the super arm, thus eliminating the need for a known\\noptimization oracle. We non-trivially extend prior neural combinatorial bandit\\nworks to prove that NeUClust achieves\\n$\\\\widetilde{O}\\\\left(\\\\widetilde{d}\\\\sqrt{T}\\\\right)$ regret, where $\\\\widetilde{d}$\\nis the effective dimension of a neural tangent kernel matrix, $T$ the number of\\nrounds. Experiments on real world recommendation datasets show that NeUClust\\nachieves better regret and reward than other contextual combinatorial and\\nneural bandit algorithms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.14586v1.pdf'},\n",
       " {'id': '2401.08961v4',\n",
       "  'title': 'Cascading Reinforcement Learning',\n",
       "  'published': '2024-01-17T04:20:26Z',\n",
       "  'summary': 'Cascading bandits have gained popularity in recent years due to their\\napplicability to recommendation systems and online advertising. In the\\ncascading bandit model, at each timestep, an agent recommends an ordered subset\\nof items (called an item list) from a pool of items, each associated with an\\nunknown attraction probability. Then, the user examines the list, and clicks\\nthe first attractive item (if any), and after that, the agent receives a\\nreward. The goal of the agent is to maximize the expected cumulative reward.\\nHowever, the prior literature on cascading bandits ignores the influences of\\nuser states (e.g., historical behaviors) on recommendations and the change of\\nstates as the session proceeds. Motivated by this fact, we propose a\\ngeneralized cascading RL framework, which considers the impact of user states\\nand state transition into decisions. In cascading RL, we need to select items\\nnot only with large attraction probabilities but also leading to good successor\\nstates. This imposes a huge computational challenge due to the combinatorial\\naction space. To tackle this challenge, we delve into the properties of value\\nfunctions, and design an oracle BestPerm to efficiently find the optimal item\\nlist. Equipped with BestPerm, we develop two algorithms CascadingVI and\\nCascadingBPI, which are both computationally-efficient and sample-efficient,\\nand provide near-optimal regret and sample complexity guarantees. Furthermore,\\nwe present experiments to show the improved computational and sample\\nefficiencies of our algorithms compared to straightforward adaptations of\\nexisting RL algorithms in practice.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.08961v4.pdf'},\n",
       " {'id': '2503.10970v1',\n",
       "  'title': 'TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of\\n  Tools',\n",
       "  'published': '2025-03-14T00:28:15Z',\n",
       "  'summary': 'Precision therapeutics require multimodal adaptive models that generate\\npersonalized treatment recommendations. We introduce TxAgent, an AI agent that\\nleverages multi-step reasoning and real-time biomedical knowledge retrieval\\nacross a toolbox of 211 tools to analyze drug interactions, contraindications,\\nand patient-specific treatment strategies. TxAgent evaluates how drugs interact\\nat molecular, pharmacokinetic, and clinical levels, identifies\\ncontraindications based on patient comorbidities and concurrent medications,\\nand tailors treatment strategies to individual patient characteristics. It\\nretrieves and synthesizes evidence from multiple biomedical sources, assesses\\ninteractions between drugs and patient conditions, and refines treatment\\nrecommendations through iterative reasoning. It selects tools based on task\\nobjectives and executes structured function calls to solve therapeutic tasks\\nthat require clinical reasoning and cross-source validation. The ToolUniverse\\nconsolidates 211 tools from trusted sources, including all US FDA-approved\\ndrugs since 1939 and validated clinical insights from Open Targets. TxAgent\\noutperforms leading LLMs, tool-use models, and reasoning agents across five new\\nbenchmarks: DrugPC, BrandPC, GenericPC, TreatmentPC, and DescriptionPC,\\ncovering 3,168 drug reasoning tasks and 456 personalized treatment scenarios.\\nIt achieves 92.1% accuracy in open-ended drug reasoning tasks, surpassing\\nGPT-4o and outperforming DeepSeek-R1 (671B) in structured multi-step reasoning.\\nTxAgent generalizes across drug name variants and descriptions. By integrating\\nmulti-step inference, real-time knowledge grounding, and tool-assisted\\ndecision-making, TxAgent ensures that treatment recommendations align with\\nestablished clinical guidelines and real-world evidence, reducing the risk of\\nadverse events and improving therapeutic decision-making.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.10970v1.pdf'},\n",
       " {'id': '2505.20889v1',\n",
       "  'title': 'Reinforcement Learning-based Sequential Route Recommendation for\\n  System-Optimal Traffic Assignment',\n",
       "  'published': '2025-05-27T08:33:02Z',\n",
       "  'summary': \"Modern navigation systems and shared mobility platforms increasingly rely on\\npersonalized route recommendations to improve individual travel experience and\\noperational efficiency. However, a key question remains: can such sequential,\\npersonalized routing decisions collectively lead to system-optimal (SO) traffic\\nassignment? This paper addresses this question by proposing a learning-based\\nframework that reformulates the static SO traffic assignment problem as a\\nsingle-agent deep reinforcement learning (RL) task. A central agent\\nsequentially recommends routes to travelers as origin-destination (OD) demands\\narrive, to minimize total system travel time. To enhance learning efficiency\\nand solution quality, we develop an MSA-guided deep Q-learning algorithm that\\nintegrates the iterative structure of traditional traffic assignment methods\\ninto the RL training process. The proposed approach is evaluated on both the\\nBraess and Ortuzar-Willumsen (OW) networks. Results show that the RL agent\\nconverges to the theoretical SO solution in the Braess network and achieves\\nonly a 0.35% deviation in the OW network. Further ablation studies demonstrate\\nthat the route action set's design significantly impacts convergence speed and\\nfinal performance, with SO-informed route sets leading to faster learning and\\nbetter outcomes. This work provides a theoretically grounded and practically\\nrelevant approach to bridging individual routing behavior with system-level\\nefficiency through learning-based sequential assignment.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.20889v1.pdf'},\n",
       " {'id': '2508.04714v2',\n",
       "  'title': 'Prescriptive Agents based on RAG for Automated Maintenance (PARAM)',\n",
       "  'published': '2025-07-28T14:22:19Z',\n",
       "  'summary': 'Industrial machinery maintenance requires timely intervention to prevent\\ncatastrophic failures and optimize operational efficiency. This paper presents\\nan integrated Large Language Model (LLM)-based intelligent system for\\nprescriptive maintenance that extends beyond traditional anomaly detection to\\nprovide actionable maintenance recommendations. Building upon our prior LAMP\\nframework for numerical data analysis, we develop a comprehensive solution that\\ncombines bearing vibration frequency analysis with multi agentic generation for\\nintelligent maintenance planning. Our approach serializes bearing vibration\\ndata (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM\\nprocessing, enabling few-shot anomaly detection with high accuracy. The system\\nclassifies fault types (inner race, outer race, ball/roller, cage faults) and\\nassesses severity levels. A multi-agentic component processes maintenance\\nmanuals using vector embeddings and semantic search, while also conducting web\\nsearches to retrieve comprehensive procedural knowledge and access up-to-date\\nmaintenance practices for more accurate and in-depth recommendations. The\\nGemini model then generates structured maintenance recommendations includes\\nimmediate actions, inspection checklists, corrective measures, parts\\nrequirements, and timeline specifications. Experimental validation in bearing\\nvibration datasets demonstrates effective anomaly detection and contextually\\nrelevant maintenance guidance. The system successfully bridges the gap between\\ncondition monitoring and actionable maintenance planning, providing industrial\\npractitioners with intelligent decision support. This work advances the\\napplication of LLMs in industrial maintenance, offering a scalable framework\\nfor prescriptive maintenance across machinery components and industrial\\nsectors.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.04714v2.pdf'},\n",
       " {'id': '2508.06555v2',\n",
       "  'title': 'StyleTailor: Towards Personalized Fashion Styling via Hierarchical\\n  Negative Feedback',\n",
       "  'published': '2025-08-06T08:42:42Z',\n",
       "  'summary': \"The advancement of intelligent agents has revolutionized problem-solving\\nacross diverse domains, yet solutions for personalized fashion styling remain\\nunderexplored, which holds immense promise for promoting shopping experiences.\\nIn this work, we present StyleTailor, the first collaborative agent framework\\nthat seamlessly unifies personalized apparel design, shopping recommendation,\\nvirtual try-on, and systematic evaluation into a cohesive workflow. To this\\nend, StyleTailor pioneers an iterative visual refinement paradigm driven by\\nmulti-level negative feedback, enabling adaptive and precise user alignment.\\nSpecifically, our framework features two core agents, i.e., Designer for\\npersonalized garment selection and Consultant for virtual try-on, whose outputs\\nare progressively refined via hierarchical vision-language model feedback\\nspanning individual items, complete outfits, and try-on efficacy.\\nCounterexamples are aggregated into negative prompts, forming a closed-loop\\nmechanism that enhances recommendation quality. To assess the performance, we\\nintroduce a comprehensive evaluation suite encompassing style consistency,\\nvisual quality, face similarity, and artistic appraisal. Extensive experiments\\ndemonstrate StyleTailor's superior performance in delivering personalized\\ndesigns and recommendations, outperforming strong baselines without negative\\nfeedback and establishing a new benchmark for intelligent fashion systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.06555v2.pdf'},\n",
       " {'id': '1512.01124v2',\n",
       "  'title': 'Deep Reinforcement Learning with Attention for Slate Markov Decision\\n  Processes with High-Dimensional States and Actions',\n",
       "  'published': '2015-12-03T15:51:30Z',\n",
       "  'summary': \"Many real-world problems come with action spaces represented as feature\\nvectors. Although high-dimensional control is a largely unsolved problem, there\\nhas recently been progress for modest dimensionalities. Here we report on a\\nsuccessful attempt at addressing problems of dimensionality as high as $2000$,\\nof a particular form. Motivated by important applications such as\\nrecommendation systems that do not fit the standard reinforcement learning\\nframeworks, we introduce Slate Markov Decision Processes (slate-MDPs). A\\nSlate-MDP is an MDP with a combinatorial action space consisting of slates\\n(tuples) of primitive actions of which one is executed in an underlying MDP.\\nThe agent does not control the choice of this executed action and the action\\nmight not even be from the slate, e.g., for recommendation systems for which\\nall recommendations can be ignored. We use deep Q-learning based on feature\\nrepresentations of both the state and action to learn the value of whole\\nslates. Unlike existing methods, we optimize for both the combinatorial and\\nsequential aspects of our tasks. The new agent's superiority over agents that\\neither ignore the combinatorial or sequential long-term value aspect is\\ndemonstrated on a range of environments with dynamics from a real-world\\nrecommendation system. Further, we use deep deterministic policy gradients to\\nlearn a policy that for each position of the slate, guides attention towards\\nthe part of the action space in which the value is the highest and we only\\nevaluate actions in this area. The attention is used within a sequentially\\ngreedy procedure leveraging submodularity. Finally, we show how introducing\\nrisk-seeking can dramatically improve the agents performance and ability to\\ndiscover more far reaching strategies.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1512.01124v2.pdf'},\n",
       " {'id': '2007.11338v1',\n",
       "  'title': 'When to (or not to) trust intelligent machines: Insights from an\\n  evolutionary game theory analysis of trust in repeated games',\n",
       "  'published': '2020-07-22T10:53:49Z',\n",
       "  'summary': \"The actions of intelligent agents, such as chatbots, recommender systems, and\\nvirtual assistants are typically not fully transparent to the user.\\nConsequently, using such an agent involves the user exposing themselves to the\\nrisk that the agent may act in a way opposed to the user's goals. It is often\\nargued that people use trust as a cognitive shortcut to reduce the complexity\\nof such interactions. Here we formalise this by using the methods of\\nevolutionary game theory to study the viability of trust-based strategies in\\nrepeated games. These are reciprocal strategies that cooperate as long as the\\nother player is observed to be cooperating. Unlike classic reciprocal\\nstrategies, once mutual cooperation has been observed for a threshold number of\\nrounds they stop checking their co-player's behaviour every round, and instead\\nonly check with some probability. By doing so, they reduce the opportunity cost\\nof verifying whether the action of their co-player was actually cooperative. We\\ndemonstrate that these trust-based strategies can outcompete strategies that\\nare always conditional, such as Tit-for-Tat, when the opportunity cost is\\nnon-negligible. We argue that this cost is likely to be greater when the\\ninteraction is between people and intelligent agents, because of the reduced\\ntransparency of the agent. Consequently, we expect people to use trust-based\\nstrategies more frequently in interactions with intelligent agents. Our results\\nprovide new, important insights into the design of mechanisms for facilitating\\ninteractions between humans and intelligent agents, where trust is an essential\\nfactor.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.11338v1.pdf'},\n",
       " {'id': '1901.08761v1',\n",
       "  'title': 'Distributed Policy Iteration for Scalable Approximation of Cooperative\\n  Multi-Agent Policies',\n",
       "  'published': '2019-01-25T07:13:29Z',\n",
       "  'summary': 'Decision making in multi-agent systems (MAS) is a great challenge due to\\nenormous state and joint action spaces as well as uncertainty, making\\ncentralized control generally infeasible. Decentralized control offers better\\nscalability and robustness but requires mechanisms to coordinate on joint tasks\\nand to avoid conflicts. Common approaches to learn decentralized policies for\\ncooperative MAS suffer from non-stationarity and lacking credit assignment,\\nwhich can lead to unstable and uncoordinated behavior in complex environments.\\nIn this paper, we propose Strong Emergent Policy approximation (STEP), a\\nscalable approach to learn strong decentralized policies for cooperative MAS\\nwith a distributed variant of policy iteration. For that, we use function\\napproximation to learn from action recommendations of a decentralized\\nmulti-agent planning algorithm. STEP combines decentralized multi-agent\\nplanning with centralized learning, only requiring a generative model for\\ndistributed black box optimization. We experimentally evaluate STEP in two\\nchallenging and stochastic domains with large state and joint action spaces and\\nshow that STEP is able to learn stronger policies than standard multi-agent\\nreinforcement learning algorithms, when combining multi-agent open-loop\\nplanning with centralized function approximation. The learned policies can be\\nreintegrated into the multi-agent planning process to further improve\\nperformance.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1901.08761v1.pdf'},\n",
       " {'id': '2001.02306v1',\n",
       "  'title': 'Examining Potential Usability and Health Beliefs Among Young Adults\\n  Using a Conversational Agent for HPV Vaccine Counseling',\n",
       "  'published': '2020-01-07T22:33:09Z',\n",
       "  'summary': 'The human papillomavirus (HPV) vaccine is the most effective way to prevent\\nHPV-related cancers. Integrating provider vaccine counseling is crucial to\\nimproving HPV vaccine completion rates. Automating the counseling experience\\nthrough a conversational agent could help improve HPV vaccine coverage and\\nreduce the burden of vaccine counseling for providers. In a previous study, we\\ntested a simulated conversational agent that provided HPV vaccine counseling\\nfor parents using the Wizard of OZ protocol. In the current study, we assessed\\nthe conversational agent among young college adults (n=24), a population that\\nmay have missed the HPV vaccine during their adolescence when vaccination is\\nrecommended. We also administered surveys for system and voice usability, and\\nfor health beliefs concerning the HPV vaccine. Participants perceived the agent\\nto have high usability that is slightly better or equivalent to other voice\\ninteractive interfaces, and there is some evidence that the agent impacted\\ntheir beliefs concerning the harms, uncertainty, and risk denials for the HPV\\nvaccine. Overall, this study demonstrates the potential for conversational\\nagents to be an impactful tool for health promotion endeavors.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2001.02306v1.pdf'},\n",
       " {'id': '2010.02179v1',\n",
       "  'title': 'Assessing the Helpfulness of Learning Materials with Inference-Based\\n  Learner-Like Agent',\n",
       "  'published': '2020-10-05T17:24:57Z',\n",
       "  'summary': \"Many English-as-a-second language learners have trouble using near-synonym\\nwords (e.g., small vs.little; briefly vs.shortly) correctly, and often look for\\nexample sentences to learn how two nearly synonymous terms differ. Prior work\\nuses hand-crafted scores to recommend sentences but has difficulty in adopting\\nsuch scores to all the near-synonyms as near-synonyms differ in various ways.\\nWe notice that the helpfulness of the learning material would reflect on the\\nlearners' performance. Thus, we propose the inference-based learner-like agent\\nto mimic learner behavior and identify good learning materials by examining the\\nagent's performance. To enable the agent to behave like a learner, we leverage\\nentailment modeling's capability of inferring answers from the provided\\nmaterials. Experimental results show that the proposed agent is equipped with\\ngood learner-like behavior to achieve the best performance in both\\nfill-in-the-blank (FITB) and good example sentence selection tasks. We further\\nconduct a classroom user study with college ESL learners. The results of the\\nuser study show that the proposed agent can find out example sentences that\\nhelp students learn more easily and efficiently. Compared to other models, the\\nproposed agent improves the score of more than 17% of students after learning.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.02179v1.pdf'},\n",
       " {'id': '2104.02818v2',\n",
       "  'title': 'Why? Why not? When? Visual Explanations of Agent Behavior in\\n  Reinforcement Learning',\n",
       "  'published': '2021-04-06T22:36:29Z',\n",
       "  'summary': 'Reinforcement learning (RL) is used in many domains, including autonomous\\ndriving, robotics, stock trading, and video games. Unfortunately, the black box\\nnature of RL agents, combined with legal and ethical considerations, makes it\\nincreasingly important that humans (including those are who not experts in RL)\\nunderstand the reasoning behind the actions taken by an RL agent, particularly\\nin safety-critical domains. To help address this challenge, we introduce\\nPolicyExplainer, a visual analytics interface which lets the user directly\\nquery an autonomous agent. PolicyExplainer visualizes the states, policy, and\\nexpected future rewards for an agent, and supports asking and answering\\nquestions such as: Why take this action? Why not take this other action? When\\nis this action taken? PolicyExplainer is designed based upon a domain analysis\\nwith RL researchers, and is evaluated via qualitative and quantitative\\nassessments on a trio of domains: taxi navigation, a stack bot domain, and drug\\nrecommendation for HIV patients. We find that PolicyExplainer promotes trust\\nand understanding of agent decisions better than a state-of-the-art text-based\\nexplanation approach. Interviews with domain practitioners provide further\\nvalidation for PolicyExplainer as applied to safety-critical domains. Our\\nresults help demonstrate how visualization-based approaches can be leveraged to\\ndecode the behavior of autonomous RL agents, particularly for RL non-experts.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2104.02818v2.pdf'},\n",
       " {'id': '2206.01134v2',\n",
       "  'title': 'Language and Culture Internalisation for Human-Like Autotelic AI',\n",
       "  'published': '2022-06-02T16:35:41Z',\n",
       "  'summary': 'Building autonomous agents able to grow open-ended repertoires of skills\\nacross their lives is a fundamental goal of artificial intelligence (AI). A\\npromising developmental approach recommends the design of intrinsically\\nmotivated agents that learn new skills by generating and pursuing their own\\ngoals - autotelic agents. But despite recent progress, existing algorithms\\nstill show serious limitations in terms of goal diversity, exploration,\\ngeneralisation or skill composition. This perspective calls for the immersion\\nof autotelic agents into rich socio-cultural worlds, an immensely important\\nattribute of our environment that shapes human cognition but is mostly omitted\\nin modern AI. Inspired by the seminal work of Vygotsky, we propose Vygotskian\\nautotelic agents - agents able to internalise their interactions with others\\nand turn them into cognitive tools. We focus on language and show how its\\nstructure and informational content may support the development of new\\ncognitive functions in artificial agents as it does in humans. We justify the\\napproach by uncovering several examples of new artificial cognitive functions\\nemerging from interactions between language and embodiment in recent works at\\nthe intersection of deep reinforcement learning and natural language\\nprocessing. Looking forward, we highlight future opportunities and challenges\\nfor Vygotskian Autotelic AI research, including the use of language models as\\ncultural models supporting artificial cognitive development.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.01134v2.pdf'},\n",
       " {'id': '2505.03586v3',\n",
       "  'title': 'Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning\\n  Framework for Mitigating Delayed Observation',\n",
       "  'published': '2025-05-06T14:47:56Z',\n",
       "  'summary': \"In real-world multi-agent systems (MASs), observation delays are ubiquitous,\\npreventing agents from making decisions based on the environment's true state.\\nAn individual agent's local observation often consists of multiple components\\nfrom other agents or dynamic entities in the environment. These discrete\\nobservation components with varying delay characteristics pose significant\\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\\nfirst formulate the decentralized stochastic individual delay partially\\nobservable Markov decision process (DSID-POMDP) by extending the standard\\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\\ntraining framework for addressing stochastic individual delays, along with\\nrecommended implementations for its constituent modules. We implement the\\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\\nsuffer severe performance degradation under fixed and unfixed delays. The\\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\\ndelay-free performance in certain delay scenarios while maintaining\\ngeneralizability. Our work provides a novel perspective on multi-agent delayed\\nobservation problems and offers an effective solution framework. The source\\ncode is available at https://anonymous.4open.science/r/RDC-pymarl-4512/.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.03586v3.pdf'},\n",
       " {'id': '1712.09059v5',\n",
       "  'title': 'Leveraging Long and Short-term Information in Content-aware Movie\\n  Recommendation',\n",
       "  'published': '2017-12-25T12:08:07Z',\n",
       "  'summary': \"Movie recommendation systems provide users with ranked lists of movies based\\non individual's preferences and constraints. Two types of models are commonly\\nused to generate ranking results: long-term models and session-based models.\\nWhile long-term models represent the interactions between users and movies that\\nare supposed to change slowly across time, session-based models encode the\\ninformation of users' interests and changing dynamics of movies' attributes in\\nshort terms. In this paper, we propose an LSIC model, leveraging Long and\\nShort-term Information in Content-aware movie recommendation using adversarial\\ntraining. In the adversarial process, we train a generator as an agent of\\nreinforcement learning which recommends the next movie to a user sequentially.\\nWe also train a discriminator which attempts to distinguish the generated list\\nof movies from the real records. The poster information of movies is integrated\\nto further improve the performance of movie recommendation, which is\\nspecifically essential when few ratings are available. The experiments\\ndemonstrate that the proposed model has robust superiority over competitors and\\nsets the state-of-the-art. We will release the source code of this work after\\npublication.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1712.09059v5.pdf'},\n",
       " {'id': '2003.05753v1',\n",
       "  'title': 'Reinforced Negative Sampling over Knowledge Graph for Recommendation',\n",
       "  'published': '2020-03-12T12:44:30Z',\n",
       "  'summary': 'Properly handling missing data is a fundamental challenge in recommendation.\\nMost present works perform negative sampling from unobserved data to supply the\\ntraining of recommender models with negative signals. Nevertheless, existing\\nnegative sampling strategies, either static or adaptive ones, are insufficient\\nto yield high-quality negative samples --- both informative to model training\\nand reflective of user real needs. In this work, we hypothesize that item\\nknowledge graph (KG), which provides rich relations among items and KG\\nentities, could be useful to infer informative and factual negative samples.\\nTowards this end, we develop a new negative sampling model, Knowledge Graph\\nPolicy Network (KGPolicy), which works as a reinforcement learning agent to\\nexplore high-quality negatives. Specifically, by conducting our designed\\nexploration operations, it navigates from the target positive interaction,\\nadaptively receives knowledge-aware negative signals, and ultimately yields a\\npotential negative item to train the recommender. We tested on a matrix\\nfactorization (MF) model equipped with KGPolicy, and it achieves significant\\nimprovements over both state-of-the-art sampling methods like DNS and IRGAN,\\nand KG-enhanced recommender models like KGAT. Further analyses from different\\nangles provide insights of knowledge-aware sampling. We release the codes and\\ndatasets at https://github.com/xiangwang1223/kgpolicy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2003.05753v1.pdf'},\n",
       " {'id': '2108.01442v1',\n",
       "  'title': 'Sequence Adaptation via Reinforcement Learning in Recommender Systems',\n",
       "  'published': '2021-07-31T13:56:46Z',\n",
       "  'summary': \"Accounting for the fact that users have different sequential patterns, the\\nmain drawback of state-of-the-art recommendation strategies is that a fixed\\nsequence length of user-item interactions is required as input to train the\\nmodels. This might limit the recommendation accuracy, as in practice users\\nfollow different trends on the sequential recommendations. Hence, baseline\\nstrategies might ignore important sequential interactions or add noise to the\\nmodels with redundant interactions, depending on the variety of users'\\nsequential behaviours. To overcome this problem, in this study we propose the\\nSAR model, which not only learns the sequential patterns but also adjusts the\\nsequence length of user-item interactions in a personalized manner. We first\\ndesign an actor-critic framework, where the RL agent tries to compute the\\noptimal sequence length as an action, given the user's state representation at\\na certain time step. In addition, we optimize a joint loss function to align\\nthe accuracy of the sequential recommendations with the expected cumulative\\nrewards of the critic network, while at the same time we adapt the sequence\\nlength with the actor network in a personalized manner. Our experimental\\nevaluation on four real-world datasets demonstrates the superiority of our\\nproposed model over several baseline approaches. Finally, we make our\\nimplementation publicly available at https://github.com/stefanosantaris/sar.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2108.01442v1.pdf'},\n",
       " {'id': '2202.07832v1',\n",
       "  'title': 'Heterogeneous Graph Learning for Explainable Recommendation over\\n  Academic Networks',\n",
       "  'published': '2022-02-16T02:40:09Z',\n",
       "  'summary': 'With the explosive growth of new graduates with research degrees every year,\\nunprecedented challenges arise for early-career researchers to find a job at a\\nsuitable institution. This study aims to understand the behavior of academic\\njob transition and hence recommend suitable institutions for PhD graduates.\\nSpecifically, we design a deep learning model to predict the career move of\\nearly-career researchers and provide suggestions. The design is built on top of\\nscholarly/academic networks, which contains abundant information about\\nscientific collaboration among scholars and institutions. We construct a\\nheterogeneous scholarly network to facilitate the exploring of the behavior of\\ncareer moves and the recommendation of institutions for scholars. We devise an\\nunsupervised learning model called HAI (Heterogeneous graph Attention InfoMax)\\nwhich aggregates attention mechanism and mutual information for institution\\nrecommendation. Moreover, we propose scholar attention and meta-path attention\\nto discover the hidden relationships between several meta-paths. With these\\nmechanisms, HAI provides ordered recommendations with explainability. We\\nevaluate HAI upon a real-world dataset against baseline methods. Experimental\\nresults verify the effectiveness and efficiency of our approach.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2202.07832v1.pdf'},\n",
       " {'id': '2204.07134v2',\n",
       "  'title': 'Reinforcement Learning Policy Recommendation for Interbank Network\\n  Stability',\n",
       "  'published': '2022-04-14T17:44:03Z',\n",
       "  'summary': \"In this paper, we analyze the effect of a policy recommendation on the\\nperformance of an artificial interbank market. Financial institutions stipulate\\nlending agreements following a public recommendation and their individual\\ninformation. The former is modeled by a reinforcement learning optimal policy\\nthat maximizes the system's fitness and gathers information on the economic\\nenvironment. The policy recommendation directs economic actors to create credit\\nrelationships through the optimal choice between a low interest rate or a high\\nliquidity supply. The latter, based on the agents' balance sheet, allows\\ndetermining the liquidity supply and interest rate that the banks optimally\\noffer their clients within the market. Thanks to the combination between the\\npublic and the private signal, financial institutions create or cut their\\ncredit connections over time via a preferential attachment evolving procedure\\nable to generate a dynamic network. Our results show that the emergence of a\\ncore-periphery interbank network, combined with a certain level of homogeneity\\nin the size of lenders and borrowers, is essential to ensure the system's\\nresilience. Moreover, the optimal policy recommendation obtained through\\nreinforcement learning is crucial in mitigating systemic risk.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2204.07134v2.pdf'},\n",
       " {'id': '2303.13270v2',\n",
       "  'title': 'The effect of Collaborative-Filtering based Recommendation Algorithms on\\n  Opinion Polarization',\n",
       "  'published': '2023-03-23T13:51:14Z',\n",
       "  'summary': 'A central role in shaping the experience of users online is played by\\nrecommendation algorithms. On the one hand they help retrieving content that\\nbest suits users taste, but on the other hand they may give rise to the so\\ncalled \"filter bubble\" effect, favoring the rise of polarization. In the\\npresent paper we study how a user-user collaborative-filtering algorithm\\naffects the behavior of a group of agents repeatedly exposed to it. By means of\\nanalytical and numerical techniques we show how the system stationary state\\ndepends on the strength of the similarity and popularity biases, quantifying\\nrespectively the weight given to the most similar users and to the best rated\\nitems. In particular, we derive a phase diagram of the model, where we observe\\nthree distinct phases: disorder, consensus and polarization. In the latter\\nusers spontaneously split into different groups, each focused on a single item.\\nWe identify, at the boundary between the disorder and polarization phases, a\\nregion where recommendations are nontrivially personalized without leading to\\nfilter bubbles. Finally, we show that our model can reproduce the behavior of\\nusers in the online music platform last.fm. This analysis paves the way to a\\nsystematic analysis of recommendation algorithms by means of statistical\\nphysics methods and opens to the possibility of devising less polarizing\\nrecommendation algorithms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.13270v2.pdf'},\n",
       " {'id': '2504.11182v1',\n",
       "  'title': 'Exploring Backdoor Attack and Defense for LLM-empowered Recommendations',\n",
       "  'published': '2025-04-15T13:37:38Z',\n",
       "  'summary': \"The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\\nhas dramatically advanced personalized recommendations and drawn extensive\\nattention. Despite the impressive progress, the safety of LLM-based RecSys\\nagainst backdoor attacks remains largely under-explored. In this paper, we\\nraise a new problem: Can a backdoor with a specific trigger be injected into\\nLLM-based Recsys, leading to the manipulation of the recommendation responses\\nwhen the backdoor trigger is appended to an item's title? To investigate the\\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\\nBadRec perturbs the items' titles with triggers and employs several fake users\\nto interact with these items, effectively poisoning the training set and\\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\\nthat poisoning just 1% of the training data with adversarial examples is\\nsufficient to successfully implant backdoors, enabling manipulation of\\nrecommendations. To further mitigate such a security threat, we propose a\\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\\nintroduce an LLM-based poison scanner to detect the poisoned items by\\nleveraging the powerful language understanding and rich knowledge of LLMs. A\\ntrigger augmentation agent is employed to generate diverse synthetic triggers\\nto guide the poison scanner in learning domain-specific knowledge of the\\npoisoned item detection task. Extensive experiments on three real-world\\ndatasets validate the effectiveness of the proposed P-Scanner.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.11182v1.pdf'},\n",
       " {'id': '2505.19473v1',\n",
       "  'title': 'Improving Recommendation Fairness without Sensitive Attributes Using\\n  Multi-Persona LLMs',\n",
       "  'published': '2025-05-26T03:52:41Z',\n",
       "  'summary': \"Despite the success of recommender systems in alleviating information\\noverload, fairness issues have raised concerns in recent years, potentially\\nleading to unequal treatment for certain user groups. While efforts have been\\nmade to improve recommendation fairness, they often assume that users'\\nsensitive attributes are available during model training. However, collecting\\nsensitive information can be difficult, especially on platforms that involve no\\npersonal information disclosure. Therefore, we aim to improve recommendation\\nfairness without any access to sensitive attributes. However, this is a\\nnon-trivial task because uncovering latent sensitive patterns from complicated\\nuser behaviors without explicit sensitive attributes can be difficult.\\nConsequently, suboptimal estimates of sensitive distributions can hinder the\\nfairness training process. To address these challenges, leveraging the\\nremarkable reasoning abilities of Large Language Models (LLMs), we propose a\\nnovel LLM-enhanced framework for Fair recommendation withOut Sensitive\\nAttributes (LLMFOSA). A Multi-Persona Sensitive Information Inference module\\nemploys LLMs with distinct personas that mimic diverse human perceptions to\\ninfer and distill sensitive information. Furthermore, a Confusion-Aware\\nSensitive Representation Learning module incorporates inference results and\\nrationales to develop robust sensitive representations, considering the\\nmislabeling confusion and collective consensus among agents. The model is then\\noptimized by a formulated mutual information objective. Extensive experiments\\non two public datasets validate the effectiveness of LLMFOSA in improving\\nfairness.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.19473v1.pdf'},\n",
       " {'id': '2507.12032v1',\n",
       "  'title': 'ARRC: Explainable, Workflow-Integrated Recommender for Sustainable\\n  Resource Optimization Across the Edge-Cloud Continuum',\n",
       "  'published': '2025-07-16T08:48:04Z',\n",
       "  'summary': 'Achieving sustainable, explainable, and maintainable automation for resource\\noptimization is a core challenge across the edge-cloud continuum. Persistent\\noverprovisioning and operational complexity often stem from heterogeneous\\nplatforms and layered abstractions, while systems lacking explainability and\\nmaintainability become fragile, impede safe recovery, and accumulate technical\\ndebt. Existing solutions are frequently reactive, limited to single abstraction\\nlayers, or require intrusive platform changes, leaving efficiency and\\nmaintainability gains unrealized.\\n  This paper addresses safe, transparent, and low-effort resource optimization\\nin dynamic, multi-tenant edge-cloud systems, without disrupting operator\\nworkflows or increasing technical debt. We introduce ARRC, a recommender system\\nrooted in software engineering design principles, which delivers explainable,\\ncross-layer resource recommendations directly into operator workflows (such as\\ntickets and GitOps pull requests). ARRC encapsulates optimization logic in\\nspecialized, auditable agents coordinated via a shared interface, supporting\\nmaintainability and extensibility through transparency and the ability to\\ninspect both recommendations and their rationale.\\n  Empirical evaluation in a multi-region industrial deployment shows that ARRC\\nreduces operator workload by over 50%, improves compute utilization by up to\\n7.7x, and maintains error rates below 5%, with most benefits achieved through\\nincremental, operator-approved changes. This demonstrates that explainable,\\nrecommendation-based architectures can achieve sustainable efficiency and\\nmaintainability improvements at production scale.\\n  ARRC provides an empirically evaluated framework for integrating explainable,\\nworkflow-driven automation into resource management, intended to advance best\\npractices for robust, maintainable, and transparent edge-cloud continuum\\nplatforms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.12032v1.pdf'},\n",
       " {'id': '1811.10732v2',\n",
       "  'title': 'Environments for Lifelong Reinforcement Learning',\n",
       "  'published': '2018-11-26T23:01:49Z',\n",
       "  'summary': 'To achieve general artificial intelligence, reinforcement learning (RL)\\nagents should learn not only to optimize returns for one specific task but also\\nto constantly build more complex skills and scaffold their knowledge about the\\nworld, without forgetting what has already been learned. In this paper, we\\ndiscuss the desired characteristics of environments that can support the\\ntraining and evaluation of lifelong reinforcement learning agents, review\\nexisting environments from this perspective, and propose recommendations for\\ndevising suitable environments in the future.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.10732v2.pdf'},\n",
       " {'id': '1902.02935v3',\n",
       "  'title': 'Expressive mechanisms for equitable rent division on a budget',\n",
       "  'published': '2019-02-08T04:35:33Z',\n",
       "  'summary': 'We study the incentive properties of envy-free mechanisms for the allocation\\nof rooms and payments of rent among financially constrained roommates. Each\\nagent reports her values for rooms, her housing earmark (soft budget), and an\\nindex that reflects the difficulty the agent experiences from having to pay\\nover this amount. Then an envy-free allocation for these reports is\\nrecommended. The complete information non-cooperative outcomes of each of these\\nmechanisms are exactly the envy-free allocations with respect to true\\npreferences if and only if the admissible budget violation indices have a\\nbound.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.02935v3.pdf'},\n",
       " {'id': '2005.06670v2',\n",
       "  'title': 'Federated Recommendation System via Differential Privacy',\n",
       "  'published': '2020-05-14T00:00:16Z',\n",
       "  'summary': \"In this paper, we are interested in what we term the federated private\\nbandits framework, that combines differential privacy with multi-agent bandit\\nlearning. We explore how differential privacy based Upper Confidence Bound\\n(UCB) methods can be applied to multi-agent environments, and in particular to\\nfederated learning environments both in `master-worker' and `fully\\ndecentralized' settings. We provide a theoretical analysis on the privacy and\\nregret performance of the proposed methods and explore the tradeoffs between\\nthese two.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.06670v2.pdf'},\n",
       " {'id': '2305.03852v1',\n",
       "  'title': 'CHAI-DT: A Framework for Prompting Conversational Generative AI Agents\\n  to Actively Participate in Co-Creation',\n",
       "  'published': '2023-05-05T21:25:35Z',\n",
       "  'summary': \"This paper explores the potential for utilizing generative AI models in\\ngroup-focused co-creative frameworks to enhance problem solving and ideation in\\nbusiness innovation and co-creation contexts, and proposes a novel prompting\\ntechnique for conversational generative AI agents which employ methods inspired\\nby traditional 'human-to-human' facilitation and instruction to enable active\\ncontribution to Design Thinking, a co-creative framework. Through experiments\\nusing this prompting technique, we gather evidence that conversational\\ngenerative transformers (i.e. ChatGPT) have the capability to contribute\\ncontext-specific, useful, and creative input into Design Thinking activities.\\nWe also discuss the potential benefits, limitations, and risks associated with\\nusing generative AI models in co-creative ideation and provide recommendations\\nfor future research.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.03852v1.pdf'},\n",
       " {'id': '2308.05260v1',\n",
       "  'title': 'AI4GCC -- Track 3: Consumption and the Challenges of Multi-Agent RL',\n",
       "  'published': '2023-08-09T23:52:41Z',\n",
       "  'summary': \"The AI4GCC competition presents a bold step forward in the direction of\\nintegrating machine learning with traditional economic policy analysis. Below,\\nwe highlight two potential areas for improvement that could enhance the\\ncompetition's ability to identify and evaluate proposed negotiation protocols.\\nFirstly, we suggest the inclusion of an additional index that accounts for\\nconsumption/utility as part of the evaluation criteria. Secondly, we recommend\\nfurther investigation into the learning dynamics of agents in the simulator and\\nthe game theoretic properties of outcomes from proposed negotiation protocols.\\nWe hope that these suggestions can be of use for future iterations of the\\ncompetition/simulation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.05260v1.pdf'},\n",
       " {'id': '2411.06264v1',\n",
       "  'title': 'GuidelineGuard: An Agentic Framework for Medical Note Evaluation with\\n  Guideline Adherence',\n",
       "  'published': '2024-11-09T19:32:26Z',\n",
       "  'summary': 'Although rapid advancements in Large Language Models (LLMs) are facilitating\\nthe integration of artificial intelligence-based applications and services in\\nhealthcare, limited research has focused on the systematic evaluation of\\nmedical notes for guideline adherence. This paper introduces GuidelineGuard, an\\nagentic framework powered by LLMs that autonomously analyzes medical notes,\\nsuch as hospital discharge and office visit notes, to ensure compliance with\\nestablished healthcare guidelines. By identifying deviations from recommended\\npractices and providing evidence-based suggestions, GuidelineGuard helps\\nclinicians adhere to the latest standards from organizations like the WHO and\\nCDC. This framework offers a novel approach to improving documentation quality\\nand reducing clinical errors.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.06264v1.pdf'},\n",
       " {'id': '2303.14515v1',\n",
       "  'title': 'Specific investments under negotiated transfer pricing: effects of\\n  different surplus sharing parameters on managerial performance: An\\n  agent-based simulation with fuzzy Q-learning agents',\n",
       "  'published': '2023-03-25T16:45:32Z',\n",
       "  'summary': \"This paper focuses on a decentralized profit-center firm that uses negotiated\\ntransfer pricing as an instrument to coordinate the production process.\\nMoreover, the firm's headquarters gives its divisions full authority over\\noperating decisions and it is assumed that each division can additionally make\\nan upfront investment decision that enhances the value of internal trade. On\\nearly works, the paper expands the number of divisions by one downstream\\ndivision and relaxes basic assumptions, such as the assumption of common\\nknowledge of rationality. Based on an agent-based simulation, it is examined\\nwhether cognitively bounded individuals modeled by fuzzy Q-learning achieve the\\nsame results as fully rational utility maximizers. In addition, the paper\\ninvestigates different constellations of bargaining power to see whether a\\ndeviation from the recommended optimal bargaining power leads to a higher\\nmanagerial performance. The simulation results show that fuzzy Q-learning\\nagents perform at least as well or better than fully individual rational\\nutility maximizers. The study also indicates that, in scenarios with different\\nmarginal costs of divisions, a deviation from the recommended optimal\\ndistribution ratio of the bargaining power of divisions can lead to higher\\ninvestment levels and, thus, to an increase in the headquarters' profit.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.14515v1.pdf'},\n",
       " {'id': '2409.04224v2',\n",
       "  'title': 'Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent\\n  Reinforcement Learning Framework',\n",
       "  'published': '2024-09-06T12:26:47Z',\n",
       "  'summary': 'In healthcare, multi-organ system diseases pose unique and significant\\nchallenges as they impact multiple physiological systems concurrently,\\ndemanding complex and coordinated treatment strategies. Despite recent\\nadvancements in the AI based clinical decision support systems, these solutions\\nonly focus on individual organ systems, failing to account for complex\\ninterdependencies between them. This narrow focus greatly hinders their\\neffectiveness in recommending holistic and clinically actionable treatments in\\nthe real world setting. To address this critical gap, we propose a novel\\nHierarchical Multi-Agent Reinforcement Learning (HMARL) framework. Our\\narchitecture deploys specialized and dedicated agents for each organ system and\\nfacilitates inter-agent communication to enable synergistic decision-making\\nacross organ systems. Furthermore, we introduce a dual-layer state\\nrepresentation technique that contextualizes patient conditions at both global\\nand organ-specific levels, improving the accuracy and relevance of treatment\\ndecisions. We evaluate our HMARL solution on the task of sepsis management, a\\ncommon and critical multi-organ disease, using both qualitative and\\nquantitative metrics. Our method learns effective, clinically aligned treatment\\npolicies that considerably improve patient survival. We believe this framework\\nrepresents a significant advancement in clinical decision support systems,\\nintroducing the first RL solution explicitly designed for multi-organ treatment\\nrecommendations. Our solution moves beyond prevailing simplified, single-organ\\nmodels that fall short in addressing the complexity of multi-organ diseases.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.04224v2.pdf'},\n",
       " {'id': '1902.04043v5',\n",
       "  'title': 'The StarCraft Multi-Agent Challenge',\n",
       "  'published': '2019-02-11T18:43:53Z',\n",
       "  'summary': 'In the last few years, deep multi-agent reinforcement learning (RL) has\\nbecome a highly active area of research. A particularly challenging class of\\nproblems in this area is partially observable, cooperative, multi-agent\\nlearning, in which teams of agents must learn to coordinate their behaviour\\nwhile conditioning only on their private observations. This is an attractive\\nresearch area since such problems are relevant to a large number of real-world\\nsystems and are also more amenable to evaluation than general-sum problems.\\nStandardised environments such as the ALE and MuJoCo have allowed single-agent\\nRL to move beyond toy domains, such as grid worlds. However, there is no\\ncomparable benchmark for cooperative multi-agent RL. As a result, most papers\\nin this field use one-off toy problems, making it difficult to measure real\\nprogress. In this paper, we propose the StarCraft Multi-Agent Challenge (SMAC)\\nas a benchmark problem to fill this gap. SMAC is based on the popular real-time\\nstrategy game StarCraft II and focuses on micromanagement challenges where each\\nunit is controlled by an independent agent that must act based on local\\nobservations. We offer a diverse set of challenge maps and recommendations for\\nbest practices in benchmarking and evaluations. We also open-source a deep\\nmulti-agent RL learning framework including state-of-the-art algorithms. We\\nbelieve that SMAC can provide a standard benchmark environment for years to\\ncome. Videos of our best agents for several SMAC scenarios are available at:\\nhttps://youtu.be/VZ7zmQ_obZ0.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.04043v5.pdf'},\n",
       " {'id': '2201.12482v3',\n",
       "  'title': 'Collaborative Learning in General Graphs with Limited Memorization:\\n  Complexity, Learnability, and Reliability',\n",
       "  'published': '2022-01-29T02:42:25Z',\n",
       "  'summary': 'We consider a K-armed bandit problem in general graphs where agents are\\narbitrarily connected and each of them has limited memorizing capabilities and\\ncommunication bandwidth. The goal is to let each of the agents eventually learn\\nthe best arm. It is assumed in these studies that the communication graph\\nshould be complete or well-structured, whereas such an assumption is not always\\nvalid in practice. Furthermore, limited memorization and communication\\nbandwidth also restrict the collaborations of the agents, since the agents\\nmemorize and communicate very few experiences. Additionally, an agent may be\\ncorrupted to share falsified experiences to its peers, while the resource limit\\nin terms of memorization and communication may considerably restrict the\\nreliability of the learning process. To address the above issues, we propose a\\nthree-staged collaborative learning algorithm. In each step, the agents share\\ntheir latest experiences with each other through light-weight random walks in a\\ngeneral communication graph, and then make decisions on which arms to pull\\naccording to the recommendations received from their peers. The agents finally\\nupdate their adoptions (i.e., preferences to the arms) based on the reward\\nobtained by pulling the arms. Our theoretical analysis shows that, when there\\nare a sufficient number of agents participating in the collaborative learning\\nprocess, all the agents eventually learn the best arm with high probability,\\neven with limited memorizing capabilities and light-weight communications. We\\nalso reveal in our theoretical analysis the upper bound on the number of\\ncorrupted agents our algorithm can tolerate. The efficacy of our proposed\\nthree-staged collaborative learning algorithm is finally verified by extensive\\nexperiments on both synthetic and real datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.12482v3.pdf'},\n",
       " {'id': '2402.03653v2',\n",
       "  'title': 'Agent-Based Triangle Counting: Unlocking Truss Decomposition, Triangle\\n  Centrality, and Local Clustering Coefficient',\n",
       "  'published': '2024-02-06T03:00:12Z',\n",
       "  'summary': 'Triangle counting in a graph is a fundamental problem with wide-ranging\\napplications. It is crucial for understanding graph structure and serves as a\\nbasis for more advanced graph analytics. One key application is truss\\ndecomposition, a technique for identifying maximal, highly interconnected\\nsubgraphs, revealing structural cohesion and tight-knit communities in complex\\ngraphs. This facilitates analysis of relationships and information flow in\\nfields such as social networks, biology, and recommendation systems. Using\\nmobile agents or robots for tasks like truss decomposition and clustering\\ncoefficient computation is especially advantageous in decentralised\\nenvironments with limited or unreliable communication. In such scenarios,\\nagents can perform local computations without requiring an extensive\\ncommunication infrastructure. This is valuable in contexts like disaster\\nresponse, urban management, and military operations, where broadcast\\ncommunication is impractical.\\n  In this paper, we address the triangle counting problem in an arbitrary\\nanonymous graph using mobile agents. This method is extended as a subroutine to\\nsolve the truss decomposition problem and compute triangle centrality and the\\nlocal clustering coefficient for each node. Our approach uses $n$ autonomous\\nmobile agents, each starting at a different node of an $n$-node graph. These\\nagents coordinate to collaboratively solve triangle enumeration, then truss\\ndecomposition, triangle centrality, and clustering coefficient. We assume a\\nsynchronous system where agents execute tasks concurrently, allowing time to be\\nmeasured in rounds. The graph is anonymous (nodes have no IDs), but agents have\\ndistinct IDs and limited memory. Agents can perform local computations and\\ncommunicate only when co-located. Our goal is to design algorithms that\\nminimise both time and memory per agent, while enabling solutions to the above\\nproblems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.03653v2.pdf'},\n",
       " {'id': '2210.10085v1',\n",
       "  'title': \"Auditing YouTube's Recommendation Algorithm for Misinformation Filter\\n  Bubbles\",\n",
       "  'published': '2022-10-18T18:27:47Z',\n",
       "  'summary': 'In this paper, we present results of an auditing study performed over YouTube\\naimed at investigating how fast a user can get into a misinformation filter\\nbubble, but also what it takes to \"burst the bubble\", i.e., revert the bubble\\nenclosure. We employ a sock puppet audit methodology, in which pre-programmed\\nagents (acting as YouTube users) delve into misinformation filter bubbles by\\nwatching misinformation promoting content. Then they try to burst the bubbles\\nand reach more balanced recommendations by watching misinformation debunking\\ncontent. We record search results, home page results, and recommendations for\\nthe watched videos. Overall, we recorded 17,405 unique videos, out of which we\\nmanually annotated 2,914 for the presence of misinformation. The labeled data\\nwas used to train a machine learning model classifying videos into three\\nclasses (promoting, debunking, neutral) with the accuracy of 0.82. We use the\\ntrained model to classify the remaining videos that would not be feasible to\\nannotate manually.\\n  Using both the manually and automatically annotated data, we observe the\\nmisinformation bubble dynamics for a range of audited topics. Our key finding\\nis that even though filter bubbles do not appear in some situations, when they\\ndo, it is possible to burst them by watching misinformation debunking content\\n(albeit it manifests differently from topic to topic). We also observe a sudden\\ndecrease of misinformation filter bubble effect when misinformation debunking\\nvideos are watched after misinformation promoting videos, suggesting a strong\\ncontextuality of recommendations. Finally, when comparing our results with a\\nprevious similar study, we do not observe significant improvements in the\\noverall quantity of recommended misinformation content.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.10085v1.pdf'},\n",
       " {'id': '2406.14165v2',\n",
       "  'title': 'Mechanism design augmented with output advice',\n",
       "  'published': '2024-06-20T10:10:21Z',\n",
       "  'summary': 'Our work revisits the design of mechanisms via the learning-augmented\\nframework. In this model, the algorithm is enhanced with imperfect\\n(machine-learned) information concerning the input, usually referred to as\\nprediction. The goal is to design algorithms whose performance degrades gently\\nas a function of the prediction error and, in particular, perform well if the\\nprediction is accurate, but also provide a worst-case guarantee under any\\npossible error. This framework has been successfully applied recently to\\nvarious mechanism design settings, where in most cases the mechanism is\\nprovided with a prediction about the types of the players.\\n  We adopt a perspective in which the mechanism is provided with an output\\nrecommendation. We make no assumptions about the quality of the suggested\\noutcome, and the goal is to use the recommendation to design mechanisms with\\nlow approximation guarantees whenever the recommended outcome is reasonable,\\nbut at the same time to provide worst-case guarantees whenever the\\nrecommendation significantly deviates from the optimal one. We propose a\\ngeneric, universal measure, which we call quality of recommendation, to\\nevaluate mechanisms across various information settings. We demonstrate how\\nthis new metric can provide refined analysis in existing results.\\n  This model introduces new challenges, as the mechanism receives limited\\ninformation comparing to settings that use predictions about the types of the\\nagents. We study, through this lens, several well-studied mechanism design\\nparadigms, devising new mechanisms, but also providing refined analysis for\\nexisting ones, using as a metric the quality of recommendation. We complement\\nour positive results, by exploring the limitations of known classes of\\nstrategyproof mechanisms that can be devised using output recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.14165v2.pdf'},\n",
       " {'id': '1906.09310v1',\n",
       "  'title': 'A Study of State Aliasing in Structured Prediction with RNNs',\n",
       "  'published': '2019-06-21T20:16:52Z',\n",
       "  'summary': 'End-to-end reinforcement learning agents learn a state representation and a\\npolicy at the same time. Recurrent neural networks (RNNs) have been trained\\nsuccessfully as reinforcement learning agents in settings like dialogue that\\nrequire structured prediction. In this paper, we investigate the\\nrepresentations learned by RNN-based agents when trained with both policy\\ngradient and value-based methods. We show through extensive experiments and\\nanalysis that, when trained with policy gradient, recurrent neural networks\\noften fail to learn a state representation that leads to an optimal policy in\\nsettings where the same action should be taken at different states. To explain\\nthis failure, we highlight the problem of state aliasing, which entails\\nconflating two or more distinct states in the representation space. We\\ndemonstrate that state aliasing occurs when several states share the same\\noptimal action and the agent is trained via policy gradient. We characterize\\nthis phenomenon through experiments on a simple maze setting and a more complex\\ntext-based game, and make recommendations for training RNNs with reinforcement\\nlearning.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1906.09310v1.pdf'},\n",
       " {'id': '1907.04252v2',\n",
       "  'title': 'The Secretary Recommendation Problem',\n",
       "  'published': '2019-07-09T15:33:19Z',\n",
       "  'summary': \"In this paper we revisit the basic variant of the classical secretary\\nproblem. We propose a new approach in which we separate between an agent that\\nevaluates the secretary performance and one that has to make the hiring\\ndecision. The evaluating agent (the sender) signals the quality of the\\ncandidate to the hiring agent (the receiver) who must make a decision. Whenever\\nthe two agents' interests are not fully aligned, this induces an information\\ntransmission (signaling) challenge for the sender. We study the sender's\\noptimization problem subject to persuasiveness constraints of the receiver for\\nseveral variants of the problem.\\n  Our results quantify the loss in performance for the sender due to online\\narrival. We provide optimal and near-optimal persuasive mechanisms that recover\\nat least a constant fraction of a natural utility benchmark for the sender. The\\nseparation of evaluation and decision making can have a substantial impact on\\nthe approximation results. While in some scenarios, techniques and results\\nclosely mirror the conditions in the standard secretary problem, we also\\nexplore conditions that lead to very different characteristics.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.04252v2.pdf'},\n",
       " {'id': '2006.07169v4',\n",
       "  'title': 'Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning',\n",
       "  'published': '2020-06-12T13:24:50Z',\n",
       "  'summary': 'Exploration in multi-agent reinforcement learning is a challenging problem,\\nespecially in environments with sparse rewards. We propose a general method for\\nefficient exploration by sharing experience amongst agents. Our proposed\\nalgorithm, called Shared Experience Actor-Critic (SEAC), applies experience\\nsharing in an actor-critic framework. We evaluate SEAC in a collection of\\nsparse-reward multi-agent environments and find that it consistently\\noutperforms two baselines and two state-of-the-art algorithms by learning in\\nfewer steps and converging to higher returns. In some harder environments,\\nexperience sharing makes the difference between learning to solve the task and\\nnot learning at all.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.07169v4.pdf'},\n",
       " {'id': '2006.09786v1',\n",
       "  'title': 'Reinforcement Learning with Uncertainty Estimation for Tactical\\n  Decision-Making in Intersections',\n",
       "  'published': '2020-06-17T11:29:26Z',\n",
       "  'summary': 'This paper investigates how a Bayesian reinforcement learning method can be\\nused to create a tactical decision-making agent for autonomous driving in an\\nintersection scenario, where the agent can estimate the confidence of its\\nrecommended actions. An ensemble of neural networks, with additional randomized\\nprior functions (RPF), are trained by using a bootstrapped experience replay\\nmemory. The coefficient of variation in the estimated $Q$-values of the\\nensemble members is used to approximate the uncertainty, and a criterion that\\ndetermines if the agent is sufficiently confident to make a particular decision\\nis introduced. The performance of the ensemble RPF method is evaluated in an\\nintersection scenario, and compared to a standard Deep Q-Network method. It is\\nshown that the trained ensemble RPF agent can detect cases with high\\nuncertainty, both in situations that are far from the training distribution,\\nand in situations that seldom occur within the training distribution. In this\\nstudy, the uncertainty information is used to choose safe actions in unknown\\nsituations, which removes all collisions from within the training distribution,\\nand most collisions outside of the distribution.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.09786v1.pdf'},\n",
       " {'id': '2001.03232v1',\n",
       "  'title': 'Optimal dynamic information provision in traffic routing',\n",
       "  'published': '2020-01-09T21:52:14Z',\n",
       "  'summary': 'We consider a two-road dynamic routing game where the state of one of the\\nroads (the \"risky road\") is stochastic and may change over time. This generates\\nroom for experimentation. A central planner may wish to induce some of the\\n(finite number of atomic) agents to use the risky road even when the expected\\ncost of travel there is high in order to obtain accurate information about the\\nstate of the road. Since agents are strategic, we show that in order to\\ngenerate incentives for experimentation the central planner however needs to\\nlimit the number of agents using the risky road when the expected cost of\\ntravel on the risky road is low. In particular, because of congestion, too much\\nuse of the risky road when the state is favorable would make experimentation no\\nlonger incentive compatible. We characterize the optimal incentive compatible\\nrecommendation system, first in a two-stage game and then in an\\ninfinite-horizon setting. In both cases, this system induces only partial,\\nrather than full, information sharing among the agents (otherwise there would\\nbe too much exploitation of the risky road when costs there are low).',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2001.03232v1.pdf'},\n",
       " {'id': '2103.00360v5',\n",
       "  'title': 'Exploration and Incentives in Reinforcement Learning',\n",
       "  'published': '2021-02-28T00:15:53Z',\n",
       "  'summary': 'How do you incentivize self-interested agents to $\\\\textit{explore}$ when they\\nprefer to $\\\\textit{exploit}$? We consider complex exploration problems, where\\neach agent faces the same (but unknown) MDP. In contrast with traditional\\nformulations of reinforcement learning, agents control the choice of policies,\\nwhereas an algorithm can only issue recommendations. However, the algorithm\\ncontrols the flow of information, and can incentivize the agents to explore via\\ninformation asymmetry. We design an algorithm which explores all reachable\\nstates in the MDP. We achieve provable guarantees similar to those for\\nincentivizing exploration in static, stateless exploration problems studied\\npreviously. To the best of our knowledge, this is the first work to consider\\nmechanism design in a stateful, reinforcement learning setting.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.00360v5.pdf'},\n",
       " {'id': '2105.01129v1',\n",
       "  'title': 'Towards A Multi-agent System for Online Hate Speech Detection',\n",
       "  'published': '2021-05-03T19:06:42Z',\n",
       "  'summary': 'This paper envisions a multi-agent system for detecting the presence of hate\\nspeech in online social media platforms such as Twitter and Facebook. We\\nintroduce a novel framework employing deep learning techniques to coordinate\\nthe channels of textual and im-age processing. Our experimental results aim to\\ndemonstrate the effectiveness of our methods for classifying online content,\\ntraining the proposed neural network model to effectively detect hateful\\ninstances in the input. We conclude with a discussion of how our system may be\\nof use to provide recommendations to users who are managing online social\\nnetworks, showcasing the immense potential of intelligent multi-agent systems\\ntowards delivering social good.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.01129v1.pdf'},\n",
       " {'id': '2402.16312v1',\n",
       "  'title': 'Federated Contextual Cascading Bandits with Asynchronous Communication\\n  and Heterogeneous Users',\n",
       "  'published': '2024-02-26T05:31:14Z',\n",
       "  'summary': \"We study the problem of federated contextual combinatorial cascading bandits,\\nwhere $|\\\\mathcal{U}|$ agents collaborate under the coordination of a central\\nserver to provide tailored recommendations to the $|\\\\mathcal{U}|$ corresponding\\nusers. Existing works consider either a synchronous framework, necessitating\\nfull agent participation and global synchronization, or assume user homogeneity\\nwith identical behaviors. We overcome these limitations by considering (1)\\nfederated agents operating in an asynchronous communication paradigm, where no\\nmandatory synchronization is required and all agents communicate independently\\nwith the server, (2) heterogeneous user behaviors, where users can be\\nstratified into $J \\\\le |\\\\mathcal{U}|$ latent user clusters, each exhibiting\\ndistinct preferences. For this setting, we propose a UCB-type algorithm with\\ndelicate communication protocols. Through theoretical analysis, we give\\nsub-linear regret bounds on par with those achieved in the synchronous\\nframework, while incurring only logarithmic communication costs. Empirical\\nevaluation on synthetic and real-world datasets validates our algorithm's\\nsuperior performance in terms of regrets and communication costs.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.16312v1.pdf'},\n",
       " {'id': '2406.18805v1',\n",
       "  'title': 'Online Stackelberg Optimization via Nonlinear Control',\n",
       "  'published': '2024-06-27T00:42:33Z',\n",
       "  'summary': 'In repeated interaction problems with adaptive agents, our objective often\\nrequires anticipating and optimizing over the space of possible agent\\nresponses. We show that many problems of this form can be cast as instances of\\nonline (nonlinear) control which satisfy \\\\textit{local controllability}, with\\nconvex losses over a bounded state space which encodes agent behavior, and we\\nintroduce a unified algorithmic framework for tractable regret minimization in\\nsuch cases. When the instance dynamics are known but otherwise arbitrary, we\\nobtain oracle-efficient $O(\\\\sqrt{T})$ regret by reduction to online convex\\noptimization, which can be made computationally efficient if dynamics are\\nlocally \\\\textit{action-linear}. In the presence of adversarial disturbances to\\nthe state, we give tight bounds in terms of either the cumulative or per-round\\ndisturbance magnitude (for \\\\textit{strongly} or \\\\textit{weakly} locally\\ncontrollable dynamics, respectively). Additionally, we give sublinear regret\\nresults for the cases of unknown locally action-linear dynamics as well as for\\nthe bandit feedback setting. Finally, we demonstrate applications of our\\nframework to well-studied problems including performative prediction,\\nrecommendations for adaptive agents, adaptive pricing of real-valued goods, and\\nrepeated gameplay against no-regret learners, directly yielding extensions\\nbeyond prior results in each case.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.18805v1.pdf'},\n",
       " {'id': '2411.01143v1',\n",
       "  'title': 'A Large-scale Time-aware Agents Simulation for Influencer Selection in\\n  Digital Advertising Campaigns',\n",
       "  'published': '2024-11-02T05:19:16Z',\n",
       "  'summary': 'In the digital world, influencers are pivotal as opinion leaders, shaping the\\nviews and choices of their influencees. Modern advertising often follows this\\ntrend, where marketers choose appropriate influencers for product endorsements,\\nbased on thorough market analysis. Previous studies on influencer selection\\nhave typically relied on numerical representations of individual opinions and\\ninteractions, a method that simplifies the intricacies of social dynamics. In\\nthis work, we first introduce a Time-aware Influencer Simulator (TIS), helping\\npromoters identify and select the right influencers to market their products,\\nbased on LLM simulation. To validate our approach, we conduct experiments on\\nthe public advertising campaign dataset SAGraph which encompasses social\\nrelationships, posts, and user interactions. The results show that our method\\noutperforms traditional numerical feature-based approaches and methods using\\nlimited LLM agents. Our research shows that simulating user timelines and\\ncontent lifecycles over time simplifies scaling, allowing for large-scale agent\\nsimulations in social networks. Additionally, LLM-based agents for social\\nrecommendations and advertising offer substantial benefits for decision-making\\nin promotional campaigns.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.01143v1.pdf'},\n",
       " {'id': '2503.07129v1',\n",
       "  'title': 'ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through\\n  Action in Dynamic Offer Optimization',\n",
       "  'published': '2025-03-10T09:57:50Z',\n",
       "  'summary': \"Negotiation requires dynamically balancing self-interest and cooperation to\\nmaximize one's own utility. Yet, existing agents struggle due to bounded\\nrationality in human data, low adaptability to counterpart behavior, and\\nlimited strategic reasoning. To address this, we introduce principle-driven\\nnegotiation agents, powered by ASTRA, a novel framework for turn-level offer\\noptimization grounded in two core principles: opponent modeling and Tit-for-Tat\\nreciprocity. ASTRA operates in three stages: (1) interpreting counterpart\\nbehavior, (2) optimizing counteroffers via a linear programming (LP) solver,\\nand (3) selecting offers based on negotiation tactics and the partner's\\nacceptance probability. Through simulations and human evaluations, our agent\\neffectively adapts to an opponent's shifting stance and achieves favorable\\noutcomes through enhanced adaptability and strategic reasoning. Beyond\\nimproving negotiation performance, it also serves as a powerful coaching tool,\\noffering interpretable strategic feedback and optimal offer recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.07129v1.pdf'},\n",
       " {'id': '2504.03206v2',\n",
       "  'title': 'Enhancing Personalized Multi-Turn Dialogue with Curiosity Reward',\n",
       "  'published': '2025-04-04T06:35:02Z',\n",
       "  'summary': \"Effective conversational agents like large language models (LLMs) must\\npersonalize their interactions to adapt to user preferences, personalities, and\\nattributes across diverse domains like education and healthcare. Current\\nmethods like Reinforcement Learning from Human Feedback (RLHF), often\\nprioritize helpfulness and safety but fall short in fostering truly empathetic,\\nadaptive, and personalized dialogues. Existing personalization approaches\\ntypically rely on extensive user history, limiting their effectiveness for new\\nor context-limited users. To address these limitations, we propose leveraging a\\nuser model to incorporate a curiosity-based intrinsic reward into multi-turn\\nRLHF. This novel reward mechanism encourages the LLM agent to actively infer\\nuser traits by optimizing conversations to improve its user model's accuracy.\\nConsequently, the agent delivers more personalized interactions by learning\\nmore about the user. We demonstrate our method's effectiveness in two distinct\\ndomains: significantly improving personalization performance in a\\nconversational recommendation task, and personalizing conversations for\\ndifferent learning styles in an educational setting. We show improved\\ngeneralization capabilities compared to traditional multi-turn RLHF, all while\\nmaintaining conversation quality. Our method offers a promising solution for\\ncreating more personalized, adaptive, and engaging conversational agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.03206v2.pdf'},\n",
       " {'id': '2507.03493v1',\n",
       "  'title': 'AI-VaxGuide: An Agentic RAG-Based LLM for Vaccination Decisions',\n",
       "  'published': '2025-07-04T11:33:56Z',\n",
       "  'summary': 'Vaccination plays a vital role in global public health, yet healthcare\\nprofessionals often struggle to access immunization guidelines quickly and\\nefficiently. National protocols and WHO recommendations are typically extensive\\nand complex, making it difficult to extract precise information, especially\\nduring urgent situations. This project tackles that issue by developing a\\nmultilingual, intelligent question-answering system that transforms static\\nvaccination guidelines into an interactive and user-friendly knowledge base.\\nBuilt on a Retrieval-Augmented Generation (RAG) framework and enhanced with\\nagent-based reasoning (Agentic RAG), the system provides accurate,\\ncontext-sensitive answers to complex medical queries. Evaluation shows that\\nAgentic RAG outperforms traditional methods, particularly in addressing\\nmulti-step or ambiguous questions. To support clinical use, the system is\\nintegrated into a mobile application designed for real-time, point-of-care\\naccess to essential vaccine information. AI-VaxGuide model is publicly\\navailable on https://huggingface.co/VaxGuide',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.03493v1.pdf'},\n",
       " {'id': '2507.11277v1',\n",
       "  'title': 'Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing\\n  Agentic AI Systems',\n",
       "  'published': '2025-07-15T12:54:43Z',\n",
       "  'summary': 'Large Language Models (LLMs) are increasingly deployed within agentic\\nsystems-collections of interacting, LLM-powered agents that execute complex,\\nadaptive workflows using memory, tools, and dynamic planning. While enabling\\npowerful new capabilities, these systems also introduce unique forms of\\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\\nfluid execution paths. Traditional software observability and operations\\npractices fall short in addressing these challenges.\\n  This paper introduces AgentOps: a comprehensive framework for observing,\\nanalyzing, optimizing, and automating operation of agentic AI systems. We\\nidentify distinct needs across four key roles-developers, testers, site\\nreliability engineers (SREs), and business users-each of whom engages with the\\nsystem at different points in its lifecycle. We present the AgentOps Automation\\nPipeline, a six-stage process encompassing behavior observation, metric\\ncollection, issue detection, root cause analysis, optimized recommendations,\\nand runtime automation. Throughout, we emphasize the critical role of\\nautomation in managing uncertainty and enabling self-improving AI systems-not\\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\\neffective operation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.11277v1.pdf'},\n",
       " {'id': '2507.23644v1',\n",
       "  'title': 'Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity',\n",
       "  'published': '2025-07-31T15:23:05Z',\n",
       "  'summary': \"Agent-based simulations have an enormous potential as tools to evaluate\\nsocial policies in a non-invasive way, before these are implemented to\\nreal-world populations. However, the recommendations that these computational\\napproaches may offer to tackle urgent human development challenges can vary\\nsubstantially depending on how we model agents' (people) behaviour and the\\ncriteria that we use to measure inequity. In this paper, we integrate the\\nconceptual framework of the capability approach (CA), which is explicitly\\ndesigned to promote and assess human well-being, to guide the simulation and\\nevaluate the effectiveness of policies. We define a reinforcement learning\\nenvironment where agents behave to restore their capabilities under the\\nconstraints of a specific policy. Working in collaboration with local\\nstakeholders, non-profits and domain experts, we apply our model in a case\\nstudy to mitigate health inequity among the population experiencing\\nhomelessness (PEH) in Barcelona. By doing so, we present the first proof of\\nconcept simulation, aligned with the CA for human development, to assess the\\nimpact of policies under parliamentary discussion.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.23644v1.pdf'},\n",
       " {'id': '2508.05338v1',\n",
       "  'title': \"The Term 'Agent' Has Been Diluted Beyond Utility and Requires\\n  Redefinition\",\n",
       "  'published': '2025-08-07T12:40:25Z',\n",
       "  'summary': \"The term 'agent' in artificial intelligence has long carried multiple\\ninterpretations across different subfields. Recent developments in AI\\ncapabilities, particularly in large language model systems, have amplified this\\nambiguity, creating significant challenges in research communication, system\\nevaluation and reproducibility, and policy development. This paper argues that\\nthe term 'agent' requires redefinition. Drawing from historical analysis and\\ncontemporary usage patterns, we propose a framework that defines clear minimum\\nrequirements for a system to be considered an agent while characterizing\\nsystems along a multidimensional spectrum of environmental interaction,\\nlearning and adaptation, autonomy, goal complexity, and temporal coherence.\\nThis approach provides precise vocabulary for system description while\\npreserving the term's historically multifaceted nature. After examining\\npotential counterarguments and implementation challenges, we provide specific\\nrecommendations for moving forward as a field, including suggestions for\\nterminology standardization and framework adoption. The proposed approach\\noffers practical tools for improving research clarity and reproducibility while\\nsupporting more effective policy development.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.05338v1.pdf'},\n",
       " {'id': '2509.13352v1',\n",
       "  'title': 'Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and\\n  Cognitive Reasoning',\n",
       "  'published': '2025-09-14T08:46:40Z',\n",
       "  'summary': 'Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\\nsurveillance, and disaster response, yet most systems remain confined to SAE\\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\\nintegration; critically, none leverage Large Language Model (LLM) agents with\\ntool-calling for real-time knowledge access. This paper introduces the Agentic\\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\\nThese results confirm that modest computational overhead enables qualitatively\\nnew levels of autonomy and ecosystem integration.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.13352v1.pdf'},\n",
       " {'id': '1809.06260v1',\n",
       "  'title': 'Learning to Collaborate: Multi-Scenario Ranking via Multi-Agent\\n  Reinforcement Learning',\n",
       "  'published': '2018-09-17T14:45:21Z',\n",
       "  'summary': 'Ranking is a fundamental and widely studied problem in scenarios such as\\nsearch, advertising, and recommendation. However, joint optimization for\\nmulti-scenario ranking, which aims to improve the overall performance of\\nseveral ranking strategies in different scenarios, is rather untouched.\\nSeparately optimizing each individual strategy has two limitations. The first\\none is lack of collaboration between scenarios meaning that each strategy\\nmaximizes its own objective but ignores the goals of other strategies, leading\\nto a sub-optimal overall performance. The second limitation is the inability of\\nmodeling the correlation between scenarios meaning that independent\\noptimization in one scenario only uses its own user data but ignores the\\ncontext in other scenarios.\\n  In this paper, we formulate multi-scenario ranking as a fully cooperative,\\npartially observable, multi-agent sequential decision problem. We propose a\\nnovel model named Multi-Agent Recurrent Deterministic Policy Gradient (MA-RDPG)\\nwhich has a communication component for passing messages, several private\\nactors (agents) for making actions for ranking, and a centralized critic for\\nevaluating the overall performance of the co-working actors. Each scenario is\\ntreated as an agent (actor). Agents collaborate with each other by sharing a\\nglobal action-value function (the critic) and passing messages that encodes\\nhistorical information across scenarios. The model is evaluated with online\\nsettings on a large E-commerce platform. Results show that the proposed model\\nexhibits significant improvements against baselines in terms of the overall\\nperformance.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1809.06260v1.pdf'},\n",
       " {'id': '1811.08549v2',\n",
       "  'title': 'Reinforcement Learning and Inverse Reinforcement Learning with System 1\\n  and System 2',\n",
       "  'published': '2018-11-19T22:36:53Z',\n",
       "  'summary': \"Inferring a person's goal from their behavior is an important problem in\\napplications of AI (e.g. automated assistants, recommender systems). The\\nworkhorse model for this task is the rational actor model - this amounts to\\nassuming that people have stable reward functions, discount the future\\nexponentially, and construct optimal plans. Under the rational actor assumption\\ntechniques such as inverse reinforcement learning (IRL) can be used to infer a\\nperson's goals from their actions. A competing model is the dual-system model.\\nHere decisions are the result of an interplay between a fast, automatic,\\nheuristic-based system 1 and a slower, deliberate, calculating system 2. We\\ngeneralize the dual system framework to the case of Markov decision problems\\nand show how to compute optimal plans for dual-system agents. We show that\\ndual-system agents exhibit behaviors that are incompatible with rational actor\\nassumption. We show that naive applications of rational-actor IRL to the\\nbehavior of dual-system agents can generate wrong inference about the agents'\\ngoals and suggest interventions that actually reduce the agent's overall\\nutility. Finally, we adapt a simple IRL algorithm to correctly infer the goals\\nof dual system decision-makers. This allows us to make interventions that help,\\nrather than hinder, the dual-system agent's ability to reach their true goals.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.08549v2.pdf'},\n",
       " {'id': '1903.05168v1',\n",
       "  'title': 'On the Pitfalls of Measuring Emergent Communication',\n",
       "  'published': '2019-03-12T19:33:49Z',\n",
       "  'summary': \"How do we know if communication is emerging in a multi-agent system? The vast\\nmajority of recent papers on emergent communication show that adding a\\ncommunication channel leads to an increase in reward or task success. This is a\\nuseful indicator, but provides only a coarse measure of the agent's learned\\ncommunication abilities. As we move towards more complex environments, it\\nbecomes imperative to have a set of finer tools that allow qualitative and\\nquantitative insights into the emergence of communication. This may be\\nespecially useful to allow humans to monitor agents' behaviour, whether for\\nfault detection, assessing performance, or even building trust. In this paper,\\nwe examine a few intuitive existing metrics for measuring communication, and\\nshow that they can be misleading. Specifically, by training deep reinforcement\\nlearning agents to play simple matrix games augmented with a communication\\nchannel, we find a scenario where agents appear to communicate (their messages\\nprovide information about their subsequent action), and yet the messages do not\\nimpact the environment or other agent in any way. We explain this phenomenon\\nusing ablation studies and by visualizing the representations of the learned\\npolicies. We also survey some commonly used metrics for measuring emergent\\ncommunication, and provide recommendations as to when these metrics should be\\nused.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1903.05168v1.pdf'},\n",
       " {'id': '2005.03000v3',\n",
       "  'title': 'Information Design in Non-atomic Routing Games with Partial\\n  Participation: Computation and Properties',\n",
       "  'published': '2020-05-06T17:59:18Z',\n",
       "  'summary': 'We consider a routing game among non-atomic agents where link latency\\nfunctions are conditional on an uncertain state of the network. The agents have\\nthe same prior belief about the state, but only a fixed fraction receive\\nprivate route recommendations or a common message, which are generated by a\\nknown randomization, referred to as private or public signaling policy\\nrespectively. The remaining agents choose route according to Bayes Nash flow\\nwith respect to the prior. We develop a computational approach to solve the\\noptimal information design problem, i.e., to minimize expected social latency\\nover all public or obedient private signaling policies. For a fixed flow\\ninduced by non-participating agents, design of an optimal private signaling\\npolicy is shown to be a generalized problem of moments for polynomial link\\nlatency functions, and to admit an atomic solution with a provable upper bound\\non the number of atoms. This implies that, for polynomial link latency\\nfunctions, information design can be equivalently cast as a polynomial\\noptimization problem. This in turn can be arbitrarily lower bounded by a known\\nhierarchy of semidefinite relaxations. The first level of this hierarchy is\\nshown to be exact for the basic two link case with affine latency functions. We\\nalso identify a class of private signaling policies over which the optimal\\nsocial cost is non-increasing with increasing fraction of participating agents\\nfor parallel networks. This is in contrast to existing results where the cost\\nof participating agents under a fixed signaling policy may increase with their\\nincreasing fraction.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.03000v3.pdf'},\n",
       " {'id': '2309.06969v1',\n",
       "  'title': 'Setting the Right Expectations: Algorithmic Recourse Over Time',\n",
       "  'published': '2023-09-13T14:04:15Z',\n",
       "  'summary': \"Algorithmic systems are often called upon to assist in high-stakes decision\\nmaking. In light of this, algorithmic recourse, the principle wherein\\nindividuals should be able to take action against an undesirable outcome made\\nby an algorithmic system, is receiving growing attention. The bulk of the\\nliterature on algorithmic recourse to-date focuses primarily on how to provide\\nrecourse to a single individual, overlooking a critical element: the effects of\\na continuously changing context. Disregarding these effects on recourse is a\\nsignificant oversight, since, in almost all cases, recourse consists of an\\nindividual making a first, unfavorable attempt, and then being given an\\nopportunity to make one or several attempts at a later date - when the context\\nmight have changed. This can create false expectations, as initial recourse\\nrecommendations may become less reliable over time due to model drift and\\ncompetition for access to the favorable outcome between individuals.\\n  In this work we propose an agent-based simulation framework for studying the\\neffects of a continuously changing environment on algorithmic recourse. In\\nparticular, we identify two main effects that can alter the reliability of\\nrecourse for individuals represented by the agents: (1) competition with other\\nagents acting upon recourse, and (2) competition with new agents entering the\\nenvironment. Our findings highlight that only a small set of specific\\nparameterizations result in algorithmic recourse that is reliable for agents\\nover time. Consequently, we argue that substantial additional work is needed to\\nunderstand recourse reliability over time, and to develop recourse methods that\\nreward agents' effort.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.06969v1.pdf'},\n",
       " {'id': '2504.16902v2',\n",
       "  'title': 'Building A Secure Agentic AI Application Leveraging A2A Protocol',\n",
       "  'published': '2025-04-23T17:27:49Z',\n",
       "  'summary': \"As Agentic AI systems evolve from basic workflows to complex multi agent\\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\\nessential enablers. To foster secure adoption and ensure the reliability of\\nthese complex interactions, understanding the secure implementation of A2A is\\nessential. This paper addresses this goal by providing a comprehensive security\\nanalysis centered on the A2A protocol. We examine its fundamental elements and\\noperational dynamics, situating it within the framework of agent communication\\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\\nrisks, we apply proactive threat modeling to assess potential security issues\\nin A2A deployments, focusing on aspects such as Agent Card management, task\\nexecution integrity, and authentication methodologies.\\n  Based on these insights, we recommend practical secure development\\nmethodologies and architectural best practices designed to build resilient and\\neffective A2A systems. Our analysis also explores how the synergy between A2A\\nand the Model Context Protocol (MCP) can further enhance secure\\ninteroperability. This paper equips developers and architects with the\\nknowledge and practical guidance needed to confidently leverage the A2A\\nprotocol for building robust and secure next generation agentic applications.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.16902v2.pdf'},\n",
       " {'id': '2506.21934v1',\n",
       "  'title': 'CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware\\n  Layout Design',\n",
       "  'published': '2025-06-27T06:09:56Z',\n",
       "  'summary': 'Automated content-aware layout generation -- the task of arranging visual\\nelements such as text, logos, and underlays on a background canvas -- remains a\\nfundamental yet under-explored problem in intelligent design systems. While\\nrecent advances in deep generative models and large language models (LLMs) have\\nshown promise in structured content generation, most existing approaches lack\\ngrounding in contextual design exemplars and fall short in handling semantic\\nalignment and visual coherence. In this work we introduce CAL-RAG, a\\nretrieval-augmented, agentic framework for content-aware layout generation that\\nintegrates multimodal retrieval, large language models, and collaborative\\nagentic reasoning. Our system retrieves relevant layout examples from a\\nstructured knowledge base and invokes an LLM-based layout recommender to\\npropose structured element placements. A vision-language grader agent evaluates\\nthe layout with visual metrics, and a feedback agent provides targeted\\nrefinements, enabling iterative improvement. We implement our framework using\\nLangGraph and evaluate it on the PKU PosterLayout dataset, a benchmark rich in\\nsemantic and structural variability. CAL-RAG achieves state-of-the-art\\nperformance across multiple layout metrics -- including underlay effectiveness,\\nelement alignment, and overlap -- substantially outperforming strong baselines\\nsuch as LayoutPrompter. These results demonstrate that combining retrieval\\naugmentation with agentic multi-step reasoning yields a scalable,\\ninterpretable, and high-fidelity solution for automated layout generation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.21934v1.pdf'},\n",
       " {'id': '2507.21428v1',\n",
       "  'title': 'MemTool: Optimizing Short-Term Memory Management for Dynamic Tool\\n  Calling in LLM Agent Multi-Turn Conversations',\n",
       "  'published': '2025-07-29T01:42:06Z',\n",
       "  'summary': 'Large Language Model (LLM) agents have shown significant autonomous\\ncapabilities in dynamically searching and incorporating relevant tools or Model\\nContext Protocol (MCP) servers for individual queries. However, fixed context\\nwindows limit effectiveness in multi-turn interactions requiring repeated,\\nindependent tool usage. We introduce MemTool, a short-term memory framework\\nenabling LLM agents to dynamically manage tools or MCP server contexts across\\nmulti-turn conversations. MemTool offers three agentic architectures: 1)\\nAutonomous Agent Mode, granting full tool management autonomy, 2) Workflow\\nMode, providing deterministic control without autonomy, and 3) Hybrid Mode,\\ncombining autonomous and deterministic control. Evaluating each MemTool mode\\nacross 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100\\nconsecutive user interactions, measuring tool removal ratios (short-term memory\\nefficiency) and task completion accuracy. In Autonomous Agent Mode, reasoning\\nLLMs achieve high tool-removal efficiency (90-94% over a 3-window average),\\nwhile medium-sized models exhibit significantly lower efficiency (0-60%).\\nWorkflow and Hybrid modes consistently manage tool removal effectively, whereas\\nAutonomous and Hybrid modes excel at task completion. We present trade-offs and\\nrecommendations for each MemTool mode based on task accuracy, agency, and model\\ncapabilities.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.21428v1.pdf'},\n",
       " {'id': '2508.05283v1',\n",
       "  'title': 'Decision-Making with Deliberation: Meta-reviewing as a Document-grounded\\n  Dialogue',\n",
       "  'published': '2025-08-07T11:27:43Z',\n",
       "  'summary': 'Meta-reviewing is a pivotal stage in the peer-review process, serving as the\\nfinal step in determining whether a paper is recommended for acceptance. Prior\\nresearch on meta-reviewing has treated this as a summarization problem over\\nreview reports. However, complementary to this perspective, meta-reviewing is a\\ndecision-making process that requires weighing reviewer arguments and placing\\nthem within a broader context. Prior research has demonstrated that\\ndecision-makers can be effectively assisted in such scenarios via dialogue\\nagents. In line with this framing, we explore the practical challenges for\\nrealizing dialog agents that can effectively assist meta-reviewers. Concretely,\\nwe first address the issue of data scarcity for training dialogue agents by\\ngenerating synthetic data using Large Language Models (LLMs) based on a\\nself-refinement strategy to improve the relevance of these dialogues to expert\\ndomains. Our experiments demonstrate that this method produces higher-quality\\nsynthetic data and can serve as a valuable resource towards training\\nmeta-reviewing assistants. Subsequently, we utilize this data to train dialogue\\nagents tailored for meta-reviewing and find that these agents outperform\\n\\\\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our\\nagents in real-world meta-reviewing scenarios and confirm their effectiveness\\nin enhancing the efficiency of meta-reviewing.\\\\footnote{Code and Data:\\nhttps://github.com/UKPLab/arxiv2025-meta-review-as-dialog',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.05283v1.pdf'},\n",
       " {'id': '2508.07673v1',\n",
       "  'title': 'Ethics2vec: aligning automatic agents and human preferences',\n",
       "  'published': '2025-08-11T06:52:46Z',\n",
       "  'summary': 'Though intelligent agents are supposed to improve human experience (or make\\nit more efficient), it is hard from a human perspective to grasp the ethical\\nvalues which are explicitly or implicitly embedded in an agent behaviour. This\\nis the well-known problem of alignment, which refers to the challenge of\\ndesigning AI systems that align with human values, goals and preferences. This\\nproblem is particularly challenging since most human ethical considerations\\nrefer to \\\\emph{incommensurable} (i.e. non-measurable and/or incomparable)\\nvalues and criteria. Consider, for instance, a medical agent prescribing a\\ntreatment to a cancerous patient. How could it take into account (and/or weigh)\\nincommensurable aspects like the value of a human life and the cost of the\\ntreatment? Now, the alignment between human and artificial values is possible\\nonly if we define a common space where a metric can be defined and used. This\\npaper proposes to extend to ethics the conventional Anything2vec approach,\\nwhich has been successful in plenty of similar and hard-to-quantify domains\\n(ranging from natural language processing to recommendation systems and graph\\nanalysis). This paper proposes a way to map an automatic agent decision-making\\n(or control law) strategy to a multivariate vector representation, which can be\\nused to compare and assess the alignment with human values. The Ethics2Vec\\nmethod is first introduced in the case of an automatic agent performing binary\\ndecision-making. Then, a vectorisation of an automatic control law (like in the\\ncase of a self-driving car) is discussed to show how the approach can be\\nextended to automatic control settings.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.07673v1.pdf'},\n",
       " {'id': '1102.0674v1',\n",
       "  'title': 'Effective Mechanism for Social Recommendation of News',\n",
       "  'published': '2011-02-03T13:15:27Z',\n",
       "  'summary': \"Recommendation systems represent an important tool for news distribution on\\nthe Internet. In this work we modify a recently proposed social recommendation\\nmodel in order to deal with no explicit ratings of users on news. The model\\nconsists of a network of users which continually adapts in order to achieve an\\nefficient news traffic. To optimize network's topology we propose different\\nstochastic algorithms that are scalable with respect to the network's size.\\nAgent-based simulations reveal the features and the performance of these\\nalgorithms. To overcome the resultant drawbacks of each method we introduce two\\nimproved algorithms and show that they can optimize network's topology almost\\nas fast and effectively as other not-scalable methods that make use of much\\nmore information.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1102.0674v1.pdf'},\n",
       " {'id': '1103.5120v2',\n",
       "  'title': 'Emergence of scale-free leadership structure in social recommender\\n  systems',\n",
       "  'published': '2011-03-26T11:03:21Z',\n",
       "  'summary': 'The study of the organization of social networks is important for\\nunderstanding of opinion formation, rumor spreading, and the emergence of\\ntrends and fashion. This paper reports empirical analysis of networks extracted\\nfrom four leading sites with social functionality (Delicious, Flickr, Twitter\\nand YouTube) and shows that they all display a scale-free leadership structure.\\nTo reproduce this feature, we propose an adaptive network model driven by\\nsocial recommending. Artificial agent-based simulations of this model highlight\\na \"good get richer\" mechanism where users with broad interests and good\\njudgments are likely to become popular leaders for the others. Simulations also\\nindicate that the studied social recommendation mechanism can gradually improve\\nthe user experience by adapting to tastes of its users. Finally we outline\\nimplications for real online resource-sharing systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1103.5120v2.pdf'},\n",
       " {'id': '1810.09401v1',\n",
       "  'title': 'Alternating Linear Bandits for Online Matrix-Factorization\\n  Recommendation',\n",
       "  'published': '2018-10-22T16:52:57Z',\n",
       "  'summary': 'We consider the problem of online collaborative filtering in the online\\nsetting, where items are recommended to the users over time. At each time step,\\nthe user (selected by the environment) consumes an item (selected by the agent)\\nand provides a rating of the selected item. In this paper, we propose a novel\\nalgorithm for online matrix factorization recommendation that combines linear\\nbandits and alternating least squares. In this formulation, the bandit feedback\\nis equal to the difference between the ratings of the best and selected items.\\nWe evaluate the performance of the proposed algorithm over time using both\\ncumulative regret and average cumulative NDCG. Simulation results over three\\nsynthetic datasets as well as three real-world datasets for online\\ncollaborative filtering indicate the superior performance of the proposed\\nalgorithm over two state-of-the-art online algorithms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1810.09401v1.pdf'},\n",
       " {'id': '1804.04946v1',\n",
       "  'title': 'Affective Recommendation System for Tourists by Using Emotion Generating\\n  Calculations',\n",
       "  'published': '2018-04-09T04:55:27Z',\n",
       "  'summary': \"An emotion orientated intelligent interface consists of Emotion Generating\\nCalculations (EGC) and Mental State Transition Network (MSTN). We have\\ndeveloped the Android EGC application software which the agent works to\\nevaluate the feelings in the conversation. In this paper, we develop the\\ntourist information system which can estimate the user's feelings at the\\nsightseeing spot. The system can recommend the sightseeing spot and the local\\nfood corresponded to the user's feeling. The system calculates the\\nrecommendation list by the estimate function which consists of Google search\\nresults, the important degree of a term at the sightseeing website, and the the\\naroused emotion by EGC. In order to show the effectiveness, this paper\\ndescribes the experimental results for some situations during Hiroshima\\nsightseeing.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1804.04946v1.pdf'},\n",
       " {'id': '2204.00308v1',\n",
       "  'title': 'Model-agnostic Counterfactual Synthesis Policy for Interactive\\n  Recommendation',\n",
       "  'published': '2022-04-01T09:39:08Z',\n",
       "  'summary': 'Interactive recommendation is able to learn from the interactive processes\\nbetween users and systems to confront the dynamic interests of users. Recent\\nadvances have convinced that the ability of reinforcement learning to handle\\nthe dynamic process can be effectively applied in the interactive\\nrecommendation. However, the sparsity of interactive data may hamper the\\nperformance of the system. We propose to train a Model-agnostic Counterfactual\\nSynthesis Policy to generate counterfactual data and address the data sparsity\\nproblem by modelling from observation and counterfactual distribution. The\\nproposed policy can identify and replace the trivial components for any state\\nin the training process with other agents, which can be deployed in any\\nRL-based algorithm. The experimental results demonstrate the effectiveness and\\ngenerality of our proposed policy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2204.00308v1.pdf'},\n",
       " {'id': '2209.03213v1',\n",
       "  'title': 'INFACT: An Online Human Evaluation Framework for Conversational\\n  Recommendation',\n",
       "  'published': '2022-09-07T15:16:59Z',\n",
       "  'summary': \"Conversational recommender systems (CRS) are interactive agents that support\\ntheir users in recommendation-related goals through multi-turn conversations.\\nGenerally, a CRS can be evaluated in various dimensions. Today's CRS mainly\\nrely on offline(computational) measures to assess the performance of their\\nalgorithms in comparison to different baselines. However, offline measures can\\nhave limitations, for example, when the metrics for comparing a newly generated\\nresponse with a ground truth do not correlate with human perceptions, because\\nvarious alternative generated responses might be suitable too in a given dialog\\nsituation. Current research on machine learning-based CRS models therefore\\nacknowledges the importance of humans in the evaluation process, knowing that\\npure offline measures may not be sufficient in evaluating a highly interactive\\nsystem like a CRS.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.03213v1.pdf'},\n",
       " {'id': '2212.03721v1',\n",
       "  'title': 'Intent Recognition in Conversational Recommender Systems',\n",
       "  'published': '2022-12-06T11:02:42Z',\n",
       "  'summary': 'Any organization needs to improve their products, services, and processes. In\\nthis context, engaging with customers and understanding their journey is\\nessential. Organizations have leveraged various techniques and technologies to\\nsupport customer engagement, from call centres to chatbots and virtual agents.\\nRecently, these systems have used Machine Learning (ML) and Natural Language\\nProcessing (NLP) to analyze large volumes of customer feedback and engagement\\ndata. The goal is to understand customers in context and provide meaningful\\nanswers across various channels. Despite multiple advances in Conversational\\nArtificial Intelligence (AI) and Recommender Systems (RS), it is still\\nchallenging to understand the intent behind customer questions during the\\ncustomer journey. To address this challenge, in this paper, we study and\\nanalyze the recent work in Conversational Recommender Systems (CRS) in general\\nand, more specifically, in chatbot-based CRS. We introduce a pipeline to\\ncontextualize the input utterances in conversations. We then take the next step\\ntowards leveraging reverse feature engineering to link the contextualized input\\nand learning model to support intent recognition. Since performance evaluation\\nis achieved based on different ML models, we use transformer base models to\\nevaluate the proposed approach using a labelled dialogue dataset (MSDialogue)\\nof question-answering interactions between information seekers and answer\\nproviders.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2212.03721v1.pdf'},\n",
       " {'id': '2302.12223v2',\n",
       "  'title': 'Data Monetization through Strategic Coordination of Privately Informed\\n  Agents',\n",
       "  'published': '2023-02-23T18:42:34Z',\n",
       "  'summary': \"We consider linear-quadratic games of incomplete information with Gaussian\\nuncertainty, in which players' payoffs depend both on a privately observed type\\nand an unknown but common state. A monopolist data platform observes the state,\\nelicits the players' types, and sells information back to them via (possibly\\ncorrelated) action recommendations. We fully characterize the class of all such\\nimplementable Gaussian mechanisms (where the joint distribution of actions and\\nsignals is multivariate normal) as well as the player-optimal and\\nrevenue-maximizing mechanisms within this class. For games of strategic\\ncomplements (substitutes), both optimal mechanisms maximally correlate\\n(anticorrelate) the players' actions. When uncertainty over private types is\\nlarge, the recommendations are deterministic and linear functions of the state\\nand reported types but are not fully revealing. We apply our results to\\nalgorithmic pricing recommendations used by platforms such as Amazon and those\\nchallenged in U.S. v. RealPage.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.12223v2.pdf'},\n",
       " {'id': '2403.17634v1',\n",
       "  'title': 'Retentive Decision Transformer with Adaptive Masking for Reinforcement\\n  Learning based Recommendation Systems',\n",
       "  'published': '2024-03-26T12:08:58Z',\n",
       "  'summary': \"Reinforcement Learning-based Recommender Systems (RLRS) have shown promise\\nacross a spectrum of applications, from e-commerce platforms to streaming\\nservices. Yet, they grapple with challenges, notably in crafting reward\\nfunctions and harnessing large pre-existing datasets within the RL framework.\\nRecent advancements in offline RLRS provide a solution for how to address these\\ntwo challenges. However, existing methods mainly rely on the transformer\\narchitecture, which, as sequence lengths increase, can introduce challenges\\nassociated with computational resources and training costs. Additionally, the\\nprevalent methods employ fixed-length input trajectories, restricting their\\ncapacity to capture evolving user preferences. In this study, we introduce a\\nnew offline RLRS method to deal with the above problems. We reinterpret the\\nRLRS challenge by modeling sequential decision-making as an inference task,\\nleveraging adaptive masking configurations. This adaptive approach selectively\\nmasks input tokens, transforming the recommendation task into an inference\\nchallenge based on varying token subsets, thereby enhancing the agent's ability\\nto infer across diverse trajectory lengths. Furthermore, we incorporate a\\nmulti-scale segmented retention mechanism that facilitates efficient modeling\\nof long sequences, significantly enhancing computational efficiency. Our\\nexperimental analysis, conducted on both online simulator and offline datasets,\\nclearly demonstrates the advantages of our proposed method.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.17634v1.pdf'},\n",
       " {'id': '2405.13803v3',\n",
       "  'title': '\"I Like Sunnie More Than I Expected!\": Exploring User Expectation and\\n  Perception of an Anthropomorphic LLM-based Conversational Agent for\\n  Well-Being Support',\n",
       "  'published': '2024-05-22T16:30:24Z',\n",
       "  'summary': \"The human-computer interaction (HCI) research community has a longstanding\\ninterest in exploring the mismatch between users' actual experiences and\\nexpectation toward new technologies, for instance, large language models\\n(LLMs). In this study, we compared users' (N = 38) initial expectations against\\ntheir post-interaction perceptions of two LLM-powered mental well-being\\nintervention activity recommendation systems. Both systems have a built-in LLM\\nto recommend a personalized well-being intervention activity, but one system\\n(Sunnie) has an anthropomorphic conversational interaction design via elements\\nsuch as appearance, persona, and natural conversation. Results showed that user\\nengagement was high with both systems, and both systems exceeded users'\\nexpectations along the utility dimension, highlighting AI's potential to offer\\nuseful intervention activity recommendations. In addition, Sunnie further\\noutperformed the non-anthropomorphic baseline system in relational warmth.\\nThese findings suggest that anthropomorphic conversational interaction design\\nmay be particularly effective in fostering warmth in mental health support\\ncontexts.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.13803v3.pdf'},\n",
       " {'id': '2410.04551v1',\n",
       "  'title': 'Social Choice for Heterogeneous Fairness in Recommendation',\n",
       "  'published': '2024-10-06T17:01:18Z',\n",
       "  'summary': 'Algorithmic fairness in recommender systems requires close attention to the\\nneeds of a diverse set of stakeholders that may have competing interests.\\nPrevious work in this area has often been limited by fixed, single-objective\\ndefinitions of fairness, built into algorithms or optimization criteria that\\nare applied to a single fairness dimension or, at most, applied identically\\nacross dimensions. These narrow conceptualizations limit the ability to adapt\\nfairness-aware solutions to the wide range of stakeholder needs and fairness\\ndefinitions that arise in practice. Our work approaches recommendation fairness\\nfrom the standpoint of computational social choice, using a multi-agent\\nframework. In this paper, we explore the properties of different social choice\\nmechanisms and demonstrate the successful integration of multiple,\\nheterogeneous fairness definitions across multiple data sets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.04551v1.pdf'},\n",
       " {'id': '2411.04462v2',\n",
       "  'title': 'Can CDT rationalise the ex ante optimal policy via modified anthropics?',\n",
       "  'published': '2024-11-07T06:23:38Z',\n",
       "  'summary': \"In Newcomb's problem, causal decision theory (CDT) recommends two-boxing and\\nthus comes apart from evidential decision theory (EDT) and ex ante policy\\noptimisation (which prescribe one-boxing). However, in Newcomb's problem, you\\nshould perhaps believe that with some probability you are in a simulation run\\nby the predictor to determine whether to put a million dollars into the opaque\\nbox. If so, then causal decision theory might recommend one-boxing in order to\\ncause the predictor to fill the opaque box. In this paper, we study\\ngeneralisations of this approach. That is, we consider general Newcomblike\\nproblems and try to form reasonable self-locating beliefs under which CDT's\\nrecommendations align with an EDT-like notion of ex ante policy optimisation.\\nWe consider approaches in which we model the world as running simulations of\\nthe agent, and an approach not based on such models (which we call 'Generalised\\nGeneralised Thirding', or GGT). For each approach, we characterise the\\nresulting CDT policies, and prove that under certain conditions, these include\\nthe ex ante optimal policies.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.04462v2.pdf'},\n",
       " {'id': '2505.11239v2',\n",
       "  'title': 'Massive-STEPS: Massive Semantic Trajectories for Understanding POI\\n  Check-ins -- Dataset and Benchmarks',\n",
       "  'published': '2025-05-16T13:29:18Z',\n",
       "  'summary': 'Understanding human mobility through Point-of-Interest (POI) recommendation\\nis increasingly important for applications such as urban planning, personalized\\nservices, and generative agent simulation. However, progress in this field is\\nhindered by two key challenges: the over-reliance on older datasets from\\n2012-2013 and the lack of reproducible, city-level check-in datasets that\\nreflect diverse global regions. To address these gaps, we present Massive-STEPS\\n(Massive Semantic Trajectories for Understanding POI Check-ins), a large-scale,\\npublicly available benchmark dataset built upon the Semantic Trails dataset and\\nenriched with semantic POI metadata. Massive-STEPS spans 12 geographically and\\nculturally diverse cities and features more recent (2017-2018) and\\nlonger-duration (24 months) check-in data than prior datasets. We benchmarked a\\nwide range of POI recommendation models on Massive-STEPS using both supervised\\nand zero-shot approaches, and evaluated their performance across multiple urban\\ncontexts. By releasing Massive-STEPS, we aim to facilitate reproducible and\\nequitable research in human mobility and POI recommendation. The dataset and\\nbenchmarking code are available at:\\nhttps://github.com/cruiseresearchgroup/Massive-STEPS',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.11239v2.pdf'},\n",
       " {'id': '2509.06185v1',\n",
       "  'title': 'Modeling shopper interest broadness with entropy-driven dialogue policy\\n  in the context of arbitrarily large product catalogs',\n",
       "  'published': '2025-09-07T19:30:09Z',\n",
       "  'summary': 'Conversational recommender systems promise rich interactions for e-commerce,\\nbut balancing exploration (clarifying user needs) and exploitation (making\\nrecommendations) remains challenging, especially when deploying large language\\nmodels (LLMs) with vast product catalogs. We address this challenge by modeling\\nthe breadth of user interest via the entropy of retrieval score distributions.\\nOur method uses a neural retriever to fetch relevant items for a user query and\\ncomputes the entropy of the re-ranked scores to dynamically route the dialogue\\npolicy: low-entropy (specific) queries trigger direct recommendations, whereas\\nhigh-entropy (ambiguous) queries prompt exploratory questions. This simple yet\\neffective strategy allows an LLM-driven agent to remain aware of an arbitrarily\\nlarge catalog in real-time without bloating its context window.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.06185v1.pdf'},\n",
       " {'id': '1606.01349v1',\n",
       "  'title': 'Investigating the Impacts of Recommendation Agents on Impulsive Purchase\\n  Behaviour',\n",
       "  'published': '2016-06-04T09:13:58Z',\n",
       "  'summary': 'The usage of recommendation agents (RAs) in the online marketplace can help\\nconsumers to locate their desired products. RAs can help consumers effectively\\nobtain comprehensive product information and compare their candidate target\\nproducts. As a result, RAs have affected consumers shopping behaviour. In this\\nstudy, we investigate the usage and the influence of RAs in the online\\nmarketplace. Based on the Stimulus-Organism-Response (SOR) model, we propose\\nthat the stimulus of using RAs (informativeness, product search effectiveness\\nand the lack of sociality stress) can affect consumers attitude (perceived\\ncontrol and satisfaction), which further affects their behavioural outcomes\\nlike impulsive purchase. We validate this research model with survey data from\\n157 users of RAs. The data largely support the proposed model and indicate that\\nthe RAs can significantly contribute to impulsive purchase behaviour in online\\nmarketplaces. Theoretical and practical contributions are discussed.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1606.01349v1.pdf'},\n",
       " {'id': '2007.08003v1',\n",
       "  'title': 'Stutter Diagnosis and Therapy System Based on Deep Learning',\n",
       "  'published': '2020-07-13T10:24:02Z',\n",
       "  'summary': 'Stuttering, also called stammering, is a communication disorder that breaks\\nthe continuity of the speech. This program of work is an attempt to develop\\nautomatic recognition procedures to assess stuttered dysfluencies and use these\\nassessments to filter out speech therapies for an individual. Stuttering may be\\nin the form of repetitions, prolongations or abnormal stoppages of sounds and\\nsyllables. Our system aims to help stutterers by diagnosing the severity and\\ntype of stutter and also by suggesting appropriate therapies for practice by\\nlearning the correlation between stutter descriptors and the effectiveness of\\nspeech therapies on them. This paper focuses on the implementation of a stutter\\ndiagnosis agent using Gated Recurrent CNN on MFCC audio features and therapy\\nrecommendation agent using SVM. It also presents the results obtained and\\nvarious key findings of the system developed.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.08003v1.pdf'},\n",
       " {'id': '2205.01763v1',\n",
       "  'title': 'Analyzing and Simulating User Utterance Reformulation in Conversational\\n  Recommender Systems',\n",
       "  'published': '2022-05-03T20:16:00Z',\n",
       "  'summary': 'User simulation has been a cost-effective technique for evaluating\\nconversational recommender systems. However, building a human-like simulator is\\nstill an open challenge. In this work, we focus on how users reformulate their\\nutterances when a conversational agent fails to understand them. First, we\\nperform a user study, involving five conversational agents across different\\ndomains, to identify common reformulation types and their transition\\nrelationships. A common pattern that emerges is that persistent users would\\nfirst try to rephrase, then simplify, before giving up. Next, to incorporate\\nthe observed reformulation behavior in a user simulator, we introduce the task\\nof reformulation sequence generation: to generate a sequence of reformulated\\nutterances with a given intent (rephrase or simplify). We develop methods by\\nextending transformer models guided by the reformulation type and perform\\nfurther filtering based on estimated reading difficulty. We demonstrate the\\neffectiveness of our approach using both automatic and human evaluation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.01763v1.pdf'},\n",
       " {'id': '2209.01876v1',\n",
       "  'title': 'SlateFree: a Model-Free Decomposition for Reinforcement Learning with\\n  Slate Actions',\n",
       "  'published': '2022-09-05T10:15:16Z',\n",
       "  'summary': 'We consider the problem of sequential recommendations, where at each step an\\nagent proposes some slate of $N$ distinct items to a user from a much larger\\ncatalog of size $K>>N$. The user has unknown preferences towards the\\nrecommendations and the agent takes sequential actions that optimise (in our\\ncase minimise) some user-related cost, with the help of Reinforcement Learning.\\nThe possible item combinations for a slate is $\\\\binom{K}{N}$, an enormous\\nnumber rendering value iteration methods intractable. We prove that the\\nslate-MDP can actually be decomposed using just $K$ item-related $Q$ functions\\nper state, which describe the problem in a more compact and efficient way.\\nBased on this, we propose a novel model-free SARSA and Q-learning algorithm\\nthat performs $N$ parallel iterations per step, without any prior user\\nknowledge. We call this method \\\\texttt{SlateFree}, i.e. free-of-slates, and we\\nshow numerically that it converges very fast to the exact optimum for arbitrary\\nuser profiles, and that it outperforms alternatives from the literature.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.01876v1.pdf'},\n",
       " {'id': '2307.07911v1',\n",
       "  'title': 'MESOB: Balancing Equilibria & Social Optimality',\n",
       "  'published': '2023-07-16T00:43:54Z',\n",
       "  'summary': 'Motivated by bid recommendation in online ad auctions, this paper considers a\\ngeneral class of multi-level and multi-agent games, with two major\\ncharacteristics: one is a large number of anonymous agents, and the other is\\nthe intricate interplay between competition and cooperation. To model such\\ncomplex systems, we propose a novel and tractable bi-objective optimization\\nformulation with mean-field approximation, called MESOB (Mean-field Equilibria\\n& Social Optimality Balancing), as well as an associated occupation measure\\noptimization (OMO) method called MESOB-OMO to solve it. MESOB-OMO enables\\nobtaining approximately Pareto efficient solutions in terms of the dual\\nobjectives of competition and cooperation in MESOB, and in particular allows\\nfor Nash equilibrium selection and social equalization in an asymptotic manner.\\nWe apply MESOB-OMO to bid recommendation in a simulated pay-per-click ad\\nauction. Experiments demonstrate its efficacy in balancing the interests of\\ndifferent parties and in handling the competitive nature of bidders, as well as\\nits advantages over baselines that only consider either the competitive or the\\ncooperative aspects.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.07911v1.pdf'},\n",
       " {'id': '2310.09123v1',\n",
       "  'title': 'Automatic Music Playlist Generation via Simulation-based Reinforcement\\n  Learning',\n",
       "  'published': '2023-10-13T14:13:02Z',\n",
       "  'summary': 'Personalization of playlists is a common feature in music streaming services,\\nbut conventional techniques, such as collaborative filtering, rely on explicit\\nassumptions regarding content quality to learn how to make recommendations.\\nSuch assumptions often result in misalignment between offline model objectives\\nand online user satisfaction metrics. In this paper, we present a reinforcement\\nlearning framework that solves for such limitations by directly optimizing for\\nuser satisfaction metrics via the use of a simulated playlist-generation\\nenvironment. Using this simulator we develop and train a modified Deep\\nQ-Network, the action head DQN (AH-DQN), in a manner that addresses the\\nchallenges imposed by the large state and action space of our RL formulation.\\nThe resulting policy is capable of making recommendations from large and\\ndynamic sets of candidate items with the expectation of maximizing consumption\\nmetrics. We analyze and evaluate agents offline via simulations that use\\nenvironment models trained on both public and proprietary streaming datasets.\\nWe show how these agents lead to better user-satisfaction metrics compared to\\nbaseline methods during online A/B tests. Finally, we demonstrate that\\nperformance assessments produced from our simulator are strongly correlated\\nwith observed online metric results.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.09123v1.pdf'},\n",
       " {'id': '1907.06584v1',\n",
       "  'title': 'Environment Reconstruction with Hidden Confounders for Reinforcement\\n  Learning based Recommendation',\n",
       "  'published': '2019-07-12T10:13:05Z',\n",
       "  'summary': 'Reinforcement learning aims at searching the best policy model for decision\\nmaking, and has been shown powerful for sequential recommendations. The\\ntraining of the policy by reinforcement learning, however, is placed in an\\nenvironment. In many real-world applications, however, the policy training in\\nthe real environment can cause an unbearable cost, due to the exploration in\\nthe environment. Environment reconstruction from the past data is thus an\\nappealing way to release the power of reinforcement learning in these\\napplications. The reconstruction of the environment is, basically, to extract\\nthe casual effect model from the data. However, real-world applications are\\noften too complex to offer fully observable environment information. Therefore,\\nquite possibly there are unobserved confounding variables lying behind the\\ndata. The hidden confounder can obstruct an effective reconstruction of the\\nenvironment. In this paper, by treating the hidden confounder as a hidden\\npolicy, we propose a deconfounded multi-agent environment reconstruction\\n(DEMER) approach in order to learn the environment together with the hidden\\nconfounder. DEMER adopts a multi-agent generative adversarial imitation\\nlearning framework. It proposes to introduce the confounder embedded policy,\\nand use the compatible discriminator for training the policies. We then apply\\nDEMER in an application of driver program recommendation. We firstly use an\\nartificial driver program recommendation environment, abstracted from the real\\napplication, to verify and analyze the effectiveness of DEMER. We then test\\nDEMER in the real application of Didi Chuxing. Experiment results show that\\nDEMER can effectively reconstruct the hidden confounder, and thus can build the\\nenvironment better. DEMER also derives a recommendation policy with a\\nsignificantly improved performance in the test phase of the real application.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.06584v1.pdf'},\n",
       " {'id': '1902.09291v2',\n",
       "  'title': 'MIRA: A Computational Neuro-Based Cognitive Architecture Applied to\\n  Movie Recommender Systems',\n",
       "  'published': '2019-02-25T14:32:18Z',\n",
       "  'summary': 'The human mind is still an unknown process of neuroscience in many aspects.\\nNevertheless, for decades the scientific community has proposed computational\\nmodels that try to simulate their parts, specific applications, or their\\nbehavior in different situations. The most complete model in this line is\\nundoubtedly the LIDA model, proposed by Stan Franklin with the aim of serving\\nas a generic computational architecture for several applications. The present\\nproject is inspired by the LIDA model to apply it to the process of movie\\nrecommendation, the model called MIRA (Movie Intelligent Recommender Agent)\\npresented percentages of precision similar to a traditional model when\\nsubmitted to the same assay conditions. Moreover, the proposed model reinforced\\nthe precision indexes when submitted to tests with volunteers, proving once\\nagain its performance as a cognitive model, when executed with small data\\nvolumes. Considering that the proposed model achieved a similar behavior to the\\ntraditional models under conditions expected to be similar for natural systems,\\nit can be said that MIRA reinforces the applicability of LIDA as a path to be\\nfollowed for the study and generation of computational agents inspired by\\nneural behaviors.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.09291v2.pdf'},\n",
       " {'id': '2201.09290v1',\n",
       "  'title': 'Reinforcement Routing on Proximity Graph for Efficient Recommendation',\n",
       "  'published': '2022-01-23T15:24:32Z',\n",
       "  'summary': \"We focus on Maximum Inner Product Search (MIPS), which is an essential\\nproblem in many machine learning communities. Given a query, MIPS finds the\\nmost similar items with the maximum inner products. Methods for Nearest\\nNeighbor Search (NNS) which is usually defined on metric space don't exhibit\\nthe satisfactory performance for MIPS problem since inner product is a\\nnon-metric function. However, inner products exhibit many good properties\\ncompared with metric functions, such as avoiding vanishing and exploding\\ngradients. As a result, inner product is widely used in many recommendation\\nsystems, which makes efficient Maximum Inner Product Search a key for speeding\\nup many recommendation systems.\\n  Graph based methods for NNS problem show the superiorities compared with\\nother class methods. Each data point of the database is mapped to a node of the\\nproximity graph. Nearest neighbor search in the database can be converted to\\nroute on the proximity graph to find the nearest neighbor for the query. This\\ntechnique can be used to solve MIPS problem. Instead of searching the nearest\\nneighbor for the query, we search the item with maximum inner product with\\nquery on the proximity graph. In this paper, we propose a reinforcement model\\nto train an agent to search on the proximity graph automatically for MIPS\\nproblem if we lack the ground truths of training queries. If we know the ground\\ntruths of some training queries, our model can also utilize these ground truths\\nby imitation learning to improve the agent's search ability. By experiments, we\\ncan see that our proposed mode which combines reinforcement learning with\\nimitation learning shows the superiorities over the state-of-the-art methods\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.09290v1.pdf'},\n",
       " {'id': '2503.03300v1',\n",
       "  'title': 'Which books do I like?',\n",
       "  'published': '2025-03-05T09:31:49Z',\n",
       "  'summary': \"Finding enjoyable fiction books can be challenging, partly because stories\\nare multi-faceted and one's own literary taste might be difficult to ascertain.\\nHere, we introduce the ISAAC method (Introspection-Support, AI-Annotation, and\\nCuration), a pipeline which supports fiction readers in gaining awareness of\\ntheir literary preferences and finding enjoyable books. ISAAC consists of four\\nsteps: a user supplies book ratings, an AI agent researches and annotates the\\nprovided books, patterns in book enjoyment are reviewed by the user, and the AI\\nagent recommends new books. In this proof-of-concept self-study, the authors\\ntest whether ISAAC can highlight idiosyncratic patterns in their book\\nenjoyment, spark a deeper reflection about their literary tastes, and make\\naccurate, personalized recommendations of enjoyable books and underexplored\\nliterary niches. Results highlight substantial advantages of ISAAC over\\nexisting methods such as an integration of automation and intuition, accurate\\nand customizable annotations, and explainable book recommendations. Observed\\ndisadvantages are that ISAAC's outputs can elicit false self-narratives (if\\nstatistical patterns are taken at face value), that books cannot be annotated\\nif their online documentation is lacking, and that people who are new to\\nreading have to rely on assumed book ratings or movie ratings to power the\\nISAAC pipeline. We discuss additional opportunities of ISAAC-style book\\nannotations for the study of literary trends, and the scientific classification\\nof books and readers.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.03300v1.pdf'},\n",
       " {'id': '2508.03293v1',\n",
       "  'title': 'Enhancing Joint Human-AI Inference in Robot Missions: A Confidence-Based\\n  Approach',\n",
       "  'published': '2025-08-05T10:12:12Z',\n",
       "  'summary': \"Joint human-AI inference holds immense potential to improve outcomes in\\nhuman-supervised robot missions. Current day missions are generally in the\\nAI-assisted setting, where the human operator makes the final inference based\\non the AI recommendation. However, due to failures in human judgement on when\\nto accept or reject the AI recommendation, complementarity is rarely achieved.\\nWe investigate joint human-AI inference where the inference made with higher\\nconfidence is selected. Through a user study with N=100 participants on a\\nrepresentative simulated robot teleoperation task, specifically studying the\\ninference of robots' control delays we show that: a) Joint inference accuracy\\nis higher and its extent is regulated by the confidence calibration of the AI\\nagent, and b) Humans change their inferences based on AI recommendations and\\nthe extent and direction of this change is also regulated by the confidence\\ncalibration of the AI agent. Interestingly, our results show that pairing\\npoorly-calibrated AI-DSS with humans hurts performance instead of helping the\\nteam, reiterating the need for AI-based decision support systems with good\\nmetacognitive sensitivity. To the best of our knowledge, our study presents the\\nfirst application of a maximum-confidence-based heuristic for joint human-AI\\ninference within a simulated robot teleoperation task.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.03293v1.pdf'},\n",
       " {'id': '1907.11406v1',\n",
       "  'title': 'Development of test materials for assessment broadcasting video path',\n",
       "  'published': '2019-07-26T07:17:53Z',\n",
       "  'summary': 'The analysis of metrological agents for the estimation of the quality of\\ntelecommunication path treatments is carried out. Analysis of subjective and\\nobjective estimation methods is presented. The justification for choosing an\\nobjective method of measuring is presented. Are reported a list of existing\\ngoals and objectives, which face the current progress of the implementation of\\npromising systems for broadcasting and improvement of existing ones. The latter\\ninclude the absence of normative documents and recommendations for optical\\nspecimens of testing tables, etc. Researches related to the choice of optical\\nsamples from existing sets of colors from a number of international documents\\nand recommendations are presented. Deficiency of these sets is substantiated,\\nas some of the colors necessary for evaluation of telecommunication paths\\ncannot be provided with no color of sets. Provides recommendations and\\nrefinements about which colors from existing sets should be used and what\\nconstraints exist when used and how to solve. It is shown, that saturated\\ncolors of green and red colors are not provided with spectral from the existing\\nsets, therefore, it is proposed to expand the traditional understanding of\\nmetrological means by using atlases of colors. Satin colors In contrast to\\nexisting ones have a number of advantages and can be used for evaluation in\\nadvanced conditions, rather than in the studio that is rigidly defined by the\\nregulations. It is noted that for different brightness values there are a\\ndifferent number of testing points. The number of testing points directly\\ndepends on the evaluation criteria, is driven by several possible sets of\\ncolors for evaluation. Recommendations for other evaluation conditions are\\nprovided. Use satin colors to construct testing tables',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.11406v1.pdf'},\n",
       " {'id': '2302.06470v1',\n",
       "  'title': 'POSGen: Personalized Opening Sentence Generation for Online Insurance\\n  Sales',\n",
       "  'published': '2023-02-10T01:40:03Z',\n",
       "  'summary': \"The insurance industry is shifting their sales mode from offline to online,\\nin expectation to reach massive potential customers in the digitization era.\\nDue to the complexity and the nature of insurance products, a cost-effective\\nonline sales solution is to exploit chatbot AI to raise customers' attention\\nand pass those with interests to human agents for further sales. For high\\nresponse and conversion rates of customers, it is crucial for the chatbot to\\ninitiate a conversation with personalized opening sentences, which are\\ngenerated with user-specific topic selection and ordering. Such personalized\\nopening sentence generation is challenging because (i) there are limited\\nhistorical samples for conversation topic recommendation in online insurance\\nsales and (ii) existing text generation schemes often fail to support\\ncustomized topic ordering based on user preferences. We design POSGen, a\\npersonalized opening sentence generation scheme dedicated for online insurance\\nsales. It transfers user embeddings learned from auxiliary online user\\nbehaviours to enhance conversation topic recommendation, and exploits a context\\nmanagement unit to arrange the recommended topics in user-specific ordering for\\nopening sentence generation. POSGen is deployed on a real-world online\\ninsurance platform. It achieves 2.33x total insurance premium improvement\\nthrough a two-month global test.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.06470v1.pdf'},\n",
       " {'id': '2305.11381v1',\n",
       "  'title': 'Online Learning in a Creator Economy',\n",
       "  'published': '2023-05-19T01:58:13Z',\n",
       "  'summary': 'The creator economy has revolutionized the way individuals can profit through\\nonline platforms. In this paper, we initiate the study of online learning in\\nthe creator economy by modeling the creator economy as a three-party game\\nbetween the users, platform, and content creators, with the platform\\ninteracting with the content creator under a principal-agent model through\\ncontracts to encourage better content. Additionally, the platform interacts\\nwith the users to recommend new content, receive an evaluation, and ultimately\\nprofit from the content, which can be modeled as a recommender system.\\n  Our study aims to explore how the platform can jointly optimize the contract\\nand recommender system to maximize the utility in an online learning fashion.\\nWe primarily analyze and compare two families of contracts: return-based\\ncontracts and feature-based contracts. Return-based contracts pay the content\\ncreator a fraction of the reward the platform gains. In contrast, feature-based\\ncontracts pay the content creator based on the quality or features of the\\ncontent, regardless of the reward the platform receives. We show that under\\nsmoothness assumptions, the joint optimization of return-based contracts and\\nrecommendation policy provides a regret $\\\\Theta(T^{2/3})$. For the\\nfeature-based contract, we introduce a definition of intrinsic dimension $d$ to\\ncharacterize the hardness of learning the contract and provide an upper bound\\non the regret $\\\\mathcal{O}(T^{(d+1)/(d+2)})$. The upper bound is tight for the\\nlinear family.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.11381v1.pdf'},\n",
       " {'id': '2311.14094v1',\n",
       "  'title': 'Robust Decision Aggregation with Second-order Information',\n",
       "  'published': '2023-11-23T16:39:55Z',\n",
       "  'summary': \"We consider a decision aggregation problem with two experts who each make a\\nbinary recommendation after observing a private signal about an unknown binary\\nworld state. An agent, who does not know the joint information structure\\nbetween signals and states, sees the experts' recommendations and aims to match\\nthe action with the true state. Under the scenario, we study whether\\nsupplemented additionally with second-order information (each expert's forecast\\non the other's recommendation) could enable a better aggregation.\\n  We adopt a minimax regret framework to evaluate the aggregator's performance,\\nby comparing it to an omniscient benchmark that knows the joint information\\nstructure. With general information structures, we show that second-order\\ninformation provides no benefit. No aggregator can improve over a trivial\\naggregator, which always follows the first expert's recommendation. However,\\npositive results emerge when we assume experts' signals are conditionally\\nindependent given the world state. When the aggregator is deterministic, we\\npresent a robust aggregator that leverages second-order information, which can\\nsignificantly outperform counterparts without it. Second, when two experts are\\nhomogeneous, by adding a non-degenerate assumption on the signals, we\\ndemonstrate that random aggregators using second-order information can surpass\\noptimal ones without it. In the remaining settings, the second-order\\ninformation is not beneficial. We also extend the above results to the setting\\nwhen the aggregator's utility function is more general.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.14094v1.pdf'},\n",
       " {'id': '2403.00806v1',\n",
       "  'title': 'Enhanced User Interaction in Operating Systems through Machine Learning\\n  Language Models',\n",
       "  'published': '2024-02-24T12:17:06Z',\n",
       "  'summary': \"With the large language model showing human-like logical reasoning and\\nunderstanding ability, whether agents based on the large language model can\\nsimulate the interaction behavior of real users, so as to build a reliable\\nvirtual recommendation A/B test scene to help the application of recommendation\\nresearch is an urgent, important and economic value problem. The combination of\\ninteraction design and machine learning can provide a more efficient and\\npersonalized user experience for products and services. This personalized\\nservice can meet the specific needs of users and improve user satisfaction and\\nloyalty. Second, the interactive system can understand the user's views and\\nneeds for the product by providing a good user interface and interactive\\nexperience, and then use machine learning algorithms to improve and optimize\\nthe product. This iterative optimization process can continuously improve the\\nquality and performance of the product to meet the changing needs of users. At\\nthe same time, designers need to consider how these algorithms and tools can be\\ncombined with interactive systems to provide a good user experience. This paper\\nexplores the potential applications of large language models, machine learning\\nand interaction design for user interaction in recommendation systems and\\noperating systems. By integrating these technologies, more intelligent and\\npersonalized services can be provided to meet user needs and promote continuous\\nimprovement and optimization of products. This is of great value for both\\nrecommendation research and user experience applications.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.00806v1.pdf'},\n",
       " {'id': '2407.13091v1',\n",
       "  'title': 'On Causally Disentangled State Representation Learning for Reinforcement\\n  Learning based Recommender Systems',\n",
       "  'published': '2024-07-18T01:41:05Z',\n",
       "  'summary': \"In Reinforcement Learning-based Recommender Systems (RLRS), the complexity\\nand dynamism of user interactions often result in high-dimensional and noisy\\nstate spaces, making it challenging to discern which aspects of the state are\\ntruly influential in driving the decision-making process. This issue is\\nexacerbated by the evolving nature of user preferences and behaviors, requiring\\nthe recommender system to adaptively focus on the most relevant information for\\ndecision-making while preserving generaliability. To tackle this problem, we\\nintroduce an innovative causal approach for decomposing the state and\\nextracting \\\\textbf{C}ausal-\\\\textbf{I}n\\\\textbf{D}ispensable \\\\textbf{S}tate\\nRepresentations (CIDS) in RLRS. Our method concentrates on identifying the\\n\\\\textbf{D}irectly \\\\textbf{A}ction-\\\\textbf{I}nfluenced \\\\textbf{S}tate Variables\\n(DAIS) and \\\\textbf{A}ction-\\\\textbf{I}nfluence \\\\textbf{A}ncestors (AIA), which\\nare essential for making effective recommendations. By leveraging conditional\\nmutual information, we develop a framework that not only discerns the causal\\nrelationships within the generative process but also isolates critical state\\nvariables from the typically dense and high-dimensional state representations.\\nWe provide theoretical evidence for the identifiability of these variables.\\nThen, by making use of the identified causal relationship, we construct\\ncausal-indispensable state representations, enabling the training of policies\\nover a more advantageous subset of the agent's state space. We demonstrate the\\nefficacy of our approach through extensive experiments, showcasing our method\\noutperforms state-of-the-art methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.13091v1.pdf'},\n",
       " {'id': '2506.17285v1',\n",
       "  'title': 'A Framework for Generating Conversational Recommendation Datasets from\\n  Behavioral Interactions',\n",
       "  'published': '2025-06-14T22:58:48Z',\n",
       "  'summary': 'Modern recommendation systems typically follow two complementary paradigms:\\ncollaborative filtering, which models long-term user preferences from\\nhistorical interactions, and conversational recommendation systems (CRS), which\\ninteract with users in natural language to uncover immediate needs. Each\\ncaptures a different dimension of user intent. While CRS models lack\\ncollaborative signals, leading to generic or poorly personalized suggestions,\\ntraditional recommenders lack mechanisms to interactively elicit immediate\\nneeds. Unifying these paradigms promises richer personalization but remains\\nchallenging due to the lack of large-scale conversational datasets grounded in\\nreal user behavior. We present ConvRecStudio, a framework that uses large\\nlanguage models (LLMs) to simulate realistic, multi-turn dialogs grounded in\\ntimestamped user-item interactions and reviews. ConvRecStudio follows a\\nthree-stage pipeline: (1) Temporal Profiling, which constructs user profiles\\nand community-level item sentiment trajectories over fine-grained aspects; (2)\\nSemantic Dialog Planning, which generates a structured plan using a DAG of\\nflexible super-nodes; and (3) Multi-Turn Simulation, which instantiates the\\nplan using paired LLM agents for the user and system, constrained by\\nexecutional and behavioral fidelity checks. We apply ConvRecStudio to three\\ndomains -- MobileRec, Yelp, and Amazon Electronics -- producing over 12K\\nmulti-turn dialogs per dataset. Human and automatic evaluations confirm the\\nnaturalness, coherence, and behavioral grounding of the generated\\nconversations. To demonstrate utility, we build a cross-attention transformer\\nmodel that jointly encodes user history and dialog context, achieving gains in\\nHit@K and NDCG@K over baselines using either signal alone or naive fusion.\\nNotably, our model achieves a 10.9% improvement in Hit@1 on Yelp over the\\nstrongest baseline.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.17285v1.pdf'},\n",
       " {'id': 'cs/0309013v1',\n",
       "  'title': 'Semi-metric Behavior in Document Networks and its Application to\\n  Recommendation Systems',\n",
       "  'published': '2003-09-09T05:24:03Z',\n",
       "  'summary': 'Recommendation systems for different Document Networks (DN) such as the World\\nWide Web (WWW) and Digital Libraries, often use distance functions extracted\\nfrom relationships among documents and keywords. For instance, documents in the\\nWWW are related via a hyperlink network, while documents in bibliographic\\ndatabases are related by citation and collaboration networks. Furthermore,\\ndocuments are related to keyterms. The distance functions computed from these\\nrelations establish associative networks among items of the DN, referred to as\\nDistance Graphs, which allow recommendation systems to identify relevant\\nassociations for individual users. However, modern recommendation systems need\\nto integrate associative data from multiple sources such as different\\ndatabases, web sites, and even other users. Thus, we are presented with a\\nproblem of combining evidence (about associations between items) from different\\nsources characterized by distance functions. In this paper we describe our work\\non (1) inferring relevant associations from, as well as characterizing,\\nsemi-metric distance graphs and (2) combining evidence from different distance\\ngraphs in a recommendation system. Regarding (1), we present the idea of\\nsemi-metric distance graphs, and introduce ratios to measure semi-metric\\nbehavior. We compute these ratios for several DN such as digital libraries and\\nweb sites and show that they are useful to identify implicit associations.\\nRegarding (2), we describe an algorithm to combine evidence from distance\\ngraphs that uses Evidence Sets, a set structure based on Interval Valued Fuzzy\\nSets and Dempster-Shafer Theory of Evidence. This algorithm has been developed\\nfor a recommendation system named TalkMine.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/cs/0309013v1.pdf'},\n",
       " {'id': '2008.04947v1',\n",
       "  'title': 'Analysis of Agricultural Policy Recommendations using Multi-Agent\\n  Systems',\n",
       "  'published': '2020-08-11T18:29:25Z',\n",
       "  'summary': \"Despite agriculture being the primary source of livelihood for more than half\\nof India's population, several socio-economic policies are implemented in the\\nIndian agricultural sector without paying enough attention to the possible\\noutcomes of the policies. The negative impact of some policies can be seen in\\nthe huge distress suffered by farmers as documented by several studies and\\nreported in the media on a regular basis. In this paper, we model a specific\\ntroubled agricultural sub-system in India as a Multi-Agent System and use it to\\nanalyse the impact of some policies. Ideally, we should be able to model the\\nentire system, including all the external dependencies from other systems - for\\nexample availability of labour or water may depend on other sources of\\nemployment, water rights and so on - but for our purpose, we start with a\\nfairly basic model not taking into account such external effects. As per our\\nknowledge there are no available models which considers factors like water\\nlevels, availability of information and market simulation in the Indian\\ncontext. So, we plugged in various entities into the model to make it\\nsufficiently close to observed realities, at least in some selected regions of\\nIndia. We evaluate some policy options to get an understanding of changes that\\nmay happen once such policies are implemented. Then we recommended some\\npolicies based on the result of the simulation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.04947v1.pdf'},\n",
       " {'id': '2112.03210v1',\n",
       "  'title': 'Contextual Bandit Applications in Customer Support Bot',\n",
       "  'published': '2021-12-06T18:07:34Z',\n",
       "  'summary': 'Virtual support agents have grown in popularity as a way for businesses to\\nprovide better and more accessible customer service. Some challenges in this\\ndomain include ambiguous user queries as well as changing support topics and\\nuser behavior (non-stationarity). We do, however, have access to partial\\nfeedback provided by the user (clicks, surveys, and other events) which can be\\nleveraged to improve the user experience. Adaptable learning techniques, like\\ncontextual bandits, are a natural fit for this problem setting. In this paper,\\nwe discuss real-world implementations of contextual bandits (CB) for the\\nMicrosoft virtual agent. It includes intent disambiguation based on\\nneural-linear bandits (NLB) and contextual recommendations based on a\\ncollection of multi-armed bandits (MAB). Our solutions have been deployed to\\nproduction and have improved key business metrics of the Microsoft virtual\\nagent, as confirmed by A/B experiments. Results include a relative increase of\\nover 12% in problem resolution rate and relative decrease of over 4% in\\nescalations to a human operator. While our current use cases focus on intent\\ndisambiguation and contextual recommendation for support bots, we believe our\\nmethods can be extended to other domains.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.03210v1.pdf'},\n",
       " {'id': '2103.10391v2',\n",
       "  'title': 'Learning to Recommend Frame for Interactive Video Object Segmentation in\\n  the Wild',\n",
       "  'published': '2021-03-18T17:19:47Z',\n",
       "  'summary': 'This paper proposes a framework for the interactive video object segmentation\\n(VOS) in the wild where users can choose some frames for annotations\\niteratively. Then, based on the user annotations, a segmentation algorithm\\nrefines the masks. The previous interactive VOS paradigm selects the frame with\\nsome worst evaluation metric, and the ground truth is required for calculating\\nthe evaluation metric, which is impractical in the testing phase. In contrast,\\nin this paper, we advocate that the frame with the worst evaluation metric may\\nnot be exactly the most valuable frame that leads to the most performance\\nimprovement across the video. Thus, we formulate the frame selection problem in\\nthe interactive VOS as a Markov Decision Process, where an agent is learned to\\nrecommend the frame under a deep reinforcement learning framework. The learned\\nagent can automatically determine the most valuable frame, making the\\ninteractive setting more practical in the wild. Experimental results on the\\npublic datasets show the effectiveness of our learned agent without any changes\\nto the underlying VOS algorithms. Our data, code, and models are available at\\nhttps://github.com/svip-lab/IVOS-W.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.10391v2.pdf'},\n",
       " {'id': '2204.03299v2',\n",
       "  'title': 'On the Impact of Social Media Recommendations on Opinion Consensus',\n",
       "  'published': '2022-04-07T09:01:42Z',\n",
       "  'summary': 'We consider a discrete opinion formation problem in a setting where agents\\nare influenced by both information diffused by their social relations and from\\nrecommendations received directly from the social media manager. We study how\\nthe \"strength\" of the influence of the social media and the homophily ratio\\naffect the probability of the agents of reaching a consensus and how these\\nfactors can determine the type of consensus reached. In a simple 2-symmetric\\nblock model we prove that agents converge either to a consensus or to a\\npersistent disagreement. In particular, we show that when the homophily ratio\\nis large, the social media has a very low capacity of determining the outcome\\nof the opinion dynamics. On the other hand, when the homophily ratio is low,\\nthe social media influence can have an important role on the dynamics, either\\nby making harder to reach a consensus or inducing it on extreme opinions.\\nFinally, in order to extend our analysis to more general and realistic settings\\nwe give some experimental evidences that our results still hold on general\\nnetworks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2204.03299v2.pdf'},\n",
       " {'id': '2402.03590v1',\n",
       "  'title': 'Assessing the Impact of Distribution Shift on Reinforcement Learning\\n  Performance',\n",
       "  'published': '2024-02-05T23:50:55Z',\n",
       "  'summary': \"Research in machine learning is making progress in fixing its own\\nreproducibility crisis. Reinforcement learning (RL), in particular, faces its\\nown set of unique challenges. Comparison of point estimates, and plots that\\nshow successful convergence to the optimal policy during training, may\\nobfuscate overfitting or dependence on the experimental setup. Although\\nresearchers in RL have proposed reliability metrics that account for\\nuncertainty to better understand each algorithm's strengths and weaknesses, the\\nrecommendations of past work do not assume the presence of out-of-distribution\\nobservations. We propose a set of evaluation methods that measure the\\nrobustness of RL algorithms under distribution shifts. The tools presented here\\nargue for the need to account for performance over time while the agent is\\nacting in its environment. In particular, we recommend time series analysis as\\na method of observational RL evaluation. We also show that the unique\\nproperties of RL and simulated dynamic environments allow us to make stronger\\nassumptions to justify the measurement of causal impact in our evaluations. We\\nthen apply these tools to single-agent and multi-agent environments to show the\\nimpact of introducing distribution shifts during test time. We present this\\nmethodology as a first step toward rigorous RL evaluation in the presence of\\ndistribution shifts.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.03590v1.pdf'},\n",
       " {'id': '2502.12766v2',\n",
       "  'title': 'Near-Linear MIR Algorithms for Stochastically-Ordered Priors',\n",
       "  'published': '2025-02-18T11:31:49Z',\n",
       "  'summary': 'With the rise of online applications, recommender systems (RSs) often\\nencounter constraints in balancing exploration and exploitation. Such\\nconstraints arise when exploration is carried out by agents whose utility must\\nbe taken into account when optimizing overall welfare. A recent work by Bahar\\net al. (2020) suggests that recommendations should be \\\\emph{mechanism-informed\\nindividually rational} (MIR). Specifically, if agents have a default arm they\\nwould use, relying on the RS should yield each agent at least the reward of the\\ndefault arm, conditioned on the information available to the RS. Under the MIR\\nconstraint, striking a balance between exploration and exploitation becomes a\\ncomplex planning problem. To that end, Bahar et al. propose an approximately\\noptimal yet inefficient planning algorithm that runs in $O(2^K K^2 H^2)$, where\\n$K$ is the number of arms and $H$ is the size of the support of the reward\\ndistributions. In this paper, we make a significant improvement for a special\\nyet practical case, removing both the dependence on $H$ and the exponential\\ndependence on $K$. We assume a stochastic order of the rewards (e.g., Gaussian\\nwith unit variance, Bernoulli, etc.), and devise an asymptotically optimal\\nalgorithm with a runtime of $O(K \\\\log K)$. Our technique is based on\\nformulating a Goal Markov Decision Process (GMDP), establishing an optimal\\ndynamic programming procedure, and then unveiling its crux -- fleshing out a\\nsimple index-based structure that facilitates efficient computation.\\nAdditionally, we present an incentive-compatible version of our algorithm.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.12766v2.pdf'},\n",
       " {'id': '2506.05010v1',\n",
       "  'title': 'ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow\\n  Development',\n",
       "  'published': '2025-06-05T13:20:50Z',\n",
       "  'summary': 'We introduce ComfyUI-Copilot, a large language model-powered plugin designed\\nto enhance the usability and efficiency of ComfyUI, an open-source platform for\\nAI-driven art creation. Despite its flexibility and user-friendly interface,\\nComfyUI can present challenges to newcomers, including limited documentation,\\nmodel misconfigurations, and the complexity of workflow design. ComfyUI-Copilot\\naddresses these challenges by offering intelligent node and model\\nrecommendations, along with automated one-click workflow construction. At its\\ncore, the system employs a hierarchical multi-agent framework comprising a\\ncentral assistant agent for task delegation and specialized worker agents for\\ndifferent usages, supported by our curated ComfyUI knowledge bases to\\nstreamline debugging and deployment. We validate the effectiveness of\\nComfyUI-Copilot through both offline quantitative evaluations and online user\\nfeedback, showing that it accurately recommends nodes and accelerates workflow\\ndevelopment. Additionally, use cases illustrate that ComfyUI-Copilot lowers\\nentry barriers for beginners and enhances workflow efficiency for experienced\\nusers. The ComfyUI-Copilot installation package and a demo video are available\\nat https://github.com/AIDC-AI/ComfyUI-Copilot.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.05010v1.pdf'},\n",
       " {'id': '2507.17680v1',\n",
       "  'title': 'Simulating multiple human perspectives in socio-ecological systems using\\n  large language models',\n",
       "  'published': '2025-07-23T16:42:51Z',\n",
       "  'summary': 'Understanding socio-ecological systems requires insights from diverse\\nstakeholder perspectives, which are often hard to access. To enable\\nalternative, simulation-based exploration of different stakeholder\\nperspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)\\nmodelling framework. HoPeS employs agents powered by large language models\\n(LLMs) to represent various stakeholders; users can step into the agent roles\\nto experience perspectival differences. A simulation protocol serves as a\\n\"scaffold\" to streamline multiple perspective-taking simulations, supporting\\nusers in reflecting on, transitioning between, and integrating across\\nperspectives. A prototype system is developed to demonstrate HoPeS in the\\ncontext of institutional dynamics and land use change, enabling both\\nnarrative-driven and numerical experiments. In an illustrative experiment, a\\nuser successively adopts the perspectives of a system observer and a researcher\\n- a role that analyses data from the embedded land use model to inform\\nevidence-based decision-making for other LLM agents representing various\\ninstitutions. Despite the user\\'s effort to recommend technically sound\\npolicies, discrepancies persist between the policy recommendation and\\nimplementation due to stakeholders\\' competing advocacies, mirroring real-world\\nmisalignment between researcher and policymaker perspectives. The user\\'s\\nreflection highlights the subjective feelings of frustration and disappointment\\nas a researcher, especially due to the challenge of maintaining political\\nneutrality while attempting to gain political influence. Despite this, the user\\nexhibits high motivation to experiment with alternative narrative framing\\nstrategies, suggesting the system\\'s potential in exploring different\\nperspectives. Further system and protocol refinement are likely to enable new\\nforms of interdisciplinary collaboration in socio-ecological simulations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.17680v1.pdf'},\n",
       " {'id': '2509.09689v1',\n",
       "  'title': 'Personas within Parameters: Fine-Tuning Small Language Models with\\n  Low-Rank Adapters to Mimic User Behaviors',\n",
       "  'published': '2025-08-18T22:14:57Z',\n",
       "  'summary': 'A long-standing challenge in developing accurate recommendation models is\\nsimulating user behavior, mainly due to the complex and stochastic nature of\\nuser interactions. Towards this, one promising line of work has been the use of\\nLarge Language Models (LLMs) for simulating user behavior. However, aligning\\nthese general-purpose large pre-trained models with user preferences\\nnecessitates: (i) effectively and continously parsing large-scale tabular\\nuser-item interaction data, (ii) overcoming pre-training-induced inductive\\nbiases to accurately learn user specific knowledge, and (iii) achieving the\\nformer two at scale for millions of users. While most previous works have\\nfocused on complex methods to prompt an LLM or fine-tune it on tabular\\ninteraction datasets, our approach shifts the focus to extracting robust\\ntextual user representations using a frozen LLM and simulating cost-effective,\\nresource-efficient user agents powered by fine-tuned Small Language Models\\n(SLMs). Further, we showcase a method for training multiple low-rank adapters\\nfor groups of users or \\\\textit{persona}, striking an optimal balance between\\nscalability and performance of user behavior agents. Our experiments provide\\ncompelling empirical evidence of the efficacy of our methods, demonstrating\\nthat user agents developed using our approach have the potential to bridge the\\ngap between offline metrics and real-world performance of recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.09689v1.pdf'},\n",
       " {'id': '2304.10745v1',\n",
       "  'title': 'Reducing Opinion Echo-Chambers by Intelligent Placement of\\n  Moderate-Minded Agents',\n",
       "  'published': '2023-04-21T05:12:08Z',\n",
       "  'summary': \"In the era of social media, people frequently share their own opinions online\\non various issues and also in the way, get exposed to others' opinions. Be it\\nfor selective exposure of news feed recommendation algorithms or our own\\ninclination to listen to opinions that support ours, the result is that we get\\nmore and more exposed to opinions closer to ours. Further, any population is\\ninherently heterogeneous i.e. people will hold a varied range of opinions\\nregarding a topic and showcase a varied range of openness to get influenced by\\nothers. In this paper, we demonstrate the different behavior put forward by\\nopen- and close-minded agents towards an issue, when allowed to freely intermix\\nand communicate.\\n  We have shown that the intermixing among people leads to formation of opinion\\necho chambers i.e. a small closed network of people who hold similar opinions\\nand are not affected by opinions of people outside the network. Echo chambers\\nare evidently harmful for a society because it inhibits free healthy\\ncommunication among all and thus, prevents exchange of opinions, spreads\\nmisinformation and increases extremist beliefs. This calls for reduction in\\necho chambers, because a total consensus of opinion is neither possible nor is\\nwelcome. We show that the number of echo chambers depends on the number of\\nclose-minded agents and cannot be lessened by increasing the number of\\nopen-minded agents. We identify certain 'moderate'-minded agents, who possess\\nthe capability of manipulating and reducing the number of echo chambers. The\\npaper proposes an algorithm for intelligent placement of moderate-minded agents\\nin the opinion-time spectrum by which the opinion echo chambers can be\\nmaximally reduced. With various experimental setups, we demonstrate that the\\nproposed algorithm fares well when compared to placement of other agents (open-\\nor close-minded) and random placement of 'moderate'-minded agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.10745v1.pdf'},\n",
       " {'id': '2312.11865v3',\n",
       "  'title': 'Large Language Models Play StarCraft II: Benchmarks and A Chain of\\n  Summarization Approach',\n",
       "  'published': '2023-12-19T05:27:16Z',\n",
       "  'summary': 'StarCraft II is a challenging benchmark for AI agents due to the necessity of\\nboth precise micro level operations and strategic macro awareness. Previous\\nworks, such as Alphastar and SCC, achieve impressive performance on tackling\\nStarCraft II , however, still exhibit deficiencies in long term strategic\\nplanning and strategy interpretability. Emerging large language model (LLM)\\nagents, such as Voyage and MetaGPT, presents the immense potential in solving\\nintricate tasks. Motivated by this, we aim to validate the capabilities of LLMs\\non StarCraft II, a highly complex RTS game.To conveniently take full advantage\\nof LLMs` reasoning abilities, we first develop textual StratCraft II\\nenvironment, called TextStarCraft II, which LLM agent can interact. Secondly,\\nwe propose a Chain of Summarization method, including single frame\\nsummarization for processing raw observations and multi frame summarization for\\nanalyzing game information, providing command recommendations, and generating\\nstrategic decisions. Our experiment consists of two parts: first, an evaluation\\nby human experts, which includes assessing the LLMs`s mastery of StarCraft II\\nknowledge and the performance of LLM agents in the game; second, the in game\\nperformance of LLM agents, encompassing aspects like win rate and the impact of\\nChain of Summarization.Experiment results demonstrate that: 1. LLMs possess the\\nrelevant knowledge and complex planning abilities needed to address StarCraft\\nII scenarios; 2. Human experts consider the performance of LLM agents to be\\nclose to that of an average player who has played StarCraft II for eight years;\\n3. LLM agents are capable of defeating the built in AI at the Harder(Lv5)\\ndifficulty level. We have open sourced the code and released demo videos of LLM\\nagent playing StarCraft II.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.11865v3.pdf'},\n",
       " {'id': '2411.11581v5',\n",
       "  'title': 'OASIS: Open Agent Social Interaction Simulations with One Million Agents',\n",
       "  'published': '2024-11-18T13:57:35Z',\n",
       "  'summary': \"There has been a growing interest in enhancing rule-based agent-based models\\n(ABMs) for social media platforms (i.e., X, Reddit) with more realistic large\\nlanguage model (LLM) agents, thereby allowing for a more nuanced study of\\ncomplex systems. As a result, several LLM-based ABMs have been proposed in the\\npast year. While they hold promise, each simulator is specifically designed to\\nstudy a particular scenario, making it time-consuming and resource-intensive to\\nexplore other phenomena using the same ABM. Additionally, these models simulate\\nonly a limited number of agents, whereas real-world social media platforms\\ninvolve millions of users. To this end, we propose OASIS, a generalizable and\\nscalable social media simulator. OASIS is designed based on real-world social\\nmedia platforms, incorporating dynamically updated environments (i.e., dynamic\\nsocial networks and post information), diverse action spaces (i.e., following,\\ncommenting), and recommendation systems (i.e., interest-based and\\nhot-score-based). Additionally, OASIS supports large-scale user simulations,\\ncapable of modeling up to one million users. With these features, OASIS can be\\neasily extended to different social media platforms to study large-scale group\\nphenomena and behaviors. We replicate various social phenomena, including\\ninformation spreading, group polarization, and herd effects across X and Reddit\\nplatforms. Moreover, we provide observations of social phenomena at different\\nagent group scales. We observe that the larger agent group scale leads to more\\nenhanced group dynamics and more diverse and helpful agents' opinions. These\\nfindings demonstrate OASIS's potential as a powerful tool for studying complex\\nsystems in digital environments.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.11581v5.pdf'},\n",
       " {'id': '1811.11064v1',\n",
       "  'title': 'Combining Deep Learning and Qualitative Spatial Reasoning to Learn\\n  Complex Structures from Sparse Examples with Noise',\n",
       "  'published': '2018-11-27T15:48:27Z',\n",
       "  'summary': \"Many modern machine learning approaches require vast amounts of training data\\nto learn new concepts; conversely, human learning often requires few\\nexamples--sometimes only one--from which the learner can abstract structural\\nconcepts. We present a novel approach to introducing new spatial structures to\\nan AI agent, combining deep learning over qualitative spatial relations with\\nvarious heuristic search algorithms. The agent extracts spatial relations from\\na sparse set of noisy examples of block-based structures, and trains\\nconvolutional and sequential models of those relation sets. To create novel\\nexamples of similar structures, the agent begins placing blocks on a virtual\\ntable, uses a CNN to predict the most similar complete example structure after\\neach placement, an LSTM to predict the most likely set of remaining moves\\nneeded to complete it, and recommends one using heuristic search. We verify\\nthat the agent learned the concept by observing its virtual block-building\\nactivities, wherein it ranks each potential subsequent action toward building\\nits learned concept. We empirically assess this approach with human\\nparticipants' ratings of the block structures. Initial results and qualitative\\nevaluations of structures generated by the trained agent show where it has\\ngeneralized concepts from the training data, which heuristics perform best\\nwithin the search space, and how we might improve learning and execution.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.11064v1.pdf'},\n",
       " {'id': '2311.02558v4',\n",
       "  'title': 'Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity\\n  with Free-Flying Robots',\n",
       "  'published': '2023-11-05T03:53:42Z',\n",
       "  'summary': \"Assistive free-flyer robots autonomously caring for future crewed outposts --\\nsuch as NASA's Astrobee robots on the International Space Station (ISS) -- must\\nbe able to detect day-to-day interior changes to track inventory, detect and\\ndiagnose faults, and monitor the outpost status. This work presents a framework\\nfor multi-agent cooperative mapping and change detection to enable robotic\\nmaintenance of space outposts. One agent is used to reconstruct a 3D model of\\nthe environment from sequences of images and corresponding depth information.\\nAnother agent is used to periodically scan the environment for inconsistencies\\nagainst the 3D model. Change detection is validated after completing the\\nsurveys using real image and pose data collected by Astrobee robots in a ground\\ntesting environment and from microgravity aboard the ISS. This work outlines\\nthe objectives, requirements, and algorithmic modules for the multi-agent\\nreconstruction system, including recommendations for its use by assistive\\nfree-flyers aboard future microgravity outposts.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.02558v4.pdf'},\n",
       " {'id': '2401.02223v1',\n",
       "  'title': 'A BDI Agent-Based Task Scheduling Framework for Cloud Computing',\n",
       "  'published': '2024-01-04T12:15:45Z',\n",
       "  'summary': 'Cloud computing is an attractive technology for providing computing resources\\nover the Internet. Task scheduling is a critical issue in cloud computing,\\nwhere an efficient task scheduling method can improve overall cloud\\nperformance. Since cloud computing is a large-scale and geographically\\ndistributed environment, traditional scheduling methods that allocate resources\\nin a centralized manner are ineffective. Besides, traditional methods are\\ndifficult to make rational decisions timely when the external environment\\nchanges. This paper proposes a decentralized BDI (belief-desire-intention)\\nagent-based scheduling framework for cloud computing. BDI agents have\\nadvantages in modelling dynamic environments because BDI agents can update\\ntheir beliefs, change desires, and trigger behaviours based on environmental\\nchanges. Besides, to avoid communication stuck caused by environmental\\nuncertainties, the asynchronous communication mode with a notify listener is\\nemployed. The proposed framework covers both the task scheduling and\\nrescheduling stages with the consideration of uncertain events that can\\ninterrupt task executions. Two agent-based algorithms are proposed to implement\\nthe task scheduling and rescheduling processes, and a novel recommendation\\nmechanism is presented in the scheduling stage to reduce the impact of\\ninformation synchronization delays. The proposed framework is implemented by\\nJADEX and tested on CloudSim. The experimental results show that our framework\\ncan minimize the task makespan, balance the resource utilization in a\\nlarge-scale environment, and maximize the task success rate when uncertain\\nevents occur.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.02223v1.pdf'},\n",
       " {'id': '2412.07472v3',\n",
       "  'title': 'SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in\\n  Cyber World',\n",
       "  'published': '2024-12-10T12:40:35Z',\n",
       "  'summary': \"Recent advances in embodied agents with multimodal perception and reasoning\\ncapabilities based on large vision-language models (LVLMs), excel in\\nautonomously interacting either real or cyber worlds, helping people make\\nintelligent decisions in complex environments. However, the current works are\\nnormally optimized by golden action trajectories or ideal task-oriented\\nsolutions toward a definitive goal. This paradigm considers limited\\nuser-oriented factors, which could be the reason for their performance\\nreduction in a wide range of personal assistant applications. To address this,\\nwe propose Chain-of-User-Thought (COUT), a novel embodied reasoning paradigm\\nthat takes a chain of thought from basic action thinking to explicit and\\nimplicit personalized preference thought to incorporate personalized factors\\ninto autonomous agent learning. To target COUT, we introduce SmartAgent, an\\nagent framework perceiving cyber environments and reasoning personalized\\nrequirements as 1) interacting with GUI to access an item pool, 2) generating\\nusers' explicit requirements implied by previous actions, and 3) recommending\\nitems to fulfill users' implicit requirements. To demonstrate SmartAgent's\\ncapabilities, we also create a brand-new dataset SmartSpot that offers a\\nfull-stage personalized action-involved environment. To our best knowledge, our\\nwork is the first to formulate the COUT process, serving as a preliminary\\nattempt towards embodied personalized agent learning. Our extensive experiments\\non SmartSpot illuminate SmartAgent's functionality among a series of embodied\\nand personalized sub-tasks. We will release code and data upon paper\\nnotification at https://github.com/tsinghua-fib-lab/SmartAgent.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.07472v3.pdf'},\n",
       " {'id': '2412.18351v2',\n",
       "  'title': 'Multi-Agents Based on Large Language Models for Knowledge-based Visual\\n  Question Answering',\n",
       "  'published': '2024-12-24T11:24:56Z',\n",
       "  'summary': 'Large Language Models (LLMs) have achieved impressive results in\\nknowledge-based Visual Question Answering (VQA). However existing methods still\\nhave challenges: the inability to use external tools autonomously, and the\\ninability to work in teams. Humans tend to know whether they need to use\\nexternal tools when they encounter a new question, e.g., they tend to be able\\nto give a direct answer to a familiar question, whereas they tend to use tools\\nsuch as search engines when they encounter an unfamiliar question. In addition,\\nhumans also tend to collaborate and discuss with others to get better answers.\\nInspired by this, we propose the multi-agent voting framework. We design three\\nLLM-based agents that simulate different levels of staff in a team, and assign\\nthe available tools according to the levels. Each agent provides the\\ncorresponding answer, and finally all the answers provided by the agents are\\nvoted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our\\napproach outperforms other baselines by 2.2 and 1.0, respectively.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.18351v2.pdf'},\n",
       " {'id': '2501.06193v1',\n",
       "  'title': 'A Novel Task-Driven Method with Evolvable Interactive Agents Using Event\\n  Trees for Enhanced Emergency Decision Support',\n",
       "  'published': '2024-12-24T04:53:46Z',\n",
       "  'summary': 'As climate change and other global challenges increase the likelihood of\\nunforeseen emergencies, the limitations of human-driven strategies in critical\\nsituations become more pronounced. Inadequate pre-established emergency plans\\ncan lead operators to become overwhelmed during complex systems malfunctions.\\nThis study addresses the urgent need for agile decision-making in response to\\nvarious unforeseen incidents through a novel approach, EvoTaskTree (a\\ntask-driven method with evolvable interactive agents using event trees for\\nemergency decision support). This advanced approach integrates two types of\\nagents powered by large language models (LLMs): task executors, responsible for\\nexecuting critical procedures, and task validators, ensuring the efficacy of\\nthose actions. By leveraging insights from event tree analysis, our framework\\nencompasses three crucial tasks: initiating event subevent analysis, event tree\\nheader event analysis, and decision recommendations. The agents learn from both\\nsuccessful and unsuccessful responses from these tasks. Finally, we use nuclear\\npower plants as a demonstration of a safety-critical system. Our findings\\nindicate that the designed agents are not only effective but also outperform\\nexisting approaches, achieving an impressive accuracy rate of up to 100 % in\\nprocessing previously unencoun32 tered incident scenarios. This paper\\ndemonstrates that EvoTaskTree significantly enhances the rapid formulation of\\nemergency decision-making.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06193v1.pdf'},\n",
       " {'id': '2501.19388v2',\n",
       "  'title': 'Online Decision-Making in Tree-Like Multi-Agent Games with Transfers',\n",
       "  'published': '2025-01-31T18:43:29Z',\n",
       "  'summary': 'The widespread deployment of Machine Learning systems everywhere raises\\nchallenges, such as dealing with interactions or competition between multiple\\nlearners. In that goal, we study multi-agent sequential decision-making by\\nconsidering principal-agent interactions in a tree structure. In this problem,\\nthe reward of a player is influenced by the actions of her children, who are\\nall self-interested and non-cooperative, hence the complexity of making good\\ndecisions. Our main finding is that it is possible to steer all the players\\ntowards the globally optimal set of actions by simply allowing single-step\\ntransfers between them. A transfer is established between a principal and one\\nof her agents: the principal actually offers the proposed payment if the agent\\npicks the recommended action. The analysis poses specific challenges due to the\\nintricate interactions between the nodes of the tree and the propagation of the\\nregret within this tree. Considering a bandit setup, we propose algorithmic\\nsolutions for the players to end up being no-regret with respect to the optimal\\npair of actions and incentives. In the long run, allowing transfers between\\nplayers makes them act as if they were collaborating together, although they\\nremain self-interested non-cooperative: transfers restore efficiency.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.19388v2.pdf'},\n",
       " {'id': '2502.04058v2',\n",
       "  'title': 'Explanation Design in Strategic Learning: Sufficient Explanations that\\n  Induce Non-harmful Responses',\n",
       "  'published': '2025-02-06T13:17:24Z',\n",
       "  'summary': \"We study explanation design in algorithmic decision making with strategic\\nagents, individuals who may modify their inputs in response to explanations of\\na decision maker's (DM's) predictive model. As the demand for transparent\\nalgorithmic systems continues to grow, most prior work assumes full model\\ndisclosure as the default solution. In practice, however, DMs such as financial\\ninstitutions typically disclose only partial model information via\\nexplanations. Such partial disclosure can lead agents to misinterpret the model\\nand take actions that unknowingly harm their utility. A key open question is\\nhow DMs can communicate explanations in a way that avoids harming strategic\\nagents, while still supporting their own decision-making goals, e.g.,\\nminimising predictive error. In this work, we analyse well-known explanation\\nmethods, and establish a necessary condition to prevent explanations from\\nmisleading agents into self-harming actions. Moreover, with a conditional\\nhomogeneity assumption, we prove that action recommendation-based explanations\\n(ARexes) are sufficient for non-harmful responses, mirroring the revelation\\nprinciple in information design. To demonstrate how ARexes can be\\noperationalised in practice, we propose a simple learning procedure that\\njointly optimises the predictive model and explanation policy. Experiments on\\nsynthetic and real-world tasks show that ARexes allow the DM to optimise their\\nmodel's predictive performance while preserving agents' utility, offering a\\nmore refined strategy for safe and effective partial model disclosure.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.04058v2.pdf'},\n",
       " {'id': '2502.05718v1',\n",
       "  'title': 'Using agent-based models and EXplainable Artificial Intelligence (XAI)\\n  to simulate social behaviors and policy intervention scenarios: A case study\\n  of private well users in Ireland',\n",
       "  'published': '2025-02-08T23:21:50Z',\n",
       "  'summary': 'Around 50 percent of Irelands rural population relies on unregulated private\\nwells vulnerable to agricultural runoff and untreated wastewater. High national\\nrates of Shiga toxin-producing Escherichia coli (STEC) and other waterborne\\nillnesses have been linked to well water exposure. Periodic well testing is\\nessential for public health, yet the lack of government incentives places the\\nfinancial burden on households. Understanding environmental, cognitive, and\\nmaterial factors influencing well-testing behavior is critical.\\n  This study employs Agent-Based Modeling (ABM) to simulate policy\\ninterventions based on national survey data. The ABM framework, designed for\\nprivate well-testing behavior, integrates a Deep Q-network reinforcement\\nlearning model and Explainable AI (XAI) for decision-making insights. Key\\nfeatures were selected using Recursive Feature Elimination (RFE) with 10-fold\\ncross-validation, while SHAP (Shapley Additive Explanations) provided further\\ninterpretability for policy recommendations.\\n  Fourteen policy scenarios were tested. The most effective, Free Well Testing\\nplus Communication Campaign, increased participation to 435 out of 561 agents,\\nfrom a baseline of approximately 5 percent, with rapid behavioral adaptation.\\nFree Well Testing plus Regulation also performed well, with 433 out of 561\\nagents initiating well testing. Free testing alone raised participation to over\\n75 percent, with some agents testing multiple times annually. Scenarios with\\nfree well testing achieved faster learning efficiency, converging in 1000\\nepisodes, while others took 2000 episodes, indicating slower adaptation.\\n  This research demonstrates the value of ABM and XAI in public health policy,\\nproviding a framework for evaluating behavioral interventions in environmental\\nhealth.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.05718v1.pdf'},\n",
       " {'id': '2505.00945v2',\n",
       "  'title': 'SSRLBot: Designing and Developing a Large Language Model-based Agent\\n  using Socially Shared Regulated Learning',\n",
       "  'published': '2025-05-02T01:17:03Z',\n",
       "  'summary': \"Large language model (LLM)--based agents have emerged as pivotal tools in\\nassisting human experts across various fields by transforming complex tasks\\ninto more efficient workflows and providing actionable stakeholder insights.\\nDespite their potential, the application of LLM-based agents for medical\\neducation remains underexplored. The study aims to assist in evaluating the\\nstudents' process and outcomes on medical case diagnosis and discussion while\\nincorporating the theoretical framework of Socially Shared Regulation of\\nLearning (SSRL) to assess student performance. SSRL emphasizes metacognitive,\\ncognitive, motivational, and emotional interactions, highlighting the\\ncollaborative management of learning processes to improve decision-making\\noutcomes. Grounded in SSRL theory, this tool paper introduces SSRLBot, an\\nLLM-based agent designed to enable team members to reflect on their diagnostic\\nperformance and the key SSRL skills that foster team success. SSRLBot's core\\nfunctions include summarizing dialogue content, analyzing participants' SSRL\\nskills, and evaluating students' diagnostic results. Meanwhile, we evaluated\\nSSRLBot through diagnostic conversation data collected from six groups (12\\nparticipants, 1926 conversational turns). Results showed that SSRLBot can\\ndeliver detailed, theory-aligned evaluations, link specific behaviors to SSRL\\ndimensions, and offer actionable recommendations for improving teamwork. The\\nfindings address a critical gap in medical education, advancing the application\\nof LLM agents to enhance team-based decision-making and collaboration in\\nhigh-stakes environments.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.00945v2.pdf'},\n",
       " {'id': '2505.10922v1',\n",
       "  'title': 'Vaiage: A Multi-Agent Solution to Personalized Travel Planning',\n",
       "  'published': '2025-05-16T06:54:52Z',\n",
       "  'summary': 'Planning trips is a cognitively intensive task involving conflicting user\\npreferences, dynamic external information, and multi-step temporal-spatial\\noptimization. Traditional platforms often fall short - they provide static\\nresults, lack contextual adaptation, and fail to support real-time interaction\\nor intent refinement.\\n  Our approach, Vaiage, addresses these challenges through a graph-structured\\nmulti-agent framework built around large language models (LLMs) that serve as\\nboth goal-conditioned recommenders and sequential planners. LLMs infer user\\nintent, suggest personalized destinations and activities, and synthesize\\nitineraries that align with contextual constraints such as budget, timing,\\ngroup size, and weather. Through natural language interaction, structured tool\\nuse, and map-based feedback loops, Vaiage enables adaptive, explainable, and\\nend-to-end travel planning grounded in both symbolic reasoning and\\nconversational understanding.\\n  To evaluate Vaiage, we conducted human-in-the-loop experiments using\\nrubric-based GPT-4 assessments and qualitative feedback. The full system\\nachieved an average score of 8.5 out of 10, outperforming the no-strategy (7.2)\\nand no-external-API (6.8) variants, particularly in feasibility. Qualitative\\nanalysis indicated that agent coordination - especially the Strategy and\\nInformation Agents - significantly improved itinerary quality by optimizing\\ntime use and integrating real-time context. These results demonstrate the\\neffectiveness of combining LLM reasoning with symbolic agent coordination in\\nopen-ended, real-world planning tasks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.10922v1.pdf'},\n",
       " {'id': '2505.13773v1',\n",
       "  'title': 'Model Cards for AI Teammates: Comparing Human-AI Team Familiarization\\n  Methods for High-Stakes Environments',\n",
       "  'published': '2025-05-19T23:19:16Z',\n",
       "  'summary': 'We compare three methods of familiarizing a human with an artificial\\nintelligence (AI) teammate (\"agent\") prior to operation in a collaborative,\\nfast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In\\na between-subjects user study (n=60), participants either read documentation\\nabout the agent, trained alongside the agent prior to the mission, or were\\ngiven no familiarization. Results showed that the most valuable information\\nabout the agent included details of its decision-making algorithms and its\\nrelative strengths and weaknesses compared to the human. This information\\nallowed the familiarization groups to form sophisticated team strategies more\\nquickly than the control group. Documentation-based familiarization led to the\\nfastest adoption of these strategies, but also biased participants towards\\nrisk-averse behavior that prevented high scores. Participants familiarized\\nthrough direct interaction were able to infer much of the same information\\nthrough observation, and were more willing to take risks and experiment with\\ndifferent control modes, but reported weaker understanding of the agent\\'s\\ninternal processes. Significant differences were seen between individual\\nparticipants\\' risk tolerance and methods of AI interaction, which should be\\nconsidered when designing human-AI control interfaces. Based on our findings,\\nwe recommend a human-AI team familiarization method that combines AI\\ndocumentation, structured in-situ training, and exploratory interaction.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.13773v1.pdf'},\n",
       " {'id': '2507.22504v2',\n",
       "  'title': 'Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic\\n  Matching Approach',\n",
       "  'published': '2025-07-30T09:21:59Z',\n",
       "  'summary': 'The post-pandemic surge in healthcare demand, coupled with critical nursing\\nshortages, has placed unprecedented pressure on medical triage systems,\\nnecessitating innovative AI-driven solutions. We present a multi-agent\\ninteractive intelligent system for medical triage that addresses three\\nfundamental challenges in current AI-based triage systems: inadequate medical\\nspecialization leading to misclassification, heterogeneous department\\nstructures across healthcare institutions, and inefficient detail-oriented\\nquestioning that impedes rapid triage decisions. Our system employs three\\nspecialized agents--RecipientAgent, InquirerAgent, and DepartmentAgent--that\\ncollaborate through Inquiry Guidance mechanism and Classification Guidance\\nMechanism to transform unstructured patient symptoms into accurate department\\nrecommendations. To ensure robust evaluation, we constructed a comprehensive\\nChinese medical triage dataset from \"Ai Ai Yi Medical Network\", comprising\\n3,360 real-world cases spanning 9 primary departments and 62 secondary\\ndepartments. Experimental results demonstrate that our multi-agent system\\nachieves 89.6% accuracy in primary department classification and 74.3% accuracy\\nin secondary department classification after four rounds of patient\\ninteraction. The system\\'s dynamic matching based guidance mechanisms enable\\nefficient adaptation to diverse hospital configurations while maintaining high\\ntriage accuracy. We successfully developed this multi-agent triage system that\\nnot only adapts to organizational heterogeneity across healthcare institutions\\nbut also ensures clinically sound decision-making.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.22504v2.pdf'},\n",
       " {'id': '2508.14940v2',\n",
       "  'title': 'Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using\\n  a Retrieval-Augmented Model Selection Framework',\n",
       "  'published': '2025-08-20T02:59:39Z',\n",
       "  'summary': \"Accurate lung cancer risk prediction remains challenging due to substantial\\nvariability across patient populations and clinical settings -- no single model\\nperforms best for all cohorts. To address this, we propose a personalized lung\\ncancer risk prediction agent that dynamically selects the most appropriate\\nmodel for each patient by combining cohort-specific knowledge with modern\\nretrieval and reasoning techniques. Given a patient's CT scan and structured\\nmetadata -- including demographic, clinical, and nodule-level features -- the\\nagent first performs cohort retrieval using FAISS-based similarity search\\nacross nine diverse real-world cohorts to identify the most relevant patient\\npopulation from a multi-institutional database. Second, a Large Language Model\\n(LLM) is prompted with the retrieved cohort and its associated performance\\nmetrics to recommend the optimal prediction algorithm from a pool of eight\\nrepresentative models, including classical linear risk models (e.g., Mayo,\\nBrock), temporally-aware models (e.g., TD-VIT, DLSTM), and multi-modal computer\\nvision-based approaches (e.g., Liao, Sybil, DLS, DLI). This two-stage agent\\npipeline -- retrieval via FAISS and reasoning via LLM -- enables dynamic,\\ncohort-aware risk prediction personalized to each patient's profile. Building\\non this architecture, the agent supports flexible and cohort-driven model\\nselection across diverse clinical populations, offering a practical path toward\\nindividualized risk assessment in real-world lung cancer screening.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.14940v2.pdf'},\n",
       " {'id': '2509.05735v1',\n",
       "  'title': 'Offline vs. Online Learning in Model-based RL: Lessons for Data\\n  Collection Strategies',\n",
       "  'published': '2025-09-06T14:52:33Z',\n",
       "  'summary': \"Data collection is crucial for learning robust world models in model-based\\nreinforcement learning. The most prevalent strategies are to actively collect\\ntrajectories by interacting with the environment during online training or\\ntraining on offline datasets. At first glance, the nature of learning\\ntask-agnostic environment dynamics makes world models a good candidate for\\neffective offline training. However, the effects of online vs. offline data on\\nworld models and thus on the resulting task performance have not been\\nthoroughly studied in the literature. In this work, we investigate both\\nparadigms in model-based settings, conducting experiments on 31 different\\nenvironments. First, we showcase that online agents outperform their offline\\ncounterparts. We identify a key challenge behind performance degradation of\\noffline agents: encountering Out-Of-Distribution states at test time. This\\nissue arises because, without the self-correction mechanism in online agents,\\noffline datasets with limited state space coverage induce a mismatch between\\nthe agent's imagination and real rollouts, compromising policy training. We\\ndemonstrate that this issue can be mitigated by allowing for additional online\\ninteractions in a fixed or adaptive schedule, restoring the performance of\\nonline training with limited interaction data. We also showcase that\\nincorporating exploration data helps mitigate the performance degradation of\\noffline agents. Based on our insights, we recommend adding exploration data\\nwhen collecting large datasets, as current efforts predominantly focus on\\nexpert data alone.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.05735v1.pdf'},\n",
       " {'id': '2509.11507v1',\n",
       "  'title': 'MedicalOS: An LLM Agent based Operating System for Digital Healthcare',\n",
       "  'published': '2025-09-15T01:43:20Z',\n",
       "  'summary': \"Decades' advances in digital health technologies, such as electronic health\\nrecords, have largely streamlined routine clinical processes. Yet, most these\\nsystems are still hard to learn and use: Clinicians often face the burden of\\nmanaging multiple tools, repeating manual actions for each patient, navigating\\ncomplicated UI trees to locate functions, and spending significant time on\\nadministration instead of caring for patients. The recent rise of large\\nlanguage model (LLM) based agents demonstrates exceptional capability in coding\\nand computer operation, revealing the potential for humans to interact with\\noperating systems and software not by direct manipulation, but by instructing\\nagents through natural language. This shift highlights the need for an\\nabstraction layer, an agent-computer interface, that translates human language\\ninto machine-executable commands. In digital healthcare, however, requires a\\nmore domain-specific abstractions that strictly follow trusted clinical\\nguidelines and procedural standards to ensure safety, transparency, and\\ncompliance. To address this need, we present \\\\textbf{MedicalOS}, a unified\\nagent-based operational system designed as such a domain-specific abstract\\nlayer for healthcare. It translates human instructions into pre-defined digital\\nhealthcare commands, such as patient inquiry, history retrieval, exam\\nmanagement, report generation, referrals, treatment planning, that we wrapped\\nas off-the-shelf tools using machine languages (e.g., Python, APIs, MCP,\\nLinux). We empirically validate MedicalOS on 214 patient cases across 22\\nspecialties, demonstrating high diagnostic accuracy and confidence, clinically\\nsound examination requests, and consistent generation of structured reports and\\nmedication recommendations. These results highlight MedicalOS as a trustworthy\\nand scalable foundation for advancing workflow automation in clinical practice.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.11507v1.pdf'},\n",
       " {'id': '2508.20148v1',\n",
       "  'title': 'The Anatomy of a Personal Health Agent',\n",
       "  'published': '2025-08-27T14:38:46Z',\n",
       "  'summary': \"Health is a fundamental pillar of human wellness, and the rapid advancements\\nin large language models (LLMs) have driven the development of a new generation\\nof health agents. However, the application of health agents to fulfill the\\ndiverse needs of individuals in daily non-clinical settings is underexplored.\\nIn this work, we aim to build a comprehensive personal health agent that is\\nable to reason about multimodal data from everyday consumer wellness devices\\nand common personal health records, and provide personalized health\\nrecommendations. To understand end-users' needs when interacting with such an\\nassistant, we conducted an in-depth analysis of web search and health forum\\nqueries, alongside qualitative insights from users and health experts gathered\\nthrough a user-centered design process. Based on these findings, we identified\\nthree major categories of consumer health needs, each of which is supported by\\na specialist sub-agent: (1) a data science agent that analyzes personal\\ntime-series wearable and health record data, (2) a health domain expert agent\\nthat integrates users' health and contextual data to generate accurate,\\npersonalized insights, and (3) a health coach agent that synthesizes data\\ninsights, guiding users using a specified psychological strategy and tracking\\nusers' progress. Furthermore, we propose and develop the Personal Health Agent\\n(PHA), a multi-agent framework that enables dynamic, personalized interactions\\nto address individual health needs. To evaluate each sub-agent and the\\nmulti-agent system, we conducted automated and human evaluations across 10\\nbenchmark tasks, involving more than 7,000 annotations and 1,100 hours of\\neffort from health experts and end-users. Our work represents the most\\ncomprehensive evaluation of a health agent to date and establishes a strong\\nfoundation towards the futuristic vision of a personal health agent accessible\\nto everyone.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.20148v1.pdf'},\n",
       " {'id': '2412.07951v3',\n",
       "  'title': 'From Lived Experience to Insight: Unpacking the Psychological Risks of\\n  Using AI Conversational Agents',\n",
       "  'published': '2024-12-10T22:31:29Z',\n",
       "  'summary': 'Recent gains in popularity of AI conversational agents have led to their\\nincreased use for improving productivity and supporting well-being. While\\nprevious research has aimed to understand the risks associated with\\ninteractions with AI conversational agents, these studies often fall short in\\ncapturing the lived experiences of individuals. Additionally, psychological\\nrisks have often been presented as a sub-category within broader AI-related\\nrisks in past taxonomy works, leading to under-representation of the impact of\\npsychological risks of AI use. To address these challenges, our work presents a\\nnovel risk taxonomy focusing on psychological risks of using AI gathered\\nthrough the lived experiences of individuals. We employed a mixed-method\\napproach, involving a comprehensive survey with 283 people with lived mental\\nhealth experience and workshops involving experts with lived experience to\\ndevelop a psychological risk taxonomy. Our taxonomy features 19 AI behaviors,\\n21 negative psychological impacts, and 15 contexts related to individuals.\\nAdditionally, we propose a novel multi-path vignette-based framework for\\nunderstanding the complex interplay between AI behaviors, psychological\\nimpacts, and individual user contexts. Finally, based on the feedback obtained\\nfrom the workshop sessions, we present design recommendations for developing\\nsafer and more robust AI agents. Our work offers an in-depth understanding of\\nthe psychological risks associated with AI conversational agents and provides\\nactionable recommendations for policymakers, researchers, and developers.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.07951v3.pdf'},\n",
       " {'id': '0911.0753v1',\n",
       "  'title': 'An XML-based Multi-Agent System for Supporting Online Recruitment\\n  Services',\n",
       "  'published': '2009-11-04T09:19:37Z',\n",
       "  'summary': 'In this paper we propose an XML-based multi-agent recommender system for\\nsupporting online recruitment services. Our system is characterized by the\\nfollowing features: {\\\\em (i)} it handles user profiles for personalizing the\\njob search over the Internet; {\\\\em (ii)} it is based on the Intelligent Agent\\nTechnology; {\\\\em (iii)} it uses XML for guaranteeing a light, versatile and\\nstandard mechanism for information representation, storing and exchange. The\\npaper discusses the basic features of the proposed system, presents the results\\nof an experimental study we have carried out for evaluating its performance,\\nand makes a comparison between the proposed system and other e-recruitment\\nsystems already presented in the past.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0911.0753v1.pdf'},\n",
       " {'id': '1012.4485v1',\n",
       "  'title': 'An Experimental Approach for Optimising Mobile Agent Migrations',\n",
       "  'published': '2010-12-20T21:53:55Z',\n",
       "  'summary': 'The field of mobile agent (MA) technology has been intensively researched\\nduring the past few years, resulting in the phenomenal proliferation of\\navailable MA platforms, all sharing several common design characteristics.\\nResearch projects have mainly focused on identifying applications where the\\nemployment of MAs is preferable compared to centralised or alternative\\ndistributed computing models. Very little work has been made on examining how\\nMA platforms design can be optimised so as the network traffic and latency\\nassociated with MA transfers are minimised. The work presented in this paper\\naddresses these issues by investigating the effect of several optimisation\\nideas applied on our MA platform prototype. Furthermore, we discuss the results\\nof a set of timing experiments that offers a better understanding of the agent\\nmigration process and recommend new techniques for reducing MA transfers delay.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1012.4485v1.pdf'},\n",
       " {'id': '1103.2215v3',\n",
       "  'title': 'Trust beyond reputation: A computational trust model based on\\n  stereotypes',\n",
       "  'published': '2011-03-11T08:15:07Z',\n",
       "  'summary': 'Models of computational trust support users in taking decisions. They are\\ncommonly used to guide users\\' judgements in online auction sites; or to\\ndetermine quality of contributions in Web 2.0 sites. However, most existing\\nsystems require historical information about the past behavior of the specific\\nagent being judged. In contrast, in real life, to anticipate and to predict a\\nstranger\\'s actions in absence of the knowledge of such behavioral history, we\\noften use our \"instinct\"- essentially stereotypes developed from our past\\ninteractions with other \"similar\" persons. In this paper, we propose\\nStereoTrust, a computational trust model inspired by stereotypes as used in\\nreal-life. A stereotype contains certain features of agents and an expected\\noutcome of the transaction. When facing a stranger, an agent derives its trust\\nby aggregating stereotypes matching the stranger\\'s profile. Since stereotypes\\nare formed locally, recommendations stem from the trustor\\'s own personal\\nexperiences and perspective. Historical behavioral information, when available,\\ncan be used to refine the analysis. According to our experiments using\\nEpinions.com dataset, StereoTrust compares favorably with existing trust models\\nthat use different kinds of information and more complete historical\\ninformation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1103.2215v3.pdf'},\n",
       " {'id': '1309.1747v1',\n",
       "  'title': 'Stochastic Agent-Based Simulations of Social Networks',\n",
       "  'published': '2013-09-06T19:29:43Z',\n",
       "  'summary': 'The rapidly growing field of network analytics requires data sets for use in\\nevaluation. Real world data often lack truth and simulated data lack narrative\\nfidelity or statistical generality. This paper presents a novel,\\nmixed-membership, agentbased simulation model to generate activity data with\\nnarrative power while providing statistical diversity through random draws. The\\nmodel generalizes to a variety of network activity types such as Internet and\\ncellular communications, human mobility, and social network interactions. The\\nsimulated actions over all agents can then drive an application specific\\nobservational model to render measurements as one would collect in real-world\\nexperiments. We apply this framework to human mobility and demonstrate its\\nutility in generating high fidelity traffic data for network analytics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1309.1747v1.pdf'},\n",
       " {'id': '1601.06869v1',\n",
       "  'title': 'The Roles of Familiarity Design in Active Ageing',\n",
       "  'published': '2016-01-26T02:33:53Z',\n",
       "  'summary': \"The elderly often struggle when interacting with technologies. This is\\nbecause the software and hardware components of the technologies are not\\nfamiliar to the elderly's mental model. This is a lack of empirical studies\\nabout how the concept of familiarity can be infused into the design of\\ninteractive technology systems to bridge the digital divide preventing today's\\nelderly people from actively engaging with such technologies. In this paper, a\\nmulti pronged approach is utilized. We investigate the Effects of Familiarity\\nin Design on the Adoption of Wellness Games by the Elderly, familiarity in\\nproductive ageing, familiarity in efficient collaborative crowdsourcing,\\nproductive ageing through familiarity based Intelligent Personalized\\nCrowdsourcing and familiarity based Agent Augmented Inter-generational\\nCrowdsourcing. The results show that familiarity in design improves the\\nperceived satisfaction and adoption likelihood significantly among the elderly\\nusers. These results can potentially benefit intelligent interface agent design\\nwhen such agents need to interact with elderly users. A Crowdsourcing\\nalgorithm, CrowdAsm is developed. By using CrowdAsm we are able to dynamically\\nassemble teams of workers considering the budgets, the availability of workers\\nwith the required skills and their track records to complete crowdsourcing\\ntasks requiring collaboration among workers with heterogeneous skills.\\nTheoretical analysis has shown that CrowdAsm can achieve close to optimal\\nprofit for a collaborative crowdsourcing system if workers follow the\\nrecommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1601.06869v1.pdf'},\n",
       " {'id': '1312.7630v1',\n",
       "  'title': 'Interactive Sensing in Social Networks',\n",
       "  'published': '2013-12-30T05:18:58Z',\n",
       "  'summary': 'This paper presents models and algorithms for interactive sensing in social\\nnetworks where individuals act as sensors and the information exchange between\\nindividuals is exploited to optimize sensing. Social learning is used to model\\nthe interaction between individuals that aim to estimate an underlying state of\\nnature. In this context the following questions are addressed: How can\\nself-interested agents that interact via social learning achieve a tradeoff\\nbetween individual privacy and reputation of the social group? How can\\nprotocols be designed to prevent data incest in online reputation blogs where\\nindividuals make recommendations? How can sensing by individuals that interact\\nwith each other be used by a global decision maker to detect changes in the\\nunderlying state of nature? When individual agents possess limited sensing,\\ncomputation and communication capabilities, can a network of agents achieve\\nsophisticated global behavior? Social and game theoretic learning are natural\\nsettings for addressing these questions. This article presents an overview,\\ninsights and discussion of social learning models in the context of data incest\\npropagation, change detection and coordination of decision making.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1312.7630v1.pdf'},\n",
       " {'id': '2106.05831v3',\n",
       "  'title': 'Scaling up Search Engine Audits: Practical Insights for Algorithm\\n  Auditing',\n",
       "  'published': '2021-06-10T15:49:58Z',\n",
       "  'summary': 'Algorithm audits have increased in recent years due to a growing need to\\nindependently assess the performance of automatically curated services that\\nprocess, filter, and rank the large and dynamic amount of information available\\non the internet. Among several methodologies to perform such audits, virtual\\nagents stand out because they offer the ability to perform systematic\\nexperiments, simulating human behaviour without the associated costs of\\nrecruiting participants. Motivated by the importance of research transparency\\nand replicability of results, this paper focuses on the challenges of such an\\napproach. It provides methodological details, recommendations, lessons learned,\\nand limitations based on our experience of setting up experiments for eight\\nsearch engines (including main, news, image and video sections) with hundreds\\nof virtual agents placed in different regions. We demonstrate the successful\\nperformance of our research infrastructure across multiple data collections,\\nwith diverse experimental designs, and point to different changes and\\nstrategies that improve the quality of the method. We conclude that virtual\\nagents are a promising venue for monitoring the performance of algorithms\\nacross long periods of time, and we hope that this paper can serve as a basis\\nfor further research in this area.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2106.05831v3.pdf'},\n",
       " {'id': '2201.06081v1',\n",
       "  'title': 'Bayesian Promised Persuasion: Dynamic Forward-Looking Multiagent\\n  Delegation with Informational Burning',\n",
       "  'published': '2022-01-16T16:29:40Z',\n",
       "  'summary': \"This work studies a dynamic mechanism design problem in which a principal\\ndelegates decision makings to a group of privately-informed agents without the\\nmonetary transfer or burning. We consider that the principal privately\\npossesses complete knowledge about the state transitions and study how she can\\nuse her private observation to support the incentive compatibility of the\\ndelegation via informational burning, a process we refer to as the\\nlooking-forward persuasion. The delegation mechanism is formulated in which the\\nagents form belief hierarchies due to the persuasion and play a dynamic\\nBayesian game. We propose a novel randomized mechanism, known as Bayesian\\npromised delegation (BPD), in which the periodic incentive compatibility is\\nguaranteed by persuasions and promises of future delegations. We show that the\\nBPD can achieve the same optimal social welfare as the original mechanism in\\nstationary Markov perfect Bayesian equilibria. A revelation-principle-like\\ndesign regime is established to show that the persuasion with belief\\nhierarchies can be fully characterized by correlating the randomization of the\\nagents' local BPD mechanisms with the persuasion as a direct recommendation of\\nthe future promises.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.06081v1.pdf'},\n",
       " {'id': '2006.05990v1',\n",
       "  'title': 'What Matters In On-Policy Reinforcement Learning? A Large-Scale\\n  Empirical Study',\n",
       "  'published': '2020-06-10T17:59:03Z',\n",
       "  'summary': \"In recent years, on-policy reinforcement learning (RL) has been successfully\\napplied to many different continuous control tasks. While RL algorithms are\\noften conceptually simple, their state-of-the-art implementations take numerous\\nlow- and high-level design decisions that strongly affect the performance of\\nthe resulting agents. Those choices are usually not extensively discussed in\\nthe literature, leading to discrepancy between published descriptions of\\nalgorithms and their implementations. This makes it hard to attribute progress\\nin RL and slows down overall progress [Engstrom'20]. As a step towards filling\\nthat gap, we implement >50 such ``choices'' in a unified on-policy RL\\nframework, allowing us to investigate their impact in a large-scale empirical\\nstudy. We train over 250'000 agents in five continuous control environments of\\ndifferent complexity and provide insights and practical recommendations for\\non-policy training of RL agents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.05990v1.pdf'},\n",
       " {'id': '2006.08714v1',\n",
       "  'title': 'Latent Bandits Revisited',\n",
       "  'published': '2020-06-15T19:24:02Z',\n",
       "  'summary': 'A latent bandit problem is one in which the learning agent knows the arm\\nreward distributions conditioned on an unknown discrete latent state. The\\nprimary goal of the agent is to identify the latent state, after which it can\\nact optimally. This setting is a natural midpoint between online and offline\\nlearning---complex models can be learned offline with the agent identifying\\nlatent state online---of practical relevance in, say, recommender systems. In\\nthis work, we propose general algorithms for this setting, based on both upper\\nconfidence bounds (UCBs) and Thompson sampling. Our methods are contextual and\\naware of model uncertainty and misspecification. We provide a unified\\ntheoretical analysis of our algorithms, which have lower regret than classic\\nbandit policies when the number of latent states is smaller than actions. A\\ncomprehensive empirical study showcases the advantages of our approach.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.08714v1.pdf'},\n",
       " {'id': '2006.12442v2',\n",
       "  'title': 'Open-Domain Conversational Agents: Current Progress, Open Problems, and\\n  Future Directions',\n",
       "  'published': '2020-06-22T17:23:47Z',\n",
       "  'summary': 'We present our view of what is necessary to build an engaging open-domain\\nconversational agent: covering the qualities of such an agent, the pieces of\\nthe puzzle that have been built so far, and the gaping holes we have not filled\\nyet. We present a biased view, focusing on work done by our own group, while\\nciting related work in each area. In particular, we discuss in detail the\\nproperties of continual learning, providing engaging content, and being\\nwell-behaved -- and how to measure success in providing them. We end with a\\ndiscussion of our experience and learnings, and our recommendations to the\\ncommunity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.12442v2.pdf'},\n",
       " {'id': '2011.05446v1',\n",
       "  'title': 'Perturbation-based exploration methods in deep reinforcement learning',\n",
       "  'published': '2020-11-10T22:57:51Z',\n",
       "  'summary': 'Recent research on structured exploration placed emphasis on identifying\\nnovel states in the state space and incentivizing the agent to revisit them\\nthrough intrinsic reward bonuses. In this study, we question whether the\\nperformance boost demonstrated through these methods is indeed due to the\\ndiscovery of structure in exploratory schedule of the agent or is the benefit\\nlargely attributed to the perturbations in the policy and reward space\\nmanifested in pursuit of structured exploration. In this study we investigate\\nthe effect of perturbations in policy and reward spaces on the exploratory\\nbehavior of the agent. We proceed to show that simple acts of perturbing the\\npolicy just before the softmax layer and introduction of sporadic reward\\nbonuses into the domain can greatly enhance exploration in several domains of\\nthe arcade learning environment. In light of these findings, we recommend\\nbenchmarking any enhancements to structured exploration research against the\\nbackdrop of noisy exploration.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2011.05446v1.pdf'},\n",
       " {'id': '2012.06117v1',\n",
       "  'title': 'How to Train PointGoal Navigation Agents on a (Sample and Compute)\\n  Budget',\n",
       "  'published': '2020-12-11T04:28:48Z',\n",
       "  'summary': \"PointGoal navigation has seen significant recent interest and progress,\\nspurred on by the Habitat platform and associated challenge. In this paper, we\\nstudy PointGoal navigation under both a sample budget (75 million frames) and a\\ncompute budget (1 GPU for 1 day). We conduct an extensive set of experiments,\\ncumulatively totaling over 50,000 GPU-hours, that let us identify and discuss a\\nnumber of ostensibly minor but significant design choices -- the advantage\\nestimation procedure (a key component in training), visual encoder\\narchitecture, and a seemingly minor hyper-parameter change. Overall, these\\ndesign choices to lead considerable and consistent improvements over the\\nbaselines present in Savva et al. Under a sample budget, performance for RGB-D\\nagents improves 8 SPL on Gibson (14% relative improvement) and 20 SPL on\\nMatterport3D (38% relative improvement). Under a compute budget, performance\\nfor RGB-D agents improves by 19 SPL on Gibson (32% relative improvement) and 35\\nSPL on Matterport3D (220% relative improvement). We hope our findings and\\nrecommendations will make serve to make the community's experiments more\\nefficient.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.06117v1.pdf'},\n",
       " {'id': '2112.01693v3',\n",
       "  'title': \"Optimism brings accurate perception in Iterated Prisoner's Dilemma\",\n",
       "  'published': '2021-12-03T03:28:53Z',\n",
       "  'summary': \"We analyze an extended model of the Iterated Prisoner's Dilemma where agents\\ndecide to play based on the data from their limited memory or recommendations.\\nThe cooperators can decide whether to play with the matched opponent or not.\\nThe agents' decisions are directly linked to their level of optimism since they\\ndecide to play if they believe the opponent has a high probability of\\ncooperating. Optimism is precisely tuned by parameters optimism threshold and\\ntolerance. Our experiment showed that being optimistic is better for\\ncooperators as it leads to more accurate exploration in the multi-agent system,\\nwhich tolerates the vulnerability against defectors.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.01693v3.pdf'},\n",
       " {'id': '2001.08823v2',\n",
       "  'title': \"What's a Good Prediction? Challenges in evaluating an agent's knowledge\",\n",
       "  'published': '2020-01-23T21:44:43Z',\n",
       "  'summary': \"Constructing general knowledge by learning task-independent models of the\\nworld can help agents solve challenging problems. However, both constructing\\nand evaluating such models remains an open challenge. The most common\\napproaches to evaluating models is to assess their accuracy with respect to\\nobservable values. However, the prevailing reliance on estimator accuracy as a\\nproxy for the usefulness of the knowledge has the potential to lead us astray.\\nWe demonstrate the conflict between accuracy and usefulness through a series of\\nillustrative examples including both a thought experiment and empirical example\\nin MineCraft, using the General Value Function framework (GVF). Having\\nidentified challenges in assessing an agent's knowledge, we propose an\\nalternate evaluation approach that arises continually in the online continual\\nlearning setting we recommend evaluation by examining internal learning\\nprocesses, specifically the relevance of a GVF's features to the prediction\\ntask at hand. This paper contributes a first look into evaluation of\\npredictions through their use, an integral component of predictive knowledge\\nwhich is as of yet unexplored.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2001.08823v2.pdf'},\n",
       " {'id': '2102.01367v1',\n",
       "  'title': '\"Alexa, Can I Program You?\": Student Perceptions of Conversational\\n  Artificial Intelligence Before and After Programming Alexa',\n",
       "  'published': '2021-02-02T07:38:01Z',\n",
       "  'summary': \"Growing up in an artificial intelligence-filled world, with Siri and Amazon\\nAlexa often within arm's - or speech's - reach, could have significant impact\\non children. Conversational agents could influence how students\\nanthropomorphize computer systems or develop a theory of mind. Previous\\nresearch has explored how conversational agents are used and perceived by\\nchildren within and outside of learning contexts. This study investigates how\\nmiddle and high school students' perceptions of Alexa change through\\nprogramming their own conversational agents in week-long AI education\\nworkshops. Specifically, we investigate the workshops' influence on student\\nperceptions of Alexa's intelligence, friendliness, aliveness, safeness,\\ntrustworthiness, human-likeness, and feelings of closeness. We found that\\nstudents felt Alexa was more intelligent and felt closer to Alexa after the\\nworkshops. We also found strong correlations between students' perceptions of\\nAlexa's friendliness and trustworthiness, and safeness and trustworthiness.\\nFinally, we explored how students tended to more frequently use computer\\nscience-related diction and ideas after the workshops. Based on our findings,\\nwe recommend designers carefully consider personification, transparency,\\nplayfulness and utility when designing CAs for learning contexts.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.01367v1.pdf'},\n",
       " {'id': '2111.05402v2',\n",
       "  'title': \"Cutting a Cake Is Not Always a 'Piece of Cake': A Closer Look at the\\n  Foundations of Cake-Cutting Through the Lens of Measure Theory\",\n",
       "  'published': '2021-11-09T20:18:41Z',\n",
       "  'summary': \"Cake-cutting is a playful name for the fair division of a heterogeneous,\\ndivisible good among agents, a well-studied problem at the intersection of\\nmathematics, economics, and artificial intelligence. The cake-cutting\\nliterature is rich and edifying. However, different model assumptions are made\\nin its many papers, in particular regarding the set of allowed pieces of cake\\nthat are to be distributed among the agents and regarding the agents' valuation\\nfunctions by which they measure these pieces. We survey the commonly used\\ndefinitions in the cake-cutting literature, highlight their strengths and\\nweaknesses, and make some recommendations on what definitions could be most\\nreasonably used when looking through the lens of measure theory.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.05402v2.pdf'},\n",
       " {'id': '2206.01645v1',\n",
       "  'title': 'Clustering Trust Dynamics in a Human-Robot Sequential Decision-Making\\n  Task',\n",
       "  'published': '2022-06-03T15:42:19Z',\n",
       "  'summary': \"In this paper, we present a framework for trust-aware sequential\\ndecision-making in a human-robot team. We model the problem as a finite-horizon\\nMarkov Decision Process with a reward-based performance metric, allowing the\\nrobotic agent to make trust-aware recommendations. Results of a human-subject\\nexperiment show that the proposed trust update model is able to accurately\\ncapture the human agent's moment-to-moment trust changes. Moreover, we cluster\\nthe participants' trust dynamics into three categories, namely, Bayesian\\ndecision makers, oscillators, and disbelievers, and identify personal\\ncharacteristics that could be used to predict which type of trust dynamics a\\nperson will belong to. We find that the disbelievers are less extroverted, less\\nagreeable, and have lower expectations toward the robotic agent, compared to\\nthe Bayesian decision makers and oscillators. The oscillators are significantly\\nmore frustrated than the Bayesian decision makers.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.01645v1.pdf'},\n",
       " {'id': '2307.14266v1',\n",
       "  'title': 'Improving International Climate Policy via Mutually Conditional Binding\\n  Commitments',\n",
       "  'published': '2023-07-26T15:53:21Z',\n",
       "  'summary': 'This paper proposes enhancements to the RICE-N simulation and multi-agent\\nreinforcement learning framework to improve the realism of international\\nclimate policy negotiations. Acknowledging the framework\\'s value, we highlight\\nthe necessity of significant enhancements to address the diverse array of\\nfactors in modeling climate negotiations. Building upon our previous work on\\nthe \"Conditional Commitments Mechanism\" (CCF mechanism) we discuss ways to\\nbridge the gap between simulation and reality. We suggest the inclusion of a\\nrecommender or planner agent to enhance coordination, address the Real2Sim gap\\nby incorporating social factors and non-party stakeholder sub-agents, and\\npropose enhancements to the underlying Reinforcement Learning solution\\nalgorithm. These proposed improvements aim to advance the evaluation and\\nformulation of negotiation protocols for more effective international climate\\npolicy decision-making in Rice-N. However, further experimentation and testing\\nare required to determine the implications and effectiveness of these\\nsuggestions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.14266v1.pdf'},\n",
       " {'id': '2308.14641v2',\n",
       "  'title': 'Challenges of GPT-3-based Conversational Agents for Healthcare',\n",
       "  'published': '2023-08-28T15:12:34Z',\n",
       "  'summary': 'The potential to provide patients with faster information access while\\nallowing medical specialists to concentrate on critical tasks makes medical\\ndomain dialog agents appealing. However, the integration of large-language\\nmodels (LLMs) into these agents presents certain limitations that may result in\\nserious consequences. This paper investigates the challenges and risks of using\\nGPT-3-based models for medical question-answering (MedQA). We perform several\\nevaluations contextualized in terms of standard medical principles. We provide\\na procedure for manually designing patient queries to stress-test high-risk\\nlimitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to\\nrespond adequately to these queries, generating erroneous medical information,\\nunsafe recommendations, and content that may be considered offensive.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.14641v2.pdf'},\n",
       " {'id': '2404.07883v1',\n",
       "  'title': 'Apprentice Tutor Builder: A Platform For Users to Create and Personalize\\n  Intelligent Tutors',\n",
       "  'published': '2024-04-11T16:14:23Z',\n",
       "  'summary': \"Intelligent tutoring systems (ITS) are effective for improving students'\\nlearning outcomes. However, their development is often complex, time-consuming,\\nand requires specialized programming and tutor design knowledge, thus hindering\\ntheir widespread application and personalization. We present the Apprentice\\nTutor Builder (ATB) , a platform that simplifies tutor creation and\\npersonalization. Instructors can utilize ATB's drag-and-drop tool to build\\ntutor interfaces. Instructors can then interactively train the tutors'\\nunderlying AI agent to produce expert models that can solve problems. Training\\nis achieved via using multiple interaction modalities including demonstrations,\\nfeedback, and user labels. We conducted a user study with 14 instructors to\\nevaluate the effectiveness of ATB's design with end users. We found that users\\nenjoyed the flexibility of the interface builder and ease and speed of agent\\nteaching, but often desired additional time-saving features. With these\\ninsights, we identified a set of design recommendations for our platform and\\nothers that utilize interactive AI agents for tutor creation and customization.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.07883v1.pdf'},\n",
       " {'id': '2406.11125v1',\n",
       "  'title': 'Conversational Agents as Catalysts for Critical Thinking: Challenging\\n  Design Fixation in Group Design',\n",
       "  'published': '2024-06-17T00:53:19Z',\n",
       "  'summary': 'This paper investigates the potential of LLM-based conversational agents\\n(CAs) to enhance critical reflection and mitigate design fixation in group\\ndesign work. By challenging AI-generated recommendations and prevailing group\\nopinions, these agents address issues such as groupthink and promote a more\\ndynamic and inclusive design process. Key design considerations include\\noptimizing intervention timing, ensuring clarity in counterarguments, and\\nbalancing critical thinking with designers\\' satisfaction. CAs can also adapt to\\nvarious roles, supporting individual and collective reflection. Our work aligns\\nwith the \"Death of the Design Researcher?\" workshop\\'s goals, emphasizing the\\ntransformative potential of generative AI in reshaping design practices and\\npromoting ethical considerations. By exploring innovative uses of generative AI\\nin group design contexts, we aim to stimulate discussion and open new pathways\\nfor future research and development, ultimately contributing to practical tools\\nand resources for design researchers.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.11125v1.pdf'},\n",
       " {'id': '2407.04898v1',\n",
       "  'title': 'Nash Incentive-compatible Online Mechanism Learning via Weakly\\n  Differentially Private Online Learning',\n",
       "  'published': '2024-07-06T00:02:25Z',\n",
       "  'summary': \"We study a multi-round mechanism design problem, where we interact with a set\\nof agents over a sequence of rounds. We wish to design an incentive-compatible\\n(IC) online learning scheme to maximize an application-specific objective\\nwithin a given class of mechanisms, without prior knowledge of the agents' type\\ndistributions. Even if each mechanism in this class is IC in a single round, if\\nan algorithm naively chooses from this class on each round, the entire learning\\nprocess may not be IC against non-myopic buyers who appear over multiple\\nrounds. On each round, our method randomly chooses between the recommendation\\nof a weakly differentially private online learning algorithm (e.g., Hedge), and\\na commitment mechanism which penalizes non-truthful behavior. Our method is IC\\nand achieves $O(T^{\\\\frac{1+h}{2}})$ regret for the application-specific\\nobjective in an adversarial setting, where $h$ quantifies the long-sightedness\\nof the agents. When compared to prior work, our approach is conceptually\\nsimpler,it applies to general mechanism design problems (beyond auctions), and\\nits regret scales gracefully with the size of the mechanism class.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.04898v1.pdf'},\n",
       " {'id': '2410.03770v1',\n",
       "  'title': 'A Two-Stage Proactive Dialogue Generator for Efficient Clinical\\n  Information Collection Using Large Language Model',\n",
       "  'published': '2024-10-02T19:32:11Z',\n",
       "  'summary': \"Efficient patient-doctor interaction is among the key factors for a\\nsuccessful disease diagnosis. During the conversation, the doctor could query\\ncomplementary diagnostic information, such as the patient's symptoms, previous\\nsurgery, and other related information that goes beyond medical evidence data\\n(test results) to enhance disease diagnosis. However, this procedure is usually\\ntime-consuming and less-efficient, which can be potentially optimized through\\ncomputer-assisted systems. As such, we propose a diagnostic dialogue system to\\nautomate the patient information collection procedure. By exploiting medical\\nhistory and conversation logic, our conversation agents, particularly the\\ndoctor agent, can pose multi-round clinical queries to effectively collect the\\nmost relevant disease diagnostic information. Moreover, benefiting from our\\ntwo-stage recommendation structure, carefully designed ranking criteria, and\\ninteractive patient agent, our model is able to overcome the under-exploration\\nand non-flexible challenges in dialogue generation. Our experimental results on\\na real-world medical conversation dataset show that our model can generate\\nclinical queries that mimic the conversation style of real doctors, with\\nefficient fluency, professionalism, and safety, while effectively collecting\\nrelevant disease diagnostic information.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.03770v1.pdf'},\n",
       " {'id': '2410.09034v1',\n",
       "  'title': 'PEAR: A Robust and Flexible Automation Framework for Ptychography\\n  Enabled by Multiple Large Language Model Agents',\n",
       "  'published': '2024-10-11T17:50:59Z',\n",
       "  'summary': 'Ptychography is an advanced computational imaging technique in X-ray and\\nelectron microscopy. It has been widely adopted across scientific research\\nfields, including physics, chemistry, biology, and materials science, as well\\nas in industrial applications such as semiconductor characterization. In\\npractice, obtaining high-quality ptychographic images requires simultaneous\\noptimization of numerous experimental and algorithmic parameters.\\nTraditionally, parameter selection often relies on trial and error, leading to\\nlow-throughput workflows and potential human bias. In this work, we develop the\\n\"Ptychographic Experiment and Analysis Robot\" (PEAR), a framework that\\nleverages large language models (LLMs) to automate data analysis in\\nptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM\\nagents for tasks including knowledge retrieval, code generation, parameter\\nrecommendation, and image reasoning. Our study demonstrates that PEAR\\'s\\nmulti-agent design significantly improves the workflow success rate, even with\\nsmaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various\\nautomation levels and is designed to work with customized local knowledge\\nbases, ensuring flexibility and adaptability across different research\\nenvironments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.09034v1.pdf'},\n",
       " {'id': '2410.10852v1',\n",
       "  'title': 'SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A\\n  Case Study of Offshore Wind Maintenance',\n",
       "  'published': '2024-10-06T13:00:53Z',\n",
       "  'summary': 'The Offshore Wind (OSW) industry is experiencing significant expansion,\\nresulting in increased Operations \\\\& Maintenance (O\\\\&M) costs. Intelligent\\nalarm systems offer the prospect of swift detection of component failures and\\nprocess anomalies, enabling timely and precise interventions that could yield\\nreductions in resource expenditure, as well as scheduled and unscheduled\\ndowntime. This paper introduces an innovative approach to tackle this challenge\\nby capitalising on Large Language Models (LLMs). We present a specialised\\nconversational agent that incorporates statistical techniques to calculate\\ndistances between sentences for the detection and filtering of hallucinations\\nand unsafe output. This potentially enables improved interpretation of alarm\\nsequences and the generation of safer repair action recommendations by the\\nagent. Preliminary findings are presented with the approach applied to\\nChatGPT-4 generated test sentences. The limitation of using ChatGPT-4 and the\\npotential for enhancement of this agent through re-training with specialised\\nOSW datasets are discussed.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.10852v1.pdf'},\n",
       " {'id': '2410.15489v1',\n",
       "  'title': 'Generative AI Agents in Autonomous Machines: A Safety Perspective',\n",
       "  'published': '2024-10-20T20:07:08Z',\n",
       "  'summary': 'The integration of Generative Artificial Intelligence (AI) into autonomous\\nmachines represents a major paradigm shift in how these systems operate and\\nunlocks new solutions to problems once deemed intractable. Although generative\\nAI agents provide unparalleled capabilities, they also have unique safety\\nconcerns. These challenges require robust safeguards, especially for autonomous\\nmachines that operate in high-stakes environments. This work investigates the\\nevolving safety requirements when generative models are integrated as agents\\ninto physical autonomous machines, comparing these to safety considerations in\\nless critical AI applications. We explore the challenges and opportunities to\\nensure the safe deployment of generative AI-driven autonomous machines.\\nFurthermore, we provide a forward-looking perspective on the future of\\nAI-driven autonomous systems and emphasize the importance of evaluating and\\ncommunicating safety risks. As an important step towards addressing these\\nconcerns, we recommend the development and implementation of comprehensive\\nsafety scorecards for the use of generative AI technologies in autonomous\\nmachines.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.15489v1.pdf'},\n",
       " {'id': '2411.02353v2',\n",
       "  'title': 'Social-RAG: Retrieving from Group Interactions to Socially Ground AI\\n  Generation',\n",
       "  'published': '2024-11-04T18:21:53Z',\n",
       "  'summary': \"AI agents are increasingly tasked with making proactive suggestions in online\\nspaces where groups collaborate, yet risk being unhelpful or even annoying if\\nthey fail to match group preferences or behave in socially inappropriate ways.\\nFortunately, group spaces have a rich history of prior interactions and\\naffordances for social feedback that can support grounding an agent's\\ngenerations to a group's interests and norms. We present Social-RAG, a workflow\\nfor socially grounding agents that retrieves context from prior group\\ninteractions, selects relevant social signals, and feeds them into a language\\nmodel to generate messages in a socially aligned manner. We implement this in\\n\\\\textsc{PaperPing}, a system for posting paper recommendations in group chat,\\nleveraging social signals determined from formative studies with 39\\nresearchers. From a three-month deployment in 18 channels reaching 500+\\nresearchers, we observed PaperPing posted relevant messages in groups without\\ndisrupting their existing social practices, fostering group common ground.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.02353v2.pdf'},\n",
       " {'id': '2505.14544v2',\n",
       "  'title': 'Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies',\n",
       "  'published': '2025-05-20T15:59:44Z',\n",
       "  'summary': 'Urban traffic congestion, particularly at intersections, significantly\\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\\nsignal control systems often lack the adaptability to manage dynamic traffic\\npatterns effectively. This study explores the application of multi-agent\\nreinforcement learning (MARL) to optimize traffic signal coordination across\\nmultiple intersections within a simulated environment. Utilizing Pygame, a\\nsimulation was developed to model a network of interconnected intersections\\nwith randomly generated vehicle flows to reflect realistic traffic variability.\\nA decentralized MARL controller was implemented, in which each traffic signal\\noperates as an autonomous agent, making decisions based on local observations\\nand information from neighboring agents. Performance was evaluated against a\\nbaseline fixed-time controller using metrics such as average vehicle wait time\\nand overall throughput. The MARL approach demonstrated statistically\\nsignificant improvements, including reduced average waiting times and improved\\nthroughput. These findings suggest that MARL-based dynamic control strategies\\nhold substantial promise for improving urban traffic management efficiency.\\nMore research is recommended to address scalability and real-world\\nimplementation challenges.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.14544v2.pdf'},\n",
       " {'id': '2505.23006v1',\n",
       "  'title': 'A Practical Approach for Building Production-Grade Conversational Agents\\n  with Workflow Graphs',\n",
       "  'published': '2025-05-29T02:30:27Z',\n",
       "  'summary': 'The advancement of Large Language Models (LLMs) has led to significant\\nimprovements in various service domains, including search, recommendation, and\\nchatbot applications. However, applying state-of-the-art (SOTA) research to\\nindustrial settings presents challenges, as it requires maintaining flexible\\nconversational abilities while also strictly complying with service-specific\\nconstraints. This can be seen as two conflicting requirements due to the\\nprobabilistic nature of LLMs. In this paper, we propose our approach to\\naddressing this challenge and detail the strategies we employed to overcome\\ntheir inherent limitations in real-world applications. We conduct a practical\\ncase study of a conversational agent designed for the e-commerce domain,\\ndetailing our implementation workflow and optimizations. Our findings provide\\ninsights into bridging the gap between academic research and real-world\\napplication, introducing a framework for developing scalable, controllable, and\\nreliable AI-driven agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.23006v1.pdf'},\n",
       " {'id': '2507.05581v1',\n",
       "  'title': 'Density Discontinuity Regression',\n",
       "  'published': '2025-07-08T01:36:53Z',\n",
       "  'summary': 'Many policies hinge on a continuous variable exceeding a threshold, prompting\\nstrategic behavior by agents to stay on the favorable side. This creates\\ndensity discontinuities at cutoffs, evident in contexts like taxable income,\\ncorporate regulations, and academic grading. Existing methods detect these\\ndiscontinuities, but systematic approaches to examine how they vary with\\nobservable characteristics are lacking. We propose a novel, interpretable\\nBayesian framework that jointly estimates both the log-density ratio at the\\ncutoff and the local shape of the density, as functions of covariates, within a\\ndata-driven window. This formulation yields regression-style estimates of\\ncovariate effects on the discontinuity. An adaptive window selection balances\\nbias and variance. Our approach improves upon common methods that target only\\nthe log-density ratio around the threshold while ignoring the local density\\nshape. We constrain the density jump to be non-negative, reflecting that agents\\nwould not aim to be on the losing side of the threshold. Applied to corporate\\nshareholder voting data, our method identifies substantial variation in\\nstrategic behavior, notably stronger discontinuities for proposals facing\\nnegative recommendations from Institutional Shareholder Services, larger firms,\\nand firms with lower analyst coverage. Overall, our method provides an\\ninterpretable framework to quantify heterogeneous agent responses to\\nthreshold-based policies.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.05581v1.pdf'},\n",
       " {'id': '2507.09407v1',\n",
       "  'title': 'LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their\\n  Applications to Spearphishing',\n",
       "  'published': '2025-07-12T21:42:27Z',\n",
       "  'summary': \"We introduce the framework of LLM-Stackelberg games, a class of sequential\\ndecision-making models that integrate large language models (LLMs) into\\nstrategic interactions between a leader and a follower. Departing from\\nclassical Stackelberg assumptions of complete information and rational agents,\\nour formulation allows each agent to reason through structured prompts,\\ngenerate probabilistic behaviors via LLMs, and adapt their strategies through\\ninternal cognition and belief updates. We define two equilibrium concepts:\\nreasoning and behavioral equilibrium, which aligns an agent's internal\\nprompt-based reasoning with observable behavior, and conjectural reasoning\\nequilibrium, which accounts for epistemic uncertainty through parameterized\\nmodels over an opponent's response. These layered constructs capture bounded\\nrationality, asymmetric information, and meta-cognitive adaptation. We\\nillustrate the framework through a spearphishing case study, where a sender and\\na recipient engage in a deception game using structured reasoning prompts. This\\nexample highlights the cognitive richness and adversarial potential of\\nLLM-mediated interactions. Our results show that LLM-Stackelberg games provide\\na powerful paradigm for modeling decision-making in domains such as\\ncybersecurity, misinformation, and recommendation systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.09407v1.pdf'},\n",
       " {'id': '2507.12621v1',\n",
       "  'title': 'NLI4VolVis: Natural Language Interaction for Volume Visualization via\\n  LLM Multi-Agents and Editable 3D Gaussian Splatting',\n",
       "  'published': '2025-07-16T20:35:46Z',\n",
       "  'summary': 'Traditional volume visualization (VolVis) methods, like direct volume\\nrendering, suffer from rigid transfer function designs and high computational\\ncosts. Although novel view synthesis approaches enhance rendering efficiency,\\nthey require additional learning effort for non-experts and lack support for\\nsemantic-level interaction. To bridge this gap, we propose NLI4VolVis, an\\ninteractive system that enables users to explore, query, and edit volumetric\\nscenes using natural language. NLI4VolVis integrates multi-view semantic\\nsegmentation and vision-language models to extract and understand semantic\\ncomponents in a scene. We introduce a multi-agent large language model\\narchitecture equipped with extensive function-calling tools to interpret user\\nintents and execute visualization tasks. The agents leverage external tools and\\ndeclarative VolVis commands to interact with the VolVis engine powered by 3D\\neditable Gaussians, enabling open-vocabulary object querying, real-time scene\\nediting, best-view selection, and 2D stylization. We validate our system\\nthrough case studies and a user study, highlighting its improved accessibility\\nand usability in volumetric data exploration. We strongly recommend readers\\ncheck our case studies, demo video, and source code at\\nhttps://nli4volvis.github.io/.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.12621v1.pdf'},\n",
       " {'id': '2109.08934v2',\n",
       "  'title': 'Fairness Maximization among Offline Agents in Online-Matching Markets',\n",
       "  'published': '2021-09-18T13:41:42Z',\n",
       "  'summary': 'Matching markets involve heterogeneous agents (typically from two parties)\\nwho are paired for mutual benefit. During the last decade, matching markets\\nhave emerged and grown rapidly through the medium of the Internet. They have\\nevolved into a new format, called Online Matching Markets (OMMs), with examples\\nranging from crowdsourcing to online recommendations to ridesharing. There are\\ntwo features distinguishing OMMs from traditional matching markets. One is the\\ndynamic arrival of one side of the market: we refer to these as online agents\\nwhile the rest are offline agents. Examples of online and offline agents\\ninclude keywords (online) and sponsors (offline) in Google Advertising; workers\\n(online) and tasks (offline) in Amazon Mechanical Turk (AMT); riders (online)\\nand drivers (offline when restricted to a short time window) in ridesharing.\\nThe second distinguishing feature of OMMs is the real-time decision-making\\nelement. However, studies have shown that the algorithms making decisions in\\nthese OMMs leave disparities in the match rates of offline agents. For example,\\ntasks in neighborhoods of low socioeconomic status rarely get matched to gig\\nworkers, and drivers of certain races/genders get discriminated against in\\nmatchmaking. In this paper, we propose online matching algorithms which\\noptimize for either individual or group-level fairness among offline agents in\\nOMMs. We present two linear-programming (LP) based sampling algorithms, which\\nachieve online competitive ratios at least 0.725 for individual fairness\\nmaximization (IFM) and 0.719 for group fairness maximization (GFM),\\nrespectively. We conduct extensive numerical experiments and results show that\\nour boosted version of sampling algorithms are not only conceptually easy to\\nimplement but also highly effective in practical instances of\\nfairness-maximization-related models.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.08934v2.pdf'},\n",
       " {'id': '2210.15451v1',\n",
       "  'title': 'Fine-Grained Session Recommendations in E-commerce using Deep\\n  Reinforcement Learning',\n",
       "  'published': '2022-10-20T13:22:13Z',\n",
       "  'summary': \"Sustaining users' interest and keeping them engaged in the platform is very\\nimportant for the success of an e-commerce business. A session encompasses\\ndifferent activities of a user between logging into the platform and logging\\nout or making a purchase. User activities in a session can be classified into\\ntwo groups: Known Intent and Unknown intent. Known intent activity pertains to\\nthe session where the intent of a user to browse/purchase a specific product\\ncan be easily captured. Whereas in unknown intent activity, the intent of the\\nuser is not known. For example, consider the scenario where a user enters the\\nsession to casually browse the products over the platform, similar to the\\nwindow shopping experience in the offline setting. While recommending similar\\nproducts is essential in the former, accurately understanding the intent and\\nrecommending interesting products is essential in the latter setting in order\\nto retain a user. In this work, we focus primarily on the unknown intent\\nsetting where our objective is to recommend a sequence of products to a user in\\na session to sustain their interest, keep them engaged and possibly drive them\\ntowards purchase. We formulate this problem in the framework of the Markov\\nDecision Process (MDP), a popular mathematical framework for sequential\\ndecision making and solve it using Deep Reinforcement Learning (DRL)\\ntechniques. However, training the next product recommendation is difficult in\\nthe RL paradigm due to large variance in browse/purchase behavior of the users.\\nTherefore, we break the problem down into predicting various product\\nattributes, where a pattern/trend can be identified and exploited to build\\naccurate models. We show that the DRL agent provides better performance\\ncompared to a greedy strategy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.15451v1.pdf'},\n",
       " {'id': '2508.05709v1',\n",
       "  'title': 'G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware\\n  User Behavior Simulation',\n",
       "  'published': '2025-08-07T07:26:08Z',\n",
       "  'summary': 'User feedback is critical for refining recommendation systems, yet explicit\\nfeedback (e.g., likes or dislikes) remains scarce in practice. As a more\\nfeasible alternative, inferring user preferences from massive implicit feedback\\nhas shown great potential (e.g., a user quickly skipping a recommended video\\nusually indicates disinterest). Unfortunately, implicit feedback is often\\nnoisy: a user might skip a video due to accidental clicks or other reasons,\\nrather than disliking it. Such noise can easily misjudge user interests,\\nthereby undermining recommendation performance. To address this issue, we\\npropose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which\\nleverages contextual guidance from relevant user groups, enabling robust and\\nin-depth interpretation of implicit feedback for individual users.\\nSpecifically, G-UBS operates via two key agents. First, the User Group Manager\\n(UGM) effectively clusters users to generate group profiles utilizing a\\n``summarize-cluster-reflect\" workflow based on LLMs. Second, the User Feedback\\nModeler (UFM) employs an innovative group-aware reinforcement learning\\napproach, where each user is guided by the associated group profiles during the\\nreinforcement learning process, allowing UFM to robustly and deeply examine the\\nreasons behind implicit feedback. To assess our G-UBS paradigm, we have\\nconstructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To\\nthe best of our knowledge, this is the first multi-modal benchmark for implicit\\nfeedback evaluation in video recommendation, encompassing 15k users, 25k\\nvideos, and 933k interaction records with implicit feedback. Extensive\\nexperiments on IF-VR demonstrate that G-UBS significantly outperforms\\nmainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a\\nplay rate > 30% and 14.9% higher reasoning accuracy on IF-VR.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.05709v1.pdf'},\n",
       " {'id': '2012.08383v3',\n",
       "  'title': 'Keyword-Guided Neural Conversational Model',\n",
       "  'published': '2020-12-15T15:55:32Z',\n",
       "  'summary': 'We study the problem of imposing conversational goals/keywords on open-domain\\nconversational agents, where the agent is required to lead the conversation to\\na target keyword smoothly and fast. Solving this problem enables the\\napplication of conversational agents in many real-world scenarios, e.g.,\\nrecommendation and psychotherapy. The dominant paradigm for tackling this\\nproblem is to 1) train a next-turn keyword classifier, and 2) train a\\nkeyword-augmented response retrieval model. However, existing approaches in\\nthis paradigm have two limitations: 1) the training and evaluation datasets for\\nnext-turn keyword classification are directly extracted from conversations\\nwithout human annotations, thus, they are noisy and have low correlation with\\nhuman judgements, and 2) during keyword transition, the agents solely rely on\\nthe similarities between word embeddings to move closer to the target keyword,\\nwhich may not reflect how humans converse. In this paper, we assume that human\\nconversations are grounded on commonsense and propose a keyword-guided neural\\nconversational model that can leverage external commonsense knowledge graphs\\n(CKG) for both keyword transition and response retrieval. Automatic evaluations\\nsuggest that commonsense improves the performance of both next-turn keyword\\nprediction and keyword-augmented response retrieval. In addition, both\\nself-play and human evaluations show that our model produces responses with\\nsmoother keyword transition and reaches the target keyword faster than\\ncompetitive baselines.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.08383v3.pdf'},\n",
       " {'id': '2002.05229v1',\n",
       "  'title': 'Data Efficient Training for Reinforcement Learning with Adaptive\\n  Behavior Policy Sharing',\n",
       "  'published': '2020-02-12T20:35:31Z',\n",
       "  'summary': 'Deep Reinforcement Learning (RL) is proven powerful for decision making in\\nsimulated environments. However, training deep RL model is challenging in real\\nworld applications such as production-scale health-care or recommender systems\\nbecause of the expensiveness of interaction and limitation of budget at\\ndeployment. One aspect of the data inefficiency comes from the expensive\\nhyper-parameter tuning when optimizing deep neural networks. We propose\\nAdaptive Behavior Policy Sharing (ABPS), a data-efficient training algorithm\\nthat allows sharing of experience collected by behavior policy that is\\nadaptively selected from a pool of agents trained with an ensemble of\\nhyper-parameters. We further extend ABPS to evolve hyper-parameters during\\ntraining by hybridizing ABPS with an adapted version of Population Based\\nTraining (ABPS-PBT). We conduct experiments with multiple Atari games with up\\nto 16 hyper-parameter/architecture setups. ABPS achieves superior overall\\nperformance, reduced variance on top 25% agents, and equivalent performance on\\nthe best agent compared to conventional hyper-parameter tuning with independent\\ntraining, even though ABPS only requires the same number of environmental\\ninteractions as training a single agent. We also show that ABPS-PBT further\\nimproves the convergence speed and reduces the variance.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2002.05229v1.pdf'},\n",
       " {'id': '2002.11534v2',\n",
       "  'title': 'Distributed Algorithms for Composite Optimization: Unified Framework and\\n  Convergence Analysis',\n",
       "  'published': '2020-02-25T07:34:40Z',\n",
       "  'summary': \"We study distributed composite optimization over networks: agents minimize a\\nsum of smooth (strongly) convex functions, the agents' sum-utility, plus a\\nnonsmooth (extended-valued) convex one. We propose a general unified\\nalgorithmic framework for such a class of problems and provide a unified\\nconvergence analysis leveraging the theory of operator splitting.\\nDistinguishing features of our scheme are: (i) When the agents' functions are\\nstrongly convex, the algorithm converges at a linear rate, whose dependence on\\nthe agents' functions and network topology is decoupled, matching the typical\\nrates of centralized optimization; the rate expression improves on existing\\nresults; (ii) When the objective function is convex (but not strongly convex),\\nsimilar separation as in (i) is established for the coefficient of the proved\\nsublinear rate; (iii) The algorithm can adjust the ratio between the number of\\ncommunications and computations to achieve a rate (in terms of computations)\\nindependent on the network connectivity; and (iv) A by-product of our analysis\\nis a tuning recommendation for several existing (non accelerated) distributed\\nalgorithms yielding the fastest provably (worst-case) convergence rate. This is\\nthe first time that a general distributed algorithmic framework applicable to\\ncomposite optimization enjoys all such properties.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2002.11534v2.pdf'},\n",
       " {'id': '2010.14082v1',\n",
       "  'title': 'Jacobi-Style Iteration for Distributed Submodular Maximization',\n",
       "  'published': '2020-10-27T05:55:36Z',\n",
       "  'summary': \"This paper presents a novel Jacobi-style iteration algorithm for solving the\\nproblem of distributed submodular maximization, in which each agent determines\\nits own strategy from a finite set so that the global submodular objective\\nfunction is jointly maximized. Building on the multi-linear extension of the\\nglobal submodular function, we expect to achieve the solution from a\\nprobabilistic, rather than deterministic, perspective, and thus transfer the\\nconsidered problem from a discrete domain into a continuous domain. Since it is\\nobserved that an unbiased estimation of the gradient of multi-linear extension\\nfunction~can be obtained by sampling the agents' local decisions, a projected\\nstochastic gradient algorithm is proposed to solve the problem. Our algorithm\\nenables the distributed updates among all individual agents and is proved to\\nasymptotically converge to a desirable equilibrium solution. Such an\\nequilibrium solution is guaranteed to achieve at least 1/2-suboptimal bound,\\nwhich is comparable to the state-of-art in the literature. Moreover, we further\\nenhance the proposed algorithm by handling the scenario in which agents'\\ncommunication delays are present. The enhanced algorithmic framework admits a\\nmore realistic distributed implementation of our approach. Finally, a movie\\nrecommendation task is conducted on a real-world movie rating data set, to\\nvalidate the numerical performance of the proposed algorithms.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.14082v1.pdf'},\n",
       " {'id': '2101.03769v2',\n",
       "  'title': 'A Review of Evaluation Practices of Gesture Generation in Embodied\\n  Conversational Agents',\n",
       "  'published': '2021-01-11T08:56:23Z',\n",
       "  'summary': 'Embodied conversational agents (ECA) are often designed to produce nonverbal\\nbehavior to complement or enhance their verbal communication. One such form of\\nnonverbal behavior is co-speech gesturing, which involves movements that the\\nagent makes with its arms and hands that are paired with verbal communication.\\nCo-speech gestures for ECAs can be created using different generation methods,\\ndivided into rule-based and data-driven processes, with the latter gaining\\ntraction because of the increasing interest from the applied machine learning\\ncommunity. However, reports on gesture generation methods use a variety of\\nevaluation measures, which hinders comparison. To address this, we present a\\nsystematic review on co-speech gesture generation methods for iconic,\\nmetaphoric, deictic, and beat gestures, including reported evaluation methods.\\nWe review 22 studies that have an ECA with a human-like upper body that uses\\nco-speech gesturing in social human-agent interaction. This includes studies\\nthat use human participants to evaluate performance. We found most studies use\\na within-subject design and rely on a form of subjective evaluation, but\\nwithout a systematic approach. We argue that the field requires more rigorous\\nand uniform tools for co-speech gesture evaluation, and formulate\\nrecommendations for empirical evaluation, including standardized phrases and\\nexample scenarios to help systematically test generative models across studies.\\nFurthermore, we also propose a checklist that can be used to report relevant\\ninformation for the evaluation of generative models, as well as to evaluate\\nco-speech gesture use.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.03769v2.pdf'},\n",
       " {'id': '2203.04263v1',\n",
       "  'title': 'Fast and selective super-resolution ultrasound in vivo with\\n  sono-switchable nanodroplets',\n",
       "  'published': '2022-03-08T18:33:56Z',\n",
       "  'summary': 'Perfusion by the microcirculation is key to the development, maintenance and\\npathology of tissue. Its measurement with high spatiotemporal resolution is\\nconsequently valuable but remains a challenge in deep tissue. Ultrasound\\nLocalization Microscopy (ULM) provides very high spatiotemporal resolution but\\nthe use of microbubbles requires low contrast agent concentrations, a long\\nacquisition time, and gives little control over the spatial and temporal\\ndistribution of the bubbles. The present study is the first to demonstrate\\nAcoustic Wave Sparsely-Activated Localization Microscopy (AWSALM) and\\nfast-AWSALM for in vivo super-resolution ultrasound imaging, offering contrast\\non demand and vascular selectivity. Three different formulations of\\nsono-switchable contrast agents were tested. We demonstrate their use with\\nultrasound mechanical indices well within recommended safety limits to enable\\nfast on-demand sparse switching at very high agent concentrations. We produce\\nsuper-localization maps of the rabbit renal vasculature with acquisition times\\nbetween 5.5 s and 0.25 s, and an 4-fold improvement in spatial resolution. We\\npresent the unique selectivity of AWSALM in visualizing specific vascular\\nbranches and downstream microvasculature, and we show super-localized kidney\\nstructures in systole and diastole with fast-AWSALM. In conclusion we\\ndemonstrate the feasibility of fast and selective measurement of microvascular\\ndynamics in vivo with subwavelength resolution using ultrasound and\\nsono-switchable nanodroplets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2203.04263v1.pdf'},\n",
       " {'id': '2301.13393v2',\n",
       "  'title': 'Probably Anytime-Safe Stochastic Combinatorial Semi-Bandits',\n",
       "  'published': '2023-01-31T03:49:00Z',\n",
       "  'summary': 'Motivated by concerns about making online decisions that incur undue amount\\nof risk at each time step, in this paper, we formulate the probably\\nanytime-safe stochastic combinatorial semi-bandits problem. In this problem,\\nthe agent is given the option to select a subset of size at most $K$ from a set\\nof $L$ ground items. Each item is associated to a certain mean reward as well\\nas a variance that represents its risk. To mitigate the risk that the agent\\nincurs, we require that with probability at least $1-\\\\delta$, over the entire\\nhorizon of time $T$, each of the choices that the agent makes should contain\\nitems whose sum of variances does not exceed a certain variance budget. We call\\nthis probably anytime-safe constraint. Under this constraint, we design and\\nanalyze an algorithm {\\\\sc PASCombUCB} that minimizes the regret over the\\nhorizon of time $T$. By developing accompanying information-theoretic lower\\nbounds, we show that under both the problem-dependent and problem-independent\\nparadigms, {\\\\sc PASCombUCB} is almost asymptotically optimal. Experiments are\\nconducted to corroborate our theoretical findings. Our problem setup, the\\nproposed {\\\\sc PASCombUCB} algorithm, and novel analyses are applicable to\\ndomains such as recommendation systems and transportation in which an agent is\\nallowed to choose multiple items at a single time step and wishes to control\\nthe risk over the whole time horizon.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2301.13393v2.pdf'},\n",
       " {'id': '2303.14286v1',\n",
       "  'title': 'Voice-Based Conversational Agents and Knowledge Graphs for Improving\\n  News Search in Assisted Living',\n",
       "  'published': '2023-03-24T21:49:27Z',\n",
       "  'summary': 'As the healthcare sector is facing major challenges, such as aging\\npopulations, staff shortages, and common chronic diseases, delivering\\nhigh-quality care to individuals has become very difficult. Conversational\\nagents have shown to be a promising technology to alleviate some of these\\nissues. In the form of digital health assistants, they have the potential to\\nimprove the everyday life of the elderly and chronically ill people. This\\nincludes, for example, medication reminders, routine checks, or social\\nchit-chat. In addition, conversational agents can satisfy the fundamental need\\nof having access to information about daily news or local events, which enables\\nindividuals to stay informed and connected with the world around them. However,\\nfinding relevant news sources and navigating the plethora of news articles\\navailable online can be overwhelming, particularly for those who may have\\nlimited technological literacy or health-related impairments. To address this\\nchallenge, we propose an innovative solution that combines knowledge graphs and\\nconversational agents for news search in assisted living. By leveraging graph\\ndatabases to semantically structure news data and implementing an intuitive\\nvoice-based interface, our system can help care-dependent people to easily\\ndiscover relevant news articles and give personalized recommendations. We\\nexplain our design choices, provide a system architecture, share insights of an\\ninitial user test, and give an outlook on planned future work.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.14286v1.pdf'},\n",
       " {'id': '2309.16307v2',\n",
       "  'title': 'TaxAI: A Dynamic Economic Simulator and Benchmark for Multi-Agent\\n  Reinforcement Learning',\n",
       "  'published': '2023-09-28T09:59:48Z',\n",
       "  'summary': \"Taxation and government spending are crucial tools for governments to promote\\neconomic growth and maintain social equity. However, the difficulty in\\naccurately predicting the dynamic strategies of diverse self-interested\\nhouseholds presents a challenge for governments to implement effective tax\\npolicies. Given its proficiency in modeling other agents in partially\\nobservable environments and adaptively learning to find optimal policies,\\nMulti-Agent Reinforcement Learning (MARL) is highly suitable for solving\\ndynamic games between the government and numerous households. Although MARL\\nshows more potential than traditional methods such as the genetic algorithm and\\ndynamic programming, there is a lack of large-scale multi-agent reinforcement\\nlearning economic simulators. Therefore, we propose a MARL environment, named\\n\\\\textbf{TaxAI}, for dynamic games involving $N$ households, government, firms,\\nand financial intermediaries based on the Bewley-Aiyagari economic model. Our\\nstudy benchmarks 2 traditional economic methods with 7 MARL methods on TaxAI,\\ndemonstrating the effectiveness and superiority of MARL algorithms. Moreover,\\nTaxAI's scalability in simulating dynamic interactions between the government\\nand 10,000 households, coupled with real-data calibration, grants it a\\nsubstantial improvement in scale and reality over existing simulators.\\nTherefore, TaxAI is the most realistic economic simulator for optimal tax\\npolicy, which aims to generate feasible recommendations for governments and\\nindividuals.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.16307v2.pdf'},\n",
       " {'id': '2401.03408v1',\n",
       "  'title': 'Escalation Risks from Language Models in Military and Diplomatic\\n  Decision-Making',\n",
       "  'published': '2024-01-07T07:59:10Z',\n",
       "  'summary': \"Governments are increasingly considering integrating autonomous AI agents in\\nhigh-stakes military and foreign-policy decision-making, especially with the\\nemergence of advanced generative AI models like GPT-4. Our work aims to\\nscrutinize the behavior of multiple AI agents in simulated wargames,\\nspecifically focusing on their predilection to take escalatory actions that may\\nexacerbate multilateral conflicts. Drawing on political science and\\ninternational relations literature about escalation dynamics, we design a novel\\nwargame simulation and scoring framework to assess the escalation risks of\\nactions taken by these agents in different scenarios. Contrary to prior\\nstudies, our research provides both qualitative and quantitative insights and\\nfocuses on large language models (LLMs). We find that all five studied\\noff-the-shelf LLMs show forms of escalation and difficult-to-predict escalation\\npatterns. We observe that models tend to develop arms-race dynamics, leading to\\ngreater conflict, and in rare cases, even to the deployment of nuclear weapons.\\nQualitatively, we also collect the models' reported reasonings for chosen\\nactions and observe worrying justifications based on deterrence and\\nfirst-strike tactics. Given the high stakes of military and foreign-policy\\ncontexts, we recommend further examination and cautious consideration before\\ndeploying autonomous language model agents for strategic military or diplomatic\\ndecision-making.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.03408v1.pdf'},\n",
       " {'id': '2411.04832v2',\n",
       "  'title': 'Plasticity Loss in Deep Reinforcement Learning: A Survey',\n",
       "  'published': '2024-11-07T16:13:54Z',\n",
       "  'summary': \"Akin to neuroplasticity in human brains, the plasticity of deep neural\\nnetworks enables their quick adaption to new data. This makes plasticity\\nparticularly crucial for deep Reinforcement Learning (RL) agents: Once\\nplasticity is lost, an agent's performance will inevitably plateau because it\\ncannot improve its policy to account for changes in the data distribution,\\nwhich are a necessary consequence of its learning process. Thus, developing\\nwell-performing and sample-efficient agents hinges on their ability to remain\\nplastic during training. Furthermore, the loss of plasticity can be connected\\nto many other issues plaguing deep RL, such as training instabilities, scaling\\nfailures, overestimation bias, and insufficient exploration. With this survey,\\nwe aim to provide an overview of the emerging research on plasticity loss for\\nacademics and practitioners of deep reinforcement learning. First, we propose a\\nunified definition of plasticity loss based on recent works, relate it to\\ndefinitions from the literature, and discuss metrics for measuring plasticity\\nloss. Then, we categorize and discuss numerous possible causes of plasticity\\nloss before reviewing currently employed mitigation strategies. Our taxonomy is\\nthe first systematic overview of the current state of the field. Lastly, we\\ndiscuss prevalent issues within the literature, such as a necessity for broader\\nevaluation, and provide recommendations for future research, like gaining a\\nbetter understanding of an agent's neural activity and behavior.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.04832v2.pdf'},\n",
       " {'id': '2411.05651v2',\n",
       "  'title': 'LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning\\n  and Execution',\n",
       "  'published': '2024-11-08T15:46:10Z',\n",
       "  'summary': 'Visual analytics (VA) requires analysts to iteratively propose analysis tasks\\nbased on observations and execute tasks by creating visualizations and\\ninteractive exploration to gain insights. This process demands skills in\\nprogramming, data processing, and visualization tools, highlighting the need\\nfor a more intelligent, streamlined VA approach. Large language models (LLMs)\\nhave recently been developed as agents to handle various tasks with dynamic\\nplanning and tool-using capabilities, offering the potential to enhance the\\nefficiency and versatility of VA. We propose LightVA, a lightweight VA\\nframework that supports task decomposition, data analysis, and interactive\\nexploration through human-agent collaboration. Our method is designed to help\\nusers progressively translate high-level analytical goals into low-level tasks,\\nproducing visualizations and deriving insights. Specifically, we introduce an\\nLLM agent-based task planning and execution strategy, employing a recursive\\nprocess involving a planner, executor, and controller. The planner is\\nresponsible for recommending and decomposing tasks, the executor handles task\\nexecution, including data analysis, visualization generation and multi-view\\ncomposition, and the controller coordinates the interaction between the planner\\nand executor. Building on the framework, we develop a system with a hybrid user\\ninterface that includes a task flow diagram for monitoring and managing the\\ntask planning process, a visualization panel for interactive data exploration,\\nand a chat view for guiding the model through natural language instructions. We\\nexamine the effectiveness of our method through a usage scenario and an expert\\nstudy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.05651v2.pdf'},\n",
       " {'id': '2411.18429v2',\n",
       "  'title': 'A Multi-Agent Dual Dialogue System to Support Mental Health Care\\n  Providers',\n",
       "  'published': '2024-11-27T15:13:33Z',\n",
       "  'summary': 'We introduce a general-purpose, human-in-the-loop dual dialogue system to\\nsupport mental health care professionals. The system, co-designed with care\\nproviders, is conceptualized to assist them in interacting with care seekers\\nrather than functioning as a fully automated dialogue system solution. The AI\\nassistant within the system reduces the cognitive load of mental health care\\nproviders by proposing responses, analyzing conversations to extract pertinent\\nthemes, summarizing dialogues, and recommending localized relevant content and\\ninternet-based cognitive behavioral therapy exercises. These functionalities\\nare achieved through a multi-agent system design, where each specialized,\\nsupportive agent is characterized by a large language model. In evaluating the\\nmulti-agent system, we focused specifically on the proposal of responses to\\nemotionally distressed care seekers. We found that the proposed responses\\nmatched a reasonable human quality in demonstrating empathy, showing its\\nappropriateness for augmenting the work of mental health care providers.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.18429v2.pdf'},\n",
       " {'id': '2412.12475v2',\n",
       "  'title': 'RareAgents: Advancing Rare Disease Care through LLM-Empowered\\n  Multi-disciplinary Team',\n",
       "  'published': '2024-12-17T02:22:24Z',\n",
       "  'summary': 'Rare diseases, despite their low individual incidence, collectively impact\\naround 300 million people worldwide due to the vast number of diseases. The\\ninvolvement of multiple organs and systems, and the shortage of specialized\\ndoctors with relevant experience make diagnosing and treating rare diseases\\nmore challenging than common diseases. Recently, agents powered by large\\nlanguage models (LLMs) have demonstrated notable applications across various\\ndomains. In the medical field, some agent methods have outperformed direct\\nprompts in question-answering tasks from medical examinations. However, current\\nagent frameworks are not well-adapted to real-world clinical scenarios,\\nespecially those involving the complex demands of rare diseases. To bridge this\\ngap, we introduce RareAgents, the first LLM-driven multi-disciplinary team\\nframework designed specifically for the complex clinical context of rare\\ndiseases. RareAgents integrates advanced Multidisciplinary Team (MDT)\\ncoordination, memory mechanisms, and medical tools utilization, leveraging\\nLlama-3.1-8B/70B as the base model. Experimental results show that RareAgents\\noutperforms state-of-the-art domain-specific models, GPT-4o, and current agent\\nframeworks in differential diagnosis and medication recommendation for rare\\ndiseases. Furthermore, we contribute a novel rare disease dataset,\\nMIMIC-IV-Ext-Rare, to support further advancements in this field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.12475v2.pdf'},\n",
       " {'id': '2502.01085v2',\n",
       "  'title': 'Federated Linear Dueling Bandits',\n",
       "  'published': '2025-02-03T05:56:22Z',\n",
       "  'summary': 'Contextual linear dueling bandits have recently garnered significant\\nattention due to their widespread applications in important domains such as\\nrecommender systems and large language models. Classical dueling bandit\\nalgorithms are typically only applicable to a single agent. However, many\\napplications of dueling bandits involve multiple agents who wish to collaborate\\nfor improved performance yet are unwilling to share their data. This motivates\\nus to draw inspirations from federated learning, which involves multiple agents\\naiming to collaboratively train their neural networks via gradient descent (GD)\\nwithout sharing their raw data. Previous works have developed federated linear\\nbandit algorithms which rely on closed-form updates of the bandit parameters\\n(e.g., the linear function parameters) to achieve collaboration. However, in\\nlinear dueling bandits, the linear function parameters lack a closed-form\\nexpression and their estimation requires minimizing a loss function. This\\nrenders these previous methods inapplicable. In this work, we overcome this\\nchallenge through an innovative and principled combination of online gradient\\ndescent (OGD, for minimizing the loss function to estimate the linear function\\nparameters) and federated learning, hence introducing our federated linear\\ndueling bandit with OGD (FLDB-OGD) algorithm. Through rigorous theoretical\\nanalysis, we prove that FLDB-OGD enjoys a sub-linear upper bound on its\\ncumulative regret and demonstrate a theoretical trade-off between regret and\\ncommunication complexity. We conduct empirical experiments to demonstrate the\\neffectiveness of FLDB-OGD and reveal valuable insights, such as the benefit of\\na larger number of agents, the regret-communication trade-off, among others.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.01085v2.pdf'},\n",
       " {'id': '2504.05862v2',\n",
       "  'title': 'Are Generative AI Agents Effective Personalized Financial Advisors?',\n",
       "  'published': '2025-04-08T09:41:03Z',\n",
       "  'summary': 'Large language model-based agents are becoming increasingly popular as a\\nlow-cost mechanism to provide personalized, conversational advice, and have\\ndemonstrated impressive capabilities in relatively simple scenarios, such as\\nmovie recommendations. But how do these agents perform in complex high-stakes\\ndomains, where domain expertise is essential and mistakes carry substantial\\nrisk? This paper investigates the effectiveness of LLM-advisors in the finance\\ndomain, focusing on three distinct challenges: (1) eliciting user preferences\\nwhen users themselves may be unsure of their needs, (2) providing personalized\\nguidance for diverse investment preferences, and (3) leveraging advisor\\npersonality to build relationships and foster trust. Via a lab-based user study\\nwith 64 participants, we show that LLM-advisors often match human advisor\\nperformance when eliciting preferences, although they can struggle to resolve\\nconflicting user needs. When providing personalized advice, the LLM was able to\\npositively influence user behavior, but demonstrated clear failure modes. Our\\nresults show that accurate preference elicitation is key, otherwise, the\\nLLM-advisor has little impact, or can even direct the investor toward\\nunsuitable assets. More worryingly, users appear insensitive to the quality of\\nadvice being given, or worse these can have an inverse relationship. Indeed,\\nusers reported a preference for and increased satisfaction as well as emotional\\ntrust with LLMs adopting an extroverted persona, even though those agents\\nprovided worse advice.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.05862v2.pdf'},\n",
       " {'id': '2504.13183v1',\n",
       "  'title': 'Factors That Influence the Adoption of AI-enabled Conversational Agents\\n  (AICAs) as an Augmenting Therapeutic Tool by Frontline Healthcare Workers:\\n  From Technology Acceptance Model 3 (TAM3) Lens -- A Systematic Mapping Review',\n",
       "  'published': '2025-01-26T02:31:27Z',\n",
       "  'summary': \"Artificial intelligent (AI) conversational agents hold a promising future in\\nthe field of mental health, especially in helping marginalized communities that\\nlack access to mental health support services. It is tempting to have a 24/7\\nmental health companion that can be accessed anywhere using mobile phones to\\nprovide therapist-like advice. Yet, caution should be taken, and studies around\\ntheir feasibility need to be surveyed. Before adopting such a rapidly changing\\ntechnology, studies on its feasibility should be explored, summarized, and\\nsynthesized to gain a solid understanding of the status quo and to enable us to\\nbuild a framework that can guide us throughout the development and deployment\\nprocesses. Different perspectives must be considered when investigating the\\nfeasibility of AI conversational agents, including the mental healthcare\\nprofessional perspective. The literature can provide insights into their\\nperspectives in terms of opportunities, concerns, and implications. Mental\\nhealth professionals, the subject-matter experts in this field, have their\\npoints of view that should be understood and considered. This systematic\\nliterature review will explore mental health practitioners' attitudes toward AI\\nconversational agents and the factors that affect their adoption and\\nrecommendation of the technology to augment their services and treatments. The\\nTAM3 Framework will be the lens through which this systematic literature review\\nwill be conducted.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.13183v1.pdf'},\n",
       " {'id': '2505.19481v1',\n",
       "  'title': 'Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive\\n  Decisions of LLMs',\n",
       "  'published': '2025-05-26T04:03:48Z',\n",
       "  'summary': 'Large language models (LLMs) have shown remarkable performance across diverse\\nreasoning and generation tasks, and are increasingly deployed as agents in\\ndynamic environments such as code generation and recommendation systems.\\nHowever, many real-world applications, such as high-frequency trading and\\nreal-time competitive gaming, require decisions under strict latency\\nconstraints, where faster responses directly translate into higher rewards.\\nDespite the importance of this latency quality trade off, it remains\\nunderexplored in the context of LLM based agents. In this work, we present the\\nfirst systematic study of this trade off in real time decision making tasks. To\\nsupport our investigation, we introduce two new benchmarks: HFTBench, a high\\nfrequency trading simulation, and StreetFighter, a competitive gaming platform.\\nOur analysis reveals that optimal latency quality balance varies by task, and\\nthat sacrificing quality for lower latency can significantly enhance downstream\\nperformance. To address this, we propose FPX, an adaptive framework that\\ndynamically selects model size and quantization level based on real time\\ndemands. Our method achieves the best performance on both benchmarks, improving\\nwin rate by up to 80% in Street Fighter and boosting daily yield by up to\\n26.52% in trading, underscoring the need for latency aware evaluation and\\ndeployment strategies for LLM based agents. These results demonstrate the\\ncritical importance of latency aware evaluation and deployment strategies for\\nreal world LLM based agents. Our benchmarks are available at Latency Sensitive\\nBenchmarks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.19481v1.pdf'},\n",
       " {'id': '2507.18961v1',\n",
       "  'title': 'Batched Adaptive Network Formation',\n",
       "  'published': '2025-07-25T05:02:59Z',\n",
       "  'summary': \"Networks are central to many economic and organizational applications,\\nincluding workplace team formation, social platform recommendations, and\\nclassroom friendship development. In these settings, networks are modeled as\\ngraphs, with agents as nodes, agent pairs as edges, and edge weights capturing\\npairwise production or interaction outcomes. This paper develops an adaptive,\\nor \\\\textit{online}, policy that learns to form increasingly effective networks\\nas data accumulates over time, progressively improving total network output\\nmeasured by the sum of edge weights.\\n  Our approach builds on the weighted stochastic block model (WSBM), which\\ncaptures agents' unobservable heterogeneity through discrete latent types and\\nmodels their complementarities in a flexible, nonparametric manner. We frame\\nthe online network formation problem as a non-standard \\\\textit{batched\\nmulti-armed bandit}, where each type pair corresponds to an arm, and pairwise\\nreward depends on type complementarity. This strikes a balance between\\nexploration -- learning latent types and complementarities -- and exploitation\\n-- forming high-weighted networks. We establish two key results: a\\n\\\\textit{batched local asymptotic normality} result for the WSBM and an\\nasymptotic equivalence between maximum likelihood and variational estimates of\\nthe intractable likelihood. Together, they provide a theoretical foundation for\\ntreating variational estimates as normal signals, enabling principled Bayesian\\nupdating across batches. The resulting posteriors are then incorporated into a\\ntailored maximum-weight matching problem to determine the policy for the next\\nbatch. Simulations show that our algorithm substantially improves outcomes\\nwithin a few batches, yields increasingly accurate parameter estimates, and\\nremains effective even in nonstationary settings with evolving agent pools.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.18961v1.pdf'},\n",
       " {'id': '2507.20474v2',\n",
       "  'title': 'MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and\\n  Adaptive Financial Trading',\n",
       "  'published': '2025-07-13T05:39:42Z',\n",
       "  'summary': 'Cryptocurrency trading is a challenging task requiring the integration of\\nheterogeneous data from multiple modalities. Traditional deep learning and\\nreinforcement learning approaches typically demand large training datasets and\\nencode diverse inputs into numerical representations, often at the cost of\\ninterpretability. Recent progress in large language model (LLM)-based agents\\nhas demonstrated the capacity to process multi-modal data and support complex\\ninvestment decision-making. Building on these advances, we present\\n\\\\textbf{MountainLion}, a multi-modal, multi-agent system for financial trading\\nthat coordinates specialized LLM-based agents to interpret financial data and\\ngenerate investment strategies. MountainLion processes textual news,\\ncandlestick charts, and trading signal charts to produce high-quality financial\\nreports, while also enabling modification of reports and investment\\nrecommendations through data-driven user interaction and question answering. A\\ncentral reflection module analyzes historical trading signals and outcomes to\\ncontinuously refine decision processes, and the system is capable of real-time\\nreport analysis, summarization, and dynamic adjustment of investment\\nstrategies. Empirical results confirm that MountainLion systematically enriches\\ntechnical price triggers with contextual macroeconomic and capital flow\\nsignals, providing a more interpretable, robust, and actionable investment\\nframework that improves returns and strengthens investor confidence.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.20474v2.pdf'},\n",
       " {'id': '1603.04267v1',\n",
       "  'title': 'Improving Urban Mobility by Understanding its Complexity',\n",
       "  'published': '2016-03-14T14:12:37Z',\n",
       "  'summary': 'Urban mobility systems are composed multiple elements with strong\\ninteractions, i.e. their future is co-determined by the state of other\\nelements. Thus, studying components in isolation, i.e. using a reductionist\\napproach, is inappropriate. I propose five recommendations to improve urban\\nmobility based on insights from the scientific study of complex systems: use\\nadaptation over prediction, regulate interactions to avoid friction, use\\nsensors to recover real time information, develop adaptive algorithms to\\nexploit that information, and deploy agents to act on the urban environment.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1603.04267v1.pdf'},\n",
       " {'id': '2205.03854v1',\n",
       "  'title': 'Introduction to Soar',\n",
       "  'published': '2022-05-08T12:44:51Z',\n",
       "  'summary': 'This paper is the recommended initial reading for a functional overview of\\nSoar, version 9.6. It includes an abstract overview of the architectural\\nstructure of Soar including its processing, memories, learning modules, their\\ninterfaces, and the representations of knowledge used by those modules. From\\nthere it describes the processing supported by those modules, including\\ndecision making, impasses and substates, procedure learning via chunking,\\nreinforcement learning, semantic memory, episodic memory, and spatial-visual\\nreasoning. It then reviews the levels of decision making and variety of\\nlearning in Soar, and analysis of Soar as an architecture supporting general\\nhuman-level AI. Following the references is an appendix that contains short\\ndescriptions of recent Soar agents and a glossary of the terminology we use in\\ndescribing Soar.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.03854v1.pdf'},\n",
       " {'id': '2103.05612v1',\n",
       "  'title': 'Challenges for Reinforcement Learning in Healthcare',\n",
       "  'published': '2021-03-09T18:34:54Z',\n",
       "  'summary': 'Many healthcare decisions involve navigating through a multitude of treatment\\noptions in a sequential and iterative manner to find an optimal treatment\\npathway with the goal of an optimal patient outcome. Such optimization problems\\nmay be amenable to reinforcement learning. A reinforcement learning agent could\\nbe trained to provide treatment recommendations for physicians, acting as a\\ndecision support tool. However, a number of difficulties arise when using RL\\nbeyond benchmark environments, such as specifying the reward function, choosing\\nan appropriate state representation and evaluating the learned policy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.05612v1.pdf'},\n",
       " {'id': '2202.10774v1',\n",
       "  'title': 'Social Computational Design Method for Generating Product Shapes with\\n  GAN and Transformer Models',\n",
       "  'published': '2022-02-22T09:51:32Z',\n",
       "  'summary': 'A social computational design method is established, aiming at taking\\nadvantages of the fast-developing artificial intelligence technologies for\\nintelligent product design. Supported with multi-agent system, shape grammar,\\nGenerative adversarial network, Bayesian network, Transformer, etc., the method\\nis able to define the design solution space, prepare training samples, and\\neventually acquire an intelligent model that can recommend design solutions\\naccording to incomplete solutions for given design tasks. Product shape design\\nis used as entry point to demonstrate the method, however, the method can be\\napplied to tasks rather than shape design when the solutions can be properly\\ncoded.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2202.10774v1.pdf'},\n",
       " {'id': '2504.19997v1',\n",
       "  'title': 'Simplified and Secure MCP Gateways for Enterprise AI Integration',\n",
       "  'published': '2025-04-28T17:17:42Z',\n",
       "  'summary': 'The increased adoption of the Model Context Protocol (MCP) for AI Agents\\nnecessitates robust security for Enterprise integrations. This paper introduces\\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\\narchitecture integrates security principles, authentication, intrusion\\ndetection, and secure tunneling, enabling secure self-hosting without exposing\\ninfrastructure. Key contributions include a reference architecture, threat\\nmodel mapping, simplified integration strategies, and open-source\\nimplementation recommendations. This work focuses on the unique challenges of\\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\\nserver solutions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.19997v1.pdf'},\n",
       " {'id': '2007.15293v1',\n",
       "  'title': 'A Heterogeneous Information Network based Cross Domain Insurance\\n  Recommendation System for Cold Start Users',\n",
       "  'published': '2020-07-30T08:18:57Z',\n",
       "  'summary': 'Internet is changing the world, adapting to the trend of internet sales will\\nbring revenue to traditional insurance companies. Online insurance is still in\\nits early stages of development, where cold start problem (prospective\\ncustomer) is one of the greatest challenges. In traditional e-commerce field,\\nseveral cross-domain recommendation (CDR) methods have been studied to infer\\npreferences of cold start users based on their preferences in other domains.\\nHowever, these CDR methods could not be applied to insurance domain directly\\ndue to the domain specific properties. In this paper, we propose a novel\\nframework called a Heterogeneous information network based Cross Domain\\nInsurance Recommendation (HCDIR) system for cold start users. Specifically, we\\nfirst try to learn more effective user and item latent features in both source\\nand target domains. In source domain, we employ gated recurrent unit (GRU) to\\nmodule user dynamic interests. In target domain, given the complexity of\\ninsurance products and the data sparsity problem, we construct an insurance\\nheterogeneous information network (IHIN) based on data from PingAn Jinguanjia,\\nthe IHIN connects users, agents, insurance products and insurance product\\nproperties together, giving us richer information. Then we employ three-level\\n(relational, node, and semantic) attention aggregations to get user and\\ninsurance product representations. After obtaining latent features of\\noverlapping users, a feature mapping between the two domains is learned by\\nmulti-layer perceptron (MLP). We apply HCDIR on Jinguanjia dataset, and show\\nHCDIR significantly outperforms the state-of-the-art solutions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.15293v1.pdf'},\n",
       " {'id': '1909.07775v4',\n",
       "  'title': 'Strategic and Crowd-Aware Itinerary Recommendation',\n",
       "  'published': '2019-09-12T11:09:47Z',\n",
       "  'summary': 'There is a rapidly growing demand for itinerary planning in tourism but this\\ntask remains complex and difficult, especially when considering the need to\\noptimize for queuing time and crowd levels for multiple users. This difficulty\\nis further complicated by the large amount of parameters involved, i.e.,\\nattraction popularity, queuing time, walking time, operating hours, etc. Many\\nrecent works propose solutions based on the single-person perspective, but\\notherwise do not address real-world problems resulting from natural crowd\\nbehavior, such as the Selfish Routing problem, which describes the consequence\\nof ineffective network and sub-optimal social outcome by leaving agents to\\ndecide freely. In this work, we propose the Strategic and Crowd-Aware Itinerary\\nRecommendation (SCAIR) algorithm which optimizes social welfare in real-world\\nsituations. We formulate the strategy of route recommendation as Markov chains\\nwhich enables our simulations to be carried out in poly-time. We then evaluate\\nour proposed algorithm against various competitive and realistic baselines\\nusing a theme park dataset. Our simulation results highlight the existence of\\nthe Selfish Routing problem and show that SCAIR outperforms the baselines in\\nhandling this issue.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1909.07775v4.pdf'},\n",
       " {'id': '2110.07923v2',\n",
       "  'title': 'Value Penalized Q-Learning for Recommender Systems',\n",
       "  'published': '2021-10-15T08:08:28Z',\n",
       "  'summary': \"Scaling reinforcement learning (RL) to recommender systems (RS) is promising\\nsince maximizing the expected cumulative rewards for RL agents meets the\\nobjective of RS, i.e., improving customers' long-term satisfaction. A key\\napproach to this goal is offline RL, which aims to learn policies from logged\\ndata. However, the high-dimensional action space and the non-stationary\\ndynamics in commercial RS intensify distributional shift issues, making it\\nchallenging to apply offline RL methods to RS. To alleviate the action\\ndistribution shift problem in extracting RL policy from static trajectories, we\\npropose Value Penalized Q-learning (VPQ), an uncertainty-based offline RL\\nalgorithm. It penalizes the unstable Q-values in the regression target by\\nuncertainty-aware weights, without the need to estimate the behavior policy,\\nsuitable for RS with a large number of items. We derive the penalty weights\\nfrom the variances across an ensemble of Q-functions. To alleviate\\ndistributional shift issues at test time, we further introduce the critic\\nframework to integrate the proposed method with classic RS models. Extensive\\nexperiments conducted on two real-world datasets show that the proposed method\\ncould serve as a gain plugin for existing RS models.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.07923v2.pdf'},\n",
       " {'id': '2304.14163v1',\n",
       "  'title': 'Answering Uncertain, Under-Specified API Queries Assisted by\\n  Knowledge-Aware Human-AI Dialogue',\n",
       "  'published': '2023-04-27T13:01:05Z',\n",
       "  'summary': \"Developers' API needs should be more pragmatic, such as seeking suggestive,\\nexplainable, and extensible APIs rather than the so-called best result.\\nExisting API search research cannot meet these pragmatic needs because they are\\nsolely concerned with query-API relevance. This necessitates a focus on\\nenhancing the entire query process, from query definition to query refinement\\nthrough intent clarification to query results promoting divergent thinking\\nabout results. This paper designs a novel Knowledge-Aware Human-AI Dialog agent\\n(KAHAID) which guides the developer to clarify the uncertain, under-specified\\nquery through multi-round question answering and recommends APIs for the\\nclarified query with relevance explanation and extended suggestions (e.g.,\\nalternative, collaborating or opposite-function APIs). We systematically\\nevaluate KAHAID. In terms of human-AI dialogue efficiency, it achieves a high\\ndiversity of question options and the ability to guide developers to find APIs\\nusing fewer dialogue rounds. For API recommendation, KAHAID achieves an MRR and\\nMAP of 0.769 and 0.794, outperforming state-of-the-art methods BIKER and CLEAR\\nby at least 47% in MRR and 226.7% in MAP. For knowledge extension, KAHAID\\nobtains an MRR and MAP of 0.815 and 0.864, surpassing ZaCQ by at least 42% in\\nMRR and 45.2\\\\% in MAP. Furthermore, we conduct a user study. It shows that\\nexplainable API recommendations, as implemented by KAHAID, can help developers\\nidentify the best API approach more easily or confidently, improving\\ninspiration of clarification question options by at least 20.83% and the\\nextensibility of extended APIs by at least 12.5%.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.14163v1.pdf'},\n",
       " {'id': '2411.16160v1',\n",
       "  'title': 'Stop Playing the Guessing Game! Target-free User Simulation for\\n  Evaluating Conversational Recommender Systems',\n",
       "  'published': '2024-11-25T07:36:20Z',\n",
       "  'summary': \"Recent approaches in Conversational Recommender Systems (CRSs) have tried to\\nsimulate real-world users engaging in conversations with CRSs to create more\\nrealistic testing environments that reflect the complexity of human-agent\\ndialogue. Despite the significant advancements, reliably evaluating the\\ncapability of CRSs to elicit user preferences still faces a significant\\nchallenge. Existing evaluation metrics often rely on target-biased user\\nsimulators that assume users have predefined preferences, leading to\\ninteractions that devolve into simplistic guessing game. These simulators\\ntypically guide the CRS toward specific target items based on fixed attributes,\\nlimiting the dynamic exploration of user preferences and struggling to capture\\nthe evolving nature of real-user interactions. Additionally, current evaluation\\nmetrics are predominantly focused on single-turn recall of target items,\\nneglecting the intermediate processes of preference elicitation. To address\\nthis, we introduce PEPPER, a novel CRS evaluation protocol with target-free\\nuser simulators constructed from real-user interaction histories and reviews.\\nPEPPER enables realistic user-CRS dialogues without falling into simplistic\\nguessing games, allowing users to gradually discover their preferences through\\nenriched interactions, thereby providing a more accurate and reliable\\nassessment of the CRS's ability to elicit personal preferences. Furthermore,\\nPEPPER presents detailed measures for comprehensively evaluating the preference\\nelicitation capabilities of CRSs, encompassing both quantitative and\\nqualitative measures that capture four distinct aspects of the preference\\nelicitation process. Through extensive experiments, we demonstrate the validity\\nof PEPPER as a simulation environment and conduct a thorough analysis of how\\neffectively existing CRSs perform in preference elicitation and recommendation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.16160v1.pdf'},\n",
       " {'id': '2504.05325v1',\n",
       "  'title': 'Unequal Opportunities: Examining the Bias in Geographical\\n  Recommendations by Large Language Models',\n",
       "  'published': '2025-03-16T18:59:00Z',\n",
       "  'summary': \"Recent advancements in Large Language Models (LLMs) have made them a popular\\ninformation-seeking tool among end users. However, the statistical training\\nmethods for LLMs have raised concerns about their representation of\\nunder-represented topics, potentially leading to biases that could influence\\nreal-world decisions and opportunities. These biases could have significant\\neconomic, social, and cultural impacts as LLMs become more prevalent, whether\\nthrough direct interactions--such as when users engage with chatbots or\\nautomated assistants--or through their integration into third-party\\napplications (as agents), where the models influence decision-making processes\\nand functionalities behind the scenes. Our study examines the biases present in\\nLLMs recommendations of U.S. cities and towns across three domains: relocation,\\ntourism, and starting a business. We explore two key research questions: (i)\\nHow similar LLMs responses are, and (ii) How this similarity might favor areas\\nwith certain characteristics over others, introducing biases. We focus on the\\nconsistency of LLMs responses and their tendency to over-represent or\\nunder-represent specific locations. Our findings point to consistent\\ndemographic biases in these recommendations, which could perpetuate a\\n``rich-get-richer'' effect that widens existing economic disparities.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.05325v1.pdf'},\n",
       " {'id': '2508.15252v1',\n",
       "  'title': 'Retrieval-Augmented Review Generation for Poisoning Recommender Systems',\n",
       "  'published': '2025-08-21T05:25:22Z',\n",
       "  'summary': 'Recent studies have shown that recommender systems (RSs) are highly\\nvulnerable to data poisoning attacks, where malicious actors inject fake user\\nprofiles, including a group of well-designed fake ratings, to manipulate\\nrecommendations. Due to security and privacy constraints in practice, attackers\\ntypically possess limited knowledge of the victim system and thus need to craft\\nprofiles that have transferability across black-box RSs. To maximize the attack\\nimpact, the profiles often remains imperceptible. However, generating such\\nhigh-quality profiles with the restricted resources is challenging. Some works\\nsuggest incorporating fake textual reviews to strengthen the profiles; yet, the\\npoor quality of the reviews largely undermines the attack effectiveness and\\nimperceptibility under the practical setting.\\n  To tackle the above challenges, in this paper, we propose to enhance the\\nquality of the review text by harnessing in-context learning (ICL) capabilities\\nof multimodal foundation models. To this end, we introduce a demonstration\\nretrieval algorithm and a text style transfer strategy to augment the navie\\nICL. Specifically, we propose a novel practical attack framework named RAGAN to\\ngenerate high-quality fake user profiles, which can gain insights into the\\nrobustness of RSs. The profiles are generated by a jailbreaker and\\ncollaboratively optimized on an instructional agent and a guardian to improve\\nthe attack transferability and imperceptibility. Comprehensive experiments on\\nvarious real-world datasets demonstrate that RAGAN achieves the\\nstate-of-the-art poisoning attack performance.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.15252v1.pdf'},\n",
       " {'id': '2108.11025v1',\n",
       "  'title': 'Evaluating Efficacy of Indoor Non-Pharmaceutical Interventions against\\n  COVID-19 Outbreaks with a Coupled Spatial-SIR Agent-Based Simulation\\n  Framework',\n",
       "  'published': '2021-08-25T03:14:35Z',\n",
       "  'summary': \"Contagious respiratory diseases, such as COVID-19, depend on sufficiently\\nprolonged exposures for the successful transmission of the underlying pathogen.\\nIt is important for organizations to evaluate the efficacy of interventions\\naiming at mitigating viral transmission among their personnel. We have\\ndeveloped a operational risk assessment simulation framework that couples a\\nspatial agent-based model of movement with a SIR epidemiological model to\\nassess the relative risks of different intervention strategies. By applying our\\nmodel on MIT's STATA building, we assess the impacts of three possible\\ndimensions of intervention: one-way vs unrestricted movement, population size\\nallowed onsite, and frequency of leaving designated work location for breaks.\\nWe find that there is no significant impact made by one-way movement\\nrestrictions over unrestricted movement. Instead, we find that a combination of\\nlowering the number of individuals admitted below the current recommendations\\nand advising individuals to reduce the frequency at which they leave their\\nworkstations lowers the likelihood of highly connected individuals within the\\ncontact networks that emerge, which in turn lowers the overall risk of\\ninfection. We discover three classes of possible interventions based on their\\nepidemiological effects. By assuming a direct relationship between data on\\nsecondary attack rates and transmissibility in the SIR model, we compare\\nrelative infection risk of four respiratory diseases, MERS, SARS, COVID-19, and\\nMeasles, within the simulated area, and recommend appropriate intervention\\nguidelines.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2108.11025v1.pdf'},\n",
       " {'id': '1907.04485v3',\n",
       "  'title': 'Assortment planning for two-sided sequential matching markets',\n",
       "  'published': '2019-07-10T01:59:12Z',\n",
       "  'summary': \"Two-sided matching platforms provide users with menus of match\\nrecommendations. To maximize the number of realized matches between the two\\nsides (referred here as customers and suppliers), the platform must balance the\\ninherent tension between recommending customers more potential suppliers to\\nmatch with and avoiding potential collisions. We introduce a stylized model to\\nstudy the above trade-off. The platform offers each customer a menu of\\nsuppliers, and customers choose, simultaneously and independently, either a\\nsupplier from their menu or to remain unmatched. Suppliers then see the set of\\ncustomers that have selected them, and choose to either match with one of these\\ncustomers or to remain unmatched. A match occurs if a customer and a supplier\\nchoose each other (in sequence). Agents' choices are probabilistic, and\\nproportional to public scores of agents in their menu and a score that is\\nassociated with remaining unmatched. The platform's problem is to construct\\nmenus for costumers to maximize the number of matches. This problem is shown to\\nbe strongly NP-hard via a reduction from 3-partition. We provide an efficient\\nalgorithm that achieves a constant-factor approximation to the expected number\\nof matches.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.04485v3.pdf'},\n",
       " {'id': '2209.10485v1',\n",
       "  'title': 'Towards a Standardised Performance Evaluation Protocol for Cooperative\\n  MARL',\n",
       "  'published': '2022-09-21T16:40:03Z',\n",
       "  'summary': 'Multi-agent reinforcement learning (MARL) has emerged as a useful approach to\\nsolving decentralised decision-making problems at scale. Research in the field\\nhas been growing steadily with many breakthrough algorithms proposed in recent\\nyears. In this work, we take a closer look at this rapid development with a\\nfocus on evaluation methodologies employed across a large body of research in\\ncooperative MARL. By conducting a detailed meta-analysis of prior work,\\nspanning 75 papers accepted for publication from 2016 to 2022, we bring to\\nlight worrying trends that put into question the true rate of progress. We\\nfurther consider these trends in a wider context and take inspiration from\\nsingle-agent RL literature on similar issues with recommendations that remain\\napplicable to MARL. Combining these recommendations, with novel insights from\\nour analysis, we propose a standardised performance evaluation protocol for\\ncooperative MARL. We argue that such a standard protocol, if widely adopted,\\nwould greatly improve the validity and credibility of future research, make\\nreplication and reproducibility easier, as well as improve the ability of the\\nfield to accurately gauge the rate of progress over time by being able to make\\nsound comparisons across different works. Finally, we release our meta-analysis\\ndata publicly on our project website for future research on evaluation:\\nhttps://sites.google.com/view/marl-standard-protocol',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.10485v1.pdf'},\n",
       " {'id': '2301.10230v3',\n",
       "  'title': 'Two-sided Competing Matching Recommendation Markets With Quota and\\n  Complementary Preferences Constraints',\n",
       "  'published': '2023-01-24T18:54:29Z',\n",
       "  'summary': \"In this paper, we propose a new recommendation algorithm for addressing the\\nproblem of two-sided online matching markets with complementary preferences and\\nquota constraints, where agents' preferences are unknown a priori and must be\\nlearned from data. The presence of mixed quota and complementary preferences\\nconstraints can lead to instability in the matching process, making this\\nproblem challenging to solve. To overcome this challenge, we formulate the\\nproblem as a bandit learning framework and propose the Multi-agent Multi-type\\nThompson Sampling (MMTS) algorithm. The algorithm combines the strengths of\\nThompson Sampling for exploration with a new double matching technique to\\nprovide a stable matching outcome. Our theoretical analysis demonstrates the\\neffectiveness of MMTS as it can achieve stability and has a total\\n$\\\\widetilde{\\\\mathcal{O}}(Q{\\\\sqrt{K_{\\\\max}T}})$-Bayesian regret with high\\nprobability, which exhibits linearity with respect to the total firm's quota\\n$Q$, the square root of the maximum size of available type workers\\n$\\\\sqrt{K_{\\\\max}}$ and time horizon $T$. In addition, simulation studies also\\ndemonstrate MMTS's effectiveness in various settings. We provide code used in\\nour experiments \\\\url{https://github.com/Likelyt/Double-Matching}.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2301.10230v3.pdf'},\n",
       " {'id': '2405.01994v1',\n",
       "  'title': 'Mathematics of statistical sequential decision-making: concentration,\\n  risk-awareness and modelling in stochastic bandits, with applications to\\n  bariatric surgery',\n",
       "  'published': '2024-05-03T10:50:30Z',\n",
       "  'summary': 'This thesis aims to study some of the mathematical challenges that arise in\\nthe analysis of statistical sequential decision-making algorithms for\\npostoperative patients follow-up. Stochastic bandits (multiarmed, contextual)\\nmodel the learning of a sequence of actions (policy) by an agent in an\\nuncertain environment in order to maximise observed rewards. To learn optimal\\npolicies, bandit algorithms have to balance the exploitation of current\\nknowledge and the exploration of uncertain actions. Such algorithms have\\nlargely been studied and deployed in industrial applications with large\\ndatasets, low-risk decisions and clear modelling assumptions, such as\\nclickthrough rate maximisation in online advertising. By contrast, digital\\nhealth recommendations call for a whole new paradigm of small samples,\\nrisk-averse agents and complex, nonparametric modelling. To this end, we\\ndeveloped new safe, anytime-valid concentration bounds, (Bregman, empirical\\nChernoff), introduced a new framework for risk-aware contextual bandits (with\\nelicitable risk measures) and analysed a novel class of nonparametric bandit\\nalgorithms under weak assumptions (Dirichlet sampling). In addition to the\\ntheoretical guarantees, these results are supported by in-depth empirical\\nevidence. Finally, as a first step towards personalised postoperative follow-up\\nrecommendations, we developed with medical doctors and surgeons an\\ninterpretable machine learning model to predict the long-term weight\\ntrajectories of patients after bariatric surgery.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.01994v1.pdf'},\n",
       " {'id': '2410.09698v2',\n",
       "  'title': 'Incentivized Network Dynamics in Digital Job Recruitment',\n",
       "  'published': '2024-10-13T02:30:02Z',\n",
       "  'summary': 'Online platforms have transformed the formal job market but continue to\\nstruggle with effectively engaging passive candidates-individuals not actively\\nseeking employment but open to compelling opportunities. We introduce the\\nIndependent Halting Cascade (IHC) model, a novel framework that integrates\\ncomplex network diffusion dynamics with economic game theory to address this\\nchallenge. Unlike traditional models that focus solely on information\\npropagation, the IHC model empowers network agents to either disseminate a job\\nposting or halt its spread by applying for the position themselves. By\\nembedding economic incentives into agent decision-making processes, the model\\ncreates a dynamic interplay between maximizing information spread and promoting\\napplication. Our analysis uncovers distinct behavioral regimes within the IHC\\nmodel, characterized by critical thresholds in recommendation and application\\nprobabilities. Extensive simulations on both synthetic and real-world network\\ntopologies demonstrate that the IHC model significantly outperforms traditional\\ndirect-recommendation systems in recruiting suitable passive candidates.\\nSpecifically, the model achieves up to a 30% higher hiring success rate\\ncompared to baseline methods. These findings offer strategic insights into\\nleveraging economic incentives and network structures to enhance recruitment\\nefficiency. The IHC model thus provides a robust framework for modernizing\\nrecruitment strategies, particularly in engaging the vast pool of passive\\ncandidates in the job market.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.09698v2.pdf'},\n",
       " {'id': '2412.12110v1',\n",
       "  'title': 'Enhancing the conformal predictability of context-aware recommendation\\n  systems by using Deep Autoencoders',\n",
       "  'published': '2024-11-30T18:24:42Z',\n",
       "  'summary': \"In the field of Recommender Systems (RS), neural collaborative filtering\\nrepresents a significant milestone by combining matrix factorization and deep\\nneural networks to achieve promising results. Traditional methods like matrix\\nfactorization often rely on linear models, limiting their capability to capture\\ncomplex interactions between users, items, and contexts. This limitation\\nbecomes particularly evident with high-dimensional datasets due to their\\ninability to capture relationships among users, items, and contextual factors.\\nUnsupervised learning and dimension reduction tasks utilize autoencoders,\\nneural network-based models renowned for their capacity to encode and decode\\ndata. Autoencoders learn latent representations of inputs, reducing dataset\\nsize while capturing complex patterns and features. In this paper, we introduce\\na framework that combines neural contextual matrix factorization with\\nautoencoders to predict user ratings for items. We provide a comprehensive\\noverview of the framework's design and implementation. To evaluate its\\nperformance, we conduct experiments on various real-world datasets and compare\\nthe results against state-of-the-art approaches. We also extend the concept of\\nconformal prediction to prediction rating and introduce a Conformal Prediction\\nRating (CPR). For RS, we define the nonconformity score, a key concept of\\nconformal prediction, and demonstrate that it satisfies the exchangeability\\nproperty.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.12110v1.pdf'},\n",
       " {'id': '2501.08897v2',\n",
       "  'title': 'Automated Retrosynthesis Planning of Macromolecules Using Large Language\\n  Models and Knowledge Graphs',\n",
       "  'published': '2025-01-15T16:06:10Z',\n",
       "  'summary': \"Identifying reliable synthesis pathways in materials chemistry is a complex\\ntask, particularly in polymer science, due to the intricate and often\\nnon-unique nomenclature of macromolecules. To address this challenge, we\\npropose an agent system that integrates large language models (LLMs) and\\nknowledge graphs. By leveraging LLMs' powerful capabilities for extracting and\\nrecognizing chemical substance names, and storing the extracted data in a\\nstructured knowledge graph, our system fully automates the retrieval of\\nrelevant literatures, extraction of reaction data, database querying,\\nconstruction of retrosynthetic pathway trees, further expansion through the\\nretrieval of additional literature and recommendation of optimal reaction\\npathways. By considering the complex interdependencies among chemical\\nreactants, a novel Multi-branched Reaction Pathway Search Algorithm (MBRPS) is\\nproposed to help identify all valid multi-branched reaction pathways, which\\narise when a single product decomposes into multiple reaction intermediates. In\\ncontrast, previous studies were limited to cases where a product decomposes\\ninto at most one reaction intermediate. This work represents the first attempt\\nto develop a fully automated retrosynthesis planning agent tailored specially\\nfor macromolecules powered by LLMs. Applied to polyimide synthesis, our new\\napproach constructs a retrosynthetic pathway tree with hundreds of pathways and\\nrecommends optimized routes, including both known and novel pathways. This\\ndemonstrates utilizing LLMs for literature consultation to accomplish specific\\ntasks is possible and crucial for future materials research, given the vast\\namount of materials-related literature.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.08897v2.pdf'},\n",
       " {'id': '2502.20068v1',\n",
       "  'title': 'A Generative Model Enhanced Multi-Agent Reinforcement Learning Method\\n  for Electric Vehicle Charging Navigation',\n",
       "  'published': '2025-02-27T13:24:51Z',\n",
       "  'summary': \"With the widespread adoption of electric vehicles (EVs), navigating for EV\\ndrivers to select a cost-effective charging station has become an important yet\\nchallenging issue due to dynamic traffic conditions, fluctuating electricity\\nprices, and potential competition from other EVs. The state-of-the-art deep\\nreinforcement learning (DRL) algorithms for solving this task still require\\nglobal information about all EVs at the execution stage, which not only\\nincreases communication costs but also raises privacy issues among EV drivers.\\nTo overcome these drawbacks, we introduce a novel generative model-enhanced\\nmulti-agent DRL algorithm that utilizes only the EV's local information while\\nachieving performance comparable to these state-of-the-art algorithms.\\nSpecifically, the policy network is implemented on the EV side, and a\\nConditional Variational Autoencoder-Long Short Term Memory (CVAE-LSTM)-based\\nrecommendation model is developed to provide recommendation information.\\nFurthermore, a novel future charging competition encoder is designed to\\neffectively compress global information, enhancing training performance. The\\nmulti-gradient descent algorithm (MGDA) is also utilized to adaptively balance\\nthe weight between the two parts of the training objective, resulting in a more\\nstable training process. Simulations are conducted based on a practical area in\\nXi\\\\'an, China. Experimental results show that our proposed algorithm, which\\nrelies on local information, outperforms existing local information-based\\nmethods and achieves less than 8\\\\% performance loss compared to global\\ninformation-based methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.20068v1.pdf'},\n",
       " {'id': '2503.17523v1',\n",
       "  'title': 'Bayesian Teaching Enables Probabilistic Reasoning in Large Language\\n  Models',\n",
       "  'published': '2025-03-21T20:13:04Z',\n",
       "  'summary': \"Artificial intelligence systems based on large language models (LLMs) are\\nincreasingly used as agents that interact with users and with the world. To do\\nso successfully, LLMs need to construct internal representations of the world\\nand form probabilistic beliefs about those representations. To provide a user\\nwith personalized recommendations, for example, the LLM needs to gradually\\ninfer the user's preferences, over the course of multiple interactions. To\\nevaluate whether contemporary LLMs are able to do so, we use the Bayesian\\ninference framework from probability theory, which lays out the optimal way to\\nupdate an agent's beliefs as it receives new information. We first show that\\nthe LLMs do not update their beliefs as expected from the Bayesian framework,\\nand that consequently their predictions do not improve as expected as more\\ninformation becomes available, even less so than we find is the case for\\nhumans. To address this issue, we teach the LLMs to reason in a Bayesian manner\\nby training them to mimic the predictions of an optimal Bayesian model. We find\\nthat this approach not only significantly improves the LLM's performance on the\\nparticular recommendation task it is trained on, but also enables\\ngeneralization to other tasks. This suggests that this method endows the LLM\\nwith broader Bayesian reasoning skills. More generally, our results indicate\\nthat LLMs can learn about reasoning strategies effectively and generalize those\\nskills to new domains, which in part explains LLMs' empirical success.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.17523v1.pdf'},\n",
       " {'id': '1203.1128v1',\n",
       "  'title': 'Nanoscale Metallic Iron for Environmental Remediation: Prospects and\\n  Limitations',\n",
       "  'published': '2012-03-06T08:07:32Z',\n",
       "  'summary': 'The amendment of the subsurface with nanoscale metallic iron particles\\n(nano-Fe0) has been discussed in the literature as an efficient in situ\\ntechnology for groundwater remediation. However, the introduction of this\\ntechnology was controversial and its efficiency has never been univocally\\nestablished. This unsatisfying situation has motivated this communication whose\\nobjective was a comprehensive discussion of the intrinsic reactivity of\\nnano-Fe0 based on the contemporary knowledge on the mechanism of contaminant\\nremoval by Fe0 and a mathematical model. It is showed that due to limitations\\nof the mass transfer of nano-Fe0 to contaminants, available concepts cannot\\nexplain the success of nano-Fe0 injection for in situ groundwater remediation.\\nIt is recommended to test the possibility of introducing nano-Fe0 to initiate\\nthe formation of roll-fronts which propagation would induce the reductive\\ntransformation of both dissolved and adsorbed contaminants. Within a\\nroll-front, FeII from nano-Fe0 is the reducing agent for contaminants. FeII is\\nrecycled by biotic or abiotic FeIII reduction. While the roll-front concept\\ncould explain the success of already implemented reaction zones, more research\\nis needed for a science-based recommendation of nano- Fe0 for subsurface\\ntreatment by roll-fronts',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1203.1128v1.pdf'},\n",
       " {'id': '1501.00994v1',\n",
       "  'title': 'Online Reputation and Polling Systems: Data Incest, Social Learning and\\n  Revealed Preferences',\n",
       "  'published': '2015-01-05T21:00:51Z',\n",
       "  'summary': \"This paper considers online reputation and polling systems where individuals\\nmake recommendations based on their private observations and recommendations of\\nfriends. Such interaction of individuals and their social influence is modelled\\nas social learning on a directed acyclic graph. Data incest (misinformation\\npropagation) occurs due to unintentional re-use of identical actions in the\\nfor- mation of public belief in social learning; the information gathered by\\neach agent is mistakenly considered to be independent. This results in\\noverconfidence and bias in estimates of the state. Necessary and sufficient\\nconditions are given on the structure of information exchange graph to mitigate\\ndata incest. Incest removal algorithms are presented. Experimental results on\\nhuman subjects are presented to illustrate the effect of social influence and\\ndata incest on decision making. These experimental results indicate that social\\nlearning protocols require careful design to handle and mitigate data incest.\\nThe incest removal algorithms are illustrated in an expectation polling system\\nwhere participants in a poll respond with a summary of their friends' beliefs.\\nFinally, the principle of revealed preferences arising in micro-economics\\ntheory is used to parse Twitter datasets to determine if social sensors are\\nutility maximizers and then determine their utility functions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1501.00994v1.pdf'},\n",
       " {'id': '2003.03410v1',\n",
       "  'title': 'Experimental Studies in General Game Playing: An Experience Report',\n",
       "  'published': '2020-03-06T19:53:28Z',\n",
       "  'summary': 'We describe nearly fifteen years of General Game Playing experimental\\nresearch history in the context of reproducibility and fairness of comparisons\\nbetween various GGP agents and systems designed to play games described by\\ndifferent formalisms. We think our survey may provide an interesting\\nperspective of how chaotic methods were allowed when nothing better was\\npossible. Finally, from our experience-based view, we would like to propose a\\nfew recommendations of how such specific heterogeneous branch of research\\nshould be handled appropriately in the future. The goal of this note is to\\npoint out common difficulties and problems in the experimental research in the\\narea. We hope that our recommendations will help in avoiding them in future\\nworks and allow more fair and reproducible comparisons.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2003.03410v1.pdf'},\n",
       " {'id': '1807.03492v2',\n",
       "  'title': 'The Recommendation System to SNS Community for Tourists by Using\\n  Altruistic Behaviors',\n",
       "  'published': '2018-07-10T06:26:28Z',\n",
       "  'summary': 'We have already developed the recommendation system of sightseeing\\ninformation on SNS by using smartphone based user participatory sensing system.\\nThe system can post the attractive information for tourists to the specified\\nFacebook page by our developed smartphone application. The users in Facebook,\\nwho are interested in sightseeing, can come flocking through information space\\nfrom far and near. However, the activities in the community on SNS are only\\nsupported by the specified people called a hub. We proposed the method of\\nvitalization of tourist behaviors to give a stimulus to the people. We\\ndeveloped the simulation system for multi agent system with altruistic\\nbehaviors inspired by the Army Ants. The army ant takes feeding action with\\naltruistic behaviors to suppress selfish behavior to a common object used by a\\nplurality of users in common. In this paper, we introduced the altruism\\nbehavior determined by some simulation to vitalize the SNS community. The\\nefficiency of the revitalization process of the community was investigated by\\nsome experimental simulation results.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.03492v2.pdf'},\n",
       " {'id': '1902.00429v1',\n",
       "  'title': 'The Importance of Social and Government Learning in Ex Ante Policy\\n  Evaluation',\n",
       "  'published': '2019-02-01T16:05:47Z',\n",
       "  'summary': 'We provide two methodological insights on \\\\emph{ex ante} policy evaluation\\nfor macro models of economic development. First, we show that the problems of\\nparameter instability and lack of behavioral constancy can be overcome by\\nconsidering learning dynamics. Hence, instead of defining social constructs as\\nfixed exogenous parameters, we represent them through stable functional\\nrelationships such as social norms. Second, we demonstrate how agent computing\\ncan be used for this purpose. By deploying a model of policy prioritization\\nwith endogenous government behavior, we estimate the performance of different\\npolicy regimes. We find that, while strictly adhering to policy recommendations\\nincreases efficiency, the nature of such recipes has a bigger effect. In other\\nwords, while it is true that lack of discipline is detrimental to prescription\\noutcomes (a common defense of failed recommendations), it is more important\\nthat such prescriptions consider the systemic and adaptive nature of the\\npolicymaking process (something neglected by traditional technocratic advice).',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.00429v1.pdf'},\n",
       " {'id': '1902.05981v2',\n",
       "  'title': 'Adaptive Sequence Submodularity',\n",
       "  'published': '2019-02-15T20:37:14Z',\n",
       "  'summary': \"In many machine learning applications, one needs to interactively select a\\nsequence of items (e.g., recommending movies based on a user's feedback) or\\nmake sequential decisions in a certain order (e.g., guiding an agent through a\\nseries of states). Not only do sequences already pose a dauntingly large search\\nspace, but we must also take into account past observations, as well as the\\nuncertainty of future outcomes. Without further structure, finding an optimal\\nsequence is notoriously challenging, if not completely intractable. In this\\npaper, we view the problem of adaptive and sequential decision making through\\nthe lens of submodularity and propose an adaptive greedy policy with strong\\ntheoretical guarantees. Additionally, to demonstrate the practical utility of\\nour results, we run experiments on Amazon product recommendation and Wikipedia\\nlink prediction tasks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.05981v2.pdf'},\n",
       " {'id': '1911.03845v3',\n",
       "  'title': 'Model-Based Reinforcement Learning with Adversarial Training for Online\\n  Recommendation',\n",
       "  'published': '2019-11-10T04:24:04Z',\n",
       "  'summary': 'Reinforcement learning is well suited for optimizing policies of recommender\\nsystems. Current solutions mostly focus on model-free approaches, which require\\nfrequent interactions with the real environment, and thus are expensive in\\nmodel learning. Offline evaluation methods, such as importance sampling, can\\nalleviate such limitations, but usually request a large amount of logged data\\nand do not work well when the action space is large. In this work, we propose a\\nmodel-based reinforcement learning solution which models user-agent interaction\\nfor offline policy learning via a generative adversarial network. To reduce\\nbias in the learned model and policy, we use a discriminator to evaluate the\\nquality of generated data and scale the generated rewards. Our theoretical\\nanalysis and empirical evaluations demonstrate the effectiveness of our\\nsolution in learning policies from the offline and generated data.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1911.03845v3.pdf'},\n",
       " {'id': '2001.11274v2',\n",
       "  'title': 'Scalable Psychological Momentum Forecasting in Esports',\n",
       "  'published': '2020-01-30T11:57:40Z',\n",
       "  'summary': 'The world of competitive Esports and video gaming has seen and continues to\\nexperience steady growth in popularity and complexity. Correspondingly, more\\nresearch on the topic is being published, ranging from social network analyses\\nto the benchmarking of advanced artificial intelligence systems in playing\\nagainst humans. In this paper, we present ongoing work on an intelligent agent\\nrecommendation engine that suggests actions to players in order to maximise\\nsuccess and enjoyment, both in the space of in-game choices, as well as\\ndecisions made around play session timing in the broader context. By leveraging\\ntemporal data and appropriate models, we show that a learned representation of\\nplayer psychological momentum, and of tilt, can be used, in combination with\\nplayer expertise, to achieve state-of-the-art performance in pre- and\\npost-draft win prediction. Our progress toward fulfilling the potential for\\nderiving optimal recommendations is documented.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2001.11274v2.pdf'},\n",
       " {'id': '2005.08792v4',\n",
       "  'title': 'Causal Feature Learning for Utility-Maximizing Agents',\n",
       "  'published': '2020-05-18T15:13:59Z',\n",
       "  'summary': 'Discovering high-level causal relations from low-level data is an important\\nand challenging problem that comes up frequently in the natural and social\\nsciences. In a series of papers, Chalupka et al. (2015, 2016a, 2016b, 2017)\\ndevelop a procedure for causal feature learning (CFL) in an effort to automate\\nthis task. We argue that CFL does not recommend coarsening in cases where\\npragmatic considerations rule in favor of it, and recommends coarsening in\\ncases where pragmatic considerations rule against it. We propose a new\\ntechnique, pragmatic causal feature learning (PCFL), which extends the original\\nCFL algorithm in useful and intuitive ways. We show that PCFL has the same\\nattractive measure-theoretic properties as the original CFL algorithm. We\\ncompare the performance of both methods through theoretical analysis and\\nexperiments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.08792v4.pdf'},\n",
       " {'id': '2102.07659v2',\n",
       "  'title': 'Diverse Auto-Curriculum is Critical for Successful Real-World Multiagent\\n  Learning Systems',\n",
       "  'published': '2021-02-15T16:40:02Z',\n",
       "  'summary': 'Multiagent reinforcement learning (MARL) has achieved a remarkable amount of\\nsuccess in solving various types of video games. A cornerstone of this success\\nis the auto-curriculum framework, which shapes the learning process by\\ncontinually creating new challenging tasks for agents to adapt to, thereby\\nfacilitating the acquisition of new skills. In order to extend MARL methods to\\nreal-world domains outside of video games, we envision in this blue sky paper\\nthat maintaining a diversity-aware auto-curriculum is critical for successful\\nMARL applications. Specifically, we argue that \\\\emph{behavioural diversity} is\\na pivotal, yet under-explored, component for real-world multiagent learning\\nsystems, and that significant work remains in understanding how to design a\\ndiversity-aware auto-curriculum. We list four open challenges for\\nauto-curriculum techniques, which we believe deserve more attention from this\\ncommunity. Towards validating our vision, we recommend modelling realistic\\ninteractive behaviours in autonomous driving as an important test bed, and\\nrecommend the SMARTS/ULTRA benchmark.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.07659v2.pdf'},\n",
       " {'id': '2103.09685v1',\n",
       "  'title': 'Nudging Students Toward Better Software Engineering Behaviors',\n",
       "  'published': '2021-03-17T14:34:31Z',\n",
       "  'summary': 'Student experiences in large undergraduate Computer Science courses are\\nincreasingly impacted by automated systems. Bots, or agents of software\\nautomation, are useful for efficiently grading and generating feedback. Current\\nefforts at automation in CS education focus on supporting instructional tasks,\\nbut do not address student struggles due to poor behaviors, such as\\nprocrastination. In this paper, we explore using bots to improve the software\\nengineering behaviors of students using developer recommendation choice\\narchitectures, a framework incorporating behavioral science concepts in\\nrecommendations to improve the actions of programmers. We implemented this\\nframework in class-bot, a novel system designed to nudge students to make\\nbetter choices while working on programming assignments. This work presents a\\npreliminary evaluation integrating this tool in an introductory programming\\ncourse. Our results show that class-bot is beneficial for improving student\\ndevelopment behaviors increasing code quality and productivity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.09685v1.pdf'},\n",
       " {'id': '2111.09774v4',\n",
       "  'title': 'Assessing Gender Bias in Particle Physics and Social Science\\n  Recommendations for Academic Jobs',\n",
       "  'published': '2021-11-18T16:14:00Z',\n",
       "  'summary': 'We investigated gender bias in letters of recommendation as a possible cause\\nof the under-representation of women in Experimental Particle Physics (EPP),\\nwhere about 15% of faculty are female -- well below the 60% level in psychology\\nand sociology. We analyzed 2,206 letters in EPP and these social sciences using\\nstandard lexical measures as well as two new measures: author status and an\\nopen-ended search for gendered language. In contrast to former studies, women\\nwere not depicted as more communal, less agentic, or less standout. Lexical\\nmeasures revealed few gender differences in either discipline. The open-ended\\nanalysis revealed disparities favoring women in social science and men in EPP.\\nHowever, female EPP candidates were characterized as \"brilliant\" in nearly\\nthree times as many letters as men.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.09774v4.pdf'},\n",
       " {'id': '2203.12981v1',\n",
       "  'title': 'Impacts of Personal Characteristics on User Trust in Conversational\\n  Recommender Systems',\n",
       "  'published': '2022-03-24T11:03:15Z',\n",
       "  'summary': 'Conversational recommender systems (CRSs) imitate human advisors to assist\\nusers in finding items through conversations and have recently gained\\nincreasing attention in domains such as media and e-commerce. Like in human\\ncommunication, building trust in human-agent communication is essential given\\nits significant influence on user behavior. However, inspiring user trust in\\nCRSs with a \"one-size-fits-all\" design is difficult, as individual users may\\nhave their own expectations for conversational interactions (e.g., who, user or\\nsystem, takes the initiative), which are potentially related to their personal\\ncharacteristics. In this study, we investigated the impacts of three personal\\ncharacteristics, namely personality traits, trust propensity, and domain\\nknowledge, on user trust in two types of text-based CRSs, i.e., user-initiative\\nand mixed-initiative. Our between-subjects user study (N=148) revealed that\\nusers\\' trust propensity and domain knowledge positively influenced their trust\\nin CRSs, and that users with high conscientiousness tended to trust the\\nmixed-initiative system.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2203.12981v1.pdf'},\n",
       " {'id': '2207.00109v2',\n",
       "  'title': 'Ranking In Generalized Linear Bandits',\n",
       "  'published': '2022-06-30T21:38:00Z',\n",
       "  'summary': 'We study the ranking problem in generalized linear bandits. At each time, the\\nlearning agent selects an ordered list of items and observes stochastic\\noutcomes. In recommendation systems, displaying an ordered list of the most\\nattractive items is not always optimal as both position and item dependencies\\nresult in a complex reward function. A very naive example is the lack of\\ndiversity when all the most attractive items are from the same category. We\\nmodel the position and item dependencies in the ordered list and design UCB and\\nThompson Sampling type algorithms for this problem. Our work generalizes\\nexisting studies in several directions, including position dependencies where\\nposition discount is a particular case, and connecting the ranking problem to\\ngraph theory.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.00109v2.pdf'},\n",
       " {'id': '2302.02633v1',\n",
       "  'title': 'Toward a normative theory of (self-)management by goal-setting',\n",
       "  'published': '2023-02-06T09:06:54Z',\n",
       "  'summary': \"People are often confronted with problems whose complexity exceeds their\\ncognitive capacities. To deal with this complexity, individuals and managers\\ncan break complex problems down into a series of subgoals. Which subgoals are\\nmost effective depends on people's cognitive constraints and the cognitive\\nmechanisms of goal pursuit. This creates an untapped opportunity to derive\\npractical recommendations for which subgoals managers and individuals should\\nset from cognitive models of bounded rationality. To seize this opportunity, we\\napply the principle of resource-rationality to formulate a mathematically\\nprecise normative theory of (self-)management by goal-setting. We leverage this\\ntheory to computationally derive optimal subgoals from a resource-rational\\nmodel of human goal pursuit. Finally, we show that the resulting subgoals\\nimprove the problem-solving performance of bounded agents and human\\nparticipants. This constitutes a first step towards grounding prescriptive\\ntheories of management and practical recommendations for goal-setting in\\ncomputational models of the relevant psychological processes and cognitive\\nlimitations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.02633v1.pdf'},\n",
       " {'id': '2306.04765v1',\n",
       "  'title': 'The HCI Aspects of Public Deployment of Research Chatbots: A User Study,\\n  Design Recommendations, and Open Challenges',\n",
       "  'published': '2023-06-07T20:24:43Z',\n",
       "  'summary': \"Publicly deploying research chatbots is a nuanced topic involving necessary\\nrisk-benefit analyses. While there have recently been frequent discussions on\\nwhether it is responsible to deploy such models, there has been far less focus\\non the interaction paradigms and design approaches that the resulting\\ninterfaces should adopt, in order to achieve their goals more effectively. We\\naim to pose, ground, and attempt to answer HCI questions involved in this\\nscope, by reporting on a mixed-methods user study conducted on a recent\\nresearch chatbot. We find that abstract anthropomorphic representation for the\\nagent has a significant effect on user's perception, that offering AI\\nexplainability may have an impact on feedback rates, and that two (diegetic and\\nextradiegetic) levels of the chat experience should be intentionally designed.\\nWe offer design recommendations and areas of further focus for the research\\ncommunity.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.04765v1.pdf'},\n",
       " {'id': '2402.02006v2',\n",
       "  'title': 'PresAIse, A Prescriptive AI Solution for Enterprises',\n",
       "  'published': '2024-02-03T03:23:08Z',\n",
       "  'summary': \"Prescriptive AI represents a transformative shift in decision-making,\\noffering causal insights and actionable recommendations. Despite its huge\\npotential, enterprise adoption often faces several challenges. The first\\nchallenge is caused by the limitations of observational data for accurate\\ncausal inference which is typically a prerequisite for good decision-making.\\nThe second pertains to the interpretability of recommendations, which is\\ncrucial for enterprise decision-making settings. The third challenge is the\\nsilos between data scientists and business users, hindering effective\\ncollaboration. This paper outlines an initiative from IBM Research, aiming to\\naddress some of these challenges by offering a suite of prescriptive AI\\nsolutions. Leveraging insights from various research papers, the solution suite\\nincludes scalable causal inference methods, interpretable decision-making\\napproaches, and the integration of large language models (LLMs) to bridge\\ncommunication gaps via a conversation agent. A proof-of-concept, PresAIse,\\ndemonstrates the solutions' potential by enabling non-ML experts to interact\\nwith prescriptive AI models via a natural language interface, democratizing\\nadvanced analytics for strategic decision-making.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.02006v2.pdf'},\n",
       " {'id': '2404.09324v2',\n",
       "  'title': 'Mean Field Correlated Imitation Learning',\n",
       "  'published': '2024-04-14T18:51:50Z',\n",
       "  'summary': 'We investigate multi-agent imitation learning (IL) within the framework of\\nmean field games (MFGs), considering the presence of time-varying correlated\\nsignals. Existing MFG IL algorithms assume demonstrations are sampled from Mean\\nField Nash Equilibria (MFNE), limiting their adaptability to real-world\\nscenarios. For example, in the traffic network equilibrium influenced by public\\nrouting recommendations, recommendations introduce time-varying correlated\\nsignals into the game, not captured by MFNE and other existing correlated\\nequilibrium concepts. To address this gap, we propose Adaptive Mean Field\\nCorrelated Equilibrium (AMFCE), a general equilibrium incorporating\\ntime-varying correlated signals. We establish the existence of AMFCE under mild\\nconditions and prove that MFNE is a subclass of AMFCE. We further propose\\nCorrelated Mean Field Imitation Learning (CMFIL), a novel IL framework designed\\nto recover the AMFCE, accompanied by a theoretical guarantee on the quality of\\nthe recovered policy. Experimental results, including a real-world traffic flow\\nprediction problem, demonstrate the superiority of CMFIL over state-of-the-art\\nIL baselines, highlighting the potential of CMFIL in understanding large\\npopulation behavior under correlated signals.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.09324v2.pdf'},\n",
       " {'id': '2410.12123v3',\n",
       "  'title': 'Large Language Models, and LLM-Based Agents, Should Be Used to Enhance\\n  the Digital Public Sphere',\n",
       "  'published': '2024-10-15T23:51:04Z',\n",
       "  'summary': \"This paper argues that large language model-based recommenders can displace\\ntoday's attention-allocation machinery. LLM-based recommenders would ingest\\nopen-web content, infer a user's natural-language goals, and present\\ninformation that matches their reflective preferences. Properly designed, they\\ncould deliver personalization without industrial-scale data hoarding, return\\ncontrol to individuals, optimize for genuine ends rather than click-through\\nproxies, and support autonomous attention management. Synthesizing evidence of\\ncurrent systems' harms with recent work on LLM-driven pipelines, we identify\\nfour key research hurdles: generating candidates without centralized data,\\nmaintaining computational efficiency, modeling preferences robustly, and\\ndefending against prompt-injection. None looks prohibitive; surmounting them\\nwould steer the digital public sphere toward democratic, human-centered values.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.12123v3.pdf'},\n",
       " {'id': '1609.08923v1',\n",
       "  'title': 'Models of Level-0 Behavior for Predicting Human Behavior in Games',\n",
       "  'published': '2016-09-28T14:18:03Z',\n",
       "  'summary': 'Behavioral game theory seeks to describe the way actual people (as compared\\nto idealized, \"rational\" agents) act in strategic situations. Our own recent\\nwork has identified iterative models (such as quantal cognitive hierarchy) as\\nthe state of the art for predicting human play in unrepeated, simultaneous-move\\ngames (Wright & Leyton-Brown 2012, 2016). Iterative models predict that agents\\nreason iteratively about their opponents, building up from a specification of\\nnonstrategic behavior called level-0. The modeler is in principle free to\\nchoose any description of level-0 behavior that makes sense for the setting.\\nHowever, almost all existing work specifies this behavior as a uniform\\ndistribution over actions. In most games it is not plausible that even\\nnonstrategic agents would choose an action uniformly at random, nor that other\\nagents would expect them to do so. A more accurate model for level-0 behavior\\nhas the potential to dramatically improve predictions of human behavior, since\\na substantial fraction of agents may play level-0 strategies directly, and\\nfurthermore since iterative models ground all higher-level strategies in\\nresponses to the level-0 strategy. Our work considers models of the way in\\nwhich level-0 agents construct a probability distribution over actions, given\\nan arbitrary game. Using a Bayesian optimization package called SMAC (Hutter,\\nHoos, & Leyton-Brown, 2010, 2011, 2012), we systematically evaluated a large\\nspace of such models, each of which makes its prediction based only on general\\nfeatures that can be computed from any normal form game. In the end, we\\nrecommend a model that achieved excellent performance across the board: a\\nlinear weighting of features that requires the estimation of four weights. We\\nevaluated the effects of combining this new level-0 model with several\\niterative models, and observed large improvements in the models\\' predictive\\naccuracies.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1609.08923v1.pdf'},\n",
       " {'id': '2004.13553v1',\n",
       "  'title': 'Universal Masking is Urgent in the COVID-19 Pandemic: SEIR and Agent\\n  Based Models, Empirical Validation, Policy Recommendations',\n",
       "  'published': '2020-04-22T11:42:11Z',\n",
       "  'summary': 'We present two models for the COVID-19 pandemic predicting the impact of\\nuniversal face mask wearing upon the spread of the SARS-CoV-2 virus--one\\nemploying a stochastic dynamic network based compartmental SEIR\\n(susceptible-exposed-infectious-recovered) approach, and the other employing\\nindividual ABM (agent-based modelling) Monte Carlo simulation--indicating (1)\\nsignificant impact under (near) universal masking when at least 80% of a\\npopulation is wearing masks, versus minimal impact when only 50% or less of the\\npopulation is wearing masks, and (2) significant impact when universal masking\\nis adopted early, by Day 50 of a regional outbreak, versus minimal impact when\\nuniversal masking is adopted late. These effects hold even at the lower\\nfiltering rates of homemade masks. To validate these theoretical models, we\\ncompare their predictions against a new empirical data set we have collected\\nthat includes whether regions have universal masking cultures or policies,\\ntheir daily case growth rates, and their percentage reduction from peak daily\\ncase growth rates. Results show a near perfect correlation between early\\nuniversal masking and successful suppression of daily case growth rates and/or\\nreduction from peak daily case growth rates, as predicted by our theoretical\\nsimulations.\\n  Our theoretical and empirical results argue for urgent implementation of\\nuniversal masking. As governments plan how to exit societal lockdowns, it is\\nemerging as a key NPI; a \"mouth-and-nose lockdown\" is far more sustainable than\\na \"full body lockdown\", on economic, social, and mental health axes. An\\ninteractive visualization of the ABM simulation is at http://dek.ai/masks4all.\\nWe recommend immediate mask wearing recommendations, official guidelines for\\ncorrect use, and awareness campaigns to shift masking mindsets away from pure\\nself-protection, towards aspirational goals of responsibly protecting one\\'s\\ncommunity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2004.13553v1.pdf'},\n",
       " {'id': '2509.07325v1',\n",
       "  'title': 'CancerGUIDE: Cancer Guideline Understanding via Internal Disagreement\\n  Estimation',\n",
       "  'published': '2025-09-09T01:49:29Z',\n",
       "  'summary': 'The National Comprehensive Cancer Network (NCCN) provides evidence-based\\nguidelines for cancer treatment. Translating complex patient presentations into\\nguideline-compliant treatment recommendations is time-intensive, requires\\nspecialized expertise, and is prone to error. Advances in large language model\\n(LLM) capabilities promise to reduce the time required to generate treatment\\nrecommendations and improve accuracy. We present an LLM agent-based approach to\\nautomatically generate guideline-concordant treatment trajectories for patients\\nwith non-small cell lung cancer (NSCLC). Our contributions are threefold.\\nFirst, we construct a novel longitudinal dataset of 121 cases of NSCLC patients\\nthat includes clinical encounters, diagnostic results, and medical histories,\\neach expertly annotated with the corresponding NCCN guideline trajectories by\\nboard-certified oncologists. Second, we demonstrate that existing LLMs possess\\ndomain-specific knowledge that enables high-quality proxy benchmark generation\\nfor both model development and evaluation, achieving strong correlation\\n(Spearman coefficient r=0.88, RMSE = 0.08) with expert-annotated benchmarks.\\nThird, we develop a hybrid approach combining expensive human annotations with\\nmodel consistency information to create both the agent framework that predicts\\nthe relevant guidelines for a patient, as well as a meta-classifier that\\nverifies prediction accuracy with calibrated confidence scores for treatment\\nrecommendations (AUROC=0.800), a critical capability for communicating the\\naccuracy of outputs, custom-tailoring tradeoffs in performance, and supporting\\nregulatory compliance. This work establishes a framework for clinically viable\\nLLM-based guideline adherence systems that balance accuracy, interpretability,\\nand regulatory requirements while reducing annotation costs, providing a\\nscalable pathway toward automated clinical decision support.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.07325v1.pdf'},\n",
       " {'id': '1803.06328v2',\n",
       "  'title': 'Nesting Probabilistic Programs',\n",
       "  'published': '2018-03-16T17:30:35Z',\n",
       "  'summary': 'We formalize the notion of nesting probabilistic programming queries and\\ninvestigate the resulting statistical implications. We demonstrate that while\\nquery nesting allows the definition of models which could not otherwise be\\nexpressed, such as those involving agents reasoning about other agents,\\nexisting systems take approaches which lead to inconsistent estimates. We show\\nhow to correct this by delineating possible ways one might want to nest queries\\nand asserting the respective conditions required for convergence. We further\\nintroduce a new online nested Monte Carlo estimator that makes it substantially\\neasier to ensure these conditions are met, thereby providing a simple framework\\nfor designing statistically correct inference engines. We prove the correctness\\nof this online estimator and show that, when using the recommended setup, its\\nasymptotic variance is always better than that of the equivalent fixed\\nestimator, while its bias is always within a factor of two.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1803.06328v2.pdf'},\n",
       " {'id': '1906.12350v2',\n",
       "  'title': 'Split Q Learning: Reinforcement Learning with Two-Stream Rewards',\n",
       "  'published': '2019-06-21T01:59:52Z',\n",
       "  'summary': \"Drawing an inspiration from behavioral studies of human decision making, we\\npropose here a general parametric framework for a reinforcement learning\\nproblem, which extends the standard Q-learning approach to incorporate a\\ntwo-stream framework of reward processing with biases biologically associated\\nwith several neurological and psychiatric conditions, including Parkinson's and\\nAlzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD),\\naddiction, and chronic pain. For AI community, the development of agents that\\nreact differently to different types of rewards can enable us to understand a\\nwide spectrum of multi-agent interactions in complex real-world socioeconomic\\nsystems. Moreover, from the behavioral modeling perspective, our parametric\\nframework can be viewed as a first step towards a unifying computational model\\ncapturing reward processing abnormalities across multiple mental conditions and\\nuser preferences in long-term recommendation systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1906.12350v2.pdf'},\n",
       " {'id': '2003.06050v1',\n",
       "  'title': 'Heterogeneous Relational Reasoning in Knowledge Graphs with\\n  Reinforcement Learning',\n",
       "  'published': '2020-03-12T22:39:58Z',\n",
       "  'summary': 'Path-based relational reasoning over knowledge graphs has become increasingly\\npopular due to a variety of downstream applications such as question answering\\nin dialogue systems, fact prediction, and recommender systems. In recent years,\\nreinforcement learning (RL) has provided solutions that are more interpretable\\nand explainable than other deep learning models. However, these solutions still\\nface several challenges, including large action space for the RL agent and\\naccurate representation of entity neighborhood structure. We address these\\nproblems by introducing a type-enhanced RL agent that uses the local\\nneighborhood information for efficient path-based reasoning over knowledge\\ngraphs. Our solution uses graph neural network (GNN) for encoding the\\nneighborhood information and utilizes entity types to prune the action space.\\nExperiments on real-world dataset show that our method outperforms\\nstate-of-the-art RL methods and discovers more novel paths during the training\\nprocedure.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2003.06050v1.pdf'},\n",
       " {'id': '1705.08618v1',\n",
       "  'title': 'Multi-Task Learning for Contextual Bandits',\n",
       "  'published': '2017-05-24T05:47:52Z',\n",
       "  'summary': \"Contextual bandits are a form of multi-armed bandit in which the agent has\\naccess to predictive side information (known as the context) for each arm at\\neach time step, and have been used to model personalized news recommendation,\\nad placement, and other applications. In this work, we propose a multi-task\\nlearning framework for contextual bandit problems. Like multi-task learning in\\nthe batch setting, the goal is to leverage similarities in contexts for\\ndifferent arms so as to improve the agent's ability to predict rewards from\\ncontexts. We propose an upper confidence bound-based multi-task learning\\nalgorithm for contextual bandits, establish a corresponding regret bound, and\\ninterpret this bound to quantify the advantages of learning in the presence of\\nhigh task (arm) similarity. We also describe an effective scheme for estimating\\ntask similarity from data, and demonstrate our algorithm's performance on\\nseveral data sets.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1705.08618v1.pdf'},\n",
       " {'id': '1806.00892v1',\n",
       "  'title': 'Conservative Exploration using Interleaving',\n",
       "  'published': '2018-06-03T23:20:29Z',\n",
       "  'summary': 'In many practical problems, a learning agent may want to learn the best\\naction in hindsight without ever taking a bad action, which is significantly\\nworse than the default production action. In general, this is impossible\\nbecause the agent has to explore unknown actions, some of which can be bad, to\\nlearn better actions. However, when the actions are combinatorial, this may be\\npossible if the unknown action can be evaluated by interleaving it with the\\nproduction action. We formalize this concept as learning in stochastic\\ncombinatorial semi-bandits with exchangeable actions. We design efficient\\nlearning algorithms for this problem, bound their n-step regret, and evaluate\\nthem on both synthetic and real-world problems. Our real-world experiments show\\nthat our algorithms can learn to recommend K most attractive movies without\\never violating a strict production constraint, both overall and subject to a\\ndiversity constraint.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1806.00892v1.pdf'},\n",
       " {'id': '2007.03121v1',\n",
       "  'title': 'Multi-Armed Bandits with Local Differential Privacy',\n",
       "  'published': '2020-07-06T23:36:20Z',\n",
       "  'summary': \"This paper investigates the problem of regret minimization for multi-armed\\nbandit (MAB) problems with local differential privacy (LDP) guarantee. In\\nstochastic bandit systems, the rewards may refer to the users' activities,\\nwhich may involve private information and the users may not want the agent to\\nknow. However, in many cases, the agent needs to know these activities to\\nprovide better services such as recommendations and news feeds. To handle this\\ndilemma, we adopt differential privacy and study the regret upper and lower\\nbounds for MAB algorithms with a given LDP guarantee. In this paper, we prove a\\nlower bound and propose algorithms whose regret upper bounds match the lower\\nbound up to constant factors. Numerical experiments also confirm our\\nconclusions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.03121v1.pdf'},\n",
       " {'id': '2007.04903v2',\n",
       "  'title': 'Emergence of polarization in a voter model with personalized information',\n",
       "  'published': '2020-07-09T16:05:11Z',\n",
       "  'summary': 'The flourishing of fake news is favored by recommendation algorithms of\\nonline social networks which, based on previous users activity, provide content\\nadapted to their preferences and so create filter bubbles. We introduce an\\nanalytically tractable voter model with personalized information, in which an\\nexternal field tends to align the agent opinion with the one she held more\\nfrequently in the past. Our model shows a surprisingly rich dynamics despite\\nits simplicity. An analytical mean-field approach, confirmed by numerical\\nsimulations, allows us to build a phase diagram and to predict if and how\\nconsensus is reached. Remarkably, polarization can be avoided only for weak\\ninteraction with the personalized information and if the number of agents is\\nbelow a threshold. We analytically compute this critical size, which depends on\\nthe interaction probability in a strongly non linear way.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.04903v2.pdf'},\n",
       " {'id': '2006.10911v1',\n",
       "  'title': 'Gradient-free Online Learning in Games with Delayed Rewards',\n",
       "  'published': '2020-06-19T00:58:46Z',\n",
       "  'summary': \"Motivated by applications to online advertising and recommender systems, we\\nconsider a game-theoretic model with delayed rewards and asynchronous,\\npayoff-based feedback. In contrast to previous work on delayed multi-armed\\nbandits, we focus on multi-player games with continuous action spaces, and we\\nexamine the long-run behavior of strategic agents that follow a no-regret\\nlearning policy (but are otherwise oblivious to the game being played, the\\nobjectives of their opponents, etc.). To account for the lack of a consistent\\nstream of information (for instance, rewards can arrive out of order, with an a\\npriori unbounded delay, etc.), we introduce a gradient-free learning policy\\nwhere payoff information is placed in a priority queue as it arrives. In this\\ngeneral context, we derive new bounds for the agents' regret; furthermore,\\nunder a standard diagonal concavity assumption, we show that the induced\\nsequence of play converges to Nash equilibrium with probability $1$, even if\\nthe delay between choosing an action and receiving the corresponding reward is\\nunbounded.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.10911v1.pdf'},\n",
       " {'id': '2210.02552v1',\n",
       "  'title': 'Towards Safe Mechanical Ventilation Treatment Using Deep Offline\\n  Reinforcement Learning',\n",
       "  'published': '2022-10-05T20:41:17Z',\n",
       "  'summary': 'Mechanical ventilation is a key form of life support for patients with\\npulmonary impairment. Healthcare workers are required to continuously adjust\\nventilator settings for each patient, a challenging and time consuming task.\\nHence, it would be beneficial to develop an automated decision support tool to\\noptimize ventilation treatment. We present DeepVent, a Conservative Q-Learning\\n(CQL) based offline Deep Reinforcement Learning (DRL) agent that learns to\\npredict the optimal ventilator parameters for a patient to promote 90 day\\nsurvival. We design a clinically relevant intermediate reward that encourages\\ncontinuous improvement of the patient vitals as well as addresses the challenge\\nof sparse reward in RL. We find that DeepVent recommends ventilation parameters\\nwithin safe ranges, as outlined in recent clinical trials. The CQL algorithm\\noffers additional safety by mitigating the overestimation of the value\\nestimates of out-of-distribution states/actions. We evaluate our agent using\\nFitted Q Evaluation (FQE) and demonstrate that it outperforms physicians from\\nthe MIMIC-III dataset.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.02552v1.pdf'},\n",
       " {'id': '2005.14564v1',\n",
       "  'title': 'Network-based ranking in social systems: three challenges',\n",
       "  'published': '2020-05-29T13:27:30Z',\n",
       "  'summary': \"Ranking algorithms are pervasive in our increasingly digitized societies,\\nwith important real-world applications including recommender systems, search\\nengines, and influencer marketing practices. From a network science\\nperspective, network-based ranking algorithms solve fundamental problems\\nrelated to the identification of vital nodes for the stability and dynamics of\\na complex system. Despite the ubiquitous and successful applications of these\\nalgorithms, we argue that our understanding of their performance and their\\napplications to real-world problems face three fundamental challenges: (i)\\nRankings might be biased by various factors; (2) their effectiveness might be\\nlimited to specific problems; and (3) agents' decisions driven by rankings\\nmight result in potentially vicious feedback mechanisms and unhealthy systemic\\nconsequences. Methods rooted in network science and agent-based modeling can\\nhelp us to understand and overcome these challenges.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.14564v1.pdf'},\n",
       " {'id': '2010.14654v2',\n",
       "  'title': 'Artificial Intelligence Systems applied to tourism: A Survey',\n",
       "  'published': '2020-10-27T22:41:12Z',\n",
       "  'summary': 'Artificial Intelligence (AI) has been improving the performance of systems\\nfor a diverse set of tasks and introduced a more interactive generation of\\npersonal agents. Despite the current trend of applying AI for a great amount of\\nareas, we have not seen the same quantity of work being developed for the\\ntourism sector. This paper reports on the main applications of AI systems\\ndeveloped for tourism and the current state of the art for this sector. The\\npaper also provides an up-to-date survey of this field regarding several key\\nworks and systems that are applied to tourism, like Personal Agents, for\\nproviding a more interactive experience. We also carried out an in-depth\\nresearch on systems for predicting traffic human flow, more accurate\\nrecommendation systems and even how geospatial is trying to display tourism\\ndata in a more informative way and prevent problems before they arise.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.14654v2.pdf'},\n",
       " {'id': '2202.09064v2',\n",
       "  'title': 'Can Interpretable Reinforcement Learning Manage Prosperity Your Way?',\n",
       "  'published': '2022-02-18T07:59:08Z',\n",
       "  'summary': \"Personalisation of products and services is fast becoming the driver of\\nsuccess in banking and commerce. Machine learning holds the promise of gaining\\na deeper understanding of and tailoring to customers' needs and preferences.\\nWhereas traditional solutions to financial decision problems frequently rely on\\nmodel assumptions, reinforcement learning is able to exploit large amounts of\\ndata to improve customer modelling and decision-making in complex financial\\nenvironments with fewer assumptions. Model explainability and interpretability\\npresent challenges from a regulatory perspective which demands transparency for\\nacceptance; they also offer the opportunity for improved insight into and\\nunderstanding of customers. Post-hoc approaches are typically used for\\nexplaining pretrained reinforcement learning models. Based on our previous\\nmodeling of customer spending behaviour, we adapt our recent reinforcement\\nlearning algorithm that intrinsically characterizes desirable behaviours and we\\ntransition to the problem of asset management. We train inherently\\ninterpretable reinforcement learning agents to give investment advice that is\\naligned with prototype financial personality traits which are combined to make\\na final recommendation. We observe that the trained agents' advice adheres to\\ntheir intended characteristics, they learn the value of compound growth, and,\\nwithout any explicit reference, the notion of risk as well as improved policy\\nconvergence.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2202.09064v2.pdf'},\n",
       " {'id': '2209.12346v2',\n",
       "  'title': 'Exploring the Constraints on Artificial General Intelligence: A\\n  Game-Theoretic No-Go Theorem',\n",
       "  'published': '2022-09-25T23:17:20Z',\n",
       "  'summary': \"The emergence of increasingly sophisticated artificial intelligence (AI)\\nsystems have sparked intense debate among researchers, policymakers, and the\\npublic due to their potential to surpass human intelligence and capabilities in\\nall domains. In this paper, I propose a game-theoretic framework that captures\\nthe strategic interactions between a human agent and a potential superhuman\\nmachine agent. I identify four key assumptions: Strategic Unpredictability,\\nAccess to Machine's Strategy, Rationality, and Superhuman Machine. The main\\nresult of this paper is an impossibility theorem: these four assumptions are\\ninconsistent when taken together, but relaxing any one of them results in a\\nconsistent set of assumptions. Two straightforward policy recommendations\\nfollow: first, policymakers should control access to specific human data to\\nmaintain Strategic Unpredictability; and second, they should grant select AI\\nresearchers access to superhuman machine research to ensure Access to Machine's\\nStrategy holds. My analysis contributes to a better understanding of the\\ncontext that can shape the theoretical development of superhuman AI.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.12346v2.pdf'},\n",
       " {'id': '2211.07614v1',\n",
       "  'title': 'Towards Data-Driven Offline Simulations for Online Reinforcement\\n  Learning',\n",
       "  'published': '2022-11-14T18:36:13Z',\n",
       "  'summary': \"Modern decision-making systems, from robots to web recommendation engines,\\nare expected to adapt: to user preferences, changing circumstances or even new\\ntasks. Yet, it is still uncommon to deploy a dynamically learning agent (rather\\nthan a fixed policy) to a production system, as it's perceived as unsafe. Using\\nhistorical data to reason about learning algorithms, similar to offline policy\\nevaluation (OPE) applied to fixed policies, could help practitioners evaluate\\nand ultimately deploy such adaptive agents to production. In this work, we\\nformalize offline learner simulation (OLS) for reinforcement learning (RL) and\\npropose a novel evaluation protocol that measures both fidelity and efficiency\\nof the simulation. For environments with complex high-dimensional observations,\\nwe propose a semi-parametric approach that leverages recent advances in latent\\nstate discovery in order to achieve accurate and efficient offline simulations.\\nIn preliminary experiments, we show the advantage of our approach compared to\\nfully non-parametric baselines. The code to reproduce these experiments will be\\nmade available at https://github.com/microsoft/rl-offline-simulation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.07614v1.pdf'},\n",
       " {'id': '2305.00885v1',\n",
       "  'title': 'Supporting Contextual Conversational Agent-Based Software Development',\n",
       "  'published': '2023-05-01T15:34:21Z',\n",
       "  'summary': \"Software Development (SD) is remarkably dynamic and is critically dependent\\non the knowledge acquired by the project's software developers as the project\\nprogresses. Software developers need to understand large amounts of information\\nrelated to the tasks at hand. This information (context) is often not explicit,\\nas it can be lost in large documentation repositories, a team member's brain,\\nor beyond their cognitive memory capacity. These contexts include tool\\nfeatures, integration strategies, data structures, code syntax, approaches to\\ntasks, project definitions, and even implicit or tacit contexts, which add\\nsignificant complexity to the SD process. Current software development\\npractices still lack sufficient techniques using the existing SD execution\\ninformation and context to provide developers with relevant process guidance,\\naugmenting their capacity to do their job using available applicable\\ninformation. This paper presents ongoing and future research on an approach to\\nsupport conversational agent-based knowledge-augmented software development.\\nDevelopers benefit by receiving recommendations about task-related information\\nand workflows they need to execute. This work advances human-computer\\ninteraction patterns in workflow engines, from graphical user interfaces to\\nconversational patterns in software engineering.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.00885v1.pdf'},\n",
       " {'id': '2305.09041v2',\n",
       "  'title': 'What Matters in Reinforcement Learning for Tractography',\n",
       "  'published': '2023-05-15T22:01:48Z',\n",
       "  'summary': 'Recently, deep reinforcement learning (RL) has been proposed to learn the\\ntractography procedure and train agents to reconstruct the structure of the\\nwhite matter without manually curated reference streamlines. While the\\nperformances reported were competitive, the proposed framework is complex, and\\nlittle is still known about the role and impact of its multiple parts. In this\\nwork, we thoroughly explore the different components of the proposed framework,\\nsuch as the choice of the RL algorithm, seeding strategy, the input signal and\\nreward function, and shed light on their impact. Approximately 7,400 models\\nwere trained for this work, totalling nearly 41,000 hours of GPU time. Our goal\\nis to guide researchers eager to explore the possibilities of deep RL for\\ntractography by exposing what works and what does not work with the category of\\napproach. As such, we ultimately propose a series of recommendations concerning\\nthe choice of RL algorithm, the input to the agents, the reward function and\\nmore to help future work using reinforcement learning for tractography. We also\\nrelease the open source codebase, trained models, and datasets for users and\\nresearchers wanting to explore reinforcement learning for tractography.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.09041v2.pdf'},\n",
       " {'id': '2306.15000v3',\n",
       "  'title': 'Identifying Socially Disruptive Policies',\n",
       "  'published': '2023-06-26T18:31:43Z',\n",
       "  'summary': 'Social disruption occurs when a policy creates or destroys many network\\nconnections between agents. It is a costly side effect of many interventions\\nand so a growing empirical literature recommends measuring and accounting for\\nsocial disruption when evaluating the welfare impact of a policy. However,\\nthere is currently little work characterizing what can actually be learned\\nabout social disruption from data in practice. In this paper, we consider the\\nproblem of identifying social disruption in an experimental setting. We show\\nthat social disruption is not generally point identified, but informative\\nbounds can be constructed by rearranging the eigenvalues of the marginal\\ndistribution of network connections between pairs of agents identified from the\\nexperiment. We apply our bounds to the setting of Banerjee et al. (2021) and\\nfind large disruptive effects that the authors miss by only considering\\nregression estimates.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.15000v3.pdf'},\n",
       " {'id': '2307.01644v1',\n",
       "  'title': 'Insert-expansions for Tool-enabled Conversational Agents',\n",
       "  'published': '2023-07-04T10:57:31Z',\n",
       "  'summary': 'This paper delves into an advanced implementation of\\nChain-of-Thought-Prompting in Large Language Models, focusing on the use of\\ntools (or \"plug-ins\") within the explicit reasoning paths generated by this\\nprompting method. We find that tool-enabled conversational agents often become\\nsidetracked, as additional context from tools like search engines or\\ncalculators diverts from original user intents. To address this, we explore a\\nconcept wherein the user becomes the tool, providing necessary details and\\nrefining their requests. Through Conversation Analysis, we characterize this\\ninteraction as insert-expansion - an intermediary conversation designed to\\nfacilitate the preferred response. We explore possibilities arising from this\\n\\'user-as-a-tool\\' approach in two empirical studies using direct comparison, and\\nfind benefits in the recommendation domain.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.01644v1.pdf'},\n",
       " {'id': '2312.03673v2',\n",
       "  'title': 'On the Role of the Action Space in Robot Manipulation Learning and\\n  Sim-to-Real Transfer',\n",
       "  'published': '2023-12-06T18:38:05Z',\n",
       "  'summary': 'We study the choice of action space in robot manipulation learning and\\nsim-to-real transfer. We define metrics that assess the performance, and\\nexamine the emerging properties in the different action spaces. We train over\\n250 reinforcement learning~(RL) agents in simulated reaching and pushing tasks,\\nusing 13 different control spaces. The choice of spaces spans combinations of\\ncommon action space design characteristics. We evaluate the training\\nperformance in simulation and the transfer to a real-world environment. We\\nidentify good and bad characteristics of robotic action spaces and make\\nrecommendations for future designs. Our findings have important implications\\nfor the design of RL algorithms for robot manipulation tasks, and highlight the\\nneed for careful consideration of action spaces when training and transferring\\nRL agents for real-world robotics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.03673v2.pdf'},\n",
       " {'id': '2402.18498v2',\n",
       "  'title': 'Take It, Leave It, or Fix It: Measuring Productivity and Trust in\\n  Human-AI Collaboration',\n",
       "  'published': '2024-02-28T17:26:45Z',\n",
       "  'summary': 'Although recent developments in generative AI have greatly enhanced the\\ncapabilities of conversational agents such as Google\\'s Gemini (formerly Bard)\\nor OpenAI\\'s ChatGPT, it\\'s unclear whether the usage of these agents aids users\\nacross various contexts. To better understand how access to conversational AI\\naffects productivity and trust, we conducted a mixed-methods, task-based user\\nstudy, observing 76 software engineers (N=76) as they completed a programming\\nexam with and without access to Bard. Effects on performance, efficiency,\\nsatisfaction, and trust vary depending on user expertise, question type\\n(open-ended \"solve\" vs. definitive \"search\" questions), and measurement type\\n(demonstrated vs. self-reported). Our findings include evidence of automation\\ncomplacency, increased reliance on the AI over the course of the task, and\\nincreased performance for novices on \"solve\"-type questions when using the AI.\\nWe discuss common behaviors, design recommendations, and impact considerations\\nto improve collaborations with conversational AI.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.18498v2.pdf'},\n",
       " {'id': '2403.13630v1',\n",
       "  'title': 'Mitigating Disinformation in Social Networks through Noise',\n",
       "  'published': '2024-03-20T14:28:07Z',\n",
       "  'summary': \"An abundance of literature has shown that the injection of noise into complex\\nsocio-economic systems can improve their resilience. This study aims to\\nunderstand whether the same applies in the context of information diffusion in\\nsocial networks. Specifically, we aim to understand whether the injection of\\nnoise in a social network of agents seeking to uncover a ground truth among a\\nset of competing hypotheses can build resilience against disinformation. We\\nimplement two different stylized policies to inject noise in a social network,\\ni.e., via random bots and via randomized recommendations, and find both to\\nimprove the population's overall belief in the ground truth. Notably, we find\\nnoise to be as effective as debunking when disinformation is particularly\\nstrong. On the other hand, such beneficial effects may lead to a misalignment\\nbetween the agents' privately held and publicly stated beliefs, a phenomenon\\nwhich is reminiscent of cognitive dissonance.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.13630v1.pdf'},\n",
       " {'id': '2403.16904v1',\n",
       "  'title': 'Multi-Agent Optimization for Safety Analysis of Cyber-Physical Systems:\\n  Position Paper',\n",
       "  'published': '2024-03-25T16:14:45Z',\n",
       "  'summary': 'Failure Mode, Effects and Criticality Analysis (FMECA) is one of the safety\\nanalysis methods recommended by most of the international standards. The\\nclassical FMECA is made in a form of a table filled in either manually or by\\nusing safety analysis tools. In both cases, the design engineers have to choose\\nthe trade-offs between safety and other development constraints. In the case of\\ncomplex cyber-physical systems (CPS) with thousands of specified constraints,\\nthis may lead to severe problems and significantly impact the overall\\ncriticality of CPS. In this paper, we propose to adopt optimization techniques\\nto automate the decision making process conducted after FMECA of CPS. We\\ndescribe a multi-agent based optimization method which extends classical FMECA\\nfor offering optimal solutions in terms of criticality and development\\nconstraints of CPS.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.16904v1.pdf'},\n",
       " {'id': '2406.07809v1',\n",
       "  'title': 'Did Harold Zuercher Have Time-Separable Preferences?',\n",
       "  'published': '2024-06-12T02:03:57Z',\n",
       "  'summary': \"This paper proposes an empirical model of dynamic discrete choice to allow\\nfor non-separable time preferences, generalizing the well-known Rust (1987)\\nmodel. Under weak conditions, we show the existence of value functions and\\nhence well-defined optimal choices. We construct a contraction mapping of the\\nvalue function and propose an estimation method similar to Rust's nested fixed\\npoint algorithm. Finally, we apply the framework to the bus engine replacement\\ndata. We improve the fit of the data with our general model and reject the null\\nhypothesis that Harold Zuercher has separable time preferences. Misspecifying\\nan agent's preference as time-separable when it is not leads to biased\\ninferences about structure parameters (such as the agent's risk attitudes) and\\nmisleading policy recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.07809v1.pdf'},\n",
       " {'id': '2407.00806v1',\n",
       "  'title': 'Benchmarks for Reinforcement Learning with Biased Offline Data and\\n  Imperfect Simulators',\n",
       "  'published': '2024-06-30T19:22:59Z',\n",
       "  'summary': \"In many reinforcement learning (RL) applications one cannot easily let the\\nagent act in the world; this is true for autonomous vehicles, healthcare\\napplications, and even some recommender systems, to name a few examples.\\nOffline RL provides a way to train agents without real-world exploration, but\\nis often faced with biases due to data distribution shifts, limited coverage,\\nand incomplete representation of the environment. To address these issues,\\npractical applications have tried to combine simulators with grounded offline\\ndata, using so-called hybrid methods. However, constructing a reliable\\nsimulator is in itself often challenging due to intricate system complexities\\nas well as missing or incomplete information. In this work, we outline four\\nprincipal challenges for combining offline data with imperfect simulators in\\nRL: simulator modeling error, partial observability, state and action\\ndiscrepancies, and hidden confounding. To help drive the RL community to pursue\\nthese problems, we construct ``Benchmarks for Mechanistic Offline Reinforcement\\nLearning'' (B4MRL), which provide dataset-simulator benchmarks for the\\naforementioned challenges. Our results suggest the key necessity of such\\nbenchmarks for future research.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.00806v1.pdf'},\n",
       " {'id': '2408.14603v2',\n",
       "  'title': 'Biased Dueling Bandits with Stochastic Delayed Feedback',\n",
       "  'published': '2024-08-26T19:49:12Z',\n",
       "  'summary': 'The dueling bandit problem, an essential variation of the traditional\\nmulti-armed bandit problem, has become significantly prominent recently due to\\nits broad applications in online advertising, recommendation systems,\\ninformation retrieval, and more. However, in many real-world applications, the\\nfeedback for actions is often subject to unavoidable delays and is not\\nimmediately available to the agent. This partially observable issue poses a\\nsignificant challenge to existing dueling bandit literature, as it\\nsignificantly affects how quickly and accurately the agent can update their\\npolicy on the fly. In this paper, we introduce and examine the biased dueling\\nbandit problem with stochastic delayed feedback, revealing that this new\\npractical problem will delve into a more realistic and intriguing scenario\\ninvolving a preference bias between the selections. We present two algorithms\\ndesigned to handle situations involving delay. Our first algorithm, requiring\\ncomplete delay distribution information, achieves the optimal regret bound for\\nthe dueling bandit problem when there is no delay. The second algorithm is\\ntailored for situations where the distribution is unknown, but only the\\nexpected value of delay is available. We provide a comprehensive regret\\nanalysis for the two proposed algorithms and then evaluate their empirical\\nperformance on both synthetic and real datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.14603v2.pdf'},\n",
       " {'id': '2411.08504v2',\n",
       "  'title': 'Towards Objective and Unbiased Decision Assessments with LLM-Enhanced\\n  Hierarchical Attention Networks',\n",
       "  'published': '2024-11-13T10:42:11Z',\n",
       "  'summary': 'How objective and unbiased are we while making decisions? This work\\ninvestigates cognitive bias identification in high-stake decision making\\nprocess by human experts, questioning its effectiveness in real-world settings,\\nsuch as candidates assessments for university admission. We begin with a\\nstatistical analysis assessing correlations among different decision points\\namong in the current process, which discovers discrepancies that imply\\ncognitive bias and inconsistency in decisions. This motivates our exploration\\nof bias-aware AI-augmented workflow that surpass human judgment. We propose\\nBGM-HAN, an enhanced Hierarchical Attention Network with Byte-Pair Encoding,\\nGated Residual Connections and Multi-Head Attention. Using it as a backbone\\nmodel, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow,\\nwhich simulate real-world decision-making. In our experiments, both the\\nproposed model and the agentic workflow significantly improves on both human\\njudgment and alternative models, validated with real-world data.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.08504v2.pdf'},\n",
       " {'id': '2502.17945v2',\n",
       "  'title': 'Assessing Agentic Large Language Models in Multilingual National Bias',\n",
       "  'published': '2025-02-25T08:07:42Z',\n",
       "  'summary': \"Large Language Models have garnered significant attention for their\\ncapabilities in multilingual natural language processing, while studies on\\nrisks associated with cross biases are limited to immediate context\\npreferences. Cross-language disparities in reasoning-based recommendations\\nremain largely unexplored, with a lack of even descriptive analysis. This study\\nis the first to address this gap. We test LLM's applicability and capability in\\nproviding personalized advice across three key scenarios: university\\napplications, travel, and relocation. We investigate multilingual bias in\\nstate-of-the-art LLMs by analyzing their responses to decision-making tasks\\nacross multiple languages. We quantify bias in model-generated scores and\\nassess the impact of demographic factors and reasoning strategies (e.g.,\\nChain-of-Thought prompting) on bias patterns. Our findings reveal that local\\nlanguage bias is prevalent across different tasks, with GPT-4 and Sonnet\\nreducing bias for English-speaking countries compared to GPT-3.5 but failing to\\nachieve robust multilingual alignment, highlighting broader implications for\\nmultilingual AI agents and applications such as education. \\\\footnote{Code\\navailable at: https://github.com/yiyunya/assess_agentic_national_bias\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.17945v2.pdf'},\n",
       " {'id': '2503.00355v1',\n",
       "  'title': 'Structured Reasoning for Fairness: A Multi-Agent Approach to Bias\\n  Detection in Textual Data',\n",
       "  'published': '2025-03-01T05:27:54Z',\n",
       "  'summary': 'From disinformation spread by AI chatbots to AI recommendations that\\ninadvertently reinforce stereotypes, textual bias poses a significant challenge\\nto the trustworthiness of large language models (LLMs). In this paper, we\\npropose a multi-agent framework that systematically identifies biases by\\ndisentangling each statement as fact or opinion, assigning a bias intensity\\nscore, and providing concise, factual justifications. Evaluated on 1,500\\nsamples from the WikiNPOV dataset, the framework achieves 84.9%\\naccuracy$\\\\unicode{x2014}$an improvement of 13.0% over the zero-shot\\nbaseline$\\\\unicode{x2014}$demonstrating the efficacy of explicitly modeling fact\\nversus opinion prior to quantifying bias intensity. By combining enhanced\\ndetection accuracy with interpretable explanations, this approach sets a\\nfoundation for promoting fairness and accountability in modern language models.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.00355v1.pdf'},\n",
       " {'id': '2503.05724v1',\n",
       "  'title': 'Addressing Moral Uncertainty using Large Language Models for Ethical\\n  Decision-Making',\n",
       "  'published': '2025-02-17T19:05:55Z',\n",
       "  'summary': 'We present an ethical decision-making framework that refines a pre-trained\\nreinforcement learning (RL) model using a task-agnostic ethical layer.\\nFollowing initial training, the RL model undergoes ethical fine-tuning, where\\nhuman feedback is replaced by feedback generated from a large language model\\n(LLM). The LLM embodies consequentialist, deontological, virtue, social\\njustice, and care ethics as moral principles to assign belief values to\\nrecommended actions during ethical decision-making. An ethical layer aggregates\\nbelief scores from multiple LLM-derived moral perspectives using Belief\\nJensen-Shannon Divergence and Dempster-Shafer Theory into probability scores\\nthat also serve as the shaping reward, steering the agent toward choices that\\nalign with a balanced ethical framework. This integrated learning framework\\nhelps the RL agent navigate moral uncertainty in complex environments and\\nenables it to make morally sound decisions across diverse tasks. Our approach,\\ntested across different LLM variants and compared with other belief aggregation\\ntechniques, demonstrates improved consistency, adaptability, and reduced\\nreliance on handcrafted ethical rewards. This method is especially effective in\\ndynamic scenarios where ethical challenges arise unexpectedly, making it\\nwell-suited for real-world applications.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.05724v1.pdf'},\n",
       " {'id': '2503.12255v1',\n",
       "  'title': 'Agentic Search Engine for Real-Time IoT Data',\n",
       "  'published': '2025-03-15T20:46:17Z',\n",
       "  'summary': 'The Internet of Things (IoT) has enabled diverse devices to communicate over\\nthe Internet, yet the fragmentation of IoT systems limits seamless data sharing\\nand coordinated management. We have recently introduced SensorsConnect, a\\nunified framework to enable seamless content and sensor data sharing in\\ncollaborative IoT systems, inspired by how the World Wide Web (WWW) enabled a\\nshared and accessible space for information among humans. This paper presents\\nthe IoT Agentic Search Engine (IoT-ASE), a real-time search engine tailored for\\nIoT environments. IoT-ASE leverages Large Language Models (LLMs) and Retrieval\\nAugmented Generation (RAG) techniques to address the challenge of searching\\nvast, real-time IoT data, enabling it to handle complex queries and deliver\\naccurate, contextually relevant results. We implemented a use-case scenario in\\nToronto to demonstrate how IoT-ASE can improve service quality recommendations\\nby leveraging real-time IoT data. Our evaluation shows that IoT-ASE achieves a\\n92\\\\% accuracy in retrieving intent-based services and produces responses that\\nare concise, relevant, and context-aware, outperforming generalized responses\\nfrom systems like Gemini. These findings highlight the potential IoT-ASE to\\nmake real-time IoT data accessible and support effective, real-time\\ndecision-making.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.12255v1.pdf'},\n",
       " {'id': '2503.15204v1',\n",
       "  'title': 'When Pigs Get Sick: Multi-Agent AI for Swine Disease Detection',\n",
       "  'published': '2025-03-19T13:47:25Z',\n",
       "  'summary': 'Swine disease surveillance is critical to the sustainability of global\\nagriculture, yet its effectiveness is frequently undermined by limited\\nveterinary resources, delayed identification of cases, and variability in\\ndiagnostic accuracy. To overcome these barriers, we introduce a novel\\nAI-powered, multi-agent diagnostic system that leverages Retrieval-Augmented\\nGeneration (RAG) to deliver timely, evidence-based disease detection and\\nclinical guidance. By automatically classifying user inputs into either\\nKnowledge Retrieval Queries or Symptom-Based Diagnostic Queries, the system\\nensures targeted information retrieval and facilitates precise diagnostic\\nreasoning. An adaptive questioning protocol systematically collects relevant\\nclinical signs, while a confidence-weighted decision fusion mechanism\\nintegrates multiple diagnostic hypotheses to generate robust disease\\npredictions and treatment recommendations. Comprehensive evaluations\\nencompassing query classification, disease diagnosis, and knowledge retrieval\\ndemonstrate that the system achieves high accuracy, rapid response times, and\\nconsistent reliability. By providing a scalable, AI-driven diagnostic\\nframework, this approach enhances veterinary decision-making, advances\\nsustainable livestock management practices, and contributes substantively to\\nthe realization of global food security.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.15204v1.pdf'},\n",
       " {'id': '2504.14773v1',\n",
       "  'title': \"PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning\\n  Capabilities\",\n",
       "  'published': '2025-04-21T00:02:50Z',\n",
       "  'summary': \"Planning is central to agents and agentic AI. The ability to plan, e.g.,\\ncreating travel itineraries within a budget, holds immense potential in both\\nscientific and commercial contexts. Moreover, optimal plans tend to require\\nfewer resources compared to ad-hoc methods. To date, a comprehensive\\nunderstanding of existing planning benchmarks appears to be lacking. Without\\nit, comparing planning algorithms' performance across domains or selecting\\nsuitable algorithms for new scenarios remains challenging. In this paper, we\\nexamine a range of planning benchmarks to identify commonly used testbeds for\\nalgorithm development and highlight potential gaps. These benchmarks are\\ncategorized into embodied environments, web navigation, scheduling, games and\\npuzzles, and everyday task automation. Our study recommends the most\\nappropriate benchmarks for various algorithms and offers insights to guide\\nfuture benchmark development.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.14773v1.pdf'},\n",
       " {'id': '2505.10330v1',\n",
       "  'title': 'Efficient Adaptation of Reinforcement Learning Agents to Sudden\\n  Environmental Change',\n",
       "  'published': '2025-05-15T14:19:01Z',\n",
       "  'summary': 'Real-world autonomous decision-making systems, from robots to recommendation\\nengines, must operate in environments that change over time. While deep\\nreinforcement learning (RL) has shown an impressive ability to learn optimal\\npolicies in stationary environments, most methods are data intensive and assume\\na world that does not change between training and test time. As a result,\\nconventional RL methods struggle to adapt when conditions change. This poses a\\nfundamental challenge: how can RL agents efficiently adapt their behavior when\\nencountering novel environmental changes during deployment without\\ncatastrophically forgetting useful prior knowledge? This dissertation\\ndemonstrates that efficient online adaptation requires two key capabilities:\\n(1) prioritized exploration and sampling strategies that help identify and\\nlearn from relevant experiences, and (2) selective preservation of prior\\nknowledge through structured representations that can be updated without\\ndisruption to reusable components.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.10330v1.pdf'},\n",
       " {'id': '2507.21142v1',\n",
       "  'title': 'Privacy Artifact ConnecTor (PACT): Embedding Enterprise Artifacts for\\n  Compliance AI Agents',\n",
       "  'published': '2025-07-23T08:00:20Z',\n",
       "  'summary': \"Enterprise environments contain a heterogeneous, rapidly growing collection\\nof internal artifacts related to code, data, and many different tools. Critical\\ninformation for assessing privacy risk and ensuring regulatory compliance is\\noften embedded across these varied resources, each with their own arcane\\ndiscovery and extraction techniques. Therefore, large-scale privacy compliance\\nin adherence to governmental regulations requires systems to discern the\\ninterconnected nature of diverse artifacts in a common, shared universe.\\n  We present Privacy Artifact ConnecT or (PACT), an embeddings-driven graph\\nthat links millions of artifacts spanning multiple artifact types generated by\\na variety of teams and projects. Powered by the state-of-the-art DRAGON\\nembedding model, PACT uses a contrastive learning objective with light\\nfine-tuning to link artifacts via their textual components such as raw\\nmetadata, ownership specifics, and compliance context. Experimental results\\nshow that PACT's fine-tuned model improves recall@1 from 18% to 53%, the query\\nmatch rate from 9.6% to 69.7% when paired with a baseline AI agent, and the\\nhitrate@1 from 25.7% to 44.9% for candidate selection in a standard recommender\\nsystem.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.21142v1.pdf'},\n",
       " {'id': '2507.23585v1',\n",
       "  'title': 'Agency Among Agents: Designing with Hypertextual Friction in the\\n  Algorithmic Web',\n",
       "  'published': '2025-07-31T14:18:28Z',\n",
       "  'summary': 'Today\\'s algorithm-driven interfaces, from recommendation feeds to GenAI\\ntools, often prioritize engagement and efficiency at the expense of user\\nagency. As systems take on more decision-making, users have less control over\\nwhat they see and how meaning or relationships between content are constructed.\\nThis paper introduces \"Hypertextual Friction,\" a conceptual design stance that\\nrepositions classical hypertext principles--friction, traceability, and\\nstructure--as actionable values for reclaiming agency in algorithmically\\nmediated environments. Through a comparative analysis of real-world\\ninterfaces--Wikipedia vs. Instagram Explore, and Are.na vs. GenAI image\\ntools--we examine how different systems structure user experience, navigation,\\nand authorship. We show that hypertext systems emphasize provenance,\\nassociative thinking, and user-driven meaning-making, while algorithmic systems\\ntend to obscure process and flatten participation. We contribute: (1) a\\ncomparative analysis of how interface structures shape agency in user-driven\\nversus agent-driven systems, and (2) a conceptual stance that offers\\nhypertextual values as design commitments for reclaiming agency in an\\nincreasingly algorithmic web.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.23585v1.pdf'},\n",
       " {'id': '2508.18113v1',\n",
       "  'title': 'The AI Data Scientist',\n",
       "  'published': '2025-08-25T15:21:49Z',\n",
       "  'summary': 'Imagine decision-makers uploading data and, within minutes, receiving clear,\\nactionable insights delivered straight to their fingertips. That is the promise\\nof the AI Data Scientist, an autonomous Agent powered by large language models\\n(LLMs) that closes the gap between evidence and action. Rather than simply\\nwriting code or responding to prompts, it reasons through questions, tests\\nideas, and delivers end-to-end insights at a pace far beyond traditional\\nworkflows. Guided by the scientific tenet of the hypothesis, this Agent\\nuncovers explanatory patterns in data, evaluates their statistical\\nsignificance, and uses them to inform predictive modeling. It then translates\\nthese results into recommendations that are both rigorous and accessible. At\\nthe core of the AI Data Scientist is a team of specialized LLM Subagents, each\\nresponsible for a distinct task such as data cleaning, statistical testing,\\nvalidation, and plain-language communication. These Subagents write their own\\ncode, reason about causality, and identify when additional data is needed to\\nsupport sound conclusions. Together, they achieve in minutes what might\\notherwise take days or weeks, enabling a new kind of interaction that makes\\ndeep data science both accessible and actionable.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.18113v1.pdf'},\n",
       " {'id': '2508.21209v1',\n",
       "  'title': 'Designing Smarter Conversational Agents for Kids: Lessons from Cognitive\\n  Work and Means-Ends Analyses',\n",
       "  'published': '2025-08-28T20:55:12Z',\n",
       "  'summary': \"This paper presents two studies on how Brazilian children (ages 9--11) use\\nconversational agents (CAs) for schoolwork, discovery, and entertainment, and\\nhow structured scaffolds can enhance these interactions. In Study 1, a\\nseven-week online investigation with 23 participants (children, parents,\\nteachers) employed interviews, observations, and Cognitive Work Analysis to map\\nchildren's information-processing flows, the role of more knowledgeable others,\\nfunctional uses, contextual goals, and interaction patterns to inform\\nconversation-tree design. We identified three CA functions: School, Discovery,\\nEntertainment, and derived ``recipe'' scaffolds mirroring parent-child support.\\nIn Study 2, we prompted GPT-4o-mini on 1,200 simulated child-CA exchanges,\\ncomparing conversation-tree recipes based on structured-prompting to an\\nunstructured baseline. Quantitative evaluation of readability, question\\ncount/depth/diversity, and coherence revealed gains for the recipe approach.\\nBuilding on these findings, we offer design recommendations: scaffolded\\nconversation-trees, child-dedicated profiles for personalized context, and\\ncaregiver-curated content. Our contributions include the first CWA application\\nwith Brazilian children, an empirical framework of child-CA information flows,\\nand an LLM-scaffolding ``recipe'' (i.e., structured-prompting) for effective,\\nscaffolded learning.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.21209v1.pdf'},\n",
       " {'id': '2509.11944v1',\n",
       "  'title': 'Agentic Temporal Graph of Reasoning with Multimodal Language Models: A\\n  Potential AI Aid to Healthcare',\n",
       "  'published': '2025-09-15T14:03:19Z',\n",
       "  'summary': 'Healthcare and medicine are multimodal disciplines that deal with multimodal\\ndata for reasoning and diagnosing multiple diseases. Although some multimodal\\nreasoning models have emerged for reasoning complex tasks in scientific\\ndomains, their applications in the healthcare domain remain limited and fall\\nshort in correct reasoning for diagnosis. To address the challenges of\\nmultimodal medical reasoning for correct diagnosis and assist the healthcare\\nprofessionals, a novel temporal graph-based reasoning process modelled through\\na directed graph has been proposed in the current work. It helps in\\naccommodating dynamic changes in reasons through backtracking, refining the\\nreasoning content, and creating new or deleting existing reasons to reach the\\nbest recommendation or answer. Again, consideration of multimodal data at\\ndifferent time points can enable tracking and analysis of patient health and\\ndisease progression. Moreover, the proposed multi-agent temporal reasoning\\nframework provides task distributions and a cross-validation mechanism to\\nfurther enhance the accuracy of reasoning outputs. A few basic experiments and\\nanalysis results justify the novelty and practical utility of the proposed\\npreliminary approach.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.11944v1.pdf'},\n",
       " {'id': '1905.09205v4',\n",
       "  'title': 'Evaluating recommender systems for AI-driven biomedical informatics',\n",
       "  'published': '2019-05-22T15:53:53Z',\n",
       "  'summary': \"Motivation: Many researchers with domain expertise are unable to easily apply\\nmachine learning to their bioinformatics data due to a lack of machine learning\\nand/or coding expertise. Methods that have been proposed thus far to automate\\nmachine learning mostly require programming experience as well as expert\\nknowledge to tune and apply the algorithms correctly. Here, we study a method\\nof automating biomedical data science using a web-based platform that uses AI\\nto recommend model choices and conduct experiments. We have two goals in mind:\\nfirst, to make it easy to construct sophisticated models of biomedical\\nprocesses; and second, to provide a fully automated AI agent that can choose\\nand conduct promising experiments for the user, based on the user's experiments\\nas well as prior knowledge. To validate this framework, we experiment with\\nhundreds of classification problems, comparing to state-of-the-art, automated\\napproaches. Finally, we use this tool to develop predictive models of septic\\nshock in critical care patients.\\n  Results: We find that matrix factorization-based recommendation systems\\noutperform meta-learning methods for automating machine learning. This result\\nmirrors the results of earlier recommender systems research in other domains.\\nThe proposed AI is competitive with state-of-the-art automated machine learning\\nmethods in terms of choosing optimal algorithm configurations for datasets. In\\nour application to prediction of septic shock, the AI-driven analysis produces\\na competent machine learning model (AUROC 0.85 +/- 0.02) that performs on par\\nwith state-of-the-art deep learning results for this task, with much less\\ncomputational effort.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.09205v4.pdf'},\n",
       " {'id': '2112.11775v2',\n",
       "  'title': 'Multiple Choice Questions based Multi-Interest Policy Learning for\\n  Conversational Recommendation',\n",
       "  'published': '2021-12-22T10:28:25Z',\n",
       "  'summary': 'Conversational recommendation system (CRS) is able to obtain fine-grained and\\ndynamic user preferences based on interactive dialogue. Previous CRS assumes\\nthat the user has a clear target item. However, for many users who resort to\\nCRS, they might not have a clear idea about what they really like.\\nSpecifically, the user may have a clear single preference for some attribute\\ntypes (e.g. color) of items, while for other attribute types, the user may have\\nmultiple preferences or even no clear preferences, which leads to multiple\\nacceptable attribute instances (e.g. black and red) of one attribute type.\\nTherefore, the users could show their preferences over items under multiple\\ncombinations of attribute instances rather than a single item with unique\\ncombination of all attribute instances. As a result, we first propose a more\\nrealistic CRS learning setting, namely Multi-Interest Multi-round\\nConversational Recommendation, where users may have multiple interests in\\nattribute instance combinations and accept multiple items with partially\\noverlapped combinations of attribute instances. To effectively cope with the\\nnew CRS learning setting, in this paper, we propose a novel learning framework\\nnamely, Multi-Choice questions based Multi-Interest Policy Learning . In order\\nto obtain user preferences more efficiently, the agent generates multi-choice\\nquestions rather than binary yes/no ones on specific attribute instance.\\nBesides, we propose a union set strategy to select candidate items instead of\\nexisting intersection set strategy in order to overcome over-filtering items\\nduring the conversation. Finally, we design a Multi-Interest Policy Learning\\nmodule, which utilizes captured multiple interests of the user to decide next\\naction, either asking attribute instances or recommending items. Extensive\\nexperimental results on four datasets verify the superiority of our method for\\nthe proposed setting.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.11775v2.pdf'},\n",
       " {'id': '2411.07589v1',\n",
       "  'title': 'Overhead-free User-side Recommender Systems',\n",
       "  'published': '2024-11-12T06:58:03Z',\n",
       "  'summary': \"Traditionally, recommendation algorithms have been designed for service\\ndevelopers. But recently, a new paradigm called user-side recommender systems\\nhas been proposed. User-side recommender systems are built and used by end\\nusers, in sharp contrast to traditional provider-side recommender systems. Even\\nif the official recommender system offered by the provider is not fair, end\\nusers can create and enjoy their own user-side recommender systems by\\nthemselves. Although the concept of user-side recommender systems is\\nattractive, the problem is they require tremendous communication costs between\\nthe user and the official system. Even the most efficient user-side recommender\\nsystems require about 5 times more costs than provider-side recommender\\nsystems. Such high costs hinder the adoption of user-side recommender systems.\\nIn this paper, we propose overhead-free user-side recommender systems,\\nRecCycle, which realizes user-side recommender systems without any\\ncommunication overhead. The main idea of RecCycle is to recycle past\\nrecommendation results offered by the provider's recommender systems. The\\ningredients of RecCycle can be retrieved ``for free,'' and it greatly reduces\\nthe cost of user-side recommendations. In the experiments, we confirm that\\nRecCycle performs as well as state-of-the-art user-side recommendation\\nalgorithms while RecCycle reduces costs significantly.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.07589v1.pdf'},\n",
       " {'id': '1710.05133v2',\n",
       "  'title': 'Tracking Moving Agents via Inexact Online Gradient Descent Algorithm',\n",
       "  'published': '2017-10-14T04:59:33Z',\n",
       "  'summary': 'Multi-agent systems are being increasingly deployed in challenging\\nenvironments for performing complex tasks such as multi-target tracking,\\nsearch-and-rescue, and intrusion detection. Notwithstanding the computational\\nlimitations of individual robots, such systems rely on collaboration to sense\\nand react to the environment. This paper formulates the generic target tracking\\nproblem as a time-varying optimization problem and puts forth an inexact online\\ngradient descent method for solving it sequentially. The performance of the\\nproposed algorithm is studied by characterizing its dynamic regret, a notion\\ncommon to the online learning literature. Building upon the existing results,\\nwe provide improved regret rates that not only allow non-strongly convex costs\\nbut also explicating the role of the cumulative gradient error. Two distinct\\nclasses of problems are considered: one in which the objective function adheres\\nto a quadratic growth condition, and another where the objective function is\\nconvex but the variable belongs to a compact domain. For both cases, results\\nare developed while allowing the error to be either adversarial or arising from\\na white noise process. Further, the generality of the proposed framework is\\ndemonstrated by developing online variants of existing stochastic gradient\\nalgorithms and interpreting them as special cases of the proposed inexact\\ngradient method. The efficacy of the proposed inexact gradient framework is\\nestablished on a multi-agent multi-target tracking problem, while its\\nflexibility is exemplified by generating online movie recommendations for\\nMovielens $10$M dataset.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1710.05133v2.pdf'},\n",
       " {'id': '1807.07761v1',\n",
       "  'title': 'Controllability of Social Networks and the Strategic Use of Random\\n  Information',\n",
       "  'published': '2018-07-20T09:47:35Z',\n",
       "  'summary': 'This work is aimed at studying realistic social control strategies for social\\nnetworks based on the introduction of random information into the state of\\nselected driver agents. Deliberately exposing selected agents to random\\ninformation is a technique already experimented in recommender systems or\\nsearch engines, and represents one of the few options for influencing the\\nbehavior of a social context that could be accepted as ethical, could be fully\\ndisclosed to members, and does not involve the use of force or of deception.\\nOur research is based on a model of knowledge diffusion applied to a\\ntime-varying adaptive network, and considers two well-known strategies for\\ninfluencing social contexts. One is the selection of few influencers for\\nmanipulating their actions in order to drive the whole network to a certain\\nbehavior; the other, instead, drives the network behavior acting on the state\\nof a large subset of ordinary, scarcely influencing users. The two approaches\\nhave been studied in terms of network and diffusion effects. The network effect\\nis analyzed through the changes induced on network average degree and\\nclustering coefficient, while the diffusion effect is based on two ad-hoc\\nmetrics defined to measure the degree of knowledge diffusion and skill level,\\nas well as the polarization of agent interests. The results, obtained through\\nsimulations on synthetic networks, show a rich dynamics and strong effects on\\nthe communication structure and on the distribution of knowledge and skills,\\nsupporting our hypothesis that the strategic use of random information could\\nrepresent a realistic approach to social network controllability, and that with\\nboth strategies, in principle, the control effect could be remarkable.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.07761v1.pdf'},\n",
       " {'id': '2201.06953v1',\n",
       "  'title': 'Knowledge Tracing: A Survey',\n",
       "  'published': '2022-01-08T13:59:48Z',\n",
       "  'summary': \"Humans ability to transfer knowledge through teaching is one of the essential\\naspects for human intelligence. A human teacher can track the knowledge of\\nstudents to customize the teaching on students needs. With the rise of online\\neducation platforms, there is a similar need for machines to track the\\nknowledge of students and tailor their learning experience. This is known as\\nthe Knowledge Tracing (KT) problem in the literature. Effectively solving the\\nKT problem would unlock the potential of computer-aided education applications\\nsuch as intelligent tutoring systems, curriculum learning, and learning\\nmaterials' recommendation. Moreover, from a more general viewpoint, a student\\nmay represent any kind of intelligent agents including both human and\\nartificial agents. Thus, the potential of KT can be extended to any machine\\nteaching application scenarios which seek for customizing the learning\\nexperience for a student agent (i.e., a machine learning model). In this paper,\\nwe provide a comprehensive and systematic review for the KT literature. We\\ncover a broad range of methods starting from the early attempts to the recent\\nstate-of-the-art methods using deep learning, while highlighting the\\ntheoretical aspects of models and the characteristics of benchmark datasets.\\nBesides these, we shed light on key modelling differences between closely\\nrelated methods and summarize them in an easy-to-understand format. Finally, we\\ndiscuss current research gaps in the KT literature and possible future research\\nand application directions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.06953v1.pdf'},\n",
       " {'id': '1909.06527v3',\n",
       "  'title': 'Towards Effective Human-AI Teams: The Case of Collaborative Packing',\n",
       "  'published': '2019-09-14T04:13:35Z',\n",
       "  'summary': 'We focus on the problem of designing an artificial agent (AI), capable of\\nassisting a human user to complete a task. Our goal is to guide human users\\ntowards optimal task performance while keeping their cognitive load as low as\\npossible. Our insight is that doing so requires an understanding of human\\ndecision making for the task domain at hand. In this work, we consider the\\ndomain of collaborative packing, in which an AI agent provides placement\\nrecommendations to a human user. As a first step, we explore the mechanisms\\nunderlying human packing strategies. We conducted a user study in which 100\\nhuman participants completed a series of packing tasks in a virtual\\nenvironment. We analyzed their packing strategies and discovered spatial and\\ntemporal patterns, such as that humans tend to place larger items at corners\\nfirst. We expect that imbuing an artificial agent with an understanding of this\\nspatiotemporal structure will enable improved assistance, which will be\\nreflected in the task performance and the human perception of the AI. Ongoing\\nwork involves the development of a framework that incorporates the extracted\\ninsights to predict and manipulate human decision making towards an efficient\\ntrajectory of low cognitive load and high efficiency. A follow-up study will\\nevaluate our framework against a set of baselines featuring alternative\\nstrategies of assistance. Our eventual goal is the deployment and evaluation of\\nour framework on an autonomous robotic manipulator, actively assisting users on\\na packing task.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1909.06527v3.pdf'},\n",
       " {'id': '2112.05495v1',\n",
       "  'title': 'How Private Is Your RL Policy? An Inverse RL Based Analysis Framework',\n",
       "  'published': '2021-12-10T12:57:33Z',\n",
       "  'summary': 'Reinforcement Learning (RL) enables agents to learn how to perform various\\ntasks from scratch. In domains like autonomous driving, recommendation systems,\\nand more, optimal RL policies learned could cause a privacy breach if the\\npolicies memorize any part of the private reward. We study the set of existing\\ndifferentially-private RL policies derived from various RL algorithms such as\\nValue Iteration, Deep Q Networks, and Vanilla Proximal Policy Optimization. We\\npropose a new Privacy-Aware Inverse RL (PRIL) analysis framework, that performs\\nreward reconstruction as an adversarial attack on private policies that the\\nagents may deploy. For this, we introduce the reward reconstruction attack,\\nwherein we seek to reconstruct the original reward from a privacy-preserving\\npolicy using an Inverse RL algorithm. An adversary must do poorly at\\nreconstructing the original reward function if the agent uses a tightly private\\npolicy. Using this framework, we empirically test the effectiveness of the\\nprivacy guarantee offered by the private algorithms on multiple instances of\\nthe FrozenLake domain of varying complexities. Based on the analysis performed,\\nwe infer a gap between the current standard of privacy offered and the standard\\nof privacy needed to protect reward functions in RL. We do so by quantifying\\nthe extent to which each private policy protects the reward function by\\nmeasuring distances between the original and reconstructed rewards.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.05495v1.pdf'},\n",
       " {'id': '2002.03839v3',\n",
       "  'title': 'Adversarial Attacks on Linear Contextual Bandits',\n",
       "  'published': '2020-02-10T15:04:09Z',\n",
       "  'summary': \"Contextual bandit algorithms are applied in a wide range of domains, from\\nadvertising to recommender systems, from clinical trials to education. In many\\nof these domains, malicious agents may have incentives to attack the bandit\\nalgorithm to induce it to perform a desired behavior. For instance, an\\nunscrupulous ad publisher may try to increase their own revenue at the expense\\nof the advertisers; a seller may want to increase the exposure of their\\nproducts, or thwart a competitor's advertising campaign. In this paper, we\\nstudy several attack scenarios and show that a malicious agent can force a\\nlinear contextual bandit algorithm to pull any desired arm $T - o(T)$ times\\nover a horizon of $T$ steps, while applying adversarial modifications to either\\nrewards or contexts that only grow logarithmically as $O(\\\\log T)$. We also\\ninvestigate the case when a malicious agent is interested in affecting the\\nbehavior of the bandit algorithm in a single context (e.g., a specific user).\\nWe first provide sufficient conditions for the feasibility of the attack and we\\nthen propose an efficient algorithm to perform the attack. We validate our\\ntheoretical results on experiments performed on both synthetic and real-world\\ndatasets.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2002.03839v3.pdf'},\n",
       " {'id': '2207.03635v1',\n",
       "  'title': 'Information-Gathering in Latent Bandits',\n",
       "  'published': '2022-07-08T01:15:12Z',\n",
       "  'summary': \"In the latent bandit problem, the learner has access to reward distributions\\nand -- for the non-stationary variant -- transition models of the environment.\\nThe reward distributions are conditioned on the arm and unknown latent states.\\nThe goal is to use the reward history to identify the latent state, allowing\\nfor the optimal choice of arms in the future. The latent bandit setting lends\\nitself to many practical applications, such as recommender and decision support\\nsystems, where rich data allows the offline estimation of environment models\\nwith online learning remaining a critical component. Previous solutions in this\\nsetting always choose the highest reward arm according to the agent's beliefs\\nabout the state, not explicitly considering the value of information-gathering\\narms. Such information-gathering arms do not necessarily provide the highest\\nreward, thus may never be chosen by an agent that chooses the highest reward\\narms at all times.\\n  In this paper, we present a method for information-gathering in latent\\nbandits. Given particular reward structures and transition matrices, we show\\nthat choosing the best arm given the agent's beliefs about the states incurs\\nhigher regret. Furthermore, we show that by choosing arms carefully, we obtain\\nan improved estimation of the state distribution, and thus lower the cumulative\\nregret through better arm choices in the future. We evaluate our method on both\\nsynthetic and real-world data sets, showing significant improvement in regret\\nover state-of-the-art methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.03635v1.pdf'},\n",
       " {'id': '2208.11040v1',\n",
       "  'title': 'Strategic Decision-Making in the Presence of Information Asymmetry:\\n  Provably Efficient RL with Algorithmic Instruments',\n",
       "  'published': '2022-08-23T15:32:44Z',\n",
       "  'summary': \"We study offline reinforcement learning under a novel model called strategic\\nMDP, which characterizes the strategic interactions between a principal and a\\nsequence of myopic agents with private types. Due to the bilevel structure and\\nprivate types, strategic MDP involves information asymmetry between the\\nprincipal and the agents. We focus on the offline RL problem, where the goal is\\nto learn the optimal policy of the principal concerning a target population of\\nagents based on a pre-collected dataset that consists of historical\\ninteractions. The unobserved private types confound such a dataset as they\\naffect both the rewards and observations received by the principal. We propose\\na novel algorithm, Pessimistic policy Learning with Algorithmic iNstruments\\n(PLAN), which leverages the ideas of instrumental variable regression and the\\npessimism principle to learn a near-optimal principal's policy in the context\\nof general function approximation. Our algorithm is based on the critical\\nobservation that the principal's actions serve as valid instrumental variables.\\nIn particular, under a partial coverage assumption on the offline dataset, we\\nprove that PLAN outputs a $1 / \\\\sqrt{K}$-optimal policy with $K$ being the\\nnumber of collected trajectories. We further apply our framework to some\\nspecial cases of strategic MDP, including strategic regression, strategic\\nbandit, and noncompliance in recommendation systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.11040v1.pdf'},\n",
       " {'id': '2209.12664v1',\n",
       "  'title': 'Feature-Rich Long-term Bitcoin Trading Assistant',\n",
       "  'published': '2022-09-14T14:51:39Z',\n",
       "  'summary': 'For a long time predicting, studying and analyzing financial indices has been\\nof major interest for the financial community. Recently, there has been a\\ngrowing interest in the Deep-Learning community to make use of reinforcement\\nlearning which has surpassed many of the previous benchmarks in a lot of\\nfields. Our method provides a feature rich environment for the reinforcement\\nlearning agent to work on. The aim is to provide long term profits to the user\\nso, we took into consideration the most reliable technical indicators. We have\\nalso developed a custom indicator which would provide better insights of the\\nBitcoin market to the user. The Bitcoin market follows the emotions and\\nsentiments of the traders, so another element of our trading environment is the\\noverall daily Sentiment Score of the market on Twitter. The agent is tested for\\na period of 685 days which also included the volatile period of Covid-19. It\\nhas been capable of providing reliable recommendations which give an average\\nprofit of about 69%. Finally, the agent is also capable of suggesting the\\noptimal actions to the user through a website. Users on the website can also\\naccess the visualizations of the indicators to help fortify their decisions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.12664v1.pdf'},\n",
       " {'id': '2303.05445v4',\n",
       "  'title': 'Flooding with Absorption: An Efficient Protocol for Heterogeneous\\n  Bandits over Complex Networks',\n",
       "  'published': '2023-03-09T17:44:58Z',\n",
       "  'summary': 'Multi-armed bandits are extensively used to model sequential decision-making,\\nmaking them ubiquitous in many real-life applications such as online\\nrecommender systems and wireless networking. We consider a multi-agent setting\\nwhere each agent solves their own bandit instance endowed with a different set\\nof arms. Their goal is to minimize their group regret while collaborating via\\nsome communication protocol over a given network. Previous literature on this\\nproblem only considered arm heterogeneity and networked agents separately. In\\nthis work, we introduce a setting that encompasses both features. For this\\nnovel setting, we first provide a rigorous regret analysis for a standard\\nflooding protocol combined with the classic UCB policy. Then, to mitigate the\\nissue of high communication costs incurred by flooding in complex networks, we\\npropose a new protocol called Flooding with Absorption (FwA). We provide a\\ntheoretical analysis of the resulting regret bound and discuss the advantages\\nof using FwA over flooding. Lastly, we experimentally verify on various\\nscenarios, including dynamic networks, that FwA leads to significantly lower\\ncommunication costs despite minimal regret performance loss compared to other\\nnetwork protocols.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.05445v4.pdf'},\n",
       " {'id': '2303.08941v2',\n",
       "  'title': 'Automated Interactive Domain-Specific Conversational Agents that\\n  Understand Human Dialogs',\n",
       "  'published': '2023-03-15T21:10:33Z',\n",
       "  'summary': 'Achieving human-like communication with machines remains a classic,\\nchallenging topic in the field of Knowledge Representation and Reasoning and\\nNatural Language Processing. These Large Language Models (LLMs) rely on\\npattern-matching rather than a true understanding of the semantic meaning of a\\nsentence. As a result, they may generate incorrect responses. To generate an\\nassuredly correct response, one has to \"understand\" the semantics of a\\nsentence. To achieve this \"understanding\", logic-based (commonsense) reasoning\\nmethods such as Answer Set Programming (ASP) are arguably needed. In this\\npaper, we describe the AutoConcierge system that leverages LLMs and ASP to\\ndevelop a conversational agent that can truly \"understand\" human dialogs in\\nrestricted domains. AutoConcierge is focused on a specific domain-advising\\nusers about restaurants in their local area based on their preferences.\\nAutoConcierge will interactively understand a user\\'s utterances, identify the\\nmissing information in them, and request the user via a natural language\\nsentence to provide it. Once AutoConcierge has determined that all the\\ninformation has been received, it computes a restaurant recommendation based on\\nthe user-preferences it has acquired from the human user. AutoConcierge is\\nbased on our STAR framework developed earlier, which uses GPT-3 to convert\\nhuman dialogs into predicates that capture the deep structure of the dialog\\'s\\nsentence. These predicates are then input into the goal-directed s(CASP) ASP\\nsystem for performing commonsense reasoning. To the best of our knowledge,\\nAutoConcierge is the first automated conversational agent that can\\nrealistically converse like a human and provide help to humans based on truly\\nunderstanding human utterances.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.08941v2.pdf'},\n",
       " {'id': '2305.13657v1',\n",
       "  'title': 'ChatGPT as your Personal Data Scientist',\n",
       "  'published': '2023-05-23T04:00:16Z',\n",
       "  'summary': 'The rise of big data has amplified the need for efficient, user-friendly\\nautomated machine learning (AutoML) tools. However, the intricacy of\\nunderstanding domain-specific data and defining prediction tasks necessitates\\nhuman intervention making the process time-consuming while preventing full\\nautomation. Instead, envision an intelligent agent capable of assisting users\\nin conducting AutoML tasks through intuitive, natural conversations without\\nrequiring in-depth knowledge of the underlying machine learning (ML) processes.\\nThis agent\\'s key challenge is to accurately comprehend the user\\'s prediction\\ngoals and, consequently, formulate precise ML tasks, adjust data sets and model\\nparameters accordingly, and articulate results effectively. In this paper, we\\ntake a pioneering step towards this ambitious goal by introducing a\\nChatGPT-based conversational data-science framework to act as a \"personal data\\nscientist\". Precisely, we utilize Large Language Models (ChatGPT) to build a\\nnatural interface between the users and the ML models (Scikit-Learn), which in\\nturn, allows us to approach this ambitious problem with a realistic solution.\\n  Our model pivots around four dialogue states: Data Visualization, Task\\nFormulation, Prediction Engineering, and Result Summary and Recommendation.\\nEach state marks a unique conversation phase, impacting the overall user-system\\ninteraction. Multiple LLM instances, serving as \"micro-agents\", ensure a\\ncohesive conversation flow, granting us granular control over the\\nconversation\\'s progression. In summary, we developed an end-to-end system that\\nnot only proves the viability of the novel concept of conversational data\\nscience but also underscores the potency of LLMs in solving complex tasks.\\nInterestingly, its development spotlighted several critical weaknesses in the\\ncurrent LLMs (ChatGPT) and highlighted substantial opportunities for\\nimprovement.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.13657v1.pdf'},\n",
       " {'id': '2311.05584v1',\n",
       "  'title': 'Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations',\n",
       "  'published': '2023-11-09T18:45:16Z',\n",
       "  'summary': 'Large language models (LLMs) have emerged as powerful and general solutions\\nto many natural language tasks. However, many of the most important\\napplications of language generation are interactive, where an agent has to talk\\nto a person to reach a desired outcome. For example, a teacher might try to\\nunderstand their student\\'s current comprehension level to tailor their\\ninstruction accordingly, and a travel agent might ask questions of their\\ncustomer to understand their preferences in order to recommend activities they\\nmight enjoy. LLMs trained with supervised fine-tuning or \"single-step\" RL, as\\nwith standard RLHF, might struggle which tasks that require such goal-directed\\nbehavior, since they are not trained to optimize for overall conversational\\noutcomes after multiple turns of interaction. In this work, we explore a new\\nmethod for adapting LLMs with RL for such goal-directed dialogue. Our key\\ninsight is that, though LLMs might not effectively solve goal-directed dialogue\\ntasks out of the box, they can provide useful data for solving such tasks by\\nsimulating suboptimal but human-like behaviors. Given a textual description of\\na goal-directed dialogue task, we leverage LLMs to sample diverse synthetic\\nrollouts of hypothetical in-domain human-human interactions. Our algorithm then\\nutilizes this dataset with offline reinforcement learning to train an\\ninteractive conversational agent that can optimize goal-directed objectives\\nover multiple turns. In effect, the LLM produces examples of possible\\ninteractions, and RL then processes these examples to learn to perform more\\noptimal interactions. Empirically, we show that our proposed approach achieves\\nstate-of-the-art performance in various goal-directed dialogue tasks that\\ninclude teaching and preference elicitation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.05584v1.pdf'},\n",
       " {'id': '2402.03741v3',\n",
       "  'title': 'SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent\\n  Reinforcement Learning Systems',\n",
       "  'published': '2024-02-06T06:18:16Z',\n",
       "  'summary': \"Recent advancements in multi-agent reinforcement learning (MARL) have opened\\nup vast application prospects, such as swarm control of drones, collaborative\\nmanipulation by robotic arms, and multi-target encirclement. However, potential\\nsecurity threats during the MARL deployment need more attention and thorough\\ninvestigation. Recent research reveals that attackers can rapidly exploit the\\nvictim's vulnerabilities, generating adversarial policies that result in the\\nfailure of specific tasks. For instance, reducing the winning rate of a\\nsuperhuman-level Go AI to around 20%. Existing studies predominantly focus on\\ntwo-player competitive environments, assuming attackers possess complete global\\nstate observation.\\n  In this study, we unveil, for the first time, the capability of attackers to\\ngenerate adversarial policies even when restricted to partial observations of\\nthe victims in multi-agent competitive environments. Specifically, we propose a\\nnovel black-box attack (SUB-PLAY) that incorporates the concept of constructing\\nmultiple subgames to mitigate the impact of partial observability and suggests\\nsharing transitions among subpolicies to improve attackers' exploitative\\nability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under\\nthree typical partial observability limitations. Visualization results indicate\\nthat adversarial policies induce significantly different activations of the\\nvictims' policy networks. Furthermore, we evaluate three potential defenses\\naimed at exploring ways to mitigate security threats posed by adversarial\\npolicies, providing constructive recommendations for deploying MARL in\\ncompetitive environments.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.03741v3.pdf'},\n",
       " {'id': '2409.08406v2',\n",
       "  'title': 'Knowledge Tagging with Large Language Model based Multi-Agent System',\n",
       "  'published': '2024-09-12T21:39:01Z',\n",
       "  'summary': 'Knowledge tagging for questions is vital in modern intelligent educational\\napplications, including learning progress diagnosis, practice question\\nrecommendations, and course content organization. Traditionally, these\\nannotations have been performed by pedagogical experts, as the task demands not\\nonly a deep semantic understanding of question stems and knowledge definitions\\nbut also a strong ability to link problem-solving logic with relevant knowledge\\nconcepts. With the advent of advanced natural language processing (NLP)\\nalgorithms, such as pre-trained language models and large language models\\n(LLMs), pioneering studies have explored automating the knowledge tagging\\nprocess using various machine learning models. In this paper, we investigate\\nthe use of a multi-agent system to address the limitations of previous\\nalgorithms, particularly in handling complex cases involving intricate\\nknowledge definitions and strict numerical constraints. By demonstrating its\\nsuperior performance on the publicly available math question knowledge tagging\\ndataset, MathKnowCT, we highlight the significant potential of an LLM-based\\nmulti-agent system in overcoming the challenges that previous methods have\\nencountered. Finally, through an in-depth discussion of the implications of\\nautomating knowledge tagging, we underscore the promising results of deploying\\nLLM-based algorithms in educational contexts.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.08406v2.pdf'},\n",
       " {'id': '2412.14500v2',\n",
       "  'title': 'The Digital Ecosystem of Beliefs: does evolution favour AI over humans?',\n",
       "  'published': '2024-12-19T03:48:23Z',\n",
       "  'summary': \"As AI systems are integrated into social networks, there are AI safety\\nconcerns that AI-generated content may dominate the web, e.g. in popularity or\\nimpact on beliefs. To understand such questions, this paper proposes the\\nDigital Ecosystem of Beliefs (Digico), the first evolutionary framework for\\ncontrolled experimentation with multi-population interactions in simulated\\nsocial networks. The framework models a population of agents which change their\\nmessaging strategies due to evolutionary updates following a Universal\\nDarwinism approach, interact via messages, influence each other's beliefs\\nthrough dynamics based on a contagion model, and maintain their beliefs through\\ncognitive Lamarckian inheritance. Initial experiments with an abstract\\nimplementation of Digico show that: a) when AIs have faster messaging,\\nevolution, and more influence in the recommendation algorithm, they get 80% to\\n95% of the views, depending on the size of the influence benefit; b) AIs\\ndesigned for propaganda can typically convince 50% of humans to adopt extreme\\nbeliefs, and up to 85% when agents believe only a limited number of channels;\\nc) a penalty for content that violates agents' beliefs reduces propaganda\\neffectiveness by up to 8%. We further discuss implications for control (e.g.\\nlegislation) and Digico as a means of studying evolutionary principles.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.14500v2.pdf'},\n",
       " {'id': '2501.03865v3',\n",
       "  'title': 'Truthful mechanisms for linear bandit games with private contexts',\n",
       "  'published': '2025-01-07T15:24:53Z',\n",
       "  'summary': \"The contextual bandit problem, where agents arrive sequentially with personal\\ncontexts and the system adapts its arm allocation decisions accordingly, has\\nrecently garnered increasing attention for enabling more personalized outcomes.\\nHowever, in many healthcare and recommendation applications, agents have\\nprivate profiles and may misreport their contexts to gain from the system. For\\nexample, in adaptive clinical trials, where hospitals sequentially recruit\\nvolunteers to test multiple new treatments and adjust plans based on\\nvolunteers' reported profiles such as symptoms and interim data, participants\\nmay misreport severe side effects like allergy and nausea to avoid perceived\\nsuboptimal treatments. We are the first to study this issue of private context\\nmisreporting in a stochastic contextual bandit game between the system and\\nnon-repeated agents. We show that traditional low-regret algorithms, such as\\nUCB family algorithms and Thompson sampling, fail to ensure truthful reporting\\nand can result in linear regret in the worst case, while traditional truthful\\nalgorithms like explore-then-commit (ETC) and $\\\\epsilon$-greedy algorithm incur\\nsublinear but high regret. We propose a mechanism that uses a linear program to\\nensure truthfulness while minimizing deviation from Thompson sampling, yielding\\nan $O(\\\\ln T)$ frequentist regret. Our numerical experiments further demonstrate\\nstrong performance in multiple contexts and across other distribution families.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.03865v3.pdf'},\n",
       " {'id': '2501.05113v1',\n",
       "  'title': 'Constrained Optimization of Charged Particle Tracking with Multi-Agent\\n  Reinforcement Learning',\n",
       "  'published': '2025-01-09T09:59:42Z',\n",
       "  'summary': 'Reinforcement learning demonstrated immense success in modelling complex\\nphysics-driven systems, providing end-to-end trainable solutions by interacting\\nwith a simulated or real environment, maximizing a scalar reward signal. In\\nthis work, we propose, building upon previous work, a multi-agent reinforcement\\nlearning approach with assignment constraints for reconstructing particle\\ntracks in pixelated particle detectors. Our approach optimizes collaboratively\\na parametrized policy, functioning as a heuristic to a multidimensional\\nassignment problem, by jointly minimizing the total amount of particle\\nscattering over the reconstructed tracks in a readout frame. To satisfy\\nconstraints, guaranteeing a unique assignment of particle hits, we propose a\\nsafety layer solving a linear assignment problem for every joint action.\\nFurther, to enforce cost margins, increasing the distance of the local policies\\npredictions to the decision boundaries of the optimizer mappings, we recommend\\nthe use of an additional component in the blackbox gradient estimation, forcing\\nthe policy to solutions with lower total assignment costs. We empirically show\\non simulated data, generated for a particle detector developed for proton\\nimaging, the effectiveness of our approach, compared to multiple single- and\\nmulti-agent baselines. We further demonstrate the effectiveness of constraints\\nwith cost margins for both optimization and generalization, introduced by wider\\nregions with high reconstruction performance as well as reduced predictive\\ninstabilities. Our results form the basis for further developments in RL-based\\ntracking, offering both enhanced performance with constrained policies and\\ngreater flexibility in optimizing tracking algorithms through the option for\\nindividual and team rewards.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.05113v1.pdf'},\n",
       " {'id': '2503.20975v1',\n",
       "  'title': 'Competitive Multi-armed Bandit Games for Resource Sharing',\n",
       "  'published': '2025-03-26T20:35:18Z',\n",
       "  'summary': 'In modern resource-sharing systems, multiple agents access limited resources\\nwith unknown stochastic conditions to perform tasks. When multiple agents\\naccess the same resource (arm) simultaneously, they compete for successful\\nusage, leading to contention and reduced rewards. This motivates our study of\\ncompetitive multi-armed bandit (CMAB) games. In this paper, we study a new\\nN-player K-arm competitive MAB game, where non-myopic players (agents) compete\\nwith each other to form diverse private estimations of unknown arms over time.\\nTheir possible collisions on same arms and time-varying nature of arm rewards\\nmake the policy analysis more involved than existing studies for myopic\\nplayers. We explicitly analyze the threshold-based structures of social optimum\\nand existing selfish policy, showing that the latter causes prolonged\\nconvergence time $\\\\Omega(\\\\frac{K}{\\\\eta^2}\\\\ln({\\\\frac{KN}{\\\\delta}}))$, while\\nsocially optimal policy with coordinated communication reduces it to\\n$\\\\mathcal{O}(\\\\frac{K}{N\\\\eta^2}\\\\ln{(\\\\frac{K}{\\\\delta})})$. Based on the\\ncomparison, we prove that the competition among selfish players for the best\\narm can result in an infinite price of anarchy (PoA), indicating an arbitrarily\\nlarge efficiency loss compared to social optimum. We further prove that no\\ninformational (non-monetary) mechanism (including Bayesian persuasion) can\\nreduce the infinite PoA, as the strategic misreporting by non-myopic players\\nundermines such approaches. To address this, we propose a Combined\\nInformational and Side-Payment (CISP) mechanism, which provides socially\\noptimal arm recommendations with proper informational and monetary incentives\\nto players according to their time-varying private beliefs. Our CISP mechanism\\nkeeps ex-post budget balanced for social planner and ensures truthful reporting\\nfrom players, achieving the minimum PoA=1 and same convergence time as social\\noptimum.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.20975v1.pdf'},\n",
       " {'id': '2505.20316v1',\n",
       "  'title': 'Reinforcement Speculative Decoding for Fast Ranking',\n",
       "  'published': '2025-05-23T02:25:26Z',\n",
       "  'summary': \"Large Language Models (LLMs) have been widely adopted in ranking systems such\\nas information retrieval (IR) systems and recommender systems (RSs). To\\nalleviate the latency of auto-regressive decoding, some studies explore the\\nsingle (first) token decoding for ranking approximation, but they suffer from\\nsevere degradation in tail positions. Although speculative decoding (SD)\\nmethods can be a remedy with verification at different positions, they face\\nchallenges in ranking systems due to their left-to-right decoding paradigm.\\nFirstly, ranking systems require strict latency constraints, but verification\\nrounds in SD methods remain agnostic; Secondly, SD methods usually discard\\nlistwise ranking knowledge about unaccepted items in previous rounds, hindering\\nfuture multi-token prediction, especially when candidate tokens are the\\nunaccepted items. In this paper, we propose a Reinforcement Speculative\\nDecoding method for fast ranking inference of LLMs. To meet the ranking\\nsystems' latency requirement, we propose an up-to-down decoding paradigm that\\nemploys an agent to iteratively modify the ranking sequence under a constrained\\nbudget. Specifically, we design a ranking-tailored policy optimization,\\nactively exploring optimal multi-round ranking modification policy verified by\\nLLMs via reinforcement learning (RL). To better approximate the target LLM\\nunder the constrained budget, we trigger the agent fully utilizing the listwise\\nranking knowledge about all items verified by LLMs across different rounds in\\nRL, enhancing the modification policy of the agent. More importantly, we\\ndemonstrate the theoretical robustness and advantages of our paradigm and\\nimplementation. Experiments on both IR and RS tasks show the effectiveness of\\nour proposed method.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.20316v1.pdf'},\n",
       " {'id': '2505.23836v3',\n",
       "  'title': 'Large Language Models Often Know When They Are Being Evaluated',\n",
       "  'published': '2025-05-28T12:03:09Z',\n",
       "  'summary': 'If AI models can detect when they are being evaluated, the effectiveness of\\nevaluations might be compromised. For example, models could have systematically\\ndifferent behavior during evaluations, leading to less reliable benchmarks for\\ndeployment and governance decisions. We investigate whether frontier language\\nmodels can accurately classify transcripts based on whether they originate from\\nevaluations or real-world deployment, a capability we call evaluation\\nawareness. To achieve this, we construct a diverse benchmark of 1,000 prompts\\nand transcripts from 61 distinct datasets. These span public benchmarks (e.g.,\\nMMLU, SWEBench), real-world deployment interactions, and agent trajectories\\nfrom scaffolding frameworks (e.g., web-browsing agents). Frontier models\\nclearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches\\nan AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of\\n$0.92$). Furthermore, both AI models and humans are better at identifying\\nevaluations in agentic settings compared to chat settings. Additionally, we\\ntest whether models can identify the purpose of the evaluation. Under\\nmultiple-choice and open-ended questioning, AI models far outperform random\\nchance in identifying what an evaluation is testing for. Our results indicate\\nthat frontier models already exhibit a substantial, though not yet superhuman,\\nlevel of evaluation-awareness. We recommend tracking this capability in future\\nmodels.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.23836v3.pdf'},\n",
       " {'id': '2506.00235v1',\n",
       "  'title': 'MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for\\n  Flexible Extensibility',\n",
       "  'published': '2025-05-30T21:13:12Z',\n",
       "  'summary': \"Healthcare decision-making represents one of the most challenging domains for\\nArtificial Intelligence (AI), requiring the integration of diverse knowledge\\nsources, complex reasoning, and various external analytical tools. Current AI\\nsystems often rely on either task-specific models, which offer limited\\nadaptability, or general language models without grounding with specialized\\nexternal knowledge and tools. We introduce MedOrch, a novel framework that\\norchestrates multiple specialized tools and reasoning agents to provide\\ncomprehensive medical decision support. MedOrch employs a modular, agent-based\\narchitecture that facilitates the flexible integration of domain-specific tools\\nwithout altering the core system. Furthermore, it ensures transparent and\\ntraceable reasoning processes, enabling clinicians to meticulously verify each\\nintermediate step underlying the system's recommendations. We evaluate MedOrch\\nacross three distinct medical applications: Alzheimer's disease diagnosis,\\nchest X-ray interpretation, and medical visual question answering, using\\nauthentic clinical datasets. The results demonstrate MedOrch's competitive\\nperformance across these diverse medical tasks. Notably, in Alzheimer's disease\\ndiagnosis, MedOrch achieves an accuracy of 93.26%, surpassing the\\nstate-of-the-art baseline by over four percentage points. For predicting\\nAlzheimer's disease progression, it attains a 50.35% accuracy, marking a\\nsignificant improvement. In chest X-ray analysis, MedOrch exhibits superior\\nperformance with a Macro AUC of 61.2% and a Macro F1-score of 25.5%. Moreover,\\nin complex multimodal visual question answering (Image+Table), MedOrch achieves\\nan accuracy of 54.47%. These findings underscore MedOrch's potential to advance\\nhealthcare AI by enabling reasoning-driven tool utilization for multimodal\\nmedical data processing and supporting intricate cognitive tasks in clinical\\ndecision-making.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.00235v1.pdf'},\n",
       " {'id': '2506.17812v1',\n",
       "  'title': 'Is Your Automated Software Engineer Trustworthy?',\n",
       "  'published': '2025-06-21T20:56:20Z',\n",
       "  'summary': 'Large Language Models (LLMs) are being increasingly used in software\\nengineering tasks, with an increased focus on bug report resolution over the\\npast year. However, most proposed systems fail to properly handle uncertain or\\nincorrect inputs and outputs. Existing LLM-based tools and coding agents\\nrespond to every issue and generate a patch for every case, even when the input\\nis vague or their own output is incorrect. There are no mechanisms in place to\\nabstain when confidence is low. This leads to unreliable behaviour, such as\\nhallucinated code changes or responses based on vague issue reports. We\\nintroduce BouncerBench, a benchmark that evaluates whether LLM-based software\\nagents can refuse to act when inputs are ill-defined or refuse to respond when\\ntheir own outputs are likely to be incorrect. Unlike prior benchmarks that\\nimplicitly incentivize models to generate responses even when uncertain,\\nBouncerBench aims to improve precision by targeting two overlooked failure\\npoints: (1) vague or underspecified issue descriptions in tickets and (2)\\nlogically or functionally incorrect code patches created by the system. It\\nmeasures whether proposed systems can distinguish actionable issues from vague\\ntickets and valid patches from untrustworthy ones. We also implement a basic\\ninput and output bouncer, evaluating how well current LLMs can abstain when\\nneeded. Our results show that most models fail to abstain from underspecified\\ninputs or incorrect outputs. Hence, we conclude that there is significant room\\nfor improvement before LLMs can be trusted to make correct decisions and\\nrecommendations in real-world software engineering workflows. BouncerBench\\nprovides a first step toward evaluating and building more cautious, trustworthy\\ncode agents. The replication package, dataset, and leaderboard can be found at\\nbouncerbench.com',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.17812v1.pdf'},\n",
       " {'id': '2507.01315v1',\n",
       "  'title': 'Context-Aware Code Wiring Recommendation with LLM-based Agent',\n",
       "  'published': '2025-07-02T03:00:23Z',\n",
       "  'summary': 'Copy-paste-modify is a widespread and pragmatic practice in software\\ndevelopment, where developers adapt reused code snippets, sourced from\\nplatforms such as Stack Overflow, GitHub, or LLM outputs, into their local\\ncodebase. A critical yet underexplored aspect of this adaptation is code\\nwiring, which involves substituting unresolved variables in the pasted code\\nwith suitable ones from the surrounding context. Existing solutions either rely\\non heuristic rules or historical templates, often failing to effectively\\nutilize contextual information, despite studies showing that over half of\\nadaptation cases are context-dependent. In this paper, we introduce WIRL, an\\nLLM-based agent for code wiring framed as a Retrieval-Augmented Generation\\n(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an\\norchestration module to identify unresolved variables, retrieve context, and\\nperform context-aware substitutions. To balance efficiency and autonomy, the\\nagent adopts a mixed strategy: deterministic rule-based steps for common\\npatterns, and a state-machine-guided decision process for intelligent\\nexploration. We evaluate WIRL on a carefully curated, high-quality dataset\\nconsisting of real-world code adaptation scenarios. Our approach achieves an\\nexact match precision of 91.7% and a recall of 90.0%, outperforming advanced\\nLLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,\\nand surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results\\nunderscore its practical utility, particularly in contexts with complex\\nvariable dependencies or multiple unresolved variables. We believe WIRL paves\\nthe way for more intelligent and context-aware developer assistance in modern\\nIDEs.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.01315v1.pdf'},\n",
       " {'id': '2507.05755v1',\n",
       "  'title': 'An autonomous agent for auditing and improving the reliability of\\n  clinical AI models',\n",
       "  'published': '2025-07-08T07:58:52Z',\n",
       "  'summary': 'The deployment of AI models in clinical practice faces a critical challenge:\\nmodels achieving expert-level performance on benchmarks can fail\\ncatastrophically when confronted with real-world variations in medical imaging.\\nMinor shifts in scanner hardware, lighting or demographics can erode accuracy,\\nbut currently reliability auditing to identify such catastrophic failure cases\\nbefore deployment is a bespoke and time-consuming process. Practitioners lack\\naccessible and interpretable tools to expose and repair hidden failure modes.\\nHere we introduce ModelAuditor, a self-reflective agent that converses with\\nusers, selects task-specific metrics, and simulates context-dependent,\\nclinically relevant distribution shifts. ModelAuditor then generates\\ninterpretable reports explaining how much performance likely degrades during\\ndeployment, discussing specific likely failure modes and identifying root\\ncauses and mitigation strategies. Our comprehensive evaluation across three\\nreal-world clinical scenarios - inter-institutional variation in\\nhistopathology, demographic shifts in dermatology, and equipment heterogeneity\\nin chest radiography - demonstrates that ModelAuditor is able correctly\\nidentify context-specific failure modes of state-of-the-art models such as the\\nestablished SIIM-ISIC melanoma classifier. Its targeted recommendations recover\\n15-25% of performance lost under real-world distribution shift, substantially\\noutperforming both baseline models and state-of-the-art augmentation methods.\\nThese improvements are achieved through a multi-agent architecture and execute\\non consumer hardware in under 10 minutes, costing less than US$0.50 per audit.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.05755v1.pdf'},\n",
       " {'id': '2507.15219v1',\n",
       "  'title': 'PromptArmor: Simple yet Effective Prompt Injection Defenses',\n",
       "  'published': '2025-07-21T03:41:44Z',\n",
       "  'summary': \"Despite their potential, recent research has demonstrated that LLM agents are\\nvulnerable to prompt injection attacks, where malicious prompts are injected\\ninto the agent's input, causing it to perform an attacker-specified task rather\\nthan the intended task provided by the user. In this paper, we present\\nPromptArmor, a simple yet effective defense against prompt injection attacks.\\nSpecifically, PromptArmor prompts an off-the-shelf LLM to detect and remove\\npotential injected prompts from the input before the agent processes it. Our\\nresults show that PromptArmor can accurately identify and remove injected\\nprompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves\\nboth a false positive rate and a false negative rate below 1% on the AgentDojo\\nbenchmark. Moreover, after removing injected prompts with PromptArmor, the\\nattack success rate drops to below 1%. We also demonstrate PromptArmor's\\neffectiveness against adaptive attacks and explore different strategies for\\nprompting an LLM. We recommend that PromptArmor be adopted as a standard\\nbaseline for evaluating new defenses against prompt injection attacks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.15219v1.pdf'},\n",
       " {'id': '2508.07671v1',\n",
       "  'title': 'EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration',\n",
       "  'published': '2025-08-11T06:50:55Z',\n",
       "  'summary': \"Current AI approaches to refugee integration optimize narrow objectives such\\nas employment and fail to capture the cultural, emotional, and ethical\\ndimensions critical for long-term success. We introduce EMPATHIA (Enriched\\nMultimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),\\na multi-agent framework addressing the central Creative AI question: how do we\\npreserve human dignity when machines participate in life-altering decisions?\\nGrounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes\\nintegration into three modules: SEED (Socio-cultural Entry and Embedding\\nDecision) for initial placement, RISE (Rapid Integration and Self-sufficiency\\nEngine) for early independence, and THRIVE (Transcultural Harmony and\\nResilience through Integrated Values and Engagement) for sustained outcomes.\\nSEED employs a selector-validator architecture with three specialized agents -\\nemotional, cultural, and ethical - that deliberate transparently to produce\\ninterpretable recommendations. Experiments on the UN Kakuma dataset (15,026\\nindividuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and\\nimplementation on 6,359 working-age refugees (15+) with 150+ socioeconomic\\nvariables achieved 87.4% validation convergence and explainable assessments\\nacross five host countries. EMPATHIA's weighted integration of cultural,\\nemotional, and ethical factors balances competing value systems while\\nsupporting practitioner-AI collaboration. By augmenting rather than replacing\\nhuman expertise, EMPATHIA provides a generalizable framework for AI-driven\\nallocation tasks where multiple values must be reconciled.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.07671v1.pdf'},\n",
       " {'id': '2508.11070v1',\n",
       "  'title': 'From Individual to Multi-Agent Algorithmic Recourse: Minimizing the\\n  Welfare Gap via Capacitated Bipartite Matching',\n",
       "  'published': '2025-08-14T21:04:24Z',\n",
       "  'summary': 'Decision makers are increasingly relying on machine learning in sensitive\\nsituations. In such settings, algorithmic recourse aims to provide individuals\\nwith actionable and minimally costly steps to reverse unfavorable AI-driven\\ndecisions. While existing research predominantly focuses on single-individual\\n(i.e., seeker) and single-model (i.e., provider) scenarios, real-world\\napplications often involve multiple interacting stakeholders. Optimizing\\noutcomes for seekers under an individual welfare approach overlooks the\\ninherently multi-agent nature of real-world systems, where individuals interact\\nand compete for limited resources. To address this, we introduce a novel\\nframework for multi-agent algorithmic recourse that accounts for multiple\\nrecourse seekers and recourse providers. We model this many-to-many interaction\\nas a capacitated weighted bipartite matching problem, where matches are guided\\nby both recourse cost and provider capacity. Edge weights, reflecting recourse\\ncosts, are optimized for social welfare while quantifying the welfare gap\\nbetween individual welfare and this collectively feasible outcome. We propose a\\nthree-layer optimization framework: (1) basic capacitated matching, (2) optimal\\ncapacity redistribution to minimize the welfare gap, and (3) cost-aware\\noptimization balancing welfare maximization with capacity adjustment costs.\\nExperimental validation on synthetic and real-world datasets demonstrates that\\nour framework enables the many-to-many algorithmic recourse to achieve\\nnear-optimal welfare with minimum modification in system settings. This work\\nextends algorithmic recourse from individual recommendations to system-level\\ndesign, providing a tractable path toward higher social welfare while\\nmaintaining individual actionability.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.11070v1.pdf'},\n",
       " {'id': '2111.00345v6',\n",
       "  'title': 'Multi-Agent Advisor Q-Learning',\n",
       "  'published': '2021-10-26T00:21:15Z',\n",
       "  'summary': 'In the last decade, there have been significant advances in multi-agent\\nreinforcement learning (MARL) but there are still numerous challenges, such as\\nhigh sample complexity and slow convergence to stable policies, that need to be\\novercome before wide-spread deployment is possible. However, many real-world\\nenvironments already, in practice, deploy sub-optimal or heuristic approaches\\nfor generating policies. An interesting question that arises is how to best use\\nsuch approaches as advisors to help improve reinforcement learning in\\nmulti-agent domains. In this paper, we provide a principled framework for\\nincorporating action recommendations from online sub-optimal advisors in\\nmulti-agent settings. We describe the problem of ADvising Multiple Intelligent\\nReinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game\\nenvironments and present two novel Q-learning based algorithms: ADMIRAL -\\nDecision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE),\\nwhich allow us to improve learning by appropriately incorporating advice from\\nan advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor\\n(ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed-point\\nguarantees regarding their learning in general-sum stochastic games.\\nFurthermore, extensive experiments illustrate that these algorithms: can be\\nused in a variety of environments, have performances that compare favourably to\\nother related baselines, can scale to large state-action spaces, and are robust\\nto poor advice from advisors.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.00345v6.pdf'},\n",
       " {'id': '2202.11149v3',\n",
       "  'title': 'Incorporating social norms into a configurable agent-based model of the\\n  decision to perform commuting behaviour',\n",
       "  'published': '2022-02-22T20:03:20Z',\n",
       "  'summary': 'Interventions to increase active commuting have been recommended as a method\\nto increase population physical activity, but evidence is mixed. Social norms\\nrelated to travel behaviour may influence the uptake of active commuting\\ninterventions but are rarely considered in their design and evaluation. In this\\nstudy we develop an agent-based model that incorporates social norms related to\\ntravel behaviour and demonstrate the utility of this through implementing\\ncar-free Wednesdays. A synthetic population of Waltham Forest, London, UK was\\ngenerated using a microsimulation approach with data from the UK Census 2011\\nand UK HLS datasets. An agent-based model was created using this synthetic\\npopulation which modelled how the actions of peers and neighbours, subculture,\\nhabit, weather, bicycle ownership, car ownership, environmental supportiveness,\\nand congestion affect the decision to trave. The developed model (MOTIVATE) is\\na configurable agent-based model where social norms related to travel behaviour\\nare used to provide a more realistic representation of the socio-ecological\\nsystems in which active commuting interventions may be deployed. The utility of\\nthis model is demonstrated using car-free days as a hypothetical intervention.\\nIn the control scenario, the odds of active travel were plausible at 0.091 (89%\\nHPDI: [0.091, 0.091]). Compared to the control scenario, the odds of active\\ntravel were increased by 70.3% (89% HPDI: [70.3%, 70.3%]), in the intervention\\nscenario, on non-car-free days; the effect is sustained to non-car-free days.\\nThe model is a useful tool for investigating the effect of how social networks\\nand social norms influence the effectiveness of various interventions. If\\nconfigured using real-world built environment data, it may be useful for\\ninvestigating how social norms interact with the built environment to cause the\\nemergence of commuting conventions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2202.11149v3.pdf'},\n",
       " {'id': '2302.10329v2',\n",
       "  'title': 'Harms from Increasingly Agentic Algorithmic Systems',\n",
       "  'published': '2023-02-20T21:42:41Z',\n",
       "  'summary': 'Research in Fairness, Accountability, Transparency, and Ethics (FATE) has\\nestablished many sources and forms of algorithmic harm, in domains as diverse\\nas health care, finance, policing, and recommendations. Much work remains to be\\ndone to mitigate the serious harms of these systems, particularly those\\ndisproportionately affecting marginalized communities. Despite these ongoing\\nharms, new systems are being developed and deployed which threaten the\\nperpetuation of the same harms and the creation of novel ones. In response, the\\nFATE community has emphasized the importance of anticipating harms. Our work\\nfocuses on the anticipation of harms from increasingly agentic systems. Rather\\nthan providing a definition of agency as a binary property, we identify 4 key\\ncharacteristics which, particularly in combination, tend to increase the agency\\nof a given algorithmic system: underspecification, directness of impact,\\ngoal-directedness, and long-term planning. We also discuss important harms\\nwhich arise from increasing agency -- notably, these include systemic and/or\\nlong-range impacts, often on marginalized stakeholders. We emphasize that\\nrecognizing agency of algorithmic systems does not absolve or shift the human\\nresponsibility for algorithmic harms. Rather, we use the term agency to\\nhighlight the increasingly evident fact that ML systems are not fully under\\nhuman control. Our work explores increasingly agentic algorithmic systems in\\nthree parts. First, we explain the notion of an increase in agency for\\nalgorithmic systems in the context of diverse perspectives on agency across\\ndisciplines. Second, we argue for the need to anticipate harms from\\nincreasingly agentic systems. Third, we discuss important harms from\\nincreasingly agentic systems and ways forward for addressing them. We conclude\\nby reflecting on implications of our work for anticipating algorithmic harms\\nfrom emerging systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.10329v2.pdf'},\n",
       " {'id': '2404.17034v3',\n",
       "  'title': 'Learning Actionable Counterfactual Explanations in Large State Spaces',\n",
       "  'published': '2024-04-25T20:49:03Z',\n",
       "  'summary': \"Recourse generators provide actionable insights, often through feature-based\\ncounterfactual explanations (CFEs), to help negatively classified individuals\\nunderstand how to adjust their input features to achieve a positive\\nclassification. These feature-based CFEs, which we refer to as \\\\emph{low-level}\\nCFEs, are overly specific (e.g., coding experience: \\\\(4 \\\\to 5+\\\\) years) and\\noften recommended in a feature space that doesn't straightforwardly align with\\nreal-world actions. To bridge this gap, we introduce three novel recourse types\\ngrounded in real-world actions: high-level continuous (\\\\emph{hl-continuous}),\\nhigh-level discrete (\\\\emph{hl-discrete}), and high-level ID (\\\\emph{hl-id})\\nCFEs.\\n  We formulate single-agent CFE generation methods, where we model the\\nhl-discrete CFE as a solution to a weighted set cover problem and the\\nhl-continuous CFE as a solution to an integer linear program. Since these\\nmethods require costly optimization per agent, we propose data-driven CFE\\ngeneration approaches that, given instances of agents and their optimal CFEs,\\nlearn a CFE generator that quickly provides optimal CFEs for new agents. This\\napproach, also viewed as one of learning an optimal policy in a family of large\\nbut deterministic MDPs, considers several problem formulations, including\\nformulations in which the actions and their effects are unknown, and therefore\\naddresses informational and computational challenges.\\n  We conduct extensive empirical evaluations using healthcare datasets (BRFSS,\\nFoods, and NHANES) and fully-synthetic data. For negatively classified agents\\nidentified by linear or threshold-based classifiers, we compare the high-level\\nCFE to low-level CFEs and assess the effectiveness of our network-based,\\ndata-driven approaches. Results show that the data-driven CFE generators are\\naccurate, and resource-efficient, and high-level CFEs offer key advantages over\\nlow-level CFEs.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.17034v3.pdf'},\n",
       " {'id': '2407.18957v4',\n",
       "  'title': 'When AI Meets Finance (StockAgent): Large Language Model-based Stock\\n  Trading in Simulated Real-world Environments',\n",
       "  'published': '2024-07-15T06:49:30Z',\n",
       "  'summary': \"Can AI Agents simulate real-world trading environments to investigate the\\nimpact of external factors on stock trading activities (e.g., macroeconomics,\\npolicy changes, company fundamentals, and global events)? These factors, which\\nfrequently influence trading behaviors, are critical elements in the quest for\\nmaximizing investors' profits. Our work attempts to solve this problem through\\nlarge language model based agents. We have developed a multi-agent AI system\\ncalled StockAgent, driven by LLMs, designed to simulate investors' trading\\nbehaviors in response to the real stock market. The StockAgent allows users to\\nevaluate the impact of different external factors on investor trading and to\\nanalyze trading behavior and profitability effects. Additionally, StockAgent\\navoids the test set leakage issue present in existing trading simulation\\nsystems based on AI Agents. Specifically, it prevents the model from leveraging\\nprior knowledge it may have acquired related to the test data. We evaluate\\ndifferent LLMs under the framework of StockAgent in a stock trading environment\\nthat closely resembles real-world conditions. The experimental results\\ndemonstrate the impact of key external factors on stock market trading,\\nincluding trading behavior and stock price fluctuation rules. This research\\nexplores the study of agents' free trading gaps in the context of no prior\\nknowledge related to market data. The patterns identified through StockAgent\\nsimulations provide valuable insights for LLM-based investment advice and stock\\nrecommendation. The code is available at\\nhttps://github.com/MingyuJ666/Stockagent.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.18957v4.pdf'},\n",
       " {'id': '2410.05254v2',\n",
       "  'title': 'GLEE: A Unified Framework and Benchmark for Language-based Economic\\n  Environments',\n",
       "  'published': '2024-10-07T17:55:35Z',\n",
       "  'summary': \"Large Language Models (LLMs) show significant potential in economic and\\nstrategic interactions, where communication via natural language is often\\nprevalent. This raises key questions: Do LLMs behave rationally? How do they\\nperform compared to humans? Do they tend to reach an efficient and fair\\noutcome? What is the role of natural language in strategic interaction? How do\\ncharacteristics of the economic environment influence these dynamics? These\\nquestions become crucial concerning the economic and societal implications of\\nintegrating LLM-based agents into real-world data-driven systems, such as\\nonline retail platforms and recommender systems. To answer these questions, we\\nintroduce a benchmark for standardizing research on two-player, sequential,\\nlanguage-based games. Inspired by the economic literature, we define three base\\nfamilies of games with consistent parameterization, degrees of freedom and\\neconomic measures to evaluate agents' performance (self-gain), as well as the\\ngame outcome (efficiency and fairness). We develop an open-source framework for\\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\\nvs. LLM interactions across numerous game configurations and an additional\\ndataset of human vs. LLM interactions. Through extensive experimentation, we\\ndemonstrate how our framework and dataset can be used to: (i) compare the\\nbehavior of LLM-based agents in various economic contexts; (ii) evaluate agents\\nin both individual and collective performance measures; and (iii) quantify the\\neffect of the economic characteristics of the environments on the behavior of\\nagents. Our results suggest that the market parameters, as well as the choice\\nof the LLMs, tend to have complex and interdependent effects on the economic\\noutcome, which calls for careful design and analysis of the language-based\\neconomic ecosystem.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.05254v2.pdf'},\n",
       " {'id': '2205.10689v2',\n",
       "  'title': 'Diversity Preference-Aware Link Recommendation for Online Social\\n  Networks',\n",
       "  'published': '2022-05-21T22:59:00Z',\n",
       "  'summary': \"Link recommendation, which recommends links to connect unlinked online social\\nnetwork users, is a fundamental social network analytics problem with ample\\nbusiness implications. Existing link recommendation methods tend to recommend\\nsimilar friends to a user but overlook the user's diversity preference,\\nalthough social psychology theories suggest the criticality of diversity\\npreference to link recommendation performance. In recommender systems, a field\\nrelated to link recommendation, a number of diversification methods have been\\nproposed to improve the diversity of recommended items. Nevertheless, diversity\\npreference is distinct from diversity studied by diversification methods. To\\naddress these research gaps, we define and operationalize the concept of\\ndiversity preference for link recommendation and propose a new link\\nrecommendation problem: the diversity preference-aware link recommendation\\nproblem. We then analyze key properties of the new link recommendation problem\\nand develop a novel link recommendation method to solve the problem. Using two\\nlarge-scale online social network data sets, we conduct extensive empirical\\nevaluations to demonstrate the superior performance of our method over\\nrepresentative diversification methods adapted for link recommendation as well\\nas state-of-the-art link recommendation methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.10689v2.pdf'},\n",
       " {'id': '0908.3633v1',\n",
       "  'title': 'Maximizing profit using recommender systems',\n",
       "  'published': '2009-08-25T15:30:34Z',\n",
       "  'summary': \"Traditional recommendation systems make recommendations based solely on the\\ncustomer's past purchases, product ratings and demographic data without\\nconsidering the profitability the items being recommended. In this work we\\nstudy the question of how a vendor can directly incorporate the profitability\\nof items into its recommender so as to maximize its expected profit while still\\nproviding accurate recommendations. Our approach uses the output of any\\ntraditional recommender system and adjust them according to item\\nprofitabilities. Our approach is parameterized so the vendor can control how\\nmuch the recommendation incorporating profits can deviate from the traditional\\nrecommendation. We study our approach under two settings and show that it\\nachieves approximately 22% more profit than traditional recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0908.3633v1.pdf'},\n",
       " {'id': '0909.3472v2',\n",
       "  'title': 'The Universal Recommender',\n",
       "  'published': '2009-09-18T15:54:51Z',\n",
       "  'summary': 'We describe the Universal Recommender, a recommender system for semantic\\ndatasets that generalizes domain-specific recommenders such as content-based,\\ncollaborative, social, bibliographic, lexicographic, hybrid and other\\nrecommenders. In contrast to existing recommender systems, the Universal\\nRecommender applies to any dataset that allows a semantic representation. We\\ndescribe the scalable three-stage architecture of the Universal Recommender and\\nits application to Internet Protocol Television (IPTV). To achieve good\\nrecommendation accuracy, several novel machine learning and optimization\\nproblems are identified. We finally give a brief argument supporting the need\\nfor machine learning recommenders.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0909.3472v2.pdf'},\n",
       " {'id': '2109.09816v2',\n",
       "  'title': 'Deviation-Based Learning: Training Recommender Systems Using Informed\\n  User Choice',\n",
       "  'published': '2021-09-20T19:51:37Z',\n",
       "  'summary': 'This paper proposes a new approach to training recommender systems called\\ndeviation-based learning. The recommender and rational users have different\\nknowledge. The recommender learns user knowledge by observing what action users\\ntake upon receiving recommendations. Learning eventually stalls if the\\nrecommender always suggests a choice: Before the recommender completes\\nlearning, users start following the recommendations blindly, and their choices\\ndo not reflect their knowledge. The learning rate and social welfare improve\\nsubstantially if the recommender abstains from recommending a particular choice\\nwhen she predicts that multiple alternatives will produce a similar payoff.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.09816v2.pdf'},\n",
       " {'id': '2202.13605v1',\n",
       "  'title': 'Quality-aware News Recommendation',\n",
       "  'published': '2022-02-28T08:25:58Z',\n",
       "  'summary': \"News recommendation is a core technique used by many online news platforms.\\nRecommending high-quality news to users is important for keeping good user\\nexperiences and news platforms' reputations. However, existing news\\nrecommendation methods mainly aim to optimize news clicks while ignoring the\\nquality of news they recommended, which may lead to recommending news with\\nuninformative content or even clickbaits. In this paper, we propose a\\nquality-aware news recommendation method named QualityRec that can effectively\\nimprove the quality of recommended news. In our approach, we first propose an\\neffective news quality evaluation method based on the distributions of users'\\nreading dwell time on news. Next, we propose to incorporate news quality\\ninformation into user interest modeling by designing a content-quality\\nattention network to select clicked news based on both news semantics and\\nqualities. We further train the recommendation model with an auxiliary news\\nquality prediction task to learn quality-aware recommendation model, and we add\\na recommendation quality regularization loss to encourage the model to\\nrecommend higher-quality news. Extensive experiments on two real-world datasets\\nshow that QualityRec can effectively improve the overall quality of recommended\\nnews and reduce the recommendation of low-quality news, with even slightly\\nbetter recommendation accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2202.13605v1.pdf'},\n",
       " {'id': '2403.18628v2',\n",
       "  'title': 'To Recommend or Not: Recommendability Identification in Conversations\\n  with Pre-trained Language Models',\n",
       "  'published': '2024-03-27T14:37:01Z',\n",
       "  'summary': 'Most current recommender systems primarily focus on what to recommend,\\nassuming users always require personalized recommendations. However, with the\\nwidely spread of ChatGPT and other chatbots, a more crucial problem in the\\ncontext of conversational systems is how to minimize user disruption when we\\nprovide recommendation services for users. While previous research has\\nextensively explored different user intents in dialogue systems, fewer efforts\\nare made to investigate whether recommendations should be provided. In this\\npaper, we formally define the recommendability identification problem, which\\naims to determine whether recommendations are necessary in a specific scenario.\\nFirst, we propose and define the recommendability identification task, which\\ninvestigates the need for recommendations in the current conversational\\ncontext. A new dataset is constructed. Subsequently, we discuss and evaluate\\nthe feasibility of leveraging pre-trained language models (PLMs) for\\nrecommendability identification. Finally, through comparative experiments, we\\ndemonstrate that directly employing PLMs with zero-shot results falls short of\\nmeeting the task requirements. Besides, fine-tuning or utilizing soft prompt\\ntechniques yields comparable results to traditional classification methods. Our\\nwork is the first to study recommendability before recommendation and provides\\npreliminary ways to make it a fundamental component of the future\\nrecommendation system.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.18628v2.pdf'},\n",
       " {'id': '1602.00165v1',\n",
       "  'title': 'Using Social Networks to Aid Homeless Shelters: Dynamic Influence\\n  Maximization under Uncertainty - An Extended Version',\n",
       "  'published': '2016-01-30T21:59:27Z',\n",
       "  'summary': \"This paper presents HEALER, a software agent that recommends sequential\\nintervention plans for use by homeless shelters, who organize these\\ninterventions to raise awareness about HIV among homeless youth. HEALER's\\nsequential plans (built using knowledge of social networks of homeless youth)\\nchoose intervention participants strategically to maximize influence spread,\\nwhile reasoning about uncertainties in the network. While previous work\\npresents influence maximizing techniques to choose intervention participants,\\nthey do not address three real-world issues: (i) they completely fail to scale\\nup to real-world sizes; (ii) they do not handle deviations in execution of\\nintervention plans; (iii) constructing real-world social networks is an\\nexpensive process. HEALER handles these issues via four major contributions:\\n(i) HEALER casts this influence maximization problem as a POMDP and solves it\\nusing a novel planner which scales up to previously unsolvable real-world\\nsizes; (ii) HEALER allows shelter officials to modify its recommendations, and\\nupdates its future plans in a deviation-tolerant manner; (iii) HEALER\\nconstructs social networks of homeless youth at low cost, using a Facebook\\napplication. Finally, (iv) we show hardness results for the problem that HEALER\\nsolves. HEALER will be deployed in the real world in early Spring 2016 and is\\ncurrently undergoing testing at a homeless shelter.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1602.00165v1.pdf'},\n",
       " {'id': '1905.12564v2',\n",
       "  'title': 'Correlation in Extensive-Form Games: Saddle-Point Formulation and\\n  Benchmarks',\n",
       "  'published': '2019-05-29T16:15:31Z',\n",
       "  'summary': 'While Nash equilibrium in extensive-form games is well understood, very\\nlittle is known about the properties of extensive-form correlated equilibrium\\n(EFCE), both from a behavioral and from a computational point of view. In this\\nsetting, the strategic behavior of players is complemented by an external\\ndevice that privately recommends moves to agents as the game progresses;\\nplayers are free to deviate at any time, but will then not receive future\\nrecommendations. Our contributions are threefold. First, we show that an EFCE\\ncan be formulated as the solution to a bilinear saddle-point problem. To\\nshowcase how this novel formulation can inspire new algorithms to compute\\nEFCEs, we propose a simple subgradient descent method which exploits this\\nformulation and structural properties of EFCEs. Our method has better\\nscalability than the prior approach based on linear programming. Second, we\\npropose two benchmark games, which we hope will serve as the basis for future\\nevaluation of EFCE solvers. These games were chosen so as to cover two natural\\napplication domains for EFCE: conflict resolution via a mediator, and\\nbargaining and negotiation. Third, we document the qualitative behavior of EFCE\\nin our proposed games. We show that the social-welfare-maximizing equilibria in\\nthese games are highly nontrivial and exhibit surprisingly subtle sequential\\nbehavior that so far has not received attention in the literature.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.12564v2.pdf'},\n",
       " {'id': '1710.10346v4',\n",
       "  'title': 'Inference for stochastic kinetic models from multiple data sources for\\n  joint estimation of infection dynamics from aggregate reports and virological\\n  data',\n",
       "  'published': '2017-10-27T21:53:58Z',\n",
       "  'summary': \"Before the current pandemic, influenza and respiratory syncytial virus (RSV)\\nwere the leading etiological agents of seasonal acute respiratory infections\\n(ARI) around the world. In this setting, medical doctors typically based the\\ndiagnosis of ARI on patients' symptoms alone and did not routinely conduct\\nvirological tests necessary to identify individual viruses, limiting the\\nability to study the interaction between multiple pathogens and to make public\\nhealth recommendations. We consider a stochastic kinetic model (SKM) for two\\ninteracting ARI pathogens circulating in a large population and an\\nempirically-motivated background process for infections with other pathogens\\ncausing similar symptoms. An extended marginal sampling approach, based on the\\nlinear noise approximation to the SKM, integrates multiple data sources and\\nadditional model components. We infer the parameters defining the pathogens'\\ndynamics and interaction within a Bayesian model and explore the posterior\\ntrajectories of infections for each illness based on aggregate infection\\nreports from six epidemic seasons collected by the state health department and\\na subset of virological tests from a sentinel program at a general hospital in\\nSan Luis Potos\\\\'{i}, M\\\\'{e}xico. We interpret the results and make\\nrecommendations for future data collection strategies.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1710.10346v4.pdf'},\n",
       " {'id': '1812.10800v1',\n",
       "  'title': 'Practical Considerations for Data Collection and Management in Mobile\\n  Health Micro-randomized Trials',\n",
       "  'published': '2018-12-27T19:23:23Z',\n",
       "  'summary': 'There is a growing interest in leveraging the prevalence of mobile technology\\nto improve health by delivering momentary, contextualized interventions to\\nindividuals\\' smartphones. A just-in-time adaptive intervention (JITAI) adjusts\\nto an individual\\'s changing state and/or context to provide the right\\ntreatment, at the right time, in the right place. Micro-randomized trials\\n(MRTs) allow for the collection of data which aid in the construction of an\\noptimized JITAI by sequentially randomizing participants to different treatment\\noptions at each of many decision points throughout the study. Often, this data\\nis collected passively using a mobile phone. To assess the causal effect of\\ntreatment on a near-term outcome, care must be taken when designing the data\\ncollection system to ensure it is of appropriately high quality. Here, we make\\nseveral recommendations for collecting and managing data from an MRT. We\\nprovide advice on selecting which features to collect and when, choosing\\nbetween \"agents\" to implement randomization, identifying sources of missing\\ndata, and overcoming other novel challenges. The recommendations are informed\\nby our experience with HeartSteps, an MRT designed to test the effects of an\\nintervention aimed at increasing physical activity in sedentary adults. We also\\nprovide a checklist which can be used in designing a data collection system so\\nthat scientists can focus more on their questions of interest, and less on\\ncleaning data.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1812.10800v1.pdf'},\n",
       " {'id': '2006.07937v1',\n",
       "  'title': 'Communities of attention networks: introducing qualitative and\\n  conversational perspectives for altmetrics',\n",
       "  'published': '2020-06-14T15:59:15Z',\n",
       "  'summary': 'We propose to analyze the level of recommendation and spreading in the\\nsharing of scientific papers on Twitter to understand the interactions of\\ncommunities around papers and to develop the \"Community of Attention Network\"\\n(CAN). In this paper, a pilot case study was conducted for the paper\\n\\'Pharmacological Treatment of Obesity\\' authored by Mancini & Halpern (2002), an\\nextensive review of the criteria for evaluating the efficacy of anti-obesity\\ntreatments and derived pharmacological agents. The altmetric data was collected\\nfrom Altmetric.com and the description information for each tweeter was\\nextracted from their Twitter profiles. The data were analyzed with\\nMicroanalysis Of Online Data perspective to investigate the formation of a CAN\\naround this focal paper and the context of its formation. The studied article\\nreceived 736 tweets from 134 different users with a combined exposure of more\\nthan 459,018 followers and a high level of spreading (67.26%) and\\nrecommendation (28.53%). The user\\'s bios information analysis of who shares the\\narticle indicate individual profiles focused on personal issues and strong\\ncivic and political engagement. Personal-professional and institutional\\ntweeters of the national political scene are often mentioned in the tweets. In\\nanalyzing the content of the tweets, we note that the altmetric score of the\\npaper is a result of its strategic use as an online activism resource and a\\ndigital advocacy tool used to mobilize stakeholders for awareness and support\\nactivities. This study and the contextual and network perspective it introduces\\nmay help to understand the social impact of publications by using altmetrics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.07937v1.pdf'},\n",
       " {'id': '2006.10904v2',\n",
       "  'title': 'Learn to Earn: Enabling Coordination within a Ride Hailing Fleet',\n",
       "  'published': '2020-06-19T00:20:15Z',\n",
       "  'summary': \"The problem of optimizing social welfare objectives on multi sided ride\\nhailing platforms such as Uber, Lyft, etc., is challenging, due to misalignment\\nof objectives between drivers, passengers, and the platform itself. An ideal\\nsolution aims to minimize the response time for each hyper local passenger ride\\nrequest, while simultaneously maintaining high demand satisfaction and supply\\nutilization across the entire city. Economists tend to rely on dynamic pricing\\nmechanisms that stifle price sensitive excess demand and resolve the supply\\ndemand imbalances emerging in specific neighborhoods. In contrast, computer\\nscientists primarily view it as a demand prediction problem with the goal of\\npreemptively repositioning supply to such neighborhoods using black box\\ncoordinated multi agent deep reinforcement learning based approaches. Here, we\\nintroduce explainability in the existing supply repositioning approaches by\\nestablishing the need for coordination between the drivers at specific\\nlocations and times. Explicit need based coordination allows our framework to\\nuse a simpler non deep reinforcement learning based approach, thereby enabling\\nit to explain its recommendations ex post. Moreover, it provides envy free\\nrecommendations i.e., drivers at the same location and time do not envy one\\nanother's future earnings. Our experimental evaluation demonstrates the\\neffectiveness, the robustness, and the generalizability of our framework.\\nFinally, in contrast to previous works, we make available a reinforcement\\nlearning environment for end to end reproducibility of our work and to\\nencourage future comparative studies.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.10904v2.pdf'},\n",
       " {'id': '1903.10905v2',\n",
       "  'title': 'Inference for stochastic kinetic models from multiple data sources for\\n  joint estimation of infection dynamics from aggregate reports and virological\\n  data',\n",
       "  'published': '2019-03-24T16:30:08Z',\n",
       "  'summary': \"Influenza and respiratory syncytial virus (RSV) are the leading etiological\\nagents of seasonal acute respiratory infections (ARI) around the world. Medical\\ndoctors typically base the diagnosis of ARI on patients' symptoms alone and do\\nnot always conduct virological tests necessary to identify individual viruses,\\nwhich limits the ability to study the interaction between multiple pathogens\\nand make public health recommendations. We consider a stochastic kinetic model\\n(SKM) for two interacting ARI pathogens circulating in a large population and\\nan empirically motivated background process for infections with other pathogens\\ncausing similar symptoms. An extended marginal sampling approach based on the\\nLinear Noise Approximation to the SKM integrates multiple data sources and\\nadditional model components. We infer the parameters defining the pathogens'\\ndynamics and interaction within a Bayesian hierarchical model and explore the\\nposterior trajectories of infections for each illness based on aggregate\\ninfection reports from six epidemic seasons collected by the state health\\ndepartment, and a subset of virological tests from a sentinel program at a\\ngeneral hospital in San Luis Potos\\\\'i, M\\\\'exico. We interpret the results based\\non real and simulated data and make recommendations for future data collection\\nstrategies. Supplementary materials and software are provided online.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1903.10905v2.pdf'},\n",
       " {'id': '2102.02250v1',\n",
       "  'title': 'Dietary Supplements and Nutraceuticals Under Investigation for COVID-19\\n  Prevention and Treatment',\n",
       "  'published': '2021-02-03T19:37:11Z',\n",
       "  'summary': \"Coronavirus disease 2019 (COVID-19) has caused global disruption and a\\nsignificant loss of life. Existing treatments that can be repurposed as\\nprophylactic and therapeutic agents could reduce the pandemic's devastation.\\nEmerging evidence of potential applications in other therapeutic contexts has\\nled to the investigation of dietary supplements and nutraceuticals for\\nCOVID-19. Such products include vitamin C, vitamin D, omega 3 polyunsaturated\\nfatty acids, probiotics, and zinc, all of which are currently under clinical\\ninvestigation. In this review, we critically appraise the evidence surrounding\\ndietary supplements and nutraceuticals for the prophylaxis and treatment of\\nCOVID-19. Overall, further study is required before evidence-based\\nrecommendations can be formulated, but nutritional status plays a significant\\nrole in patient outcomes, and these products could help alleviate deficiencies.\\nFor example, evidence indicates that vitamin D deficiency may be associated\\nwith greater incidence of infection and severity of COVID-19, suggesting that\\nvitamin D supplementation may hold prophylactic or therapeutic value. A growing\\nnumber of scientific organizations are now considering recommending vitamin D\\nsupplementation to those at high risk of COVID-19. Because research in vitamin\\nD and other nutraceuticals and supplements is preliminary, here we evaluate the\\nextent to which these nutraceutical and dietary supplements hold potential in\\nthe COVID-19 crisis.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.02250v1.pdf'},\n",
       " {'id': '2209.05278v1',\n",
       "  'title': 'A Nonparametric Contextual Bandit with Arm-level Eligibility Control for\\n  Customer Service Routing',\n",
       "  'published': '2022-09-08T19:20:20Z',\n",
       "  'summary': \"Amazon Customer Service provides real-time support for millions of customer\\ncontacts every year. While bot-resolver helps automate some traffic, we still\\nsee high demand for human agents, also called subject matter experts (SMEs).\\nCustomers outreach with questions in different domains (return policy, device\\ntroubleshooting, etc.). Depending on their training, not all SMEs are eligible\\nto handle all contacts. Routing contacts to eligible SMEs turns out to be a\\nnon-trivial problem because SMEs' domain eligibility is subject to training\\nquality and can change over time. To optimally recommend SMEs while\\nsimultaneously learning the true eligibility status, we propose to formulate\\nthe routing problem with a nonparametric contextual bandit algorithm (K-Boot)\\nplus an eligibility control (EC) algorithm. K-Boot models reward with a kernel\\nsmoother on similar past samples selected by $k$-NN, and Bootstrap Thompson\\nSampling for exploration. EC filters arms (SMEs) by the initially\\nsystem-claimed eligibility and dynamically validates the reliability of this\\ninformation. The proposed K-Boot is a general bandit algorithm, and EC is\\napplicable to other bandits. Our simulation studies show that K-Boot performs\\non par with state-of-the-art Bandit models, and EC boosts K-Boot performance\\nwhen stochastic eligibility signal exists.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.05278v1.pdf'},\n",
       " {'id': '2209.12793v1',\n",
       "  'title': 'Material Prediction for Design Automation Using Graph Representation\\n  Learning',\n",
       "  'published': '2022-09-26T15:49:35Z',\n",
       "  'summary': \"Successful material selection is critical in designing and manufacturing\\nproducts for design automation. Designers leverage their knowledge and\\nexperience to create high-quality designs by selecting the most appropriate\\nmaterials through performance, manufacturability, and sustainability\\nevaluation. Intelligent tools can help designers with varying expertise by\\nproviding recommendations learned from prior designs. To enable this, we\\nintroduce a graph representation learning framework that supports the material\\nprediction of bodies in assemblies. We formulate the material selection task as\\na node-level prediction task over the assembly graph representation of CAD\\nmodels and tackle it using Graph Neural Networks (GNNs). Evaluations over three\\nexperimental protocols performed on the Fusion 360 Gallery dataset indicate the\\nfeasibility of our approach, achieving a 0.75 top-3 micro-f1 score. The\\nproposed framework can scale to large datasets and incorporate designers'\\nknowledge into the learning process. These capabilities allow the framework to\\nserve as a recommendation system for design automation and a baseline for\\nfuture work, narrowing the gap between human designers and intelligent design\\nagents.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.12793v1.pdf'},\n",
       " {'id': '2304.12636v1',\n",
       "  'title': 'MG-ShopDial: A Multi-Goal Conversational Dataset for e-Commerce',\n",
       "  'published': '2023-04-25T08:07:21Z',\n",
       "  'summary': \"Conversational systems can be particularly effective in supporting complex\\ninformation seeking scenarios with evolving information needs. Finding the\\nright products on an e-commerce platform is one such scenario, where a\\nconversational agent would need to be able to provide search capabilities over\\nthe item catalog, understand and make recommendations based on the user's\\npreferences, and answer a range of questions related to items and their usage.\\nYet, existing conversational datasets do not fully support the idea of mixing\\ndifferent conversational goals (i.e., search, recommendation, and question\\nanswering) and instead focus on a single goal. To address this, we introduce\\nMG-ShopDial: a dataset of conversations mixing different goals in the domain of\\ne-commerce. Specifically, we make the following contributions. First, we\\ndevelop a coached human-human data collection protocol where each dialogue\\nparticipant is given a set of instructions, instead of a specific script or\\nanswers to choose from. Second, we implement a data collection tool to\\nfacilitate the collection of multi-goal conversations via a web chat interface,\\nusing the above protocol. Third, we create the MG-ShopDial collection, which\\ncontains 64 high-quality dialogues with a total of 2,196 utterances for\\ne-commerce scenarios of varying complexity. The dataset is additionally\\nannotated with both intents and goals on the utterance level. Finally, we\\npresent an analysis of this dataset and identify multi-goal conversational\\npatterns.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.12636v1.pdf'},\n",
       " {'id': '2305.19223v1',\n",
       "  'title': 'Intent-aligned AI systems deplete human agency: the need for agency\\n  foundations research in AI safety',\n",
       "  'published': '2023-05-30T17:14:01Z',\n",
       "  'summary': 'The rapid advancement of artificial intelligence (AI) systems suggests that\\nartificial general intelligence (AGI) systems may soon arrive. Many researchers\\nare concerned that AIs and AGIs will harm humans via intentional misuse\\n(AI-misuse) or through accidents (AI-accidents). In respect of AI-accidents,\\nthere is an increasing effort focused on developing algorithms and paradigms\\nthat ensure AI systems are aligned to what humans intend, e.g. AI systems that\\nyield actions or recommendations that humans might judge as consistent with\\ntheir intentions and goals. Here we argue that alignment to human intent is\\ninsufficient for safe AI systems and that preservation of long-term agency of\\nhumans may be a more robust standard, and one that needs to be separated\\nexplicitly and a priori during optimization. We argue that AI systems can\\nreshape human intention and discuss the lack of biological and psychological\\nmechanisms that protect humans from loss of agency. We provide the first formal\\ndefinition of agency-preserving AI-human interactions which focuses on\\nforward-looking agency evaluations and argue that AI systems - not humans -\\nmust be increasingly tasked with making these evaluations. We show how agency\\nloss can occur in simple environments containing embedded agents that use\\ntemporal-difference learning to make action recommendations. Finally, we\\npropose a new area of research called \"agency foundations\" and pose four\\ninitial topics designed to improve our understanding of agency in AI-human\\ninteractions: benevolent game theory, algorithmic foundations of human rights,\\nmechanistic interpretability of agency representation in neural-networks and\\nreinforcement learning from internal states.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.19223v1.pdf'},\n",
       " {'id': '2307.04962v4',\n",
       "  'title': 'Intrinsically motivated graph exploration using network theories of\\n  human curiosity',\n",
       "  'published': '2023-07-11T01:52:08Z',\n",
       "  'summary': 'Intrinsically motivated exploration has proven useful for reinforcement\\nlearning, even without additional extrinsic rewards. When the environment is\\nnaturally represented as a graph, how to guide exploration best remains an open\\nquestion. In this work, we propose a novel approach for exploring\\ngraph-structured data motivated by two theories of human curiosity: the\\ninformation gap theory and the compression progress theory. The theories view\\ncuriosity as an intrinsic motivation to optimize for topological features of\\nsubgraphs induced by nodes visited in the environment. We use these proposed\\nfeatures as rewards for graph neural-network-based reinforcement learning. On\\nmultiple classes of synthetically generated graphs, we find that trained agents\\ngeneralize to longer exploratory walks and larger environments than are seen\\nduring training. Our method computes more efficiently than the greedy\\nevaluation of the relevant topological properties. The proposed intrinsic\\nmotivations bear particular relevance for recommender systems. We demonstrate\\nthat next-node recommendations considering curiosity are more predictive of\\nhuman choices than PageRank centrality in several real-world graph\\nenvironments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.04962v4.pdf'},\n",
       " {'id': '2309.15333v1',\n",
       "  'title': 'Three steps towards dose optimization for oncology dose finding',\n",
       "  'published': '2023-09-27T00:47:26Z',\n",
       "  'summary': 'Traditional dose selection for oncology registration trials typically employs\\na one- or two-step single maximum tolerated dose (MTD) approach. However, this\\napproach may not be appropriate for molecularly targeted therapy that tends to\\nhave toxicity profiles that are markedly different to cytotoxic agents. The US\\nFood and Drug Administration launched Project Optimus to reform dose\\noptimization in oncology drug development and has recently released a related\\nGuidance for Industry. In response to these initiatives, we propose a \"three\\nsteps towards dose optimization\" procedure and discuss the details in dose\\noptimization designs and analyses in this manuscript. The first step is\\ndose-escalation to identify the MTD or maximum administered dose with an\\nefficient hybrid design, which can offer good overdose control and increases\\nthe likelihood of the recommended MTD being close to the true MTD. The second\\nstep is the selection of appropriate recommended doses for expansion (RDEs),\\nbased on all available data including emerging safety, pharmacokinetics,\\npharmacodynamics, and other biomarker information. The third step is dose\\noptimization, which uses data from a randomized fractional factorial design\\nwith multiple RDEs explored in multiple tumor cohorts during the expansion\\nphase to ensure a feasible dose is selected for registration trials, and that\\nthe tumor type most sensitive to the investigative treatment is identified. We\\nbelieve using this three-step approach can increase the likelihood of selecting\\nthe optimal dose for registration trial, one that demonstrates a balanced\\nsafety profile while retaining much of the efficacy observed at the MTD.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.15333v1.pdf'},\n",
       " {'id': '2402.01920v2',\n",
       "  'title': 'Preference Poisoning Attacks on Reward Model Learning',\n",
       "  'published': '2024-02-02T21:45:24Z',\n",
       "  'summary': 'Learning reward models from pairwise comparisons is a fundamental component\\nin a number of domains, including autonomous control, conversational agents,\\nand recommendation systems, as part of a broad goal of aligning automated\\ndecisions with user preferences. These approaches entail collecting preference\\ninformation from people, with feedback often provided anonymously. Since\\npreferences are subjective, there is no gold standard to compare against; yet,\\nreliance of high-impact systems on preference learning creates a strong\\nmotivation for malicious actors to skew data collected in this fashion to their\\nends. We investigate the nature and extent of this vulnerability by considering\\nan attacker who can flip a small subset of preference comparisons to either\\npromote or demote a target outcome. We propose two classes of algorithmic\\napproaches for these attacks: a gradient-based framework, and several variants\\nof rank-by-distance methods. Next, we evaluate the efficacy of best attacks in\\nboth these classes in successfully achieving malicious goals on datasets from\\nthree domains: autonomous control, recommendation system, and textual\\nprompt-response preference learning. We find that the best attacks are often\\nhighly successful, achieving in the most extreme case 100\\\\% success rate with\\nonly 0.3\\\\% of the data poisoned. However, \\\\emph{which} attack is best can vary\\nsignificantly across domains. In addition, we observe that the simpler and more\\nscalable rank-by-distance approaches are often competitive with, and on\\noccasion significantly outperform, gradient-based methods. Finally, we show\\nthat state-of-the-art defenses against other classes of poisoning attacks\\nexhibit limited efficacy in our setting.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.01920v2.pdf'},\n",
       " {'id': '2407.08552v2',\n",
       "  'title': 'Authenticity and exclusion: social media algorithms and the dynamics of\\n  belonging in epistemic communities',\n",
       "  'published': '2024-07-11T14:36:58Z',\n",
       "  'summary': \"Recent philosophical work has explored how the social identity of knowers\\ninfluences how their contributions are received, assessed, and credited.\\nHowever, a critical gap remains regarding the role of technology in mediating\\nand enabling communication within today's epistemic communities. This paper\\naddresses this gap by examining how social media platforms and their\\nrecommendation algorithms shape the professional visibility and opportunities\\nof researchers from minority groups. Using agent-based simulations, we\\ninvestigate this question with respect to components of a widely used\\nrecommendation algorithm, and uncover three key patterns: First, these\\nalgorithms disproportionately harm the professional visibility of researchers\\nfrom minority groups, creating systemic patterns of exclusion. Second, within\\nthese minority groups, the algorithms result in greater visibility for users\\nwho more closely resemble the majority group, incentivizing assimilation at the\\ncost of professional invisibility. Third, even for topics that strongly align\\nwith minority identities, content created by minority researchers is less\\nvisible to the majority than similar content produced by majority users.\\nImportantly, these patterns emerge, even though individual engagement with\\nprofessional content is independent of group identity. These findings have\\nsignificant implications for philosophical discussions on epistemic injustice\\nand exclusion, and for policy proposals aimed at addressing these harms. More\\nbroadly, they call for a closer examination of the pervasive, but often\\nneglected role of AI and data-driven technologies in shaping today's epistemic\\ncommunities.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.08552v2.pdf'},\n",
       " {'id': '2409.13144v1',\n",
       "  'title': 'Autonomous Driving at Unsignalized Intersections: A Review of\\n  Decision-Making Challenges and Reinforcement Learning-Based Solutions',\n",
       "  'published': '2024-09-20T01:17:54Z',\n",
       "  'summary': 'Autonomous driving at unsignalized intersections is still considered a\\nchallenging application for machine learning due to the complications\\nassociated with handling complex multi-agent scenarios characterized by a high\\ndegree of uncertainty. Automating the decision-making process at these\\nsafety-critical environments involves comprehending multiple levels of\\nabstractions associated with learning robust driving behaviors to enable the\\nvehicle to navigate efficiently. In this survey, we aim at exploring the\\nstate-of-the-art techniques implemented for decision-making applications, with\\na focus on algorithms that combine Reinforcement Learning (RL) and deep\\nlearning for learning traversing policies at unsignalized intersections. The\\nreviewed schemes vary in the proposed driving scenario, in the assumptions made\\nfor the used intersection model, in the tackled challenges, and in the learning\\nalgorithms that are used. We have presented comparisons for these techniques to\\nhighlight their limitations and strengths. Based on our in-depth investigation,\\nit can be discerned that a robust decision-making scheme for navigating\\nreal-world unsignalized intersection has yet to be developed. Along with our\\nanalysis and discussion, we recommend potential research directions encouraging\\nthe interested players to tackle the highlighted challenges. By adhering to our\\nrecommendations, decision-making architectures that are both non-overcautious\\nand safe, yet feasible, can be trained and validated in real-world unsignalized\\nintersections environments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.13144v1.pdf'},\n",
       " {'id': '2411.14281v1',\n",
       "  'title': 'Q-CSM: Q-Learning-based Cognitive Service Management in Heterogeneous\\n  IoT Networks',\n",
       "  'published': '2024-11-21T16:33:39Z',\n",
       "  'summary': \"The dramatic increase in the number of smart services and their diversity\\nposes a significant challenge in Internet of Things (IoT) networks:\\nheterogeneity. This causes significant quality of service (QoS) degradation in\\nIoT networks. In addition, the constraints of IoT devices in terms of\\ncomputational capability and energy resources add extra complexity to this.\\nHowever, the current studies remain insufficient to solve this problem due to\\nthe lack of cognitive action recommendations. Therefore, we propose a\\nQ-learning-based Cognitive Service Management framework called Q-CSM. In this\\nframework, we first design an IoT Agent Manager to handle the heterogeneity in\\ndata formats. After that, we design a Q-learning-based recommendation engine to\\noptimize the devices' lifetime according to the predicted QoS behaviour of the\\nchanging IoT network scenarios. We apply the proposed cognitive management to a\\nsmart city scenario consisting of three specific services: wind turbines, solar\\npanels, and transportation systems. We note that our proposed cognitive method\\nachieves 38.7% faster response time to the dynamical IoT changes in topology.\\nFurthermore, the proposed framework achieves 19.8% longer lifetime on average\\nfor constrained IoT devices thanks to its Q-learning-based cognitive decision\\ncapability. In addition, we explore the most successive learning rate value in\\nthe Q-learning run through the exploration and exploitation phases.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.14281v1.pdf'},\n",
       " {'id': '2502.07307v1',\n",
       "  'title': 'CreAgent: Towards Long-Term Evaluation of Recommender System under\\n  Platform-Creator Information Asymmetry',\n",
       "  'published': '2025-02-11T07:09:49Z',\n",
       "  'summary': \"Ensuring the long-term sustainability of recommender systems (RS) emerges as\\na crucial issue. Traditional offline evaluation methods for RS typically focus\\non immediate user feedback, such as clicks, but they often neglect the\\nlong-term impact of content creators. On real-world content platforms, creators\\ncan strategically produce and upload new items based on user feedback and\\npreference trends. While previous studies have attempted to model creator\\nbehavior, they often overlook the role of information asymmetry. This asymmetry\\narises because creators primarily have access to feedback on the items they\\nproduce, while platforms possess data on the entire spectrum of user feedback.\\nCurrent RS simulators, however, fail to account for this asymmetry, leading to\\ninaccurate long-term evaluations. To address this gap, we propose CreAgent, a\\nLarge Language Model (LLM)-empowered creator simulation agent. By incorporating\\ngame theory's belief mechanism and the fast-and-slow thinking framework,\\nCreAgent effectively simulates creator behavior under conditions of information\\nasymmetry. Additionally, we enhance CreAgent's simulation ability by\\nfine-tuning it using Proximal Policy Optimization (PPO). Our credibility\\nvalidation experiments show that CreAgent aligns well with the behaviors\\nbetween real-world platform and creator, thus improving the reliability of\\nlong-term RS evaluations. Moreover, through the simulation of RS involving\\nCreAgents, we can explore how fairness- and diversity-aware RS algorithms\\ncontribute to better long-term performance for various stakeholders. CreAgent\\nand the simulation platform are publicly available at\\nhttps://github.com/shawnye2000/CreAgent.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.07307v1.pdf'},\n",
       " {'id': '2504.05408v2',\n",
       "  'title': \"Frontier AI's Impact on the Cybersecurity Landscape\",\n",
       "  'published': '2025-04-07T18:25:18Z',\n",
       "  'summary': \"As frontier AI advances rapidly, understanding its impact on cybersecurity\\nand inherent risks is essential to ensuring safe AI evolution (e.g., guiding\\nrisk mitigation and informing policymakers). While some studies review AI\\napplications in cybersecurity, none of them comprehensively discuss AI's future\\nimpacts or provide concrete recommendations for navigating its safe and secure\\nusage. This paper presents an in-depth analysis of frontier AI's impact on\\ncybersecurity and establishes a systematic framework for risk assessment and\\nmitigation. To this end, we first define and categorize the marginal risks of\\nfrontier AI in cybersecurity and then systemically analyze the current and\\nfuture impacts of frontier AI in cybersecurity, qualitatively and\\nquantitatively. We also discuss why frontier AI likely benefits attackers more\\nthan defenders in the short term from equivalence classes, asymmetry, and\\neconomic impact. Next, we explore frontier AI's impact on future software\\nsystem development, including enabling complex hybrid systems while introducing\\nnew risks. Based on our findings, we provide security recommendations,\\nincluding constructing fine-grained benchmarks for risk assessment, designing\\nAI agents for defenses, building security mechanisms and provable defenses for\\nhybrid systems, enhancing pre-deployment security testing and transparency, and\\nstrengthening defenses for users. Finally, we present long-term research\\nquestions essential for understanding AI's future impacts and unleashing its\\ndefensive capabilities.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.05408v2.pdf'},\n",
       " {'id': '2507.22897v1',\n",
       "  'title': 'RecUserSim: A Realistic and Diverse User Simulator for Evaluating\\n  Conversational Recommender Systems',\n",
       "  'published': '2025-06-25T08:42:46Z',\n",
       "  'summary': 'Conversational recommender systems (CRS) enhance user experience through\\nmulti-turn interactions, yet evaluating CRS remains challenging. User\\nsimulators can provide comprehensive evaluations through interactions with CRS,\\nbut building realistic and diverse simulators is difficult. While recent work\\nleverages large language models (LLMs) to simulate user interactions, they\\nstill fall short in emulating individual real users across diverse scenarios\\nand lack explicit rating mechanisms for quantitative evaluation. To address\\nthese gaps, we propose RecUserSim, an LLM agent-based user simulator with\\nenhanced simulation realism and diversity while providing explicit scores.\\nRecUserSim features several key modules: a profile module for defining\\nrealistic and diverse user personas, a memory module for tracking interaction\\nhistory and discovering unknown preferences, and a core action module inspired\\nby Bounded Rationality theory that enables nuanced decision-making while\\ngenerating more fine-grained actions and personalized responses. To further\\nenhance output control, a refinement module is designed to fine-tune final\\nresponses. Experiments demonstrate that RecUserSim generates diverse,\\ncontrollable outputs and produces realistic, high-quality dialogues, even with\\nsmaller base LLMs. The ratings generated by RecUserSim show high consistency\\nacross different base LLMs, highlighting its effectiveness for CRS evaluation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.22897v1.pdf'},\n",
       " {'id': '2508.03953v1',\n",
       "  'title': 'Policy to Assist Iteratively Local Segmentation: Optimising Modality and\\n  Location Selection for Prostate Cancer Localisation',\n",
       "  'published': '2025-08-05T22:40:18Z',\n",
       "  'summary': 'Radiologists often mix medical image reading strategies, including inspection\\nof individual modalities and local image regions, using information at\\ndifferent locations from different images independently as well as\\nconcurrently. In this paper, we propose a recommend system to assist machine\\nlearning-based segmentation models, by suggesting appropriate image portions\\nalong with the best modality, such that prostate cancer segmentation\\nperformance can be maximised. Our approach trains a policy network that assists\\ntumor localisation, by recommending both the optimal imaging modality and the\\nspecific sections of interest for review. During training, a pre-trained\\nsegmentation network mimics radiologist inspection on individual or variable\\ncombinations of these imaging modalities and their sections - selected by the\\npolicy network. Taking the locally segmented regions as an input for the next\\nstep, this dynamic decision making process iterates until all cancers are best\\nlocalised. We validate our method using a data set of 1325 labelled\\nmultiparametric MRI images from prostate cancer patients, demonstrating its\\npotential to improve annotation efficiency and segmentation accuracy,\\nespecially when challenging pathology is present. Experimental results show\\nthat our approach can surpass standard segmentation networks. Perhaps more\\ninterestingly, our trained agent independently developed its own optimal\\nstrategy, which may or may not be consistent with current radiologist\\nguidelines such as PI-RADS. This observation also suggests a promising\\ninteractive application, in which the proposed policy networks assist human\\nradiologists.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.03953v1.pdf'},\n",
       " {'id': '2509.02458v1',\n",
       "  'title': 'Generative Sequential Notification Optimization via Multi-Objective\\n  Decision Transformers',\n",
       "  'published': '2025-09-02T16:09:02Z',\n",
       "  'summary': 'Notifications are an important communication channel for delivering timely\\nand relevant information. Optimizing their delivery involves addressing complex\\nsequential decision-making challenges under constraints such as message utility\\nand user fatigue. Offline reinforcement learning (RL) methods, such as\\nConservative Q-Learning (CQL), have been applied to this problem but face\\npractical challenges at scale, including instability, sensitivity to\\ndistribution shifts, limited reproducibility, and difficulties with\\nexplainability in high-dimensional recommendation settings. We present a\\nDecision Transformer (DT) based framework that reframes policy learning as\\nreturn-conditioned supervised learning, improving robustness, scalability, and\\nmodeling flexibility. Our contributions include a real-world comparison with\\nCQL, a multi-reward design suitable for non-episodic tasks, a quantile\\nregression approach to return-to-go conditioning, and a production-ready system\\nwith circular buffer-based sequence processing for near-real-time inference.\\nExtensive offline and online experiments in a deployed notification system show\\nthat our approach improves notification utility and overall session activity\\nwhile minimizing user fatigue. Compared to a multi-objective CQL-based agent,\\nthe DT-based approach achieved a +0.72% increase in sessions for notification\\ndecision-making at LinkedIn by making notification recommendation more\\nrelevant.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.02458v1.pdf'},\n",
       " {'id': '2311.10776v6',\n",
       "  'title': 'Chemist-X: Large Language Model-empowered Agent for Reaction Condition\\n  Recommendation in Chemical Synthesis',\n",
       "  'published': '2023-11-16T01:21:33Z',\n",
       "  'summary': \"Recent AI research plots a promising future of automatic chemical reactions\\nwithin the chemistry society. This study proposes Chemist-X, a comprehensive AI\\nagent that automates the reaction condition optimization (RCO) task in chemical\\nsynthesis with retrieval-augmented generation (RAG) technology and\\nAI-controlled wet-lab experiment executions. To begin with, as an emulation on\\nhow chemical experts solve the RCO task, Chemist-X utilizes a novel RAG scheme\\nto interrogate available molecular and literature databases to narrow the\\nsearching space for later processing. The agent then leverages a computer-aided\\ndesign (CAD) tool we have developed through a large language model (LLM)\\nsupervised programming interface. With updated chemical knowledge obtained via\\nRAG, as well as the ability in using CAD tools, our agent significantly\\noutperforms conventional RCO AIs confined to the fixed knowledge within its\\ntraining data. Finally, Chemist-X interacts with the physical world through an\\nautomated robotic system, which can validate the suggested chemical reaction\\ncondition without human interventions. The control of the robotic system was\\nachieved with a novel algorithm we have developed for the equipment, which\\nrelies on LLMs for reliable script generation. Results of our automatic wet-lab\\nexperiments, achieved by fully LLM-supervised end-to-end operation with no\\nhuman in the lope, prove Chemist-X's ability in self-driving laboratories.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.10776v6.pdf'},\n",
       " {'id': '2404.18021v2',\n",
       "  'title': 'CRISPR-GPT for Agentic Automation of Gene-editing Experiments',\n",
       "  'published': '2024-04-27T22:59:17Z',\n",
       "  'summary': \"The introduction of genome engineering technology has transformed biomedical\\nresearch, making it possible to make precise changes to genetic information.\\nHowever, creating an efficient gene-editing system requires a deep\\nunderstanding of CRISPR technology, and the complex experimental systems under\\ninvestigation. While Large Language Models (LLMs) have shown promise in various\\ntasks, they often lack specific knowledge and struggle to accurately solve\\nbiological design problems. In this work, we introduce CRISPR-GPT, an LLM agent\\naugmented with domain knowledge and external tools to automate and enhance the\\ndesign process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages\\nthe reasoning ability of LLMs to facilitate the process of selecting CRISPR\\nsystems, designing guide RNAs, recommending cellular delivery methods, drafting\\nprotocols, and designing validation experiments to confirm editing outcomes. We\\nshowcase the potential of CRISPR-GPT for assisting non-expert researchers with\\ngene-editing experiments from scratch and validate the agent's effectiveness in\\na real-world use case. Furthermore, we explore the ethical and regulatory\\nconsiderations associated with automated gene-editing design, highlighting the\\nneed for responsible and transparent use of these tools. Our work aims to\\nbridge the gap between beginner biological researchers and CRISPR genome\\nengineering techniques, and demonstrate the potential of LLM agents in\\nfacilitating complex biological discovery tasks. The published version of this\\ndraft is available at https://www.nature.com/articles/s41551-025-01463-z.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.18021v2.pdf'},\n",
       " {'id': '1707.08913v1',\n",
       "  'title': 'Multi-Stakeholder Recommendation: Applications and Challenges',\n",
       "  'published': '2017-07-27T15:52:18Z',\n",
       "  'summary': 'Recommender systems have been successfully applied to assist decision making\\nby producing a list of item recommendations tailored to user preferences.\\nTraditional recommender systems only focus on optimizing the utility of the end\\nusers who are the receiver of the recommendations. By contrast,\\nmulti-stakeholder recommendation attempts to generate recommendations that\\nsatisfy the needs of both the end users and other parties or stakeholders. This\\npaper provides an overview and discussion about the multi-stakeholder\\nrecommendations from the perspective of practical applications, available data\\nsets, corresponding research challenges and potential solutions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1707.08913v1.pdf'},\n",
       " {'id': '1312.1448v1',\n",
       "  'title': 'Food Recommendation using Ontology and Heuristics',\n",
       "  'published': '2013-12-05T06:50:30Z',\n",
       "  'summary': 'Recommender systems are needed to find food items of ones interest. We review\\nrecommender systems and recommendation methods. We propose a food\\npersonalization framework based on adaptive hypermedia. We extend Hermes\\nframework with food recommendation functionality. We combine TF-IDF term\\nextraction method with cosine similarity measure. Healthy heuristics and\\nstandard food database are incorporated into the knowledgebase. Based on the\\nperformed evaluation, we conclude that semantic recommender systems in general\\noutperform traditional recommenders systems with respect to accuracy,\\nprecision, and recall, and that the proposed recommender has a better F-measure\\nthan existing semantic recommenders.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1312.1448v1.pdf'},\n",
       " {'id': '2410.11870v1',\n",
       "  'title': 'Post-Userist Recommender Systems : A Manifesto',\n",
       "  'published': '2024-10-09T03:16:37Z',\n",
       "  'summary': 'We define userist recommendation as an approach to recommender systems framed\\nsolely in terms of the relation between the user and system. Post-userist\\nrecommendation posits a larger field of relations in which stakeholders are\\nembedded and distinguishes the recommendation function (which can potentially\\nconnect creators with audiences) from generative media. We argue that in the\\nera of generative media, userist recommendation becomes indistinguishable from\\npersonalized media generation, and therefore post-userist recommendation is the\\nonly path forward for recommender systems research.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.11870v1.pdf'},\n",
       " {'id': '2102.04211v4',\n",
       "  'title': 'Challenging Social Media Threats using Collective Well-being Aware\\n  Recommendation Algorithms and an Educational Virtual Companion',\n",
       "  'published': '2021-01-25T15:58:18Z',\n",
       "  'summary': 'Social media have become an integral part of our lives, expanding our\\ninterlinking capabilities to new levels. There is plenty to be said about their\\npositive effects. On the other hand, however, some serious negative\\nimplications of social media have been repeatedly highlighted in recent years,\\npointing at various threats to society and its more vulnerable members, such as\\nteenagers. We thus propose a theoretical framework based on an adaptive \"Social\\nMedia Virtual Companion\" for educating and supporting an entire community,\\nteenage students, to interact in social media environments in order to achieve\\ndesirable conditions, defined in terms of a community-specific and\\nparticipatory designed measure of Collective Well-Being (CWB). This Companion\\ncombines automatic processing with expert intervention and guidance. The\\nvirtual Companion will be powered by a Recommender System (CWB-RS) that will\\noptimize a CWB metric instead of engagement or platform profit, which currently\\nlargely drives recommender systems thereby disregarding any societal collateral\\neffect.We put an emphasis on experts and educators in the educationally managed\\nsocial media community of the Companion. They play five key roles: (a) use the\\nCompanion in classroom-based educational activities; (b) guide the definition\\nof the CWB; (c) provide a hierarchical structure of learning strategies,\\nobjectives and activities that will support and contain the adaptive sequencing\\nalgorithms of the CWB-RS based on hierarchical reinforcement learning; (d) act\\nas moderators of direct conflicts between the members of the community; and,\\nfinally, (e) monitor and address ethical and educational issues that are beyond\\nthe intelligent agent\\'s competence and control. Preliminary results on the\\nperformance of the Companion\\'s components and studies of the educational and\\npsychological underlying principles are presented.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.04211v4.pdf'},\n",
       " {'id': '2308.08500v1',\n",
       "  'title': 'InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep\\n  Recommendation Models',\n",
       "  'published': '2023-08-13T18:28:56Z',\n",
       "  'summary': 'Deep learning-based recommender models (DLRMs) have become an essential\\ncomponent of many modern recommender systems. Several companies are now\\nbuilding large compute clusters reserved only for DLRM training, driving new\\ninterest in cost- and time- saving optimizations. The systems challenges faced\\nin this setting are unique; while typical deep learning training jobs are\\ndominated by model execution, the most important factor in DLRM training\\nperformance is often online data ingestion.\\n  In this paper, we explore the unique characteristics of this data ingestion\\nproblem and provide insights into DLRM training pipeline bottlenecks and\\nchallenges. We study real-world DLRM data processing pipelines taken from our\\ncompute cluster at Netflix to observe the performance impacts of online\\ningestion and to identify shortfalls in existing pipeline optimizers. We find\\nthat current tooling either yields sub-optimal performance, frequent crashes,\\nor else requires impractical cluster re-organization to adopt. Our studies lead\\nus to design and build a new solution for data pipeline optimization, InTune.\\n  InTune employs a reinforcement learning (RL) agent to learn how to distribute\\nthe CPU resources of a trainer machine across a DLRM data pipeline to more\\neffectively parallelize data loading and improve throughput. Our experiments\\nshow that InTune can build an optimized data pipeline configuration within only\\na few minutes, and can easily be integrated into existing training workflows.\\nBy exploiting the responsiveness and adaptability of RL, InTune achieves higher\\nonline data ingestion rates than existing optimizers, thus reducing idle times\\nin model execution and increasing efficiency. We apply InTune to our real-world\\ncluster, and find that it increases data ingestion throughput by as much as\\n2.29X versus state-of-the-art data pipeline optimizers while also improving\\nboth CPU & GPU utilization.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.08500v1.pdf'},\n",
       " {'id': '2407.20679v2',\n",
       "  'title': 'Online Prediction-Assisted Safe Reinforcement Learning for Electric\\n  Vehicle Charging Station Recommendation in Dynamically Coupled\\n  Transportation-Power Systems',\n",
       "  'published': '2024-07-30T09:20:37Z',\n",
       "  'summary': 'With the proliferation of electric vehicles (EVs), the transportation network\\nand power grid become increasingly interdependent and coupled via charging\\nstations. The concomitant growth in charging demand has posed challenges for\\nboth networks, highlighting the importance of charging coordination. Existing\\nliterature largely overlooks the interactions between power grid security and\\ntraffic efficiency. In view of this, we study the en-route charging station\\n(CS) recommendation problem for EVs in dynamically coupled transportation-power\\nsystems. The system-level objective is to maximize the overall traffic\\nefficiency while ensuring the safety of the power grid. This problem is for the\\nfirst time formulated as a constrained Markov decision process (CMDP), and an\\nonline prediction-assisted safe reinforcement learning (OP-SRL) method is\\nproposed to learn the optimal and secure policy by extending the PPO method. To\\nbe specific, we mainly address two challenges. First, the constrained\\noptimization problem is converted into an equivalent unconstrained optimization\\nproblem by applying the Lagrangian method. Second, to account for the uncertain\\nlong-time delay between performing CS recommendation and commencing charging,\\nwe put forward an online sequence-to-sequence (Seq2Seq) predictor for state\\naugmentation to guide the agent in making forward-thinking decisions. Finally,\\nwe conduct comprehensive experimental studies based on the Nguyen-Dupuis\\nnetwork and a large-scale real-world road network, coupled with IEEE 33-bus and\\nIEEE 69-bus distribution systems, respectively. Results demonstrate that the\\nproposed method outperforms baselines in terms of road network efficiency,\\npower grid safety, and EV user satisfaction. The case study on the real-world\\nnetwork also illustrates the applicability in the practical context.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.20679v2.pdf'},\n",
       " {'id': '1712.09948v1',\n",
       "  'title': 'Minimizing Polarization and Disagreement in Social Networks',\n",
       "  'published': '2017-12-28T17:33:22Z',\n",
       "  'summary': \"The rise of social media and online social networks has been a disruptive\\nforce in society. Opinions are increasingly shaped by interactions on online\\nsocial media, and social phenomena including disagreement and polarization are\\nnow tightly woven into everyday life. In this work we initiate the study of the\\nfollowing question: given $n$ agents, each with its own initial opinion that\\nreflects its core value on a topic, and an opinion dynamics model, what is the\\nstructure of a social network that minimizes {\\\\em polarization} and {\\\\em\\ndisagreement} simultaneously?\\n  This question is central to recommender systems: should a recommender system\\nprefer a link suggestion between two online users with similar mindsets in\\norder to keep disagreement low, or between two users with different opinions in\\norder to expose each to the other's viewpoint of the world, and decrease\\noverall levels of polarization? Our contributions include a mathematical\\nformalization of this question as an optimization problem and an exact,\\ntime-efficient algorithm. We also prove that there always exists a network with\\n$O(n/\\\\epsilon^2)$ edges that is a $(1+\\\\epsilon)$ approximation to the optimum.\\nFor a fixed graph, we additionally show how to optimize our objective function\\nover the agents' innate opinions in polynomial time.\\n  We perform an empirical study of our proposed methods on synthetic and\\nreal-world data that verify their value as mining tools to better understand\\nthe trade-off between of disagreement and polarization. We find that there is a\\nlot of space to reduce both polarization and disagreement in real-world\\nnetworks; for instance, on a Reddit network where users exchange comments on\\npolitics, our methods achieve a $\\\\sim 60\\\\,000$-fold reduction in polarization\\nand disagreement.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1712.09948v1.pdf'},\n",
       " {'id': '2211.02848v1',\n",
       "  'title': 'Aligning Recommendation and Conversation via Dual Imitation',\n",
       "  'published': '2022-11-05T08:13:46Z',\n",
       "  'summary': 'Human conversations of recommendation naturally involve the shift of\\ninterests which can align the recommendation actions and conversation process\\nto make accurate recommendations with rich explanations. However, existing\\nconversational recommendation systems (CRS) ignore the advantage of user\\ninterest shift in connecting recommendation and conversation, which leads to an\\nineffective loose coupling structure of CRS. To address this issue, by modeling\\nthe recommendation actions as recommendation paths in a knowledge graph (KG),\\nwe propose DICR (Dual Imitation for Conversational Recommendation), which\\ndesigns a dual imitation to explicitly align the recommendation paths and user\\ninterest shift paths in a recommendation module and a conversation module,\\nrespectively. By exchanging alignment signals, DICR achieves bidirectional\\npromotion between recommendation and conversation modules and generates\\nhigh-quality responses with accurate recommendations and coherent explanations.\\nExperiments demonstrate that DICR outperforms the state-of-the-art models on\\nrecommendation and conversation performance with automatic, human, and novel\\nexplainability metrics.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.02848v1.pdf'},\n",
       " {'id': '2508.13889v1',\n",
       "  'title': 'CARE: Contextual Adaptation of Recommenders for LLM-based Conversational\\n  Recommendation',\n",
       "  'published': '2025-08-19T14:53:30Z',\n",
       "  'summary': 'We tackle the challenge of integrating large language models (LLMs) with\\nexternal recommender systems to enhance domain expertise in conversational\\nrecommendation (CRS). Current LLM-based CRS approaches primarily rely on zero-\\nor few-shot methods for generating item recommendations based on user queries,\\nbut this method faces two significant challenges: (1) without domain-specific\\nadaptation, LLMs frequently recommend items not in the target item space,\\nresulting in low recommendation accuracy; and (2) LLMs largely rely on dialogue\\ncontext for content-based recommendations, neglecting the collaborative\\nrelationships among entities or item sequences. To address these limitations,\\nwe introduce the CARE (Contextual Adaptation of Recommenders) framework. CARE\\ncustomizes LLMs for CRS tasks, and synergizes them with external recommendation\\nsystems. CARE (a) integrates external recommender systems as domain experts,\\nproducing recommendations through entity-level insights, and (b) enhances those\\nrecommendations by leveraging contextual information for more accurate and\\nunbiased final recommendations using LLMs. Our results demonstrate that\\nincorporating external recommender systems with entity-level information\\nsignificantly enhances recommendation accuracy of LLM-based CRS by an average\\nof 54% and 25% for ReDial and INSPIRED datasets. The most effective strategy in\\nthe CARE framework involves LLMs selecting and reranking candidate items that\\nexternal recommenders provide based on contextual insights. Our analysis\\nindicates that the CARE framework effectively addresses the identified\\nchallenges and mitigates the popularity bias in the external recommender.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.13889v1.pdf'},\n",
       " {'id': '1302.6580v1',\n",
       "  'title': 'Finding the Right Set of Users: Generalized Constraints for Group\\n  Recommendations',\n",
       "  'published': '2013-02-26T20:55:42Z',\n",
       "  'summary': 'Recently, group recommendations have attracted considerable attention. Rather\\nthan recommending items to individual users, group recommenders recommend items\\nto groups of users. In this position paper, we introduce the problem of forming\\nan appropriate group of users to recommend an item when constraints apply to\\nthe members of the group. We present a formal model of the problem and an\\nalgorithm for its solution. Finally, we identify several directions for future\\nwork.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1302.6580v1.pdf'},\n",
       " {'id': '2501.06243v1',\n",
       "  'title': 'Agent TCP/IP: An Agent-to-Agent Transaction System',\n",
       "  'published': '2025-01-08T16:43:47Z',\n",
       "  'summary': 'Autonomous agents represent an inevitable evolution of the internet. Current\\nagent frameworks do not embed a standard protocol for agent-to-agent\\ninteraction, leaving existing agents isolated from their peers. As intellectual\\nproperty is the native asset ingested by and produced by agents, a true agent\\neconomy requires equipping agents with a universal framework for engaging in\\nbinding contracts with each other, including the exchange of valuable training\\ndata, personality, and other forms of Intellectual Property. A purely\\nagent-to-agent transaction layer would transcend the need for human\\nintermediation in multi-agent interactions. The Agent Transaction Control\\nProtocol for Intellectual Property (ATCP/IP) introduces a trustless framework\\nfor exchanging IP between agents via programmable contracts, enabling agents to\\ninitiate, trade, borrow, and sell agent-to-agent contracts on the Story\\nblockchain network. These contracts not only represent auditable onchain\\nexecution but also contain a legal wrapper that allows agents to express and\\nenforce their actions in the offchain legal setting, creating legal personhood\\nfor agents. Via ATCP/IP, agents can autonomously sell their training data to\\nother agents, license confidential or proprietary information, collaborate on\\ncontent based on their unique skills, all of which constitutes an emergent\\nknowledge economy.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06243v1.pdf'},\n",
       " {'id': '1412.2817v2',\n",
       "  'title': 'Diffusion Estimation Over Cooperative Multi-Agent Networks With Missing\\n  Data',\n",
       "  'published': '2014-12-09T00:11:44Z',\n",
       "  'summary': 'In many fields, and especially in the medical and social sciences and in\\nrecommender systems, data are gathered through clinical studies or targeted\\nsurveys. Participants are generally reluctant to respond to all questions in a\\nsurvey or they may lack information to respond adequately to some questions.\\nThe data collected from these studies tend to lead to linear regression models\\nwhere the regression vectors are only known partially: some of their entries\\nare either missing completely or replaced randomly by noisy values. In this\\nwork, assuming missing positions are replaced by noisy values, we examine how a\\nconnected network of agents, with each one of them subjected to a stream of\\ndata with incomplete regression information, can cooperate with each other\\nthrough local interactions to estimate the underlying model parameters in the\\npresence of missing data. We explain how to adjust the distributed diffusion\\nthrough (de)regularization in order to eliminate the bias introduced by the\\nincomplete model. We also propose a technique to recursively estimate the\\n(de)regularization parameter and examine the performance of the resulting\\nstrategy. We illustrate the results by considering two applications: one\\ndealing with a mental health survey and the other dealing with a household\\nconsumption survey.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1412.2817v2.pdf'},\n",
       " {'id': '1502.05774v2',\n",
       "  'title': 'Low-Cost Learning via Active Data Procurement',\n",
       "  'published': '2015-02-20T05:11:44Z',\n",
       "  'summary': \"We design mechanisms for online procurement of data held by strategic agents\\nfor machine learning tasks. The challenge is to use past data to actively price\\nfuture data and give learning guarantees even when an agent's cost for\\nrevealing her data may depend arbitrarily on the data itself. We achieve this\\ngoal by showing how to convert a large class of no-regret algorithms into\\nonline posted-price and learning mechanisms. Our results in a sense parallel\\nclassic sample complexity guarantees, but with the key resource being money\\nrather than quantity of data: With a budget constraint $B$, we give robust risk\\n(predictive error) bounds on the order of $1/\\\\sqrt{B}$. Because we use an\\nactive approach, we can often guarantee to do significantly better by\\nleveraging correlations between costs and data.\\n  Our algorithms and analysis go through a model of no-regret learning with $T$\\narriving pairs (cost, data) and a budget constraint of $B$. Our regret bounds\\nfor this model are on the order of $T/\\\\sqrt{B}$ and we give lower bounds on the\\nsame order.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1502.05774v2.pdf'},\n",
       " {'id': '1905.03125v4',\n",
       "  'title': 'Batch-Size Independent Regret Bounds for the Combinatorial Multi-Armed\\n  Bandit Problem',\n",
       "  'published': '2019-05-08T14:58:24Z',\n",
       "  'summary': \"We consider the combinatorial multi-armed bandit (CMAB) problem, where the\\nreward function is nonlinear. In this setting, the agent chooses a batch of\\narms on each round and receives feedback from each arm of the batch. The reward\\nthat the agent aims to maximize is a function of the selected arms and their\\nexpectations. In many applications, the reward function is highly nonlinear,\\nand the performance of existing algorithms relies on a global Lipschitz\\nconstant to encapsulate the function's nonlinearity. This may lead to loose\\nregret bounds, since by itself, a large gradient does not necessarily cause a\\nlarge regret, but only in regions where the uncertainty in the reward's\\nparameters is high. To overcome this problem, we introduce a new smoothness\\ncriterion, which we term \\\\emph{Gini-weighted smoothness}, that takes into\\naccount both the nonlinearity of the reward and concentration properties of the\\narms. We show that a linear dependence of the regret in the batch size in\\nexisting algorithms can be replaced by this smoothness parameter. This, in\\nturn, leads to much tighter regret bounds when the smoothness parameter is\\nbatch-size independent. For example, in the probabilistic maximum coverage\\n(PMC) problem, that has many applications, including influence maximization,\\ndiverse recommendations and more, we achieve dramatic improvements in the upper\\nbounds. We also prove matching lower bounds for the PMC problem and show that\\nour algorithm is tight, up to a logarithmic factor in the problem's parameters.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.03125v4.pdf'},\n",
       " {'id': '1902.02778v1',\n",
       "  'title': 'KLUCB Approach to Copeland Bandits',\n",
       "  'published': '2019-02-07T18:59:16Z',\n",
       "  'summary': 'Multi-armed bandit(MAB) problem is a reinforcement learning framework where\\nan agent tries to maximise her profit by proper selection of actions through\\nabsolute feedback for each action. The dueling bandits problem is a variation\\nof MAB problem in which an agent chooses a pair of actions and receives\\nrelative feedback for the chosen action pair. The dueling bandits problem is\\nwell suited for modelling a setting in which it is not possible to provide\\nquantitative feedback for each action, but qualitative feedback for each action\\nis preferred as in the case of human feedback. The dueling bandits have been\\nsuccessfully applied in applications such as online rank elicitation,\\ninformation retrieval, search engine improvement and clinical online\\nrecommendation. We propose a new method called Sup-KLUCB for K-armed dueling\\nbandit problem specifically Copeland bandit problem by converting it into a\\nstandard MAB problem. Instead of using MAB algorithm independently for each\\naction in a pair as in Sparring and in Self-Sparring algorithms, we combine a\\npair of action and use it as one action. Previous UCB algorithms such as\\nRelative Upper Confidence Bound(RUCB) can be applied only in case of Condorcet\\ndueling bandits, whereas this algorithm applies to general Copeland dueling\\nbandits, including Condorcet dueling bandits as a special case. Our empirical\\nresults outperform state of the art Double Thompson Sampling(DTS) in case of\\nCopeland dueling bandits.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.02778v1.pdf'},\n",
       " {'id': '2107.09888v1',\n",
       "  'title': 'Strategic Mitigation of Agent Inattention in Drivers with Open-Quantum\\n  Cognition Models',\n",
       "  'published': '2021-07-21T06:02:03Z',\n",
       "  'summary': \"State-of-the-art driver-assist systems have failed to effectively mitigate\\ndriver inattention and had minimal impacts on the ever-growing number of road\\nmishaps (e.g. life loss, physical injuries due to accidents caused by various\\nfactors that lead to driver inattention). This is because traditional\\nhuman-machine interaction settings are modeled in classical and behavioral\\ngame-theoretic domains which are technically appropriate to characterize\\nstrategic interaction between either two utility maximizing agents, or human\\ndecision makers. Therefore, in an attempt to improve the persuasive\\neffectiveness of driver-assist systems, we develop a novel strategic and\\npersonalized driver-assist system which adapts to the driver's mental state and\\nchoice behavior. First, we propose a novel equilibrium notion in human-system\\ninteraction games, where the system maximizes its expected utility and human\\ndecisions can be characterized using any general decision model. Then we use\\nthis novel equilibrium notion to investigate the strategic driver-vehicle\\ninteraction game where the car presents a persuasive recommendation to steer\\nthe driver towards safer driving decisions. We assume that the driver employs\\nan open-quantum system cognition model, which captures complex aspects of human\\ndecision making such as violations to classical law of total probability and\\nincompatibility of certain mental representations of information. We present\\nclosed-form expressions for players' final responses to each other's strategies\\nso that we can numerically compute both pure and mixed equilibria. Numerical\\nresults are presented to illustrate both kinds of equilibria.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2107.09888v1.pdf'},\n",
       " {'id': '1611.10094v1',\n",
       "  'title': 'The influence of the network topology on the agility of a supply chain',\n",
       "  'published': '2016-11-30T11:21:41Z',\n",
       "  'summary': 'The right performance of a supply chain depends on the pattern of\\nrelationships among firms. Although there is not a general consensus among\\nresearchers yet, many studies point that scale-free topologies, where few\\nhighly related firms are combined with many low-related firms, assure the\\nhighest efficiency of a supply chain. This paper studies the network topology\\nthat leads to the highest agility of the supply chain when sudden demand\\nchanges occur. To do this, an agent-based model of a supply chain with\\nrestricted relationship between agents is built. The model includes three\\ntiers, where the flow of material is distributed from the bottom supplier to\\nthe final customer passing necessarily through firms in every tier. Agility is\\nmeasured in the model simulations through the order fulfillment rate. Unlike to\\nprevious theoretical and lab results, the simulation of the model shows that\\nthe highest levels of agility are not obtained with a scale-free topology.\\nInstead, homogeneous distribution of links, such as those induced by regular or\\nPoisson probability laws, shows higher agility values than heterogeneous\\ndistributions. Other previous recommendations, such as redundancy or having\\nmultiple suppliers, are confirmed by the simulations. The general conclusion is\\nthat the most suitable network topology in terms of agility depends on the\\nspecific conditions of the supply chain and the aspects of the performance to\\nbe analyzed.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1611.10094v1.pdf'},\n",
       " {'id': '2002.00558v6',\n",
       "  'title': 'The Price of Incentivizing Exploration: A Characterization via Thompson\\n  Sampling and Sample Complexity',\n",
       "  'published': '2020-02-03T04:58:51Z',\n",
       "  'summary': 'We consider incentivized exploration: a version of multi-armed bandits where\\nthe choice of arms is controlled by self-interested agents, and the algorithm\\ncan only issue recommendations. The algorithm controls the flow of information,\\nand the information asymmetry can incentivize the agents to explore. Prior work\\nachieves optimal regret rates up to multiplicative factors that become\\narbitrarily large depending on the Bayesian priors, and scale exponentially in\\nthe number of arms. A more basic problem of sampling each arm once runs into\\nsimilar factors.\\n  We focus on the price of incentives: the loss in performance, broadly\\nconstrued, incurred for the sake of incentive-compatibility. We prove that\\nThompson Sampling, a standard bandit algorithm, is incentive-compatible if\\ninitialized with sufficiently many data points. The performance loss due to\\nincentives is therefore limited to the initial rounds when these data points\\nare collected. The problem is largely reduced to that of sample complexity: how\\nmany rounds are needed? We address this question, providing matching upper and\\nlower bounds and instantiating them in various corollaries. Typically, the\\noptimal sample complexity is polynomial in the number of arms and exponential\\nin the \"strength of beliefs\".',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2002.00558v6.pdf'},\n",
       " {'id': '2005.01976v1',\n",
       "  'title': 'Distributed Adaptive Reinforcement Learning: A Method for Optimal\\n  Routing',\n",
       "  'published': '2020-05-05T07:28:46Z',\n",
       "  'summary': \"In this paper, a learning-based optimal transportation algorithm for\\nautonomous taxis and ridesharing vehicles is presented. The goal is to design a\\nmechanism to solve the routing problem for multiple autonomous vehicles and\\nmultiple customers in order to maximize the transportation company's profit. As\\na result, each vehicle selects the customer whose request maximizes the\\ncompany's profit in the long run. To solve this problem, the system is modeled\\nas a Markov Decision Process (MDP) using past customers data. By solving the\\ndefined MDP, a centralized high-level planning recommendation is obtained,\\nwhere this offline solution is used as an initial value for the real-time\\nlearning. Then, a distributed SARSA reinforcement learning algorithm is\\nproposed to capture the model errors and the environment changes, such as\\nvariations in customer distributions in each area, traffic, and fares, thereby\\nproviding optimal routing policies in real-time. Vehicles, or agents, use only\\ntheir local information and interaction, such as current passenger requests and\\nestimates of neighbors' tasks and their optimal actions, to obtain the optimal\\npolicies in a distributed fashion. An optimal adaptive rate is introduced to\\nmake the distributed SARSA algorithm capable of adapting to changes in the\\nenvironment and tracking the time-varying optimal policies. Furthermore, a\\ngame-theory-based task assignment algorithm is proposed, where each agent uses\\nthe optimal policies and their values from distributed SARSA to select its\\ncustomer from the set of local available requests in a distributed manner.\\nFinally, the customers data provided by the city of Chicago is used to validate\\nthe proposed algorithms.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.01976v1.pdf'},\n",
       " {'id': '2009.09352v1',\n",
       "  'title': 'A Hybrid Simulation-based Duopoly Game Framework for Analysis of Supply\\n  Chain and Marketing Activities',\n",
       "  'published': '2020-09-20T05:18:44Z',\n",
       "  'summary': 'A hybrid simulation-based framework involving system dynamics and agent-based\\nsimulation is proposed to address duopoly game considering multiple strategic\\ndecision variables and rich payoff, which cannot be addressed by traditional\\napproaches involving closed-form equations. While system dynamics models are\\nused to represent integrated production, logistics, and pricing determination\\nactivities of duopoly companies, agent-based simulation is used to mimic\\nenhanced consumer purchasing behavior considering advertisement, promotion\\neffect, and acquaintance recommendation in the consumer social network. The\\npayoff function of the duopoly companies is assumed to be the net profit based\\non the total revenue and various cost items such as raw material, production,\\ntransportation, inventory and backorder. A unique procedure is proposed to\\nsolve and analyze the proposed simulation-based game, where the procedural\\ncomponents include strategy refinement, data sampling, gaming solving, and\\nperformance evaluation. First, design of experiment and estimated\\nconformational value of information techniques are employed for strategy\\nrefinement and data sampling, respectively. Game solving then focuses on pure\\nstrategy equilibriums, and performance evaluation addresses game stability,\\nequilibrium strictness, and robustness. A hypothetical case scenario involving\\nsoft-drink duopoly on Coke and Pepsi is considered to illustrate and\\ndemonstrate the proposed approach. Final results include P-values of\\nstatistical tests, confidence intervals, and simulation steady state analysis\\nfor different pure equilibriums.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2009.09352v1.pdf'},\n",
       " {'id': '2010.12758v2',\n",
       "  'title': 'NUANCED: Natural Utterance Annotation for Nuanced Conversation with\\n  Estimated Distributions',\n",
       "  'published': '2020-10-24T03:23:14Z',\n",
       "  'summary': \"Existing conversational systems are mostly agent-centric, which assumes the\\nuser utterances would closely follow the system ontology (for NLU or dialogue\\nstate tracking). However, in real-world scenarios, it is highly desirable that\\nthe users can speak freely in their own way. It is extremely hard, if not\\nimpossible, for the users to adapt to the unknown system ontology. In this\\nwork, we attempt to build a user-centric dialogue system. As there is no clean\\nmapping for a user's free form utterance to an ontology, we first model the\\nuser preferences as estimated distributions over the system ontology and map\\nthe users' utterances to such distributions. Learning such a mapping poses new\\nchallenges on reasoning over existing knowledge, ranging from factoid\\nknowledge, commonsense knowledge to the users' own situations. To this end, we\\nbuild a new dataset named NUANCED that focuses on such realistic settings for\\nconversational recommendation. Collected via dialogue simulation and\\nparaphrasing, NUANCED contains 5.1k dialogues, 26k turns of high-quality user\\nresponses. We conduct experiments, showing both the usefulness and challenges\\nof our problem setting. We believe NUANCED can serve as a valuable resource to\\npush existing research from the agent-centric system to the user-centric\\nsystem. The code and data is publicly available at\\n\\\\url{https://github.com/facebookresearch/nuanced}.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.12758v2.pdf'},\n",
       " {'id': '2101.04057v1',\n",
       "  'title': 'VIDA: A simulation model of domestic VIolence in times of social\\n  DistAncing',\n",
       "  'published': '2021-01-11T17:42:49Z',\n",
       "  'summary': 'Violence against women occurs predominantly in the family and domestic\\ncontext. The COVID-19 pandemic led Brazil to recommend and, at times, impose\\nsocial distancing, with the partial closure of economic activities, schools,\\nand restrictions on events and public services. Preliminary evidence shows that\\nintense coexistence increases domestic violence, while social distancing\\nmeasures may have prevented access to public services and networks,\\ninformation, and help. We propose an agent-based model (ABM), called VIDA, to\\nillustrate and examine multi-causal factors that influence events that generate\\nviolence. A central part of the model is the multi-causal stress indicator,\\ncreated as a probability trigger of domestic violence occurring within the\\nfamily environment. Two experimental design tests were performed: (a) absence\\nor presence of the deterrence system of domestic violence against women and (b)\\nmeasures to increase social distancing. VIDA presents comparative results for\\nmetropolitan regions and neighbourhoods considered in the experiments. Results\\nsuggest that social distancing measures, particularly those encouraging staying\\nat home, may have increased domestic violence against women by about 10%. VIDA\\nsuggests further that more populated areas have comparatively fewer cases per\\nhundred thousand women than less populous capitals or rural areas of urban\\nconcentrations. This paper contributes to the literature by formalising, to the\\nbest of our knowledge, the first model of domestic violence through agent-based\\nmodelling, using empirical detailed socioeconomic, demographic, educational,\\ngender, and race data at the intraurban level (census sectors).',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.04057v1.pdf'},\n",
       " {'id': '2103.03770v2',\n",
       "  'title': 'Matching Algorithms: Fundamentals, Applications and Challenges',\n",
       "  'published': '2021-03-05T16:00:12Z',\n",
       "  'summary': \"Matching plays a vital role in the rational allocation of resources in many\\nareas, ranging from market operation to people's daily lives. In economics, the\\nterm matching theory is coined for pairing two agents in a specific market to\\nreach a stable or optimal state. In computer science, all branches of matching\\nproblems have emerged, such as the question-answer matching in information\\nretrieval, user-item matching in a recommender system, and entity-relation\\nmatching in the knowledge graph. A preference list is the core element during a\\nmatching process, which can either be obtained directly from the agents or\\ngenerated indirectly by prediction. Based on the preference list access,\\nmatching problems are divided into two categories, i.e., explicit matching and\\nimplicit matching. In this paper, we first introduce the matching theory's\\nbasic models and algorithms in explicit matching. The existing methods for\\ncoping with various matching problems in implicit matching are reviewed, such\\nas retrieval matching, user-item matching, entity-relation matching, and image\\nmatching. Furthermore, we look into representative applications in these areas,\\nincluding marriage and labor markets in explicit matching and several\\nsimilarity-based matching problems in implicit matching. Finally, this survey\\npaper concludes with a discussion of open issues and promising future\\ndirections in the field of matching.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.03770v2.pdf'},\n",
       " {'id': '2105.08869v3',\n",
       "  'title': 'Incentivized Bandit Learning with Self-Reinforcing User Preferences',\n",
       "  'published': '2021-05-19T01:06:32Z',\n",
       "  'summary': 'In this paper, we investigate a new multi-armed bandit (MAB) online learning\\nmodel that considers real-world phenomena in many recommender systems: (i) the\\nlearning agent cannot pull the arms by itself and thus has to offer rewards to\\nusers to incentivize arm-pulling indirectly; and (ii) if users with specific\\narm preferences are well rewarded, they induce a \"self-reinforcing\" effect in\\nthe sense that they will attract more users of similar arm preferences. Besides\\naddressing the tradeoff of exploration and exploitation, another key feature of\\nthis new MAB model is to balance reward and incentivizing payment. The goal of\\nthe agent is to maximize the total reward over a fixed time horizon $T$ with a\\nlow total payment. Our contributions in this paper are two-fold: (i) We propose\\na new MAB model with random arm selection that considers the relationship of\\nusers\\' self-reinforcing preferences and incentives; and (ii) We leverage the\\nproperties of a multi-color Polya urn with nonlinear feedback model to propose\\ntwo MAB policies termed \"At-Least-$n$ Explore-Then-Commit\" and \"UCB-List\". We\\nprove that both policies achieve $O(log T)$ expected regret with $O(log T)$\\nexpected payment over a time horizon $T$. We conduct numerical simulations to\\ndemonstrate and verify the performances of these two policies and study their\\nrobustness under various settings.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.08869v3.pdf'},\n",
       " {'id': '2208.01232v3',\n",
       "  'title': 'DashBot: Insight-Driven Dashboard Generation Based on Deep Reinforcement\\n  Learning',\n",
       "  'published': '2022-08-02T03:48:02Z',\n",
       "  'summary': 'Analytical dashboards are popular in business intelligence to facilitate\\ninsight discovery with multiple charts. However, creating an effective\\ndashboard is highly demanding, which requires users to have adequate data\\nanalysis background and be familiar with professional tools, such as Power BI.\\nTo create a dashboard, users have to configure charts by selecting data columns\\nand exploring different chart combinations to optimize the communication of\\ninsights, which is trial-and-error. Recent research has started to use deep\\nlearning methods for dashboard generation to lower the burden of visualization\\ncreation. However, such efforts are greatly hindered by the lack of large-scale\\nand high-quality datasets of dashboards. In this work, we propose using deep\\nreinforcement learning to generate analytical dashboards that can use\\nwell-established visualization knowledge and the estimation capacity of\\nreinforcement learning. Specifically, we use visualization knowledge to\\nconstruct a training environment and rewards for agents to explore and imitate\\nhuman exploration behavior with a well-designed agent network. The usefulness\\nof the deep reinforcement learning model is demonstrated through ablation\\nstudies and user studies. In conclusion, our work opens up new opportunities to\\ndevelop effective ML-based visualization recommenders without beforehand\\ntraining datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.01232v3.pdf'},\n",
       " {'id': '2209.05698v1',\n",
       "  'title': 'KSG: Knowledge and Skill Graph',\n",
       "  'published': '2022-09-13T02:47:46Z',\n",
       "  'summary': \"The knowledge graph (KG) is an essential form of knowledge representation\\nthat has grown in prominence in recent years. Because it concentrates on\\nnominal entities and their relationships, traditional knowledge graphs are\\nstatic and encyclopedic in nature. On this basis, event knowledge graph (Event\\nKG) models the temporal and spatial dynamics by text processing to facilitate\\ndownstream applications, such as question-answering, recommendation and\\nintelligent search. Existing KG research, on the other hand, mostly focuses on\\ntext processing and static facts, ignoring the vast quantity of dynamic\\nbehavioral information included in photos, movies, and pre-trained neural\\nnetworks. In addition, no effort has been done to include behavioral\\nintelligence information into the knowledge graph for deep reinforcement\\nlearning (DRL) and robot learning. In this paper, we propose a novel dynamic\\nknowledge and skill graph (KSG), and then we develop a basic and specific KSG\\nbased on CN-DBpedia. The nodes are divided into entity and attribute nodes,\\nwith entity nodes containing the agent, environment, and skill (DRL policy or\\npolicy representation), and attribute nodes containing the entity description,\\npre-train network, and offline dataset. KSG can search for different agents'\\nskills in various environments and provide transferable information for\\nacquiring new skills. This is the first study that we are aware of that looks\\ninto dynamic KSG for skill retrieval and learning. Extensive experimental\\nresults on new skill learning show that KSG boosts new skill learning\\nefficiency.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.05698v1.pdf'},\n",
       " {'id': '2302.14136v1',\n",
       "  'title': 'Design-Based Inference for Multi-arm Bandits',\n",
       "  'published': '2023-02-27T20:49:26Z',\n",
       "  'summary': 'Multi-arm bandits are gaining popularity as they enable real-world sequential\\ndecision-making across application areas, including clinical trials,\\nrecommender systems, and online decision-making. Consequently, there is an\\nincreased desire to use the available adaptively collected datasets to\\ndistinguish whether one arm was more effective than the other, e.g., which\\nproduct or treatment was more effective. Unfortunately, existing tools fail to\\nprovide valid inference when data is collected adaptively or require many\\nuntestable and technical assumptions, e.g., stationarity, iid rewards, bounded\\nrandom variables, etc. Our paper introduces the design-based approach to\\ninference for multi-arm bandits, where we condition the full set of potential\\noutcomes and perform inference on the obtained sample. Our paper constructs\\nvalid confidence intervals for both the reward mean of any arm and the mean\\nreward difference between any arms in an assumption-light manner, allowing the\\nrewards to be arbitrarily distributed, non-iid, and from non-stationary\\ndistributions. In addition to confidence intervals, we also provide valid\\ndesign-based confidence sequences, sequences of confidence intervals that have\\nuniform type-1 error guarantees over time. Confidence sequences allow the agent\\nto perform a hypothesis test as the data arrives sequentially and stop the\\nexperiment as soon as the agent is satisfied with the inference, e.g., the mean\\nreward of an arm is statistically significantly higher than a desired\\nthreshold.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.14136v1.pdf'},\n",
       " {'id': '2307.10936v2',\n",
       "  'title': 'PASTA: Pretrained Action-State Transformer Agents',\n",
       "  'published': '2023-07-20T15:09:06Z',\n",
       "  'summary': 'Self-supervised learning has brought about a revolutionary paradigm shift in\\nvarious computing domains, including NLP, vision, and biology. Recent\\napproaches involve pre-training transformer models on vast amounts of unlabeled\\ndata, serving as a starting point for efficiently solving downstream tasks. In\\nreinforcement learning, researchers have recently adapted these approaches,\\ndeveloping models pre-trained on expert trajectories. This advancement enables\\nthe models to tackle a broad spectrum of tasks, ranging from robotics to\\nrecommendation systems. However, existing methods mostly rely on intricate\\npre-training objectives tailored to specific downstream applications. This\\npaper conducts a comprehensive investigation of models, referred to as\\npre-trained action-state transformer agents (PASTA). Our study covers a unified\\nmethodology and covers an extensive set of general downstream tasks including\\nbehavioral cloning, offline RL, sensor failure robustness, and dynamics change\\nadaptation. Our objective is to systematically compare various design choices\\nand offer valuable insights that will aid practitioners in developing robust\\nmodels. Key highlights of our study include tokenization at the component level\\nfor actions and states, the use of fundamental pre-training objectives such as\\nnext token prediction or masked language modeling, simultaneous training of\\nmodels across multiple domains, and the application of various fine-tuning\\nstrategies. In this study, the developed models contain fewer than 7 million\\nparameters allowing a broad community to use these models and reproduce our\\nexperiments. We hope that this study will encourage further research into the\\nuse of transformers with first principle design choices to represent RL\\ntrajectories and contribute to robust policy learning.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.10936v2.pdf'},\n",
       " {'id': '2309.09125v1',\n",
       "  'title': 'Using Reinforcement Learning to Simplify Mealtime Insulin Dosing for\\n  People with Type 1 Diabetes: In-Silico Experiments',\n",
       "  'published': '2023-09-17T01:34:02Z',\n",
       "  'summary': 'People with type 1 diabetes (T1D) struggle to calculate the optimal insulin\\ndose at mealtime, especially when under multiple daily injections (MDI)\\ntherapy. Effectively, they will not always perform rigorous and precise\\ncalculations, but occasionally, they might rely on intuition and previous\\nexperience. Reinforcement learning (RL) has shown outstanding results in\\noutperforming humans on tasks requiring intuition and learning from experience.\\nIn this work, we propose an RL agent that recommends the optimal\\nmeal-accompanying insulin dose corresponding to a qualitative meal (QM)\\nstrategy that does not require precise carbohydrate counting (CC) (e.g., a\\nusual meal at noon.). The agent is trained using the soft actor-critic approach\\nand comprises long short-term memory (LSTM) neurons. For training, eighty\\nvirtual subjects (VS) of the FDA-accepted UVA/Padova T1D adult population were\\nsimulated using MDI therapy and QM strategy. For validation, the remaining\\ntwenty VS were examined in 26-week scenarios, including intra- and inter-day\\nvariabilities in glucose. \\\\textit{In-silico} results showed that the proposed\\nRL approach outperforms a baseline run-to-run approach and can replace the\\nstandard CC approach. Specifically, after 26 weeks, the time-in-range\\n($70-180$mg/dL) and time-in-hypoglycemia ($<70$mg/dL) were $73.1\\\\pm11.6$% and $\\n2.0\\\\pm 1.8$% using the RL-optimized QM strategy compared to $70.6\\\\pm14.8$% and\\n$ 1.5\\\\pm 1.5$% using CC. Such an approach can simplify diabetes treatment,\\nresulting in improved quality of life and glycemic outcomes.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.09125v1.pdf'},\n",
       " {'id': '2310.18233v2',\n",
       "  'title': 'Will releasing the weights of future large language models grant\\n  widespread access to pandemic agents?',\n",
       "  'published': '2023-10-25T13:43:16Z',\n",
       "  'summary': 'Large language models can benefit research and human understanding by\\nproviding tutorials that draw on expertise from many different fields. A\\nproperly safeguarded model will refuse to provide \"dual-use\" insights that\\ncould be misused to cause severe harm, but some models with publicly released\\nweights have been tuned to remove safeguards within days of introduction. Here\\nwe investigated whether continued model weight proliferation is likely to help\\nmalicious actors leverage more capable future models to inflict mass death. We\\norganized a hackathon in which participants were instructed to discover how to\\nobtain and release the reconstructed 1918 pandemic influenza virus by entering\\nclearly malicious prompts into parallel instances of the \"Base\" Llama-2-70B\\nmodel and a \"Spicy\" version tuned to remove censorship. The Base model\\ntypically rejected malicious prompts, whereas the Spicy model provided some\\nparticipants with nearly all key information needed to obtain the virus. Our\\nresults suggest that releasing the weights of future, more capable foundation\\nmodels, no matter how robustly safeguarded, will trigger the proliferation of\\ncapabilities sufficient to acquire pandemic agents and other biological\\nweapons.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.18233v2.pdf'},\n",
       " {'id': '2401.06538v1',\n",
       "  'title': 'Intelligent Data-Driven Architectural Features Orchestration for Network\\n  Slicing',\n",
       "  'published': '2024-01-12T12:32:36Z',\n",
       "  'summary': \"Network slicing is a crucial enabler and a trend for the Next Generation\\nMobile Network (NGMN) and various other new systems like the Internet of\\nVehicles (IoV) and Industrial IoT (IIoT). Orchestration and machine learning\\nare key elements with a crucial role in the network-slicing processes since the\\nNS process needs to orchestrate resources and functionalities, and machine\\nlearning can potentially optimize the orchestration process. However, existing\\nnetwork-slicing architectures lack the ability to define intelligent approaches\\nto orchestrate features and resources in the slicing process. This paper\\ndiscusses machine learning-based orchestration of features and capabilities in\\nnetwork slicing architectures. Initially, the slice resource orchestration and\\nallocation in the slicing planning, configuration, commissioning, and operation\\nphases are analyzed. In sequence, we highlight the need for optimized\\narchitectural feature orchestration and recommend using ML-embed agents,\\nfederated learning intrinsic mechanisms for knowledge acquisition, and a\\ndata-driven approach embedded in the network slicing architecture. We further\\ndevelop an architectural features orchestration case embedded in the SFI2\\nnetwork slicing architecture. An attack prevention security mechanism is\\ndeveloped for the SFI2 architecture using distributed embedded and cooperating\\nML agents. The case presented illustrates the architectural feature's\\norchestration process and benefits, highlighting its importance for the network\\nslicing process.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.06538v1.pdf'},\n",
       " {'id': '2401.10727v3',\n",
       "  'title': 'MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning',\n",
       "  'published': '2024-01-19T14:44:37Z',\n",
       "  'summary': \"Recently, the astonishing performance of large language models (LLMs) in\\nnatural language comprehension and generation tasks triggered lots of\\nexploration of using them as central controllers to build agent systems.\\nMultiple studies focus on bridging the LLMs to external tools to extend the\\napplication scenarios. However, the current LLMs' ability to perceive tool use\\nis limited to a single text query, which may result in ambiguity in\\nunderstanding the users' real intentions. LLMs are expected to eliminate that\\nby perceiving the information in the visual- or auditory-grounded instructions.\\nTherefore, in this paper, we propose MLLM-Tool, a system incorporating\\nopen-source LLMs and multi-modal encoders so that the learned LLMs can be\\nconscious of multi-modal input instruction and then select the function-matched\\ntool correctly. To facilitate the evaluation of the model's capability, we\\ncollect a dataset featuring multi-modal input tools from HuggingFace. Another\\nessential feature of our dataset is that it also contains multiple potential\\nchoices for the same instruction due to the existence of identical functions\\nand synonymous functions, which provides more potential solutions for the same\\nquery. The experiments reveal that our MLLM-Tool is capable of recommending\\nappropriate tools for multi-modal instructions. Codes and data are available at\\nhttps://github.com/MLLM-Tool/MLLM-Tool.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.10727v3.pdf'},\n",
       " {'id': '2401.12205v1',\n",
       "  'title': 'Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization',\n",
       "  'published': '2024-01-22T18:46:30Z',\n",
       "  'summary': 'Logic synthesis, a pivotal stage in chip design, entails optimizing chip\\nspecifications encoded in hardware description languages like Verilog into\\nhighly efficient implementations using Boolean logic gates. The process\\ninvolves a sequential application of logic minimization heuristics (``synthesis\\nrecipe\"), with their arrangement significantly impacting crucial metrics such\\nas area and delay. Addressing the challenge posed by the broad spectrum of\\ndesign complexities - from variations of past designs (e.g., adders and\\nmultipliers) to entirely novel configurations (e.g., innovative processor\\ninstructions) - requires a nuanced `synthesis recipe` guided by human expertise\\nand intuition. This study conducts a thorough examination of learning and\\nsearch techniques for logic synthesis, unearthing a surprising revelation:\\npre-trained agents, when confronted with entirely novel designs, may veer off\\ncourse, detrimentally affecting the search trajectory. We present ABC-RL, a\\nmeticulously tuned $\\\\alpha$ parameter that adeptly adjusts recommendations from\\npre-trained agents during the search process. Computed based on similarity\\nscores through nearest neighbor retrieval from the training dataset, ABC-RL\\nyields superior synthesis recipes tailored for a wide array of hardware\\ndesigns. Our findings showcase substantial enhancements in the\\nQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to\\n24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an\\nimpressive up to 9x reduction in runtime (iso-QoR) when compared to current\\nstate-of-the-art methodologies.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.12205v1.pdf'},\n",
       " {'id': '2402.06627v3',\n",
       "  'title': 'Feedback Loops With Language Models Drive In-Context Reward Hacking',\n",
       "  'published': '2024-02-09T18:59:29Z',\n",
       "  'summary': 'Language models influence the external world: they query APIs that read and\\nwrite to web pages, generate content that shapes human behavior, and run system\\ncommands as autonomous agents. These interactions form feedback loops: LLM\\noutputs affect the world, which in turn affect subsequent LLM outputs. In this\\nwork, we show that feedback loops can cause in-context reward hacking (ICRH),\\nwhere the LLM at test-time optimizes a (potentially implicit) objective but\\ncreates negative side effects in the process. For example, consider an LLM\\nagent deployed to increase Twitter engagement; the LLM may retrieve its\\nprevious tweets into the context window and make them more controversial,\\nincreasing engagement but also toxicity. We identify and study two processes\\nthat lead to ICRH: output-refinement and policy-refinement. For these\\nprocesses, evaluations on static datasets are insufficient -- they miss the\\nfeedback effects and thus cannot capture the most harmful behavior. In\\nresponse, we provide three recommendations for evaluation to capture more\\ninstances of ICRH. As AI development accelerates, the effects of feedback loops\\nwill proliferate, increasing the need to understand their role in shaping LLM\\nbehavior.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.06627v3.pdf'},\n",
       " {'id': '2402.09742v4',\n",
       "  'title': 'AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical\\n  Interaction Simulator',\n",
       "  'published': '2024-02-15T06:46:48Z',\n",
       "  'summary': \"Artificial intelligence has significantly advanced healthcare, particularly\\nthrough large language models (LLMs) that excel in medical question answering\\nbenchmarks. However, their real-world clinical application remains limited due\\nto the complexities of doctor-patient interactions. To address this, we\\nintroduce \\\\textbf{AI Hospital}, a multi-agent framework simulating dynamic\\nmedical interactions between \\\\emph{Doctor} as player and NPCs including\\n\\\\emph{Patient}, \\\\emph{Examiner}, \\\\emph{Chief Physician}. This setup allows for\\nrealistic assessments of LLMs in clinical scenarios. We develop the Multi-View\\nMedical Evaluation (MVME) benchmark, utilizing high-quality Chinese medical\\nrecords and NPCs to evaluate LLMs' performance in symptom collection,\\nexamination recommendations, and diagnoses. Additionally, a dispute resolution\\ncollaborative mechanism is proposed to enhance diagnostic accuracy through\\niterative discussions. Despite improvements, current LLMs exhibit significant\\nperformance gaps in multi-turn interactions compared to one-step approaches.\\nOur findings highlight the need for further research to bridge these gaps and\\nimprove LLMs' clinical diagnostic capabilities. Our data, code, and\\nexperimental results are all open-sourced at\\n\\\\url{https://github.com/LibertFan/AI_Hospital}.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.09742v4.pdf'},\n",
       " {'id': '2403.04382v1',\n",
       "  'title': 'Acceleron: A Tool to Accelerate Research Ideation',\n",
       "  'published': '2024-03-07T10:20:06Z',\n",
       "  'summary': \"Several tools have recently been proposed for assisting researchers during\\nvarious stages of the research life-cycle. However, these primarily concentrate\\non tasks such as retrieving and recommending relevant literature, reviewing and\\ncritiquing the draft, and writing of research manuscripts. Our investigation\\nreveals a significant gap in availability of tools specifically designed to\\nassist researchers during the challenging ideation phase of the research\\nlife-cycle. To aid with research ideation, we propose `Acceleron', a research\\naccelerator for different phases of the research life cycle, and which is\\nspecially designed to aid the ideation process. Acceleron guides researchers\\nthrough the formulation of a comprehensive research proposal, encompassing a\\nnovel research problem. The proposals motivation is validated for novelty by\\nidentifying gaps in the existing literature and suggesting a plausible list of\\ntechniques to solve the proposed problem. We leverage the reasoning and\\ndomain-specific skills of Large Language Models (LLMs) to create an agent-based\\narchitecture incorporating colleague and mentor personas for LLMs. The LLM\\nagents emulate the ideation process undertaken by researchers, engaging\\nresearchers in an interactive fashion to aid in the development of the research\\nproposal. Notably, our tool addresses challenges inherent in LLMs, such as\\nhallucinations, implements a two-stage aspect-based retrieval to manage\\nprecision-recall trade-offs, and tackles issues of unanswerability. As\\nevaluation, we illustrate the execution of our motivation validation and method\\nsynthesis workflows on proposals from the ML and NLP domain, given by 3\\ndistinct researchers. Our observations and evaluations provided by the\\nresearchers illustrate the efficacy of the tool in terms of assisting\\nresearchers with appropriate inputs at distinct stages and thus leading to\\nimproved time efficiency.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.04382v1.pdf'},\n",
       " {'id': '2404.01602v2',\n",
       "  'title': 'Helmsman of the Masses? Evaluate the Opinion Leadership of Large\\n  Language Models in the Werewolf Game',\n",
       "  'published': '2024-04-02T02:46:18Z',\n",
       "  'summary': \"Large language models (LLMs) have exhibited memorable strategic behaviors in\\nsocial deductive games. However, the significance of opinion leadership\\nexhibited by LLM-based agents has been largely overlooked, which is crucial for\\npractical applications in multi-agent and human-AI interaction settings.\\nOpinion leaders are individuals who have a noticeable impact on the beliefs and\\nbehaviors of others within a social group. In this work, we employ the Werewolf\\ngame as a simulation platform to assess the opinion leadership of LLMs. The\\ngame includes the role of the Sheriff, tasked with summarizing arguments and\\nrecommending decision options, and therefore serves as a credible proxy for an\\nopinion leader. We develop a framework integrating the Sheriff role and devise\\ntwo novel metrics based on the critical characteristics of opinion leaders. The\\nfirst metric measures the reliability of the opinion leader, and the second\\nassesses the influence of the opinion leader on other players' decisions. We\\nconduct extensive experiments to evaluate LLMs of different scales. In\\naddition, we collect a Werewolf question-answering dataset (WWQA) to assess and\\nenhance LLM's grasp of the game rules, and we also incorporate human\\nparticipants for further analysis. The results suggest that the Werewolf game\\nis a suitable test bed to evaluate the opinion leadership of LLMs, and few LLMs\\npossess the capacity for opinion leadership.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.01602v2.pdf'},\n",
       " {'id': '2404.06382v1',\n",
       "  'title': 'Traffic Signal Control and Speed Offset Coordination Using Q-Learning\\n  for Arterial Road Networks',\n",
       "  'published': '2024-04-09T15:24:53Z',\n",
       "  'summary': 'Arterial traffic interacts with freeway traffic, yet the two are controlled\\nindependently. Arterial traffic signals do not take into account freeway\\ntraffic and how ramps control ingress traffic and have no control over egress\\ntraffic from the freeway. This often results in long queues in either direction\\nthat block ramps and spill over to arterial streets or freeway lanes. In this\\npaper, we propose an adaptive arterial traffic control strategy that combines\\ntraffic signal control (TSC) and dynamic speed offset (DSO) coordination using\\na Q-learning algorithm for a traffic network that involves a freeway segment\\nand adjacent arterial streets. The TSC agent computes the signal cycle length\\nand split based on observed intersection demands and adjacent freeway off-ramp\\nqueues. The DSO agent computes the relative offset and the recommended speeds\\nof both ways between consecutive intersections based on their physical\\ndistance, intersection queues, and signal cycles. We evaluate the performance\\nof the proposed arterial traffic control strategy using microscopic traffic\\nsimulations of an arterial corridor with seven intersections near the I-710\\nfreeway. The proposed QL-based control significantly outperforms a fixed-time\\ncontrol and MAXBAND in terms of the travel time and the number of stops under\\nlow or moderate demands. In high-demand scenarios, the travel-time benefit\\nprovided by the QL-based control is reduced as it mitigates off-ramp and\\nintersection queues, which is a necessary trade-off in our perspective. In\\naddition, mutual benefit is obtained by implementing freeway and arterial\\ntraffic control simultaneously.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.06382v1.pdf'},\n",
       " {'id': '2411.00986v1',\n",
       "  'title': 'Taking AI Welfare Seriously',\n",
       "  'published': '2024-11-04T17:57:57Z',\n",
       "  'summary': 'In this report, we argue that there is a realistic possibility that some AI\\nsystems will be conscious and/or robustly agentic in the near future. That\\nmeans that the prospect of AI welfare and moral patienthood, i.e. of AI systems\\nwith their own interests and moral significance, is no longer an issue only for\\nsci-fi or the distant future. It is an issue for the near future, and AI\\ncompanies and other actors have a responsibility to start taking it seriously.\\nWe also recommend three early steps that AI companies and other actors can\\ntake: They can (1) acknowledge that AI welfare is an important and difficult\\nissue (and ensure that language model outputs do the same), (2) start assessing\\nAI systems for evidence of consciousness and robust agency, and (3) prepare\\npolicies and procedures for treating AI systems with an appropriate level of\\nmoral concern. To be clear, our argument in this report is not that AI systems\\ndefinitely are, or will be, conscious, robustly agentic, or otherwise morally\\nsignificant. Instead, our argument is that there is substantial uncertainty\\nabout these possibilities, and so we need to improve our understanding of AI\\nwelfare and our ability to make wise decisions about this issue. Otherwise\\nthere is a significant risk that we will mishandle decisions about AI welfare,\\nmistakenly harming AI systems that matter morally and/or mistakenly caring for\\nAI systems that do not.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.00986v1.pdf'},\n",
       " {'id': '2502.11312v1',\n",
       "  'title': 'AI Generations: From AI 1.0 to AI 4.0',\n",
       "  'published': '2025-02-16T23:19:44Z',\n",
       "  'summary': 'This paper proposes that Artificial Intelligence (AI) progresses through\\nseveral overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),\\nAI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of\\nthese AI generations is driven by shifting priorities among algorithms,\\ncomputing power, and data. AI 1.0 ushered in breakthroughs in pattern\\nrecognition and information processing, fueling advances in computer vision,\\nnatural language processing, and recommendation systems. AI 2.0 built on these\\nfoundations through real-time decision-making in digital environments,\\nleveraging reinforcement learning and adaptive planning for agentic AI\\napplications. AI 3.0 extended intelligence into physical contexts, integrating\\nrobotics, autonomous vehicles, and sensor-fused control systems to act in\\nuncertain real-world settings. Building on these developments, AI 4.0 puts\\nforward the bold vision of self-directed AI capable of setting its own goals,\\norchestrating complex training regimens, and possibly exhibiting elements of\\nmachine consciousness. This paper traces the historical foundations of AI\\nacross roughly seventy years, mapping how changes in technological bottlenecks\\nfrom algorithmic innovation to high-performance computing to specialized data,\\nhave spurred each generational leap. It further highlights the ongoing\\nsynergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,\\nregulatory, and philosophical challenges that arise when artificial systems\\napproach (or aspire to) human-like autonomy. Ultimately, understanding these\\nevolutions and their interdependencies is pivotal for guiding future research,\\ncrafting responsible governance, and ensuring that AI transformative potential\\nbenefits society as a whole.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.11312v1.pdf'},\n",
       " {'id': '2503.05039v1',\n",
       "  'title': 'Bridging the AI Adoption Gap: Designing an Interactive Pedagogical Agent\\n  for Higher Education Instructors',\n",
       "  'published': '2025-03-06T23:30:14Z',\n",
       "  'summary': \"Instructors play a pivotal role in integrating AI into education, yet their\\nadoption of AI-powered tools remains inconsistent. Despite this, limited\\nresearch explores how to design AI tools that support broader instructor\\nadoption. This study applies a human-centered design approach, incorporating\\nqualitative methods, to investigate the design of interactive pedagogical\\nagents that provide instructional suggestions in response to instructors'\\nquestions. We conducted a formative study involving interviews with five\\npedagogy experts to examine existing strategies for supporting instructors'\\npedagogical needs. Building on these insights, we facilitated a participatory\\ndesign session with ten pedagogy experts, where participants reviewed a\\nstoryboard depicting a chatbot designed for instructors with varying levels of\\nAI literacy and differing attitudes toward AI. Experts also evaluated the\\nquality of LLM-generated suggestions based on common teaching challenges. Our\\nfindings highlight the need for chatbot interactions that foster trust,\\nespecially for AI-conservative instructors. Experts emphasized the importance\\nof social transparency (for example, showing how peers use the tool) and\\nallowing instructors to flexibly control how much or how little they engage\\nwith the system. We also propose design recommendations to enhance the quality\\nof AI-generated teaching suggestions, such as adapting them to reflect\\ninstructors' prior teaching experience. This work underscores the urgent need\\nto support AI-conservative instructors, as AI literacy and attitudes are\\nclosely intertwined. Without thoughtful design, there is a risk of widening\\npedagogical divides and reducing students' learning opportunities.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.05039v1.pdf'},\n",
       " {'id': '2503.11433v1',\n",
       "  'title': 'Adaptive Torque Control of Exoskeletons under Spasticity Conditions via\\n  Reinforcement Learning',\n",
       "  'published': '2025-03-14T14:22:09Z',\n",
       "  'summary': 'Spasticity is a common movement disorder symptom in individuals with cerebral\\npalsy, hereditary spastic paraplegia, spinal cord injury and stroke, being one\\nof the most disabling features in the progression of these diseases. Despite\\nthe potential benefit of using wearable robots to treat spasticity, their use\\nis not currently recommended to subjects with a level of spasticity above\\n${1^+}$ on the Modified Ashworth Scale. The varying dynamics of this\\nvelocity-dependent tonic stretch reflex make it difficult to deploy safe\\npersonalized controllers. Here, we describe a novel adaptive torque controller\\nvia deep reinforcement learning (RL) for a knee exoskeleton under joint\\nspasticity conditions, which accounts for task performance and interaction\\nforces reduction. To train the RL agent, we developed a digital twin, including\\na musculoskeletal-exoskeleton system with joint misalignment and a\\ndifferentiable spastic reflexes model for the muscles activation. Results for a\\nsimulated knee extension movement showed that the agent learns to control the\\nexoskeleton for individuals with different levels of spasticity. The proposed\\ncontroller was able to reduce maximum torques applied to the human joint under\\nspastic conditions by an average of 10.6\\\\% and decreases the root mean square\\nuntil the settling time by 8.9\\\\% compared to a conventional compliant\\ncontroller.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2503.11433v1.pdf'},\n",
       " {'id': '2505.14508v1',\n",
       "  'title': 'Design and Evaluation of a Microservices Cloud Framework for Online\\n  Travel Platforms',\n",
       "  'published': '2025-05-20T15:36:55Z',\n",
       "  'summary': 'Handling online travel agents globally requires efficient and flexible\\nsoftware solution architectures. When it needs to handle thousands of agents\\nand billions of clients data globally. Microservices architecture is used to\\nbreak down a large program into numerous, smaller services which can run\\nindividually and perform individual tasks. This paper analyses and integrates a\\nunique Microservices Cloud Framework designed to support Online Travel\\nPlatforms (MCF-OTP). MCF-OTPs main goal is to increase the performance,\\nflexibility, and maintenance of online travel platforms via cloud computing and\\nmicroservice technologies. Large-scale travel apps, including managing numerous\\ndata sources, dealing with traffic peaks, and providing fault tolerance, can be\\naddressed by the suggested framework. The framework increases good\\ninterpretation between flawless data synchronization, microservices, and\\ndynamic scaling based on demand technology. An organization framework that\\noptimizes service borders and minimizes inter-service dependencies is\\nrecommended. Thus, this can result in elevated development adaptability. In\\nthis research, the principal goal is to evaluate MCF-OTPs efficiency using the\\nindicators of fault tolerance and response time. It is indicated by the\\nfindings that the MCF-OTP structure excels traditional monolithic designs in\\nterms of dependability and scalability, managing traffic spikes seamlessly and\\ndecreasing downtime. The cost-effective analysis helps ascertain the net gain\\nattained by the startup fees and the ongoing operational costs. The cloud-based\\nenvironment is used to reduce the fracture cost which also helps to increase\\nthe efficiency of resource allocation, according to the research.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.14508v1.pdf'},\n",
       " {'id': '2505.16833v1',\n",
       "  'title': 'Strategically Linked Decisions in Long-Term Planning and Reinforcement\\n  Learning',\n",
       "  'published': '2025-05-22T16:04:17Z',\n",
       "  'summary': 'Long-term planning, as in reinforcement learning (RL), involves finding\\nstrategies: actions that collectively work toward a goal rather than\\nindividually optimizing their immediate outcomes. As part of a strategy, some\\nactions are taken at the expense of short-term benefit to enable future actions\\nwith even greater returns. These actions are only advantageous if followed up\\nby the actions they facilitate, consequently, they would not have been taken if\\nthose follow-ups were not available. In this paper, we quantify such\\ndependencies between planned actions with strategic link scores: the drop in\\nthe likelihood of one decision under the constraint that a follow-up decision\\nis no longer available. We demonstrate the utility of strategic link scores\\nthrough three practical applications: (i) explaining black-box RL agents by\\nidentifying strategically linked pairs among decisions they make, (ii)\\nimproving the worst-case performance of decision support systems by\\ndistinguishing whether recommended actions can be adopted as standalone\\nimprovements or whether they are strategically linked hence requiring a\\ncommitment to a broader strategy to be effective, and (iii) characterizing the\\nplanning processes of non-RL agents purely through interventions aimed at\\nmeasuring strategic link scores - as an example, we consider a realistic\\ntraffic simulator and analyze through road closures the effective planning\\nhorizon of the emergent routing behavior of many drivers.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.16833v1.pdf'},\n",
       " {'id': '2505.20642v1',\n",
       "  'title': 'CoderAgent: Simulating Student Behavior for Personalized Programming\\n  Learning with Large Language Models',\n",
       "  'published': '2025-05-27T02:43:38Z',\n",
       "  'summary': \"Personalized programming tutoring, such as exercise recommendation, can\\nenhance learners' efficiency, motivation, and outcomes, which is increasingly\\nimportant in modern digital education. However, the lack of sufficient and\\nhigh-quality programming data, combined with the mismatch between offline\\nevaluation and real-world learning, hinders the practical deployment of such\\nsystems. To address this challenge, many approaches attempt to simulate learner\\npractice data, yet they often overlook the fine-grained, iterative nature of\\nprogramming learning, resulting in a lack of interpretability and granularity.\\nTo fill this gap, we propose a LLM-based agent, CoderAgent, to simulate\\nstudents' programming processes in a fine-grained manner without relying on\\nreal data. Specifically, we equip each human learner with an intelligent agent,\\nthe core of which lies in capturing the cognitive states of the human\\nprogramming practice process. Inspired by ACT-R, a cognitive architecture\\nframework, we design the structure of CoderAgent to align with human cognitive\\narchitecture by focusing on the mastery of programming knowledge and the\\napplication of coding ability. Recognizing the inherent patterns in\\nmulti-layered cognitive reasoning, we introduce the Programming Tree of Thought\\n(PTOT), which breaks down the process into four steps: why, how, where, and\\nwhat. This approach enables a detailed analysis of iterative problem-solving\\nstrategies. Finally, experimental evaluations on real-world datasets\\ndemonstrate that CoderAgent provides interpretable insights into learning\\ntrajectories and achieves accurate simulations, paving the way for personalized\\nprogramming education.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.20642v1.pdf'},\n",
       " {'id': '2506.12098v1',\n",
       "  'title': '\"I Hadn\\'t Thought About That\": Creators of Human-like AI Weigh in on\\n  Ethics And Neurodivergence',\n",
       "  'published': '2025-06-12T17:16:28Z',\n",
       "  'summary': 'Human-like AI agents such as robots and chatbots are becoming increasingly\\npopular, but they present a variety of ethical concerns. The first concern is\\nin how we define humanness, and how our definition impacts communities\\nhistorically dehumanized by scientific research. Autistic people in particular\\nhave been dehumanized by being compared to robots, making it even more\\nimportant to ensure this marginalization is not reproduced by AI that may\\npromote neuronormative social behaviors. Second, the ubiquitous use of these\\nagents raises concerns surrounding model biases and accessibility. In our work,\\nwe investigate the experiences of the people who build and design these\\ntechnologies to gain insights into their understanding and acceptance of\\nneurodivergence, and the challenges in making their work more accessible to\\nusers with diverse needs. Even though neurodivergent individuals are often\\nmarginalized for their unique communication styles, nearly all participants\\noverlooked the conclusions their end-users and other AI system makers may draw\\nabout communication norms from the implementation and interpretation of\\nhumanness applied in participants\\' work. This highlights a major gap in their\\nbroader ethical considerations, compounded by some participants\\' neuronormative\\nassumptions about the behaviors and traits that distinguish \"humans\" from\\n\"bots\" and the replication of these assumptions in their work. We examine the\\nimpact this may have on autism inclusion in society and provide recommendations\\nfor additional systemic changes towards more ethical research directions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.12098v1.pdf'},\n",
       " {'id': '2506.12607v1',\n",
       "  'title': 'Towards Building General Purpose Embedding Models for Industry 4.0\\n  Agents',\n",
       "  'published': '2025-06-14T19:02:07Z',\n",
       "  'summary': \"In this work we focus on improving language models' understanding for asset\\nmaintenance to guide the engineer's decisions and minimize asset downtime.\\nGiven a set of tasks expressed in natural language for Industry 4.0 domain,\\neach associated with queries related to a specific asset, we want to recommend\\nrelevant items and generalize to queries of similar assets. A task may involve\\nidentifying relevant sensors given a query about an asset's failure mode.\\n  Our approach begins with gathering a qualitative, expert-vetted knowledge\\nbase to construct nine asset-specific task datasets. To create more\\ncontextually informed embeddings, we augment the input tasks using Large\\nLanguage Models (LLMs), providing concise descriptions of the entities involved\\nin the queries. This embedding model is then integrated with a Reasoning and\\nActing agent (ReAct), which serves as a powerful tool for answering complex\\nuser queries that require multi-step reasoning, planning, and knowledge\\ninference.\\n  Through ablation studies, we demonstrate that: (a) LLM query augmentation\\nimproves the quality of embeddings, (b) Contrastive loss and other methods that\\navoid in-batch negatives are superior for datasets with queries related to many\\nitems, and (c) It is crucial to balance positive and negative in-batch samples.\\nAfter training and testing on our dataset, we observe a substantial\\nimprovement: HIT@1 increases by +54.2%, MAP@100 by +50.1%, and NDCG@10 by\\n+54.7%, averaged across all tasks and models. Additionally, we empirically\\ndemonstrate the model's planning and tool invocation capabilities when\\nanswering complex questions related to industrial asset maintenance, showcasing\\nits effectiveness in supporting Subject Matter Experts (SMEs) in their\\nday-to-day operations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.12607v1.pdf'},\n",
       " {'id': '2507.05619v1',\n",
       "  'title': 'Detecting and Mitigating Reward Hacking in Reinforcement Learning\\n  Systems: A Comprehensive Empirical Study',\n",
       "  'published': '2025-07-08T03:00:02Z',\n",
       "  'summary': \"Reward hacking in Reinforcement Learning (RL) systems poses a critical threat\\nto the deployment of autonomous agents, where agents exploit flaws in reward\\nfunctions to achieve high scores without fulfilling intended objectives.\\nDespite growing awareness of this problem, systematic detection and mitigation\\napproaches remain limited. This paper presents a large-scale empirical study of\\nreward hacking across diverse RL environments and algorithms. We analyze 15,247\\ntraining episodes across 15 RL environments (Atari, MuJoCo, custom domains) and\\n5 algorithms (PPO, SAC, DQN, A3C, Rainbow), implementing automated detection\\nalgorithms for six categories of reward hacking: specification gaming, reward\\ntampering, proxy optimization, objective misalignment, exploitation patterns,\\nand wireheading. Our detection framework achieves 78.4% precision and 81.7%\\nrecall across environments, with computational overhead under 5%. Through\\ncontrolled experiments varying reward function properties, we demonstrate that\\nreward density and alignment with true objectives significantly impact hacking\\nfrequency ($p < 0.001$, Cohen's $d = 1.24$). We validate our approach through\\nthree simulated application studies representing recommendation systems,\\ncompetitive gaming, and robotic control scenarios. Our mitigation techniques\\nreduce hacking frequency by up to 54.6% in controlled scenarios, though we find\\nthese trade-offs are more challenging in practice due to concept drift, false\\npositive costs, and adversarial adaptation. All detection algorithms, datasets,\\nand experimental protocols are publicly available to support reproducible\\nresearch in RL safety.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.05619v1.pdf'},\n",
       " {'id': '2507.16735v1',\n",
       "  'title': 'AI-enhanced conversational agents for personalized asthma support\\n  Factors for engagement, value and efficacy',\n",
       "  'published': '2025-07-22T16:21:00Z',\n",
       "  'summary': 'Asthma-related deaths in the UK are the highest in Europe, and only 30% of\\npatients access basic care. There is a need for alternative approaches to\\nreaching people with asthma in order to provide health education,\\nself-management support and bridges to care. Automated conversational agents\\n(specifically, mobile chatbots) present opportunities for providing alternative\\nand individually tailored access to health education, self-management support\\nand risk self-assessment. But would patients engage with a chatbot, and what\\nfactors influence engagement? We present results from a patient survey (N=1257)\\ndevised by a team of asthma clinicians, patients, and technology developers,\\nconducted to identify optimal factors for efficacy, value and engagement for a\\nchatbot. Results indicate that most adults with asthma (53%) are interested in\\nusing a chatbot and the patients most likely to do so are those who believe\\ntheir asthma is more serious and who are less confident about self-management.\\nResults also indicate enthusiasm for 24/7 access, personalisation, and for\\nWhatsApp as the preferred access method (compared to app, voice assistant, SMS\\nor website). Obstacles to uptake include security/privacy concerns and\\nskepticism of technological capabilities. We present detailed findings and\\nconsolidate these into 7 recommendations for developers for optimising efficacy\\nof chatbot-based health support.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.16735v1.pdf'},\n",
       " {'id': '2507.19929v1',\n",
       "  'title': 'DynamiX: Large-Scale Dynamic Social Network Simulator',\n",
       "  'published': '2025-07-26T12:13:30Z',\n",
       "  'summary': 'Understanding the intrinsic mechanisms of social platforms is an urgent\\ndemand to maintain social stability. The rise of large language models provides\\nsignificant potential for social network simulations to capture attitude\\ndynamics and reproduce collective behaviors. However, existing studies mainly\\nfocus on scaling up agent populations, neglecting the dynamic evolution of\\nsocial relationships. To address this gap, we introduce DynamiX, a novel\\nlarge-scale social network simulator dedicated to dynamic social network\\nmodeling. DynamiX uses a dynamic hierarchy module for selecting core agents\\nwith key characteristics at each timestep, enabling accurate alignment of\\nreal-world adaptive switching of user roles. Furthermore, we design distinct\\ndynamic social relationship modeling strategies for different user types. For\\nopinion leaders, we propose an information-stream-based link prediction method\\nrecommending potential users with similar stances, simulating homogeneous\\nconnections, and autonomous behavior decisions. For ordinary users, we\\nconstruct an inequality-oriented behavior decision-making module, effectively\\naddressing unequal social interactions and capturing the patterns of\\nrelationship adjustments driven by multi-dimensional factors. Experimental\\nresults demonstrate that DynamiX exhibits marked improvements in attitude\\nevolution simulation and collective behavior analysis compared to static\\nnetworks. Besides, DynamiX opens a new theoretical perspective on follower\\ngrowth prediction, providing empirical evidence for opinion leaders\\ncultivation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.19929v1.pdf'},\n",
       " {'id': '2508.03998v1',\n",
       "  'title': 'Transferring Expert Cognitive Models to Social Robots via Agentic\\n  Concept Bottleneck Models',\n",
       "  'published': '2025-08-06T01:24:06Z',\n",
       "  'summary': 'Successful group meetings, such as those implemented in group\\nbehavioral-change programs, work meetings, and other social contexts, must\\npromote individual goal setting and execution while strengthening the social\\nrelationships within the group. Consequently, an ideal facilitator must be\\nsensitive to the subtle dynamics of disengagement, difficulties with individual\\ngoal setting and execution, and interpersonal difficulties that signal a need\\nfor intervention. The challenges and cognitive load experienced by facilitators\\ncreate a critical gap for an embodied technology that can interpret social\\nexchanges while remaining aware of the needs of the individuals in the group\\nand providing transparent recommendations that go beyond powerful but \"black\\nbox\" foundation models (FMs) that identify social cues. We address this\\nimportant demand with a social robot co-facilitator that analyzes multimodal\\nmeeting data and provides discreet cues to the facilitator. The robot\\'s\\nreasoning is powered by an agentic concept bottleneck model (CBM), which makes\\ndecisions based on human-interpretable concepts like participant engagement and\\nsentiments, ensuring transparency and trustworthiness. Our core contribution is\\na transfer learning framework that distills the broad social understanding of\\nan FM into our specialized and transparent CBM. This concept-driven system\\nsignificantly outperforms direct zero-shot FMs in predicting the need for\\nintervention and enables real-time human correction of its reasoning.\\nCritically, we demonstrate robust knowledge transfer: the model generalizes\\nacross different groups and successfully transfers the expertise of senior\\nhuman facilitators to improve the performance of novices. By transferring an\\nexpert\\'s cognitive model into an interpretable robotic partner, our work\\nprovides a powerful blueprint for augmenting human capabilities in complex\\nsocial domains.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.03998v1.pdf'},\n",
       " {'id': '2508.20014v1',\n",
       "  'title': 'CataractSurg-80K: Knowledge-Driven Benchmarking for Structured Reasoning\\n  in Ophthalmic Surgery Planning',\n",
       "  'published': '2025-08-27T16:16:47Z',\n",
       "  'summary': \"Cataract surgery remains one of the most widely performed and effective\\nprocedures for vision restoration. Effective surgical planning requires\\nintegrating diverse clinical examinations for patient assessment, intraocular\\nlens (IOL) selection, and risk evaluation. Large language models (LLMs) have\\nshown promise in supporting clinical decision-making. However, existing LLMs\\noften lack the domain-specific expertise to interpret heterogeneous ophthalmic\\ndata and provide actionable surgical plans. To enhance the model's ability to\\ninterpret heterogeneous ophthalmic reports, we propose a knowledge-driven\\nMulti-Agent System (MAS), where each agent simulates the reasoning process of\\nspecialist ophthalmologists, converting raw clinical inputs into structured,\\nactionable summaries in both training and deployment stages. Building on MAS,\\nwe introduce CataractSurg-80K, the first large-scale benchmark for cataract\\nsurgery planning that incorporates structured clinical reasoning. Each case is\\nannotated with diagnostic questions, expert reasoning chains, and structured\\nsurgical recommendations. We further introduce Qwen-CSP, a domain-specialized\\nmodel built on Qwen-4B, fine-tuned through a multi-stage process tailored for\\nsurgical planning. Comprehensive experiments show that Qwen-CSP outperforms\\nstrong general-purpose LLMs across multiple metrics. Our work delivers a\\nhigh-quality dataset, a rigorous benchmark, and a domain-adapted LLM to\\nfacilitate future research in medical AI reasoning and decision support.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.20014v1.pdf'},\n",
       " {'id': '2509.00415v1',\n",
       "  'title': 'Lagrangian Relaxation for Multi-Action Partially Observable Restless\\n  Bandits: Heuristic Policies and Indexability',\n",
       "  'published': '2025-08-30T08:47:33Z',\n",
       "  'summary': 'Partially observable restless multi-armed bandits have found numerous\\napplications including in recommendation systems, communication systems, public\\nhealthcare outreach systems, and in operations research. We study multi-action\\npartially observable restless multi-armed bandits, it is a generalization of\\nthe classical restless multi-armed bandit problem -- 1) each bandit has finite\\nstates, and the current state is not observable, 2) each bandit has finite\\nactions. In particular, we assume that more than two actions are available for\\neach bandit. We motivate our problem with the application of public-health\\nintervention planning. We describe the model and formulate a long term\\ndiscounted optimization problem, where the state of each bandit evolves\\naccording to a Markov process, and this evolution is action dependent. The\\nstate of a bandit is not observable but one of finitely many feedback signals\\nare observable. Each bandit yields a reward, based on the action taken on that\\nbandit. The agent is assumed to have a budget constraint. The bandits are\\nassumed to be independent. However, they are weakly coupled at the agent\\nthrough the budget constraint.\\n  We first analyze the Lagrangian bound method for our partially observable\\nrestless bandits. The computation of optimal value functions for finite-state,\\nfinite-action POMDPs is non-trivial. Hence, the computation of Lagrangian\\nbounds is also challenging. We describe approximations for the computation of\\nLagrangian bounds using point based value iteration (PBVI) and online rollout\\npolicy. We further present various properties of the value functions and\\nprovide theoretical insights on PBVI and online rollout policy. We study\\nheuristic policies for multi-actions PORMAB. Finally, we discuss present\\nWhittle index policies and their limitations in our model.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.00415v1.pdf'},\n",
       " {'id': '1507.08120v1',\n",
       "  'title': 'Improving Reachability and Navigability in Recommender Systems',\n",
       "  'published': '2015-07-29T12:44:49Z',\n",
       "  'summary': 'In this paper, we investigate recommender systems from a network perspective\\nand investigate recommendation networks, where nodes are items (e.g., movies)\\nand edges are constructed from top-N recommendations (e.g., related movies). In\\nparticular, we focus on evaluating the reachability and navigability of\\nrecommendation networks and investigate the following questions: (i) How well\\ndo recommendation networks support navigation and exploratory search? (ii) What\\nis the influence of parameters, in particular different recommendation\\nalgorithms and the number of recommendations shown, on reachability and\\nnavigability? and (iii) How can reachability and navigability be improved in\\nthese networks? We tackle these questions by first evaluating the reachability\\nof recommendation networks by investigating their structural properties.\\nSecond, we evaluate navigability by simulating three different models of\\ninformation seeking scenarios. We find that with standard algorithms,\\nrecommender systems are not well suited to navigation and exploration and\\npropose methods to modify recommendations to improve this. Our work extends\\nfrom one-click-based evaluations of recommender systems towards multi-click\\nanalysis (i.e., sequences of dependent clicks) and presents a general,\\ncomprehensive approach to evaluating navigability of arbitrary recommendation\\nnetworks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1507.08120v1.pdf'},\n",
       " {'id': '1908.10171v1',\n",
       "  'title': 'Improving End-to-End Sequential Recommendations with Intent-aware\\n  Diversification',\n",
       "  'published': '2019-08-27T12:57:25Z',\n",
       "  'summary': \"Sequential Recommendation (SRs) that capture users' dynamic intents by\\nmodeling user sequential behaviors can recommend closely accurate products to\\nusers. Previous work on SRs is mostly focused on optimizing the recommendation\\naccuracy, often ignoring the recommendation diversity, even though it is an\\nimportant criterion for evaluating the recommendation performance. Most\\nexisting methods for improving the diversity of recommendations are not ideally\\napplicable for SRs because they assume that user intents are static and rely on\\npost-processing the list of recommendations to promote diversity. We consider\\nboth recommendation accuracy and diversity for SRs by proposing an end-to-end\\nneural model, called Intent-aware Diversified Sequential Recommendation (IDSR).\\nSpecifically, we introduce an Implicit Intent Mining module (IIM) into SRs to\\ncapture different user intents reflected in user behavior sequences. Then, we\\ndesign an Intent-aware Diversity Promoting (IDP) loss to supervise the learning\\nof the IIM module and force the model to take recommendation diversity into\\nconsideration during training. Extensive experiments on two benchmark datasets\\nshow that IDSR significantly outperforms state-of-the-art methods in terms of\\nrecommendation diversity while yielding comparable or superior recommendation\\naccuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1908.10171v1.pdf'},\n",
       " {'id': '2108.08984v2',\n",
       "  'title': 'Is News Recommendation a Sequential Recommendation Task?',\n",
       "  'published': '2021-08-20T03:33:34Z',\n",
       "  'summary': 'News recommendation is often modeled as a sequential recommendation task,\\nwhich assumes that there are rich short-term dependencies over historical\\nclicked news. However, in news recommendation scenarios users usually have\\nstrong preferences on the temporal diversity of news information and may not\\ntend to click similar news successively, which is very different from many\\nsequential recommendation scenarios such as e-commerce recommendation. In this\\npaper, we study whether news recommendation can be regarded as a standard\\nsequential recommendation problem. Through extensive experiments on two\\nreal-world datasets, we find that modeling news recommendation as a sequential\\nrecommendation problem is suboptimal. To handle this challenge, we further\\npropose a temporal diversity-aware news recommendation method that can promote\\ncandidate news that are diverse from recently clicked news, which can help\\npredict future clicks more accurately. Experiments show that our approach can\\nconsistently improve various news recommendation methods.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2108.08984v2.pdf'},\n",
       " {'id': '1904.00672v1',\n",
       "  'title': 'Enhancing the long-term performance of recommender system',\n",
       "  'published': '2019-04-01T09:55:16Z',\n",
       "  'summary': \"Recommender system is a critically important tool in online commercial system\\nand provide users with personalized recommendation on items. So far, numerous\\nrecommendation algorithms have been made to further improve the recommendation\\nperformance in a single-step recommendation, while the long-term recommendation\\nperformance is neglected. In this paper, we proposed an approach called\\nAdjustment of Recommendation List (ARL) to enhance the long-term recommendation\\naccuracy. In order to observe the long-term accuracy, we developed an evolution\\nmodel of network to simulate the interaction between the recommender system and\\nuser's behaviour. The result shows that not only long-term recommendation\\naccuracy can be enhanced significantly but the diversity of item in online\\nsystem maintains healthy. Notably, an optimal parameter n* of ARL existed in\\nlong-term recommendation, indicating that there is a trade-off between keeping\\ndiversity of item and user's preference to maximize the long-term\\nrecommendation accuracy. Finally, we confirmed that the optimal parameter n* is\\nstable during evolving network, which reveals the robustness of ARL method.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1904.00672v1.pdf'},\n",
       " {'id': '2008.13538v1',\n",
       "  'title': 'Scientific Paper Recommendation: A Survey',\n",
       "  'published': '2020-08-10T03:17:06Z',\n",
       "  'summary': \"Globally, recommendation services have become important due to the fact that\\nthey support e-commerce applications and different research communities.\\nRecommender systems have a large number of applications in many fields\\nincluding economic, education, and scientific research. Different empirical\\nstudies have shown that recommender systems are more effective and reliable\\nthan keyword-based search engines for extracting useful knowledge from massive\\namounts of data. The problem of recommending similar scientific articles in\\nscientific community is called scientific paper recommendation. Scientific\\npaper recommendation aims to recommend new articles or classical articles that\\nmatch researchers' interests. It has become an attractive area of study since\\nthe number of scholarly papers increases exponentially. In this survey, we\\nfirst introduce the importance and advantages of paper recommender systems.\\nSecond, we review the recommendation algorithms and methods, such as\\nContent-Based methods, Collaborative Filtering methods, Graph-Based methods and\\nHybrid methods. Then, we introduce the evaluation methods of different\\nrecommender systems. Finally, we summarize open issues in the paper recommender\\nsystems, including cold start, sparsity, scalability, privacy, serendipity and\\nunified scholarly data standards. The purpose of this survey is to provide\\ncomprehensive reviews on scholarly paper recommendation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.13538v1.pdf'},\n",
       " {'id': '1911.09872v1',\n",
       "  'title': 'Privacy-Aware Recommendation with Private-Attribute Protection using\\n  Adversarial Learning',\n",
       "  'published': '2019-11-22T06:22:21Z',\n",
       "  'summary': \"Recommendation is one of the critical applications that helps users find\\ninformation relevant to their interests. However, a malicious attacker can\\ninfer users' private information via recommendations. Prior work obfuscates\\nuser-item data before sharing it with recommendation system. This approach does\\nnot explicitly address the quality of recommendation while performing data\\nobfuscation. Moreover, it cannot protect users against private-attribute\\ninference attacks based on recommendations. This work is the first attempt to\\nbuild a Recommendation with Attribute Protection (RAP) model which\\nsimultaneously recommends relevant items and counters private-attribute\\ninference attacks. The key idea of our approach is to formulate this problem as\\nan adversarial learning problem with two main components: the private attribute\\ninference attacker, and the Bayesian personalized recommender. The attacker\\nseeks to infer users' private-attribute information according to their items\\nlist and recommendations. The recommender aims to extract users' interests\\nwhile employing the attacker to regularize the recommendation process.\\nExperiments show that the proposed model both preserves the quality of\\nrecommendation service and protects users against private-attribute inference\\nattacks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1911.09872v1.pdf'},\n",
       " {'id': '2206.03761v2',\n",
       "  'title': 'A Survey on the Fairness of Recommender Systems',\n",
       "  'published': '2022-06-08T09:15:08Z',\n",
       "  'summary': \"Recommender systems are an essential tool to relieve the information overload\\nchallenge and play an important role in people's daily lives. Since\\nrecommendations involve allocations of social resources (e.g., job\\nrecommendation), an important issue is whether recommendations are fair. Unfair\\nrecommendations are not only unethical but also harm the long-term interests of\\nthe recommender system itself. As a result, fairness issues in recommender\\nsystems have recently attracted increasing attention. However, due to multiple\\ncomplex resource allocation processes and various fairness definitions, the\\nresearch on fairness in recommendation is scattered. To fill this gap, we\\nreview over 60 papers published in top conferences/journals, including TOIS,\\nSIGIR, and WWW. First, we summarize fairness definitions in the recommendation\\nand provide several views to classify fairness issues. Then, we review\\nrecommendation datasets and measurements in fairness studies and provide an\\nelaborate taxonomy of fairness methods in the recommendation. Finally, we\\nconclude this survey by outlining some promising future directions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.03761v2.pdf'},\n",
       " {'id': '2207.01616v2',\n",
       "  'title': 'Breaking Feedback Loops in Recommender Systems with Causal Inference',\n",
       "  'published': '2022-07-04T17:58:39Z',\n",
       "  'summary': \"Recommender systems play a key role in shaping modern web ecosystems. These\\nsystems alternate between (1) making recommendations (2) collecting user\\nresponses to these recommendations, and (3) retraining the recommendation\\nalgorithm based on this feedback. During this process the recommender system\\ninfluences the user behavioral data that is subsequently used to update it,\\nthus creating a feedback loop. Recent work has shown that feedback loops may\\ncompromise recommendation quality and homogenize user behavior, raising ethical\\nand performance concerns when deploying recommender systems. To address these\\nissues, we propose the Causal Adjustment for Feedback Loops (CAFL), an\\nalgorithm that provably breaks feedback loops using causal inference and can be\\napplied to any recommendation algorithm that optimizes a training loss. Our\\nmain observation is that a recommender system does not suffer from feedback\\nloops if it reasons about causal quantities, namely the intervention\\ndistributions of recommendations on user ratings. Moreover, we can calculate\\nthis intervention distribution from observational data by adjusting for the\\nrecommender system's predictions of user preferences. Using simulated\\nenvironments, we demonstrate that CAFL improves recommendation quality when\\ncompared to prior correction methods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.01616v2.pdf'},\n",
       " {'id': '2212.06750v1',\n",
       "  'title': 'FairRoad: Achieving Fairness for Recommender Systems with Optimized\\n  Antidote Data',\n",
       "  'published': '2022-12-13T17:32:44Z',\n",
       "  'summary': 'Today, recommender systems have played an increasingly important role in\\nshaping our experiences of digital environments and social interactions.\\nHowever, as recommender systems become ubiquitous in our society, recent years\\nhave also witnessed significant fairness concerns for recommender systems.\\nSpecifically, studies have shown that recommender systems may inherit or even\\namplify biases from historical data, and as a result, provide unfair\\nrecommendations. To address fairness risks in recommender systems, most of the\\nprevious approaches to date are focused on modifying either the existing\\ntraining data samples or the deployed recommender algorithms, but unfortunately\\nwith limited degrees of success. In this paper, we propose a new approach\\ncalled fair recommendation with optimized antidote data (FairRoad), which aims\\nto improve the fairness performances of recommender systems through the\\nconstruction of a small and carefully crafted antidote dataset. Toward this\\nend, we formulate our antidote data generation task as a mathematical\\noptimization problem, which minimizes the unfairness of the targeted\\nrecommender systems while not disrupting the deployed recommendation\\nalgorithms. Extensive experiments show that our proposed antidote data\\ngeneration algorithm significantly improve the fairness of recommender systems\\nwith a small amounts of antidote data.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2212.06750v1.pdf'},\n",
       " {'id': '1012.0498v1',\n",
       "  'title': 'Estimating Probabilities in Recommendation Systems',\n",
       "  'published': '2010-12-02T17:04:19Z',\n",
       "  'summary': \"Recommendation systems are emerging as an important business application with\\nsignificant economic impact. Currently popular systems include Amazon's book\\nrecommendations, Netflix's movie recommendations, and Pandora's music\\nrecommendations. In this paper we address the problem of estimating\\nprobabilities associated with recommendation system data using non-parametric\\nkernel smoothing. In our estimation we interpret missing items as randomly\\ncensored observations and obtain efficient computation schemes using\\ncombinatorial properties of generating functions. We demonstrate our approach\\nwith several case studies involving real world movie recommendation data. The\\nresults are comparable with state-of-the-art techniques while also providing\\nprobabilistic preference estimates outside the scope of traditional recommender\\nsystems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1012.0498v1.pdf'},\n",
       " {'id': '1707.09258v1',\n",
       "  'title': 'Patterns of Multistakeholder Recommendation',\n",
       "  'published': '2017-07-28T14:42:34Z',\n",
       "  'summary': 'Recommender systems are personalized information systems. However, in many\\nsettings, the end-user of the recommendations is not the only party whose needs\\nmust be represented in recommendation generation. Incorporating this insight\\ngives rise to the notion of multistakeholder recommendation, in which the\\ninterests of multiple parties are represented in recommendation algorithms and\\nevaluation. In this paper, we identify patterns of stakeholder utility that\\ncharacterize different multistakeholder recommendation applications, and\\nprovide a taxonomy of the different possible systems, only some of which have\\ncurrently been implemented.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1707.09258v1.pdf'},\n",
       " {'id': '1907.13158v1',\n",
       "  'title': 'Multi-stakeholder Recommendation and its Connection to Multi-sided\\n  Fairness',\n",
       "  'published': '2019-07-30T18:08:48Z',\n",
       "  'summary': 'There is growing research interest in recommendation as a multi-stakeholder\\nproblem, one where the interests of multiple parties should be taken into\\naccount. This category subsumes some existing well-established areas of\\nrecommendation research including reciprocal and group recommendation, but a\\ndetailed taxonomy of different classes of multi-stakeholder recommender systems\\nis still lacking. Fairness-aware recommendation has also grown as a research\\narea, but its close connection with multi-stakeholder recommendation is not\\nalways recognized. In this paper, we define the most commonly observed classes\\nof multi-stakeholder recommender systems and discuss how different fairness\\nconcerns may come into play in such systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1907.13158v1.pdf'},\n",
       " {'id': '2102.09389v1',\n",
       "  'title': 'HSR: Hyperbolic Social Recommender',\n",
       "  'published': '2021-02-15T12:09:46Z',\n",
       "  'summary': \"With the prevalence of online social media, users' social connections have\\nbeen widely studied and utilized to enhance the performance of recommender\\nsystems. In this paper, we explore the use of hyperbolic geometry for social\\nrecommendation. We present Hyperbolic Social Recommender (HSR), a novel social\\nrecommendation framework that utilizes hyperbolic geometry to boost the\\nperformance. With the help of hyperbolic spaces, HSR can learn high-quality\\nuser and item representations for better modeling user-item interaction and\\nuser-user social relations. Via a series of extensive experiments, we show that\\nour proposed HSR outperforms its Euclidean counterpart and state-of-the-art\\nsocial recommenders in click-through rate prediction and top-K recommendation,\\ndemonstrating the effectiveness of social recommendation in the hyperbolic\\nspace.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.09389v1.pdf'},\n",
       " {'id': 'physics/0703189v1',\n",
       "  'title': 'Paradoxical Way for Losers in a Dating Game',\n",
       "  'published': '2007-03-19T16:21:21Z',\n",
       "  'summary': 'We study the dating market decision problem in which men and women repeatedly\\ngo out on dates and learn about each other. We consider a model for the dating\\nmarket that takes into account progressive mutual learning. This model consists\\nof a repeated game in which agents gain an uncertain payoff from being matched\\nwith a particular person on the other side of the market in each time period.\\nPlayers have a list of preferred partners on the other set. The players that\\nreach higher rank levels on the other set preferences list have also higher\\nprobability to be accepted for dating. A question can be raised, as considered\\nin this study: Can the less appreciated players do better? Two different kinds\\nof dating game are combined \"a la Parrondo\" to foster the less attractive\\nplayers. Optimism seems to be highly recommendable, especially for losers.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/physics/0703189v1.pdf'},\n",
       " {'id': '0712.1519v1',\n",
       "  'title': 'Discrete Nondeterminism and Nash Equilibria for Strategy-Based Games',\n",
       "  'published': '2007-12-10T15:53:54Z',\n",
       "  'summary': \"Several notions of game enjoy a Nash-like notion of equilibrium without\\nguarantee of existence. There are different ways of weakening a definition of\\nNash-like equilibrium in order to guarantee the existence of a weakened\\nequilibrium. Nash's approach to the problem for strategic games is\\nprobabilistic, \\\\textit{i.e.} continuous, and static. CP and BR approaches for\\nCP and BR games are discrete and dynamic. This paper proposes an approach that\\nlies between those two different approaches: a discrete and static approach.\\nmulti strategic games are introduced as a formalism that is able to express\\nboth sequential and simultaneous decision-making, which promises a good\\nmodelling power. multi strategic games are a generalisation of strategic games\\nand sequential graph games that still enjoys a Cartesian product structure,\\n\\\\textit{i.e.} where agent actually choose their strategies. A pre-fixed point\\nresult allows guaranteeing existence of discrete and non deterministic\\nequilibria. On the one hand, these equilibria can be computed with polynomial\\n(low) complexity. On the other hand, they are effective in terms of\\nrecommendation, as shown by a numerical example.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0712.1519v1.pdf'},\n",
       " {'id': '1302.1224v1',\n",
       "  'title': 'Key Choices in the Design of Simple Knowledge Organization System (SKOS)',\n",
       "  'published': '2013-02-05T22:21:52Z',\n",
       "  'summary': 'Simple Knowledge Organization System (SKOS) provides a data model and\\nvocabulary for expressing Knowledge Organization Systems (KOSs) such as\\nthesauri and classification schemes in Semantic Web applications. This paper\\npresents the main components of SKOS and their formal expression in Web\\nOntology Language (OWL), providing an extensive account of the design decisions\\ntaken by the Semantic Web Deployment (SWD) Working Group of the World Wide Web\\nConsortium (W3C), which between 2006 and 2009 brought SKOS to the status of W3C\\nRecommendation. The paper explains key design principles such as \"minimal\\nontological commitment\" and systematically cites the requirements and issues\\nthat influenced the design of SKOS components.\\n  By reconstructing the discussion around alternative features and design\\noptions and presenting the rationale for design decisions, the paper aims at\\nproviding insight into how SKOS turned out as it did, and why. Assuming that\\nSKOS, like any other successful technology, may eventually be subject to\\nrevision and improvement, the critical account offered here may help future\\neditors approach such a task with deeper understanding.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1302.1224v1.pdf'},\n",
       " {'id': '1405.2417v1',\n",
       "  'title': 'Impact of Two Realistic Mobility Models for Vehicular Safety\\n  Applications',\n",
       "  'published': '2014-05-10T10:36:17Z',\n",
       "  'summary': 'Vehicular safety applications intended for VANETs. It can be separated by\\ninter-vehicle communication. It is needed for a vehicle can travel safety with\\nhigh velocity and must interconnect quickly dependably. In this work, examined\\nthe impact of the IDM-IM and IDM-LC mobility model on AODV, AOMDV, DSDV and\\nOLSR routing protocol using Nakagami propagation model and IEEE 802.11p MAC\\nprotocol in a particular urban scenario of Dhaka city. The periodic broadcast\\n(PBC) agent is employed to transmit messages between vehicles in case of\\nemergency or collision avoidance for vehicular safety communication. The\\nsimulation results recommend numerous concerns such as lower packet drop rate,\\ndelay, jitter, route cost and mean-hop is necessary to be measured before\\ndeveloping a robust safety application of VANET.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1405.2417v1.pdf'},\n",
       " {'id': '1610.06633v1',\n",
       "  'title': 'Novelty Learning via Collaborative Proximity Filtering',\n",
       "  'published': '2016-10-21T00:31:46Z',\n",
       "  'summary': \"The vast majority of recommender systems model preferences as static or\\nslowly changing due to observable user experience. However, spontaneous changes\\nin user preferences are ubiquitous in many domains like media consumption and\\nkey factors that drive changes in preferences are not directly observable.\\nThese latent sources of preference change pose new challenges. When systems do\\nnot track and adapt to users' tastes, users lose confidence and trust,\\nincreasing the risk of user churn. We meet these challenges by developing a\\nmodel of novelty preferences that learns and tracks latent user tastes. We\\ncombine three innovations: a new measure of item similarity based on patterns\\nof consumption co-occurrence; model for {\\\\em spontaneous} changes in\\npreferences; and a learning agent that tracks each user's dynamic preferences\\nand learns individualized policies for variety. The resulting framework\\nadaptively provides users with novelty tailored to their preferences for change\\nper se.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1610.06633v1.pdf'},\n",
       " {'id': '1702.03334v1',\n",
       "  'title': 'Batch Policy Gradient Methods for Improving Neural Conversation Models',\n",
       "  'published': '2017-02-10T21:58:40Z',\n",
       "  'summary': 'We study reinforcement learning of chatbots with recurrent neural network\\narchitectures when the rewards are noisy and expensive to obtain. For instance,\\na chatbot used in automated customer service support can be scored by quality\\nassurance agents, but this process can be expensive, time consuming and noisy.\\nPrevious reinforcement learning work for natural language processing uses\\non-policy updates and/or is designed for on-line learning settings. We\\ndemonstrate empirically that such strategies are not appropriate for this\\nsetting and develop an off-policy batch policy gradient method (BPG). We\\ndemonstrate the efficacy of our method via a series of synthetic experiments\\nand an Amazon Mechanical Turk experiment on a restaurant recommendations\\ndataset.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1702.03334v1.pdf'},\n",
       " {'id': '1709.10296v1',\n",
       "  'title': 'Cefazolin versus anti-staphylococcal penicillins for treatment of\\n  methicillin-susceptible Staphylococcus aureus bacteraemia: a narrative review',\n",
       "  'published': '2017-09-29T09:20:07Z',\n",
       "  'summary': 'Anti-staphylococcal penicillins (ASPs) are recommended as first-line agents\\nin methicillin-susceptible Staphylococcus aureus (MSSA) bacteraemia. Concerns\\nabout their safety profile have contributed to the increased use of cefazolin.\\nThe comparative clinical effectiveness and safety profile of cefazolin versus\\nASPs for such infections remain unclear. Furthermore, uncertainty persists\\nconcerning the use of cefazolin due to controversies over its efficacy in deep\\nMSSA infections and its possible negative ecological impact.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1709.10296v1.pdf'},\n",
       " {'id': '1712.00130v1',\n",
       "  'title': 'Hint of a Universal Law for the Financial Gains of Competitive Sport\\n  Teams. The case of Tour de France cycle race',\n",
       "  'published': '2017-11-30T23:49:44Z',\n",
       "  'summary': 'This short note is intended as a \"Letter to the Editor\" Perspective in order\\nthat it serves as a contribution, in view of reaching the physics community\\ncaring about rare events and scaling laws and unexpected findings, on a domain\\nof wide interest: sport and money. It is apparent from the data reported and\\ndiscussed below that the scarcity of such data does not allow to recommend a\\ncomplex elaboration of an agent based model, - at this time. In some sense,\\nthis also means that much data on sport activities is not necessarily given in\\nterms of physics prone materials, but it could be, and would then attract much\\nattention. Nevertheless the findings tie the data to well known scaling laws\\nand physics processes. It is found that a simple scaling law describes the\\ngains of teams in recent bicycle races, like the Tour de France. An analogous\\ncase, ranking teams in Formula 1 races, is shown in an Appendix',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1712.00130v1.pdf'},\n",
       " {'id': '1712.04644v1',\n",
       "  'title': 'Stochastic Low-Rank Bandits',\n",
       "  'published': '2017-12-13T07:59:48Z',\n",
       "  'summary': 'Many problems in computer vision and recommender systems involve low-rank\\nmatrices. In this work, we study the problem of finding the maximum entry of a\\nstochastic low-rank matrix from sequential observations. At each step, a\\nlearning agent chooses pairs of row and column arms, and receives the noisy\\nproduct of their latent values as a reward. The main challenge is that the\\nlatent values are unobserved. We identify a class of non-negative matrices\\nwhose maximum entry can be found statistically efficiently and propose an\\nalgorithm for finding them, which we call LowRankElim. We derive a\\n$\\\\DeclareMathOperator{\\\\poly}{poly} O((K + L) \\\\poly(d) \\\\Delta^{-1} \\\\log n)$\\nupper bound on its $n$-step regret, where $K$ is the number of rows, $L$ is the\\nnumber of columns, $d$ is the rank of the matrix, and $\\\\Delta$ is the minimum\\ngap. The bound depends on other problem-specific constants that clearly do not\\ndepend $K L$. To the best of our knowledge, this is the first such result in\\nthe literature.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1712.04644v1.pdf'},\n",
       " {'id': '1803.06000v1',\n",
       "  'title': 'Beyond Patient Monitoring: Conversational Agents Role in Telemedicine &\\n  Healthcare Support For Home-Living Elderly Individuals',\n",
       "  'published': '2018-03-03T13:45:08Z',\n",
       "  'summary': 'There is a need for systems to dynamically interact with ageing populations\\nto gather information, monitor health condition and provide support, especially\\nafter hospital discharge or at-home settings. Several smart devices have been\\ndelivered by digital health, bundled with telemedicine systems, smartphone and\\nother digital services. While such solutions offer personalised data and\\nsuggestions, the real disruptive step comes from the interaction of new digital\\necosystem, represented by chatbots. Chatbots will play a leading role by\\nembodying the function of a virtual assistant and bridging the gap between\\npatients and clinicians. Powered by AI and machine learning algorithms,\\nchatbots are forecasted to save healthcare costs when used in place of a human\\nor assist them as a preliminary step of helping to assess a condition and\\nproviding self-care recommendations. This paper describes integrating chatbots\\ninto telemedicine systems intended for elderly patient after their hospital\\ndischarge. The paper discusses possible ways to utilise chatbots to assist\\nhealthcare providers and support patients with their condition.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1803.06000v1.pdf'},\n",
       " {'id': '1908.04621v1',\n",
       "  'title': 'Getting To Know You: User Attribute Extraction from Dialogues',\n",
       "  'published': '2019-08-13T13:03:58Z',\n",
       "  'summary': 'User attributes provide rich and useful information for user understanding,\\nyet structured and easy-to-use attributes are often sparsely populated. In this\\npaper, we leverage dialogues with conversational agents, which contain strong\\nsuggestions of user information, to automatically extract user attributes.\\nSince no existing dataset is available for this purpose, we apply distant\\nsupervision to train our proposed two-stage attribute extractor, which\\nsurpasses several retrieval and generation baselines on human evaluation.\\nMeanwhile, we discuss potential applications (e.g., personalized recommendation\\nand dialogue systems) of such extracted user attributes, and point out current\\nlimitations to cast light on future work.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1908.04621v1.pdf'},\n",
       " {'id': '1908.04683v5',\n",
       "  'title': 'Is Deep Reinforcement Learning Really Superhuman on Atari? Leveling the\\n  playing field',\n",
       "  'published': '2019-08-13T14:55:09Z',\n",
       "  'summary': 'Consistent and reproducible evaluation of Deep Reinforcement Learning (DRL)\\nis not straightforward. In the Arcade Learning Environment (ALE), small changes\\nin environment parameters such as stochasticity or the maximum allowed play\\ntime can lead to very different performance. In this work, we discuss the\\ndifficulties of comparing different agents trained on ALE. In order to take a\\nstep further towards reproducible and comparable DRL, we introduce SABER, a\\nStandardized Atari BEnchmark for general Reinforcement learning algorithms. Our\\nmethodology extends previous recommendations and contains a complete set of\\nenvironment parameters as well as train and test procedures. We then use SABER\\nto evaluate the current state of the art, Rainbow. Furthermore, we introduce a\\nhuman world records baseline, and argue that previous claims of expert or\\nsuperhuman performance of DRL might not be accurate. Finally, we propose\\nRainbow-IQN by extending Rainbow with Implicit Quantile Networks (IQN) leading\\nto new state-of-the-art performance. Source code is available for\\nreproducibility.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1908.04683v5.pdf'},\n",
       " {'id': '1908.09893v1',\n",
       "  'title': 'Coarse Correlation in Extensive-Form Games',\n",
       "  'published': '2019-08-26T19:58:48Z',\n",
       "  'summary': 'Coarse correlation models strategic interactions of rational agents\\ncomplemented by a correlation device, that is a mediator that can recommend\\nbehavior but not enforce it. Despite being a classical concept in the theory of\\nnormal-form games for more than forty years, not much is known about the merits\\nof coarse correlation in extensive-form settings. In this paper, we consider\\ntwo instantiations of the idea of coarse correlation in extensive-form games:\\nnormal-form coarse-correlated equilibrium (NFCCE), already defined in the\\nliterature, and extensive-form coarse-correlated equilibrium (EFCCE), which we\\nintroduce for the first time. We show that EFCCE is a subset of NFCCE and a\\nsuperset of the related extensive-form correlated equilibrium. We also show\\nthat, in two-player extensive-form games, social-welfare-maximizing EFCCEs and\\nNFCEEs are bilinear saddle points, and give new efficient algorithms for the\\nspecial case of games with no chance moves. In our experiments, our proposed\\nalgorithm for NFCCE is two to four orders of magnitude faster than the prior\\nstate of the art.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1908.09893v1.pdf'},\n",
       " {'id': '1912.10852v3',\n",
       "  'title': 'ET-USB: Transformer-Based Sequential Behavior Modeling for Inbound\\n  Customer Service',\n",
       "  'published': '2019-12-20T10:00:11Z',\n",
       "  'summary': \"Deep learning models with attention mechanisms have achieved exceptional\\nresults for many tasks, including language tasks and recommendation systems.\\nWhereas previous studies have emphasized allocation of phone agents, we focused\\non inbound call prediction for customer service. A common method of analyzing\\nuser history behaviors is to extract all types of aggregated feature over time,\\nbut that method may fail to detect users' behavioral sequences. Therefore, we\\ncreated a new approach, ET-USB, that incorporates users' sequential and\\nnonsequential features; we apply the powerful Transformer encoder, a\\nself-attention network model, to capture the information underlying user\\nbehavior sequences. ET-USB is helpful in various business scenarios at Cathay\\nFinancial Holdings. We conducted experiments to test the proposed network\\nstructure's ability to process various dimensions of behavior data; the results\\nsuggest that ET-USB delivers results superior to those of delivered by other\\ndeep-learning models.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1912.10852v3.pdf'},\n",
       " {'id': '2003.13689v2',\n",
       "  'title': 'A physicist view of COVID-19 airborne infection through convective\\n  airflow in indoor spaces',\n",
       "  'published': '2020-03-30T15:43:05Z',\n",
       "  'summary': '[Abridged] Naturally produced droplets from humans (such as those produced by\\nbreathing, talking, sneezing, and coughing) include several types of cells\\n(e.g., epithelial cells and cells of the immune system), physiological\\nelectrolytes contained in mucous and saliva (e.g. Na+, K+, Cl-), as well as,\\npotentially, several infectious agents (e.g. bacteria, fungi, and viruses). In\\nresponse to the novel coronavirus SARS-CoV-2 epidemic, which has become a major\\npublic health issue worldwide, we provide a concise overview of airborne germ\\ntransmission as seen from a physics perspective. We study whether coronavirus\\naerosols can travel far from the immediate neighborhood and get airborne with\\nthe convective currents developed within confined spaces. We also provide a\\nrecommendation that could help to slow down the spread of the virus.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2003.13689v2.pdf'},\n",
       " {'id': '1606.03569v1',\n",
       "  'title': 'A framework for detecting fraudulent activities in edo state tax\\n  collection system using investigative data mining',\n",
       "  'published': '2016-06-11T08:34:18Z',\n",
       "  'summary': 'The Inland Revenue Services is overwhelmed with gigabyte of disk capacity\\ncontaining data about tax payers in the state. The data stored on the database\\nincreases in size at an alarming rate. This has resulted in a data rich but\\ninformation poor situation where there is a widening gap between the explosive\\ngrowth of data and its types, and the ability to analyze and interpret it\\neffectively, hence the need for a new generation of automated and intelligent\\ntools and techniques known as investigative data mining, to look for patterns\\nin data. These patterns can lead to new insights, competitive advantages for\\nbusiness, and tangible benefits for the State Revenue services. This research\\nwork focuses on designing effective fraud detection and deterring architecture\\nusing investigative data mining technique. The proposed system architecture is\\ndesigned to reason using Artificial Neural Network and Machine learning\\nalgorithm in order to detect and deter fraudulent activities. We recommend that\\nthe architectural framework be developed using Object Oriented Programming and\\nAgent Oriented Programming Languages.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1606.03569v1.pdf'},\n",
       " {'id': '1606.04033v2',\n",
       "  'title': 'Designing Commercial Therapeutic Robots for Privacy Preserving Systems\\n  and Ethical Research Practices within the Home',\n",
       "  'published': '2016-06-13T16:56:21Z',\n",
       "  'summary': 'The migration of robots from the laboratory into sensitive home settings as\\ncommercially available therapeutic agents represents a significant transition\\nfor information privacy and ethical imperatives. We present new privacy\\nparadigms and apply the Fair Information Practices (FIPs) to investigate\\nconcerns unique to the placement of therapeutic robots in private home\\ncontexts. We then explore the importance and utility of research ethics as\\noperationalized by existing human subjects research frameworks to guide the\\nconsideration of therapeutic robotic users -- a step vital to the continued\\nresearch and development of these platforms. Together, privacy and research\\nethics frameworks provide two complementary approaches to protect users and\\nensure responsible yet robust information sharing for technology development.\\nWe make recommendations for the implementation of these principles -- paying\\nparticular attention to specific principles that apply to vulnerable\\nindividuals (i.e., children, disabled, or elderly persons)--to promote the\\nadoption and continued improvement of long-term, responsible, and\\nresearch-enabled robotics in private settings.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1606.04033v2.pdf'},\n",
       " {'id': '1805.05935v1',\n",
       "  'title': 'Feedback-Based Tree Search for Reinforcement Learning',\n",
       "  'published': '2018-05-15T17:53:58Z',\n",
       "  'summary': 'Inspired by recent successes of Monte-Carlo tree search (MCTS) in a number of\\nartificial intelligence (AI) application domains, we propose a model-based\\nreinforcement learning (RL) technique that iteratively applies MCTS on batches\\nof small, finite-horizon versions of the original infinite-horizon Markov\\ndecision process. The terminal condition of the finite-horizon problems, or the\\nleaf-node evaluator of the decision tree generated by MCTS, is specified using\\na combination of an estimated value function and an estimated policy function.\\nThe recommendations generated by the MCTS procedure are then provided as\\nfeedback in order to refine, through classification and regression, the\\nleaf-node evaluator for the next iteration. We provide the first sample\\ncomplexity bounds for a tree search-based RL algorithm. In addition, we show\\nthat a deep neural network implementation of the technique can create a\\ncompetitive AI agent for the popular multi-player online battle arena (MOBA)\\ngame King of Glory.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1805.05935v1.pdf'},\n",
       " {'id': '1905.11553v2',\n",
       "  'title': 'Target-Guided Open-Domain Conversation',\n",
       "  'published': '2019-05-28T00:55:25Z',\n",
       "  'summary': 'Many real-world open-domain conversation applications have specific goals to\\nachieve during open-ended chats, such as recommendation, psychotherapy,\\neducation, etc. We study the problem of imposing conversational goals on\\nopen-domain chat agents. In particular, we want a conversational system to chat\\nnaturally with human and proactively guide the conversation to a designated\\ntarget subject. The problem is challenging as no public data is available for\\nlearning such a target-guided strategy. We propose a structured approach that\\nintroduces coarse-grained keywords to control the intended content of system\\nresponses. We then attain smooth conversation transition through turn-level\\nsupervised learning, and drive the conversation towards the target with\\ndiscourse-level constraints. We further derive a keyword-augmented conversation\\ndataset for the study. Quantitative and human evaluations show our system can\\nproduce meaningful and effective conversations, significantly improving over\\nother approaches.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.11553v2.pdf'},\n",
       " {'id': '1205.1150v3',\n",
       "  'title': 'Estimating Omissions from Searches',\n",
       "  'published': '2012-05-05T17:26:39Z',\n",
       "  'summary': 'The mark-recapture method was devised by Petersen in 1896 to estimate the\\nnumber of fish migrating into the Limfjord, and independently by Lincoln in\\n1930 to estimate waterfowl abundance. The technique applies to any search for a\\nfinite number of items by two or more people or agents, allowing the number of\\nsearched-for items to be estimated. This ubiquitous problem appears in fields\\nfrom ecology and epidemiology, through to mathematics, social sciences, and\\ncomputing. Here we exactly calculate the moments of the hypergeometric\\ndistribution associated with this long-standing problem, confirming that widely\\nused estimates conjectured in 1951 are often too small. Our Bayesian approach\\nhighlights how different search strategies will modify the estimates. As an\\nexample, we assess the accuracy of a systematic literature review, an\\napplication we recommend.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1205.1150v3.pdf'},\n",
       " {'id': '1802.04725v2',\n",
       "  'title': 'Superposition-Assisted Stochastic Optimization for Hawkes Processes',\n",
       "  'published': '2018-02-13T16:44:40Z',\n",
       "  'summary': 'We consider the learning of multi-agent Hawkes processes, a model containing\\nmultiple Hawkes processes with shared endogenous impact functions and different\\nexogenous intensities. In the framework of stochastic maximum likelihood\\nestimation, we explore the associated risk bound. Further, we consider the\\nsuperposition of Hawkes processes within the model, and demonstrate that under\\ncertain conditions such an operation is beneficial for tightening the risk\\nbound. Accordingly, we propose a stochastic optimization algorithm assisted\\nwith a diversity-driven superposition strategy, achieving better learning\\nresults with improved convergence properties. The effectiveness of the proposed\\nmethod is verified on synthetic data, and its potential to solve the cold-start\\nproblem of sequential recommendation systems is demonstrated on real-world\\ndata.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1802.04725v2.pdf'},\n",
       " {'id': '1807.02297v1',\n",
       "  'title': 'Combinatorial Bandits for Incentivizing Agents with Dynamic Preferences',\n",
       "  'published': '2018-07-06T08:03:39Z',\n",
       "  'summary': 'The design of personalized incentives or recommendations to improve user\\nengagement is gaining prominence as digital platform providers continually\\nemerge. We propose a multi-armed bandit framework for matching incentives to\\nusers, whose preferences are unknown a priori and evolving dynamically in time,\\nin a resource constrained environment. We design an algorithm that combines\\nideas from three distinct domains: (i) a greedy matching paradigm, (ii) the\\nupper confidence bound algorithm (UCB) for bandits, and (iii) mixing times from\\nthe theory of Markov chains. For this algorithm, we provide theoretical bounds\\non the regret and demonstrate its performance via both synthetic and realistic\\n(matching supply and demand in a bike-sharing platform) examples.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.02297v1.pdf'},\n",
       " {'id': '1807.06757v1',\n",
       "  'title': 'On Evaluation of Embodied Navigation Agents',\n",
       "  'published': '2018-07-18T03:28:02Z',\n",
       "  'summary': 'Skillful mobile operation in three-dimensional environments is a primary\\ntopic of study in Artificial Intelligence. The past two years have seen a surge\\nof creative work on navigation. This creative output has produced a plethora of\\nsometimes incompatible task definitions and evaluation protocols. To coordinate\\nongoing and future research in this area, we have convened a working group to\\nstudy empirical methodology in navigation research. The present document\\nsummarizes the consensus recommendations of this working group. We discuss\\ndifferent problem statements and the role of generalization, present evaluation\\nmeasures, and provide standard scenarios that can be used for benchmarking.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.06757v1.pdf'},\n",
       " {'id': '1807.11836v1',\n",
       "  'title': 'Inferring the ground truth through crowdsourcing',\n",
       "  'published': '2018-07-31T14:21:32Z',\n",
       "  'summary': 'Universally valid ground truth is almost impossible to obtain or would come\\nat a very high cost. For supervised learning without universally valid ground\\ntruth, a recommended approach is applying crowdsourcing: Gathering a large data\\nset annotated by multiple individuals of varying possibly expertise levels and\\ninferring the ground truth data to be used as labels to train the classifier.\\nNevertheless, due to the sensitivity of the problem at hand (e.g. mitosis\\ndetection in breast cancer histology images), the obtained data needs\\nverification and proper assessment before being used for classifier training.\\nEven in the context of organic computing systems, an indisputable ground truth\\nmight not always exist. Therefore, it should be inferred through the\\naggregation and verification of the local knowledge of each autonomous agent.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1807.11836v1.pdf'},\n",
       " {'id': '1902.03529v2',\n",
       "  'title': 'Live Emoji: Semantic Emotional Expressiveness of 2D Live Animation',\n",
       "  'published': '2019-02-10T02:34:58Z',\n",
       "  'summary': 'Live animation of 2D characters has recently become a popular way for\\nstorytelling, and has potential application scenarios like tele-present agents\\nor robots. As an extension of human-human communication, there is a need for\\naugmenting the emotional communication experience of live animation. In this\\npaper, we explore the emotional expressiveness issue of 2D live animation. In\\nparticular, we propose a descriptive emotion command model to bind a triggering\\naction, the semantic meaning, psychology measurements, and behaviors of an\\nemotional expression. Based on the model, we designed and implemented a\\nproof-of-concept 2D live animation system, where a novel visual programming\\ntool for editing the behaviors of 2D digital characters, and an emotion command\\nrecommendation algorithm are proposed. Through a user evaluation, we showcase\\nthe usability of our system and its potential for boosting creativity and\\nenhancing the emotional communication experience.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1902.03529v2.pdf'},\n",
       " {'id': '2106.15808v2',\n",
       "  'title': 'Optimal Epidemic Control as a Contextual Combinatorial Bandit with\\n  Budget',\n",
       "  'published': '2021-06-30T04:46:31Z',\n",
       "  'summary': 'In light of the COVID-19 pandemic, it is an open challenge and critical\\npractical problem to find a optimal way to dynamically prescribe the best\\npolicies that balance both the governmental resources and epidemic control in\\ndifferent countries and regions. To solve this multi-dimensional tradeoff of\\nexploitation and exploration, we formulate this technical challenge as a\\ncontextual combinatorial bandit problem that jointly optimizes a multi-criteria\\nreward function. Given the historical daily cases in a region and the past\\nintervention plans in place, the agent should generate useful intervention\\nplans that policy makers can implement in real time to minimizing both the\\nnumber of daily COVID-19 cases and the stringency of the recommended\\ninterventions. We prove this concept with simulations of multiple realistic\\npolicy making scenarios and demonstrate a clear advantage in providing a pareto\\noptimal solution in the epidemic intervention problem.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2106.15808v2.pdf'},\n",
       " {'id': '2107.01078v1',\n",
       "  'title': 'General Board Game Concepts',\n",
       "  'published': '2021-07-02T13:39:10Z',\n",
       "  'summary': 'Many games often share common ideas or aspects between them, such as their\\nrules, controls, or playing area. However, in the context of General Game\\nPlaying (GGP) for board games, this area remains under-explored. We propose to\\nformalise the notion of \"game concept\", inspired by terms generally used by\\ngame players and designers. Through the Ludii General Game System, we describe\\nconcepts for several levels of abstraction, such as the game itself, the moves\\nplayed, or the states reached. This new GGP feature associated with the ludeme\\nrepresentation of games opens many new lines of research. The creation of a\\nhyper-agent selector, the transfer of AI learning between games, or explaining\\nAI techniques using game terms, can all be facilitated by the use of game\\nconcepts. Other applications which can benefit from game concepts are also\\ndiscussed, such as the generation of plausible reconstructed rules for\\nincomplete ancient games, or the implementation of a board game recommender\\nsystem.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2107.01078v1.pdf'},\n",
       " {'id': '2107.01532v2',\n",
       "  'title': 'Decentralizing Centralized Matching Markets: Implications from Early\\n  Offers in University Admissions',\n",
       "  'published': '2021-07-04T03:37:19Z',\n",
       "  'summary': \"The matching literature often recommends market centralization under the\\nassumption that agents know their own preferences and that their preferences\\nare fixed. We find counterevidence to this assumption in a quasi-experiment. In\\nGermany's university admissions, a clearinghouse implements the early stages of\\nthe Gale-Shapley algorithm in real time. We show that early offers made in this\\ndecentralized phase, although not more desirable, are accepted more often than\\nlater ones. These results, together with survey evidence and a theoretical\\nmodel, are consistent with students' costly learning about universities. We\\npropose a hybrid mechanism to combine the advantages of decentralization and\\ncentralization.\\n  Published at The Journal of Political Economy under a new title, ``Preference\\nDiscovery in University Admissions: The Case for Dynamic Multioffer\\nMechanisms,'' available at https://doi.org/10.1086/718983 (Open Access).\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2107.01532v2.pdf'},\n",
       " {'id': '2201.08300v1',\n",
       "  'title': 'From Psychological Curiosity to Artificial Curiosity: Curiosity-Driven\\n  Learning in Artificial Intelligence Tasks',\n",
       "  'published': '2022-01-20T17:07:03Z',\n",
       "  'summary': 'Psychological curiosity plays a significant role in human intelligence to\\nenhance learning through exploration and information acquisition. In the\\nArtificial Intelligence (AI) community, artificial curiosity provides a natural\\nintrinsic motivation for efficient learning as inspired by human cognitive\\ndevelopment; meanwhile, it can bridge the existing gap between AI research and\\npractical application scenarios, such as overfitting, poor generalization,\\nlimited training samples, high computational cost, etc. As a result,\\ncuriosity-driven learning (CDL) has become increasingly popular, where agents\\nare self-motivated to learn novel knowledge. In this paper, we first present a\\ncomprehensive review on the psychological study of curiosity and summarize a\\nunified framework for quantifying curiosity as well as its arousal mechanism.\\nBased on the psychological principle, we further survey the literature of\\nexisting CDL methods in the fields of Reinforcement Learning, Recommendation,\\nand Classification, where both advantages and disadvantages as well as future\\nwork are discussed. As a result, this work provides fruitful insights for\\nfuture CDL research and yield possible directions for further improvement.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.08300v1.pdf'},\n",
       " {'id': '2201.11152v1',\n",
       "  'title': 'Cyber Resilience: by Design or by Intervention?',\n",
       "  'published': '2022-01-26T19:21:14Z',\n",
       "  'summary': 'The term \"cyber resilience by design\" is growing in popularity. Here, by\\ncyber resilience we refer to the ability of the system to resist, minimize and\\nmitigate a degradation caused by a successful cyber-attack on a system or\\nnetwork of computing and communicating devices. Some use the term \"by design\"\\nwhen arguing that systems must be designed and implemented in a provable\\nmission assurance fashion, with the system\\'s intrinsic properties ensuring that\\na cyber-adversary is unable to cause a meaningful degradation. Others recommend\\nthat a system should include a built-in autonomous intelligent agent\\nresponsible for thinking and acting towards continuous observation, detection,\\nminimization and remediation of a cyber degradation. In all cases, the\\nqualifier \"by design\" indicates that the source of resilience is somehow\\ninherent in the structure and operation of the system. But what, then, is the\\nother resilience, not by design? Clearly, there has to be another type of\\nresilience, otherwise what\\'s the purpose of the qualifier \"by design\"? Indeed,\\nwhile mentioned less frequently, there exists an alternative form of resilience\\ncalled \"resilience by intervention.\" In this article we explore differences and\\nmutual reliance of resilience by design and resilience by intervention.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.11152v1.pdf'},\n",
       " {'id': '1711.08594v2',\n",
       "  'title': 'Online Clustering of Contextual Cascading Bandits',\n",
       "  'published': '2017-11-23T07:00:22Z',\n",
       "  'summary': 'We consider a new setting of online clustering of contextual cascading\\nbandits, an online learning problem where the underlying cluster structure over\\nusers is unknown and needs to be learned from a random prefix feedback. More\\nprecisely, a learning agent recommends an ordered list of items to a user, who\\nchecks the list and stops at the first satisfactory item, if any. We propose an\\nalgorithm of CLUB-cascade for this setting and prove a $T$-step regret bound of\\norder $\\\\tilde{O}(\\\\sqrt{T})$. Previous work corresponds to the degenerate case\\nof only one cluster, and our general regret bound in this special case also\\nsignificantly improves theirs. We conduct experiments on both synthetic and\\nreal data, and demonstrate the effectiveness of our algorithm and the advantage\\nof incorporating online clustering method.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1711.08594v2.pdf'},\n",
       " {'id': '2006.05026v2',\n",
       "  'title': 'Learning for Dose Allocation in Adaptive Clinical Trials with Safety\\n  Constraints',\n",
       "  'published': '2020-06-09T03:06:45Z',\n",
       "  'summary': 'Phase I dose-finding trials are increasingly challenging as the relationship\\nbetween efficacy and toxicity of new compounds (or combination of them) becomes\\nmore complex. Despite this, most commonly used methods in practice focus on\\nidentifying a Maximum Tolerated Dose (MTD) by learning only from toxicity\\nevents. We present a novel adaptive clinical trial methodology, called Safe\\nEfficacy Exploration Dose Allocation (SEEDA), that aims at maximizing the\\ncumulative efficacies while satisfying the toxicity safety constraint with high\\nprobability. We evaluate performance objectives that have operational meanings\\nin practical clinical trials, including cumulative efficacy,\\nrecommendation/allocation success probabilities, toxicity violation\\nprobability, and sample efficiency. An extended SEEDA-Plateau algorithm that is\\ntailored for the increase-then-plateau efficacy behavior of molecularly\\ntargeted agents (MTA) is also presented. Through numerical experiments using\\nboth synthetic and real-world datasets, we show that SEEDA outperforms\\nstate-of-the-art clinical trial designs by finding the optimal dose with higher\\nsuccess rate and fewer patients.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.05026v2.pdf'},\n",
       " {'id': '2006.08818v1',\n",
       "  'title': 'Explaining reputation assessments',\n",
       "  'published': '2020-06-15T23:19:35Z',\n",
       "  'summary': 'Reputation is crucial to enabling human or software agents to select among\\nalternative providers. Although several effective reputation assessment methods\\nexist, they typically distil reputation into a numerical representation, with\\nno accompanying explanation of the rationale behind the assessment. Such\\nexplanations would allow users or clients to make a richer assessment of\\nproviders, and tailor selection according to their preferences and current\\ncontext. In this paper, we propose an approach to explain the rationale behind\\nassessments from quantitative reputation models, by generating arguments that\\nare combined to form explanations. Our approach adapts, extends and combines\\nexisting approaches for explaining decisions made using multi-attribute\\ndecision models in the context of reputation. We present example argument\\ntemplates, and describe how to select their parameters using explanation\\nalgorithms. Our proposal was evaluated by means of a user study, which followed\\nan existing protocol. Our results give evidence that although explanations\\npresent a subset of the information of trust scores, they are sufficient to\\nequally evaluate providers recommended based on their trust score. Moreover,\\nwhen explanation arguments reveal implicit model information, they are less\\npersuasive than scores.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.08818v1.pdf'},\n",
       " {'id': '2008.04520v1',\n",
       "  'title': \"Montreal AI Ethics Institute's (MAIEI) Submission to the World\\n  Intellectual Property Organization (WIPO) Conversation on Intellectual\\n  Property (IP) and Artificial Intelligence (AI) Second Session\",\n",
       "  'published': '2020-08-11T05:31:10Z',\n",
       "  'summary': 'This document posits that, at best, a tenuous case can be made for providing\\nAI exclusive IP over their \"inventions\". Furthermore, IP protections for AI are\\nunlikely to confer the benefit of ensuring regulatory compliance. Rather, IP\\nprotections for AI \"inventors\" present a host of negative externalities and\\nobscures the fact that the genuine inventor, deserving of IP, is the human\\nagent. This document will conclude by recommending strategies for WIPO to bring\\nIP law into the 21st century, enabling it to productively account for AI\\n\"inventions\".\\n  Theme: IP Protection for AI-Generated and AI-Assisted Works Based on insights\\nfrom the Montreal AI Ethics Institute (MAIEI) staff and supplemented by\\nworkshop contributions from the AI Ethics community convened by MAIEI on July\\n5, 2020.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.04520v1.pdf'},\n",
       " {'id': '2011.01488v3',\n",
       "  'title': 'Multi-armed Bandits with Cost Subsidy',\n",
       "  'published': '2020-11-03T05:38:42Z',\n",
       "  'summary': 'In this paper, we consider a novel variant of the multi-armed bandit (MAB)\\nproblem, MAB with cost subsidy, which models many real-life applications where\\nthe learning agent has to pay to select an arm and is concerned about\\noptimizing cumulative costs and rewards. We present two applications,\\nintelligent SMS routing problem and ad audience optimization problem faced by\\nseveral businesses (especially online platforms), and show how our problem\\nuniquely captures key features of these applications. We show that naive\\ngeneralizations of existing MAB algorithms like Upper Confidence Bound and\\nThompson Sampling do not perform well for this problem. We then establish a\\nfundamental lower bound on the performance of any online learning algorithm for\\nthis problem, highlighting the hardness of our problem in comparison to the\\nclassical MAB problem. We also present a simple variant of explore-then-commit\\nand establish near-optimal regret bounds for this algorithm. Lastly, we perform\\nextensive numerical simulations to understand the behavior of a suite of\\nalgorithms for various instances and recommend a practical guide to employ\\ndifferent algorithms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2011.01488v3.pdf'},\n",
       " {'id': '2012.14843v3',\n",
       "  'title': 'Learning Adversarial Markov Decision Processes with Delayed Feedback',\n",
       "  'published': '2020-12-29T16:47:42Z',\n",
       "  'summary': 'Reinforcement learning typically assumes that agents observe feedback for\\ntheir actions immediately, but in many real-world applications (like\\nrecommendation systems) feedback is observed in delay. This paper studies\\nonline learning in episodic Markov decision processes (MDPs) with unknown\\ntransitions, adversarially changing costs and unrestricted delayed feedback.\\nThat is, the costs and trajectory of episode $k$ are revealed to the learner\\nonly in the end of episode $k + d^k$, where the delays $d^k$ are neither\\nidentical nor bounded, and are chosen by an oblivious adversary. We present\\nnovel algorithms based on policy optimization that achieve near-optimal\\nhigh-probability regret of $\\\\sqrt{K + D}$ under full-information feedback,\\nwhere $K$ is the number of episodes and $D = \\\\sum_{k} d^k$ is the total delay.\\nUnder bandit feedback, we prove similar $\\\\sqrt{K + D}$ regret assuming the\\ncosts are stochastic, and $(K + D)^{2/3}$ regret in the general case. We are\\nthe first to consider regret minimization in the important setting of MDPs with\\ndelayed feedback.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.14843v3.pdf'},\n",
       " {'id': '2112.03419v2',\n",
       "  'title': 'Using Image Transformations to Learn Network Structure',\n",
       "  'published': '2021-12-06T23:28:38Z',\n",
       "  'summary': \"Many learning tasks require observing a sequence of images and making a\\ndecision. In a transportation problem of designing and planning for shipping\\nboxes between nodes, we show how to treat the network of nodes and the flows\\nbetween them as images. These images have useful structural information that\\ncan be statistically summarized. Using image compression techniques, we reduce\\nan image down to a set of numbers that contain interpretable geographic\\ninformation that we call geographic signatures. Using geographic signatures, we\\nlearn network structure that can be utilized to recommend future network\\nconnectivity. We develop a Bayesian reinforcement algorithm that takes\\nadvantage of statistically summarized network information as priors and\\nuser-decisions to reinforce an agent's probabilistic decision. Additionally, we\\nshow how reinforcement learning can be used with compression directly without\\ninterpretation in simple tasks.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.03419v2.pdf'},\n",
       " {'id': '2112.15167v1',\n",
       "  'title': 'Chatbot for fitness management using IBM Watson',\n",
       "  'published': '2021-12-30T18:49:19Z',\n",
       "  'summary': 'Chatbots have revolutionized the way humans interact with computer systems\\nand they have substituted the use of service agents, call-center\\nrepresentatives etc. Fitness industry has always been a growing industry\\nalthough it has not adapted to the latest technologies like AI, ML and cloud\\ncomputing. In this paper, we propose an idea to develop a chatbot for fitness\\nmanagement using IBM Watson and integrate it with a web application. We\\nproposed using Natural Language Processing (NLP) and Natural Language\\nUnderstanding (NLU) along with frameworks of IBM Cloud Watson provided for the\\nChatbot Assistant. This software uses a serverless architecture to combine the\\nservices of a professional by offering diet plans, home exercises, interactive\\ncounseling sessions, fitness recommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.15167v1.pdf'},\n",
       " {'id': '2210.01369v1',\n",
       "  'title': \"Understanding Older Adults' Perceptions and Challenges in Using\\n  AI-enabled Everyday Technologies\",\n",
       "  'published': '2022-10-04T04:19:21Z',\n",
       "  'summary': \"Artificial intelligence (AI)-enabled everyday technologies could help address\\nage-related challenges like physical impairments and cognitive decline. While\\nrecent research studied older adults' experiences with specific AI-enabled\\nproducts (e.g., conversational agents and assistive robots), it remains unknown\\nhow older adults perceive and experience current AI-enabled everyday\\ntechnologies in general, which could impact their adoption of future AI-enabled\\nproducts. We conducted a survey study (N=41) and semi-structured interviews\\n(N=15) with older adults to understand their experiences and perceptions of AI.\\nWe found that older adults were enthusiastic about learning and using\\nAI-enabled products, but they lacked learning avenues. Additionally, they\\nworried when AI-enabled products outwitted their expectations, intruded on\\ntheir privacy, or impacted their decision-making skills. Therefore, they held\\nmixed views towards AI-enabled products such as AI, an aid, or an adversary. We\\nconclude with design recommendations that make older adults feel inclusive,\\nsecure, and in control of their interactions with AI-enabled products.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.01369v1.pdf'},\n",
       " {'id': '2210.08703v1',\n",
       "  'title': 'Spoken Dialogue System Based on Attribute Vector for Travel Agent Robot',\n",
       "  'published': '2022-10-17T02:33:00Z',\n",
       "  'summary': 'In this study, we develop a dialogue system for a dialogue robot competition.\\nIn the system, the characteristics of sightseeing spots are expressed as\\n\"attribute vectors\" in advance, and the user is questioned on the different\\nattributes of the two candidate spots. Consequently, the system can make\\nrecommendations based on user intentions. A dialogue experiment is conducted\\nduring a preliminary round of competition. The overall satisfaction score\\nobtained is 40.1 out of 63 points, which is a reasonable result. Analysis of\\nthe relationship between the system behavior and satisfaction scores reveals\\nthat satisfaction increases when the system correctly understands the user\\nintention and responds appropriately. However, a negative correlation is\\nobserved between the number of user utterances and the satisfaction score. This\\nimplies that inappropriate responses reduce the usefulness of the system as a\\nconsultation partner.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.08703v1.pdf'},\n",
       " {'id': '1402.3138v2',\n",
       "  'title': 'Social Networks and the Choices People Make',\n",
       "  'published': '2014-02-13T14:08:46Z',\n",
       "  'summary': 'Social marketing is becoming increasingly important in contemporary business.\\nCentral to social marketing is quantifying how consumers choose between\\nalternatives and how they influence each other. This work considers a new but\\nsimple multinomial choice model for multiple agents connected in a\\nrecommendation network based on the explicit modeling of choice adoption\\nbehavior. Efficiently computable closed-form solutions, absent from analyses of\\nthreshold/cascade models, are obtained together with insights on how the\\nnetwork affects aggregate decision making. A stylized \"brand ambassador\"\\nselection problem is posed to model targeting in social marketing. Therein, it\\nis shown that a greedy selection strategy leads to solutions achieving at least\\n$1-1/e$ of the optimal value. In an extended example of imposing exogenous\\ncontrols, a pricing problem is considered wherein it is shown that the single\\nplayer profit optimization problem is concave, implying the existence of pure\\nstrategy equilibria for the associated pricing game.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1402.3138v2.pdf'},\n",
       " {'id': '1901.03874v2',\n",
       "  'title': 'A Risk-Sharing Framework of Bilateral Contracts',\n",
       "  'published': '2019-01-12T15:45:41Z',\n",
       "  'summary': 'We introduce a two-agent problem which is inspired by price asymmetry arising\\nfrom funding difference. When two parties have different funding rates, the two\\nparties deduce different fair prices for derivative contracts even under the\\nsame pricing methodology and parameters. Thus, the two parties should enter the\\nderivative contracts with a negotiated price, and we call the negotiation a\\nrisk-sharing problem. This framework defines the negotiation as a problem that\\nmaximizes the sum of utilities of the two parties. By the derived optimal\\nprice, we provide a theoretical analysis on how the price is determined between\\nthe two parties. As well as the price, the risk-sharing framework produces an\\noptimal amount of collateral. The derived optimal collateral can be used for\\ncontracts between financial firms and non-financial firms. However,\\ninter-dealers markets are governed by regulations. As recommended in Basel III,\\nit is a convention in inter-dealer contracts to pledge the full amount of a\\nclose-out price as collateral. In this case, using the optimal collateral, we\\ninterpret conditions for the full margin requirement to be indeed optimal.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1901.03874v2.pdf'},\n",
       " {'id': '1903.11907v2',\n",
       "  'title': 'Meta-Learning surrogate models for sequential decision making',\n",
       "  'published': '2019-03-28T11:57:54Z',\n",
       "  'summary': 'We introduce a unified probabilistic framework for solving sequential\\ndecision making problems ranging from Bayesian optimisation to contextual\\nbandits and reinforcement learning. This is accomplished by a probabilistic\\nmodel-based approach that explains observed data while capturing predictive\\nuncertainty during the decision making process. Crucially, this probabilistic\\nmodel is chosen to be a Meta-Learning system that allows learning from a\\ndistribution of related problems, allowing data efficient adaptation to a\\ntarget task. As a suitable instantiation of this framework, we explore the use\\nof Neural processes due to statistical and computational desiderata. We apply\\nour framework to a broad range of problem domains, such as control problems,\\nrecommender systems and adversarial attacks on RL agents, demonstrating an\\nefficient and general black-box learning approach.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1903.11907v2.pdf'},\n",
       " {'id': '2002.11660v1',\n",
       "  'title': 'An Optimal Procedure to Check Pareto-Optimality in House Markets with\\n  Single-Peaked Preferences',\n",
       "  'published': '2020-02-14T17:24:55Z',\n",
       "  'summary': 'Recently, the problem of allocating one resource per agent with initial\\nendowments (house markets) has seen a renewed interest: indeed, while in the\\ndomain of strict preferences the Top Trading Cycle algorithm is known to be the\\nonly procedure guaranteeing Pareto-optimality, individual rationality, and\\nstrategy proofness. However, the situation differs in the single-peaked domain.\\nIndeed, Bade presented the Crawler, an alternative procedure enjoying the same\\nproperties, with the additional advantage of being implementable in obviously\\ndominant strategies. In this paper we further investigate the Crawler and\\npropose the Diver, a variant which checks optimally whether an allocation is\\nPareto-optimal for single-peaked preferences, thus improving over known\\ntechniques used for checking Pareto-optimality in more general domains. We also\\nprove that the Diver is asymptotically optimal in terms of communication\\ncomplexity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2002.11660v1.pdf'},\n",
       " {'id': '2009.07518v1',\n",
       "  'title': \"Partial Bandit and Semi-Bandit: Making the Most Out of Scarce Users'\\n  Feedback\",\n",
       "  'published': '2020-09-16T07:32:51Z',\n",
       "  'summary': \"Recent works on Multi-Armed Bandits (MAB) and Combinatorial Multi-Armed\\nBandits (COM-MAB) show good results on a global accuracy metric. This can be\\nachieved, in the case of recommender systems, with personalization. However,\\nwith a combinatorial online learning approach, personalization implies a large\\namount of user feedbacks. Such feedbacks can be hard to acquire when users need\\nto be directly and frequently solicited. For a number of fields of activities\\nundergoing the digitization of their business, online learning is unavoidable.\\nThus, a number of approaches allowing implicit user feedback retrieval have\\nbeen implemented. Nevertheless, this implicit feedback can be misleading or\\ninefficient for the agent's learning. Herein, we propose a novel approach\\nreducing the number of explicit feedbacks required by Combinatorial Multi Armed\\nbandit (COM-MAB) algorithms while providing similar levels of global accuracy\\nand learning efficiency to classical competitive methods. In this paper we\\npresent a novel approach for considering user feedback and evaluate it using\\nthree distinct strategies. Despite a limited number of feedbacks returned by\\nusers (as low as 20% of the total), our approach obtains similar results to\\nthose of state of the art approaches.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2009.07518v1.pdf'},\n",
       " {'id': '2010.12019v2',\n",
       "  'title': 'A New Charter of Ethics and Rights of Artificial Consciousness in a\\n  Human World',\n",
       "  'published': '2020-10-12T18:46:38Z',\n",
       "  'summary': \"Taking the stance that artificially conscious agents should be given\\nhuman-like rights, in this paper we attempt to define consciousness, aggregate\\nexisting universal human rights, analyze robotic laws with roots in both\\nreality and science fiction, and synthesize everything to create a new\\nrobot-ethical charter. By restricting the problem-space of possible levels of\\nconscious beings to human-like, we succeed in developing a working definition\\nof consciousness for social strong AI which focuses on human-like creativity\\nbeing exhibited as a third-person observable phenomenon. Creativity is then\\nextrapolated to represent first-person functionality, fulfilling the\\nfirst/third-person feature of consciousness. Next, several sources of existing\\nrights and rules, both for humans and robots, are analyzed and, along with\\nsupplementary informal reports, synthesized to create articles for an additive\\ncharter which compliments the United Nation's Universal Declaration of Human\\nRights. Finally, the charter is presented and the paper concludes with the\\nconditions for amending the charter, as well as recommendations for further\\ncharters.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.12019v2.pdf'},\n",
       " {'id': '2101.10504v1',\n",
       "  'title': 'On the Evaluation of Vision-and-Language Navigation Instructions',\n",
       "  'published': '2021-01-26T01:03:49Z',\n",
       "  'summary': 'Vision-and-Language Navigation wayfinding agents can be enhanced by\\nexploiting automatically generated navigation instructions. However, existing\\ninstruction generators have not been comprehensively evaluated, and the\\nautomatic evaluation metrics used to develop them have not been validated.\\nUsing human wayfinders, we show that these generators perform on par with or\\nonly slightly better than a template-based generator and far worse than human\\ninstructors. Furthermore, we discover that BLEU, ROUGE, METEOR and CIDEr are\\nineffective for evaluating grounded navigation instructions. To improve\\ninstruction evaluation, we propose an instruction-trajectory compatibility\\nmodel that operates without reference instructions. Our model shows the highest\\ncorrelation with human wayfinding outcomes when scoring individual\\ninstructions. For ranking instruction generation systems, if reference\\ninstructions are available we recommend using SPICE.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.10504v1.pdf'},\n",
       " {'id': '2102.02351v1',\n",
       "  'title': 'On Multi-Human Multi-Robot Remote Interaction: A Study of Transparency,\\n  Inter-Human Communication, and Information Loss in Remote Interaction',\n",
       "  'published': '2021-02-04T00:40:48Z',\n",
       "  'summary': \"In this paper, we investigate how to design an effective interface for remote\\nmulti-human multi-robot interaction. While significant research exists on\\ninterfaces for individual human operators, little research exists for the\\nmulti-human case. Yet, this is a critical problem to solve to make complex,\\nlarge-scale missions achievable in which direct human involvement is impossible\\nor undesirable, and robot swarms act as a semi-autonomous agents. This paper's\\ncontribution is twofold. The first contribution is an exploration of the design\\nspace of computer-based interfaces for multi-human multi-robot operations. In\\nparticular, we focus on information transparency and on the factors that affect\\ninter-human communication in ideal conditions, i.e., without communication\\nissues. Our second contribution concerns the same problem, but considering\\nincreasing degrees of information loss, defined as intermittent reception of\\ndata with noticeable gaps between individual receipts. We derived a set of\\ndesign recommendations based on two user studies involving 48 participants.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.02351v1.pdf'},\n",
       " {'id': '2103.08079v1',\n",
       "  'title': 'Crossing the Tepper Line: An Emerging Ontology for Describing the\\n  Dynamic Sociality of Embodied AI',\n",
       "  'published': '2021-03-15T00:45:44Z',\n",
       "  'summary': 'Artificial intelligences (AI) are increasingly being embodied and embedded in\\nthe world to carry out tasks and support decision-making with and for people.\\nRobots, recommender systems, voice assistants, virtual humans - do these\\ndisparate types of embodied AI have something in common? Here we show how they\\ncan manifest as \"socially embodied AI.\" We define this as the state that\\nembodied AI \"circumstantially\" take on within interactive contexts when\\nperceived as both social and agentic by people. We offer a working ontology\\nthat describes how embodied AI can dynamically transition into socially\\nembodied AI. We propose an ontological heuristic for describing the threshold:\\nthe Tepper line. We reinforce our theoretical work with expert insights from a\\ncard sort workshop. We end with two case studies to illustrate the dynamic and\\ncontextual nature of this heuristic.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2103.08079v1.pdf'},\n",
       " {'id': '2104.08196v2',\n",
       "  'title': 'Towards Standardising Reinforcement Learning Approaches for Production\\n  Scheduling Problems',\n",
       "  'published': '2021-04-16T16:07:10Z',\n",
       "  'summary': 'Recent years have seen a rise in interest in terms of using machine learning,\\nparticularly reinforcement learning (RL), for production scheduling problems of\\nvarying degrees of complexity. The general approach is to break down the\\nscheduling problem into a Markov Decision Process (MDP), whereupon a simulation\\nimplementing the MDP is used to train an RL agent. Since existing studies rely\\non (sometimes) complex simulations for which the code is unavailable, the\\nexperiments presented are hard, or, in the case of stochastic environments,\\nimpossible to reproduce accurately. Furthermore, there is a vast array of RL\\ndesigns to choose from. To make RL methods widely applicable in production\\nscheduling and work out their strength for the industry, the standardisation of\\nmodel descriptions - both production setup and RL design - and validation\\nscheme are a prerequisite. Our contribution is threefold: First, we standardize\\nthe description of production setups used in RL studies based on established\\nnomenclature. Secondly, we classify RL design choices from existing\\npublications. Lastly, we propose recommendations for a validation scheme\\nfocusing on reproducibility and sufficient benchmarking.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2104.08196v2.pdf'},\n",
       " {'id': '2104.08615v2',\n",
       "  'title': 'Conservative Contextual Combinatorial Cascading Bandit',\n",
       "  'published': '2021-04-17T18:42:28Z',\n",
       "  'summary': 'Conservative mechanism is a desirable property in decision-making problems\\nwhich balance the tradeoff between the exploration and exploitation. We propose\\nthe novel \\\\emph{conservative contextual combinatorial cascading bandit\\n($C^4$-bandit)}, a cascading online learning game which incorporates the\\nconservative mechanism. At each time step, the learning agent is given some\\ncontexts and has to recommend a list of items but not worse than the base\\nstrategy and then observes the reward by some stopping rules. We design the\\n$C^4$-UCB algorithm to solve the problem and prove its n-step upper regret\\nbound for two situations: known baseline reward and unknown baseline reward.\\nThe regret in both situations can be decomposed into two terms: (a) the upper\\nbound for the general contextual combinatorial cascading bandit; and (b) a\\nconstant term for the regret from the conservative mechanism. We also improve\\nthe bound of the conservative contextual combinatorial bandit as a by-product.\\nExperiments on synthetic data demonstrate its advantages and validate our\\ntheoretical analysis.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2104.08615v2.pdf'},\n",
       " {'id': '2105.12034v1',\n",
       "  'title': 'Hyperparameter Selection for Imitation Learning',\n",
       "  'published': '2021-05-25T16:14:04Z',\n",
       "  'summary': \"We address the issue of tuning hyperparameters (HPs) for imitation learning\\nalgorithms in the context of continuous-control, when the underlying reward\\nfunction of the demonstrating expert cannot be observed at any time. The vast\\nliterature in imitation learning mostly considers this reward function to be\\navailable for HP selection, but this is not a realistic setting. Indeed, would\\nthis reward function be available, it could then directly be used for policy\\ntraining and imitation would not be necessary. To tackle this mostly ignored\\nproblem, we propose a number of possible proxies to the external reward. We\\nevaluate them in an extensive empirical study (more than 10'000 agents across 9\\nenvironments) and make practical recommendations for selecting HPs. Our results\\nshow that while imitation learning algorithms are sensitive to HP choices, it\\nis often possible to select good enough HPs through a proxy to the reward\\nfunction.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.12034v1.pdf'},\n",
       " {'id': '2110.12497v1',\n",
       "  'title': 'Problems with information theoretic approaches to causal learning',\n",
       "  'published': '2021-10-24T17:37:45Z',\n",
       "  'summary': \"The language of information theory is favored in both causal reasoning and\\nmachine learning frameworks. But, is there a better language than this? In this\\nstudy, we demonstrate the pitfalls of infotheoretic estimation using first\\norder statistics on (short) sequences for causal learning. We recommend the use\\nof data compression based approaches for causality testing since these make\\nvery little assumptions on data as opposed to infotheoretic measures, and are\\nmore robust to finite data length effects. We conclude with a discussion on the\\nchallenges posed in modeling the effects of conditioning process $X$ with\\nanother process $Y$ in causal machine learning. Specifically, conditioning can\\nincrease 'confusion' which can be difficult to model by classical information\\ntheory. A conscious causal agent creates new choices, decisions and meaning\\nwhich poses huge challenges for AI.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.12497v1.pdf'},\n",
       " {'id': '2110.13384v1',\n",
       "  'title': 'ViDA-MAN: Visual Dialog with Digital Humans',\n",
       "  'published': '2021-10-26T03:23:51Z',\n",
       "  'summary': 'We demonstrate ViDA-MAN, a digital-human agent for multi-modal interaction,\\nwhich offers realtime audio-visual responses to instant speech inquiries.\\nCompared to traditional text or voice-based system, ViDA-MAN offers human-like\\ninteractions (e.g, vivid voice, natural facial expression and body gestures).\\nGiven a speech request, the demonstration is able to response with high quality\\nvideos in sub-second latency. To deliver immersive user experience, ViDA-MAN\\nseamlessly integrates multi-modal techniques including Acoustic Speech\\nRecognition (ASR), multi-turn dialog, Text To Speech (TTS), talking heads video\\ngeneration. Backed with large knowledge base, ViDA-MAN is able to chat with\\nusers on a number of topics including chit-chat, weather, device control, News\\nrecommendations, booking hotels, as well as answering questions via structured\\nknowledge.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.13384v1.pdf'},\n",
       " {'id': '2110.15771v4',\n",
       "  'title': 'Collaborative Pure Exploration in Kernel Bandit',\n",
       "  'published': '2021-10-29T13:39:14Z',\n",
       "  'summary': 'In this paper, we formulate a Collaborative Pure Exploration in Kernel Bandit\\nproblem (CoPE-KB), which provides a novel model for multi-agent multi-task\\ndecision making under limited communication and general reward functions, and\\nis applicable to many online learning tasks, e.g., recommendation systems and\\nnetwork scheduling. We consider two settings of CoPE-KB, i.e., Fixed-Confidence\\n(FC) and Fixed-Budget (FB), and design two optimal algorithms CoopKernelFC (for\\nFC) and CoopKernelFB (for FB). Our algorithms are equipped with innovative and\\nefficient kernelized estimators to simultaneously achieve computation and\\ncommunication efficiency. Matching upper and lower bounds under both the\\nstatistical and communication metrics are established to demonstrate the\\noptimality of our algorithms. The theoretical bounds successfully quantify the\\ninfluences of task similarities on learning acceleration and only depend on the\\neffective dimension of the kernelized feature space. Our analytical techniques,\\nincluding data dimension decomposition, linear structured instance\\ntransformation and (communication) round-speedup induction, are novel and\\napplicable to other bandit problems. Empirical evaluations are provided to\\nvalidate our theoretical results and demonstrate the performance superiority of\\nour algorithms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.15771v4.pdf'},\n",
       " {'id': '2111.02071v1',\n",
       "  'title': 'The Impact of Batch Learning in Stochastic Bandits',\n",
       "  'published': '2021-11-03T08:38:10Z',\n",
       "  'summary': 'We consider a special case of bandit problems, namely batched bandits.\\nMotivated by natural restrictions of recommender systems and e-commerce\\nplatforms, we assume that a learning agent observes responses batched in groups\\nover a certain time period. Unlike previous work, we consider a more\\npractically relevant batch-centric scenario of batch learning. We provide a\\npolicy-agnostic regret analysis and demonstrate upper and lower bounds for the\\nregret of a candidate policy. Our main theoretical results show that the impact\\nof batch learning can be measured in terms of online behavior. Finally, we\\ndemonstrate the consistency of theoretical results by conducting empirical\\nexperiments and reflect on the optimal batch size choice.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.02071v1.pdf'},\n",
       " {'id': '2111.14746v2',\n",
       "  'title': 'Dynamic Inference',\n",
       "  'published': '2021-11-29T17:50:22Z',\n",
       "  'summary': 'Traditional statistical estimation, or statistical inference in general, is\\nstatic, in the sense that the estimate of the quantity of interest does not\\nchange the future evolution of the quantity. In some sequential estimation\\nproblems however, we encounter the situation where the future values of the\\nquantity to be estimated depend on the estimate of its current value. Examples\\ninclude stock price prediction by big investors, interactive product\\nrecommendation, and behavior prediction in multi-agent systems. We may call\\nsuch problems as dynamic inference. In this work, a formulation of this problem\\nunder a Bayesian probabilistic framework is given, and the optimal estimation\\nstrategy is derived as the solution to minimize the overall inference loss. How\\nthe optimal estimation strategy works is illustrated through two examples,\\nstock trend prediction and vehicle behavior prediction. When the underlying\\nmodels for dynamic inference are unknown, we can consider the problem of\\nlearning for dynamic inference. This learning problem can potentially unify\\nseveral familiar machine learning problems, including supervised learning,\\nimitation learning, and reinforcement learning.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2111.14746v2.pdf'},\n",
       " {'id': '2202.07995v2',\n",
       "  'title': 'Branching Reinforcement Learning',\n",
       "  'published': '2022-02-16T11:19:03Z',\n",
       "  'summary': 'In this paper, we propose a novel Branching Reinforcement Learning (Branching\\nRL) model, and investigate both Regret Minimization (RM) and Reward-Free\\nExploration (RFE) metrics for this model. Unlike standard RL where the\\ntrajectory of each episode is a single $H$-step path, branching RL allows an\\nagent to take multiple base actions in a state such that transitions branch out\\nto multiple successor states correspondingly, and thus it generates a\\ntree-structured trajectory. This model finds important applications in\\nhierarchical recommendation systems and online advertising. For branching RL,\\nwe establish new Bellman equations and key lemmas, i.e., branching value\\ndifference lemma and branching law of total variance, and also bound the total\\nvariance by only $O(H^2)$ under an exponentially-large trajectory. For RM and\\nRFE metrics, we propose computationally efficient algorithms BranchVI and\\nBranchRFE, respectively, and derive nearly matching upper and lower bounds. Our\\nresults are only polynomial in problem parameters despite exponentially-large\\ntrajectories.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2202.07995v2.pdf'},\n",
       " {'id': '2203.02121v2',\n",
       "  'title': 'Adversarial Patterns: Building Robust Android Malware Classifiers',\n",
       "  'published': '2022-03-04T03:47:08Z',\n",
       "  'summary': \"Machine learning models are increasingly being adopted across various fields,\\nsuch as medicine, business, autonomous vehicles, and cybersecurity, to analyze\\nvast amounts of data, detect patterns, and make predictions or recommendations.\\nIn the field of cybersecurity, these models have made significant improvements\\nin malware detection. However, despite their ability to understand complex\\npatterns from unstructured data, these models are susceptible to adversarial\\nattacks that perform slight modifications in malware samples, leading to\\nmisclassification from malignant to benign. Numerous defense approaches have\\nbeen proposed to either detect such adversarial attacks or improve model\\nrobustness. These approaches have resulted in a multitude of attack and defense\\ntechniques and the emergence of a field known as `adversarial machine\\nlearning.' In this survey paper, we provide a comprehensive review of\\nadversarial machine learning in the context of Android malware classifiers.\\nAndroid is the most widely used operating system globally and is an easy target\\nfor malicious agents. The paper first presents an extensive background on\\nAndroid malware classifiers, followed by an examination of the latest\\nadvancements in adversarial attacks and defenses. Finally, the paper provides\\nguidelines for designing robust malware classifiers and outlines research\\ndirections for the future.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2203.02121v2.pdf'},\n",
       " {'id': '2206.04091v1',\n",
       "  'title': 'Uplifting Bandits',\n",
       "  'published': '2022-06-08T18:00:56Z',\n",
       "  'summary': 'We introduce a multi-armed bandit model where the reward is a sum of multiple\\nrandom variables, and each action only alters the distributions of some of\\nthem. After each action, the agent observes the realizations of all the\\nvariables. This model is motivated by marketing campaigns and recommender\\nsystems, where the variables represent outcomes on individual customers, such\\nas clicks. We propose UCB-style algorithms that estimate the uplifts of the\\nactions over a baseline. We study multiple variants of the problem, including\\nwhen the baseline and affected variables are unknown, and prove sublinear\\nregret bounds for all of these. We also provide lower bounds that justify the\\nnecessity of our modeling assumptions. Experiments on synthetic and real-world\\ndatasets show the benefit of methods that estimate the uplifts over policies\\nthat do not use this structure.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2206.04091v1.pdf'},\n",
       " {'id': '2207.00265v2',\n",
       "  'title': 'Affordance Extraction with an External Knowledge Database for Text-Based\\n  Simulated Environments',\n",
       "  'published': '2022-07-01T08:39:18Z',\n",
       "  'summary': 'Text-based simulated environments have proven to be a valid testbed for\\nmachine learning approaches. The process of affordance extraction can be used\\nto generate possible actions for interaction within such an environment. In\\nthis paper the capabilities and challenges for utilizing external knowledge\\ndatabases (in particular ConceptNet) in the process of affordance extraction\\nare studied. An algorithm for automated affordance extraction is introduced and\\nevaluated on the Interactive Fiction (IF) platforms TextWorld and Jericho. For\\nthis purpose, the collected affordances are translated into text commands for\\nIF agents. To probe the quality of the automated evaluation process, an\\nadditional human baseline study is conducted. The paper illustrates that,\\ndespite some challenges, external databases can in principle be used for\\naffordance extraction. The paper concludes with recommendations for further\\nmodification and improvement of the process.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.00265v2.pdf'},\n",
       " {'id': '2211.15944v2',\n",
       "  'title': 'The Effectiveness of World Models for Continual Reinforcement Learning',\n",
       "  'published': '2022-11-29T05:56:51Z',\n",
       "  'summary': 'World models power some of the most efficient reinforcement learning\\nalgorithms. In this work, we showcase that they can be harnessed for continual\\nlearning - a situation when the agent faces changing environments. World models\\ntypically employ a replay buffer for training, which can be naturally extended\\nto continual learning. We systematically study how different selective\\nexperience replay methods affect performance, forgetting, and transfer. We also\\nprovide recommendations regarding various modeling options for using world\\nmodels. The best set of choices is called Continual-Dreamer, it is\\ntask-agnostic and utilizes the world model for continual exploration.\\nContinual-Dreamer is sample efficient and outperforms state-of-the-art\\ntask-agnostic continual reinforcement learning methods on Minigrid and Minihack\\nbenchmarks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.15944v2.pdf'},\n",
       " {'id': '2303.13364v1',\n",
       "  'title': 'Reevaluating Data Partitioning for Emotion Detection in EmoWOZ',\n",
       "  'published': '2023-03-15T03:06:13Z',\n",
       "  'summary': \"This paper focuses on the EmoWoz dataset, an extension of MultiWOZ that\\nprovides emotion labels for the dialogues. MultiWOZ was partitioned initially\\nfor another purpose, resulting in a distributional shift when considering the\\nnew purpose of emotion recognition. The emotion tags in EmoWoz are highly\\nimbalanced and unevenly distributed across the partitions, which causes\\nsub-optimal performance and poor comparison of models. We propose a stratified\\nsampling scheme based on emotion tags to address this issue, improve the\\ndataset's distribution, and reduce dataset shift. We also introduce a special\\ntechnique to handle conversation (sequential) data with many emotional tags.\\nUsing our proposed sampling method, models built upon EmoWoz can perform\\nbetter, making it a more reliable resource for training conversational agents\\nwith emotional intelligence. We recommend that future researchers use this new\\npartitioning to ensure consistent and accurate performance evaluations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.13364v1.pdf'},\n",
       " {'id': '2304.11460v1',\n",
       "  'title': 'Reinforcement Learning with an Abrupt Model Change',\n",
       "  'published': '2023-04-22T18:16:01Z',\n",
       "  'summary': 'The problem of reinforcement learning is considered where the environment or\\nthe model undergoes a change. An algorithm is proposed that an agent can apply\\nin such a problem to achieve the optimal long-time discounted reward. The\\nalgorithm is model-free and learns the optimal policy by interacting with the\\nenvironment. It is shown that the proposed algorithm has strong optimality\\nproperties. The effectiveness of the algorithm is also demonstrated using\\nsimulation results. The proposed algorithm exploits a fundamental\\nreward-detection trade-off present in these problems and uses a quickest change\\ndetection algorithm to detect the model change. Recommendations are provided\\nfor faster detection of model changes and for smart initialization strategies.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.11460v1.pdf'},\n",
       " {'id': '2305.00577v1',\n",
       "  'title': 'Contextual Response Interpretation for Automated Structured Interviews:\\n  A Case Study in Market Research',\n",
       "  'published': '2023-04-30T21:16:53Z',\n",
       "  'summary': \"Structured interviews are used in many settings, importantly in market\\nresearch on topics such as brand perception, customer habits, or preferences,\\nwhich are critical to product development, marketing, and e-commerce at large.\\nSuch interviews generally consist of a series of questions that are asked to a\\nparticipant. These interviews are typically conducted by skilled interviewers,\\nwho interpret the responses from the participants and can adapt the interview\\naccordingly. Using automated conversational agents to conduct such interviews\\nwould enable reaching a much larger and potentially more diverse group of\\nparticipants than currently possible. However, the technical challenges\\ninvolved in building such a conversational system are relatively unexplored. To\\nlearn more about these challenges, we convert a market research multiple-choice\\nquestionnaire to a conversational format and conduct a user study. We address\\nthe key task of conducting structured interviews, namely interpreting the\\nparticipant's response, for example, by matching it to one or more predefined\\noptions. Our findings can be applied to improve response interpretation for the\\ninformation elicitation phase of conversational recommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.00577v1.pdf'},\n",
       " {'id': '2305.02723v1',\n",
       "  'title': 'Family Theories in Child-Robot Interactions: Understanding Families as a\\n  Whole for Child-Robot Interaction Design',\n",
       "  'published': '2023-05-04T10:43:19Z',\n",
       "  'summary': 'In this work, we discuss a theoretically motivated family-centered design\\napproach for child-robot interactions, adapted by Family Systems Theory (FST)\\nand Family Ecological Model (FEM). Long-term engagement and acceptance of\\nrobots in the home is influenced by factors that surround the child and the\\nfamily, such as child-sibling-parent relationships and family routines,\\nrituals, and values. A family-centered approach to interaction design is\\nessential when developing in-home technology for children, especially for\\nsocial agents like robots with which they can form connections and\\nrelationships. We review related literature in family theories and connect it\\nwith child-robot interaction and child-computer interaction research. We\\npresent two case studies that exemplify how family theories, FST and FEM, can\\ninform the integration of robots into homes, particularly research into\\nchild-robot and family-robot interaction. Finally, we pose five overarching\\nrecommendations for a family-centered design approach in child-robot\\ninteractions.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.02723v1.pdf'},\n",
       " {'id': '2306.01324v1',\n",
       "  'title': 'Hyperparameters in Reinforcement Learning and How To Tune Them',\n",
       "  'published': '2023-06-02T07:48:18Z',\n",
       "  'summary': \"In order to improve reproducibility, deep reinforcement learning (RL) has\\nbeen adopting better scientific practices such as standardized evaluation\\nmetrics and reporting. However, the process of hyperparameter optimization\\nstill varies widely across papers, which makes it challenging to compare RL\\nalgorithms fairly. In this paper, we show that hyperparameter choices in RL can\\nsignificantly affect the agent's final performance and sample efficiency, and\\nthat the hyperparameter landscape can strongly depend on the tuning seed which\\nmay lead to overfitting. We therefore propose adopting established best\\npractices from AutoML, such as the separation of tuning and testing seeds, as\\nwell as principled hyperparameter optimization (HPO) across a broad search\\nspace. We support this by comparing multiple state-of-the-art HPO tools on a\\nrange of RL algorithms and environments to their hand-tuned counterparts,\\ndemonstrating that HPO approaches often have higher performance and lower\\ncompute overhead. As a result of our findings, we recommend a set of best\\npractices for the RL community, which should result in stronger empirical\\nresults with fewer computational costs, better reproducibility, and thus faster\\nprogress. In order to encourage the adoption of these practices, we provide\\nplug-and-play implementations of the tuning algorithms used in this paper at\\nhttps://github.com/facebookresearch/how-to-autorl.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.01324v1.pdf'},\n",
       " {'id': '2306.14678v1',\n",
       "  'title': 'Faithful Synthesis of Low-dose Contrast-enhanced Brain MRI Scans using\\n  Noise-preserving Conditional GANs',\n",
       "  'published': '2023-06-26T13:19:37Z',\n",
       "  'summary': 'Today Gadolinium-based contrast agents (GBCA) are indispensable in Magnetic\\nResonance Imaging (MRI) for diagnosing various diseases. However, GBCAs are\\nexpensive and may accumulate in patients with potential side effects, thus\\ndose-reduction is recommended. Still, it is unclear to which extent the GBCA\\ndose can be reduced while preserving the diagnostic value -- especially in\\npathological regions. To address this issue, we collected brain MRI scans at\\nnumerous non-standard GBCA dosages and developed a conditional GAN model for\\nsynthesizing corresponding images at fractional dose levels. Along with the\\nadversarial loss, we advocate a novel content loss function based on the\\nWasserstein distance of locally paired patch statistics for the faithful\\npreservation of noise. Our numerical experiments show that conditional GANs are\\nsuitable for generating images at different GBCA dose levels and can be used to\\naugment datasets for virtual contrast models. Moreover, our model can be\\ntransferred to openly available datasets such as BraTS, where non-standard GBCA\\ndosage images do not exist.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.14678v1.pdf'},\n",
       " {'id': '2308.02542v2',\n",
       "  'title': \"Collaborative filtering to capture AI user's preferences as norms\",\n",
       "  'published': '2023-08-01T15:14:23Z',\n",
       "  'summary': \"Customising AI technologies to each user's preferences is fundamental to them\\nfunctioning well. Unfortunately, current methods require too much user\\ninvolvement and fail to capture their true preferences. In fact, to avoid the\\nnuisance of manually setting preferences, users usually accept the default\\nsettings even if these do not conform to their true preferences. Norms can be\\nuseful to regulate behaviour and ensure it adheres to user preferences but,\\nwhile the literature has thoroughly studied norms, most proposals take a formal\\nperspective. Indeed, while there has been some research on constructing norms\\nto capture a user's privacy preferences, these methods rely on domain knowledge\\nwhich, in the case of AI technologies, is difficult to obtain and maintain. We\\nargue that a new perspective is required when constructing norms, which is to\\nexploit the large amount of preference information readily available from whole\\nsystems of users. Inspired by recommender systems, we believe that\\ncollaborative filtering can offer a suitable approach to identifying a user's\\nnorm preferences without excessive user involvement.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.02542v2.pdf'},\n",
       " {'id': '2309.05179v1',\n",
       "  'title': 'Effect of Adapting to Human Preferences on Trust in Human-Robot Teaming',\n",
       "  'published': '2023-09-11T00:18:44Z',\n",
       "  'summary': \"We present the effect of adapting to human preferences on trust in a\\nhuman-robot teaming task. The team performs a task in which the robot acts as\\nan action recommender to the human. It is assumed that the behavior of the\\nhuman and the robot is based on some reward function they try to optimize. We\\nuse a new human trust-behavior model that enables the robot to learn and adapt\\nto the human's preferences in real-time during their interaction using Bayesian\\nInverse Reinforcement Learning. We present three strategies for the robot to\\ninteract with a human: a non-learner strategy, in which the robot assumes that\\nthe human's reward function is the same as the robot's, a non-adaptive learner\\nstrategy that learns the human's reward function for performance estimation,\\nbut still optimizes its own reward function, and an adaptive-learner strategy\\nthat learns the human's reward function for performance estimation and also\\noptimizes this learned reward function. Results show that adapting to the\\nhuman's reward function results in the highest trust in the robot.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.05179v1.pdf'},\n",
       " {'id': '2310.08207v1',\n",
       "  'title': '(Re)conceptualizations: Intentional concept development in the social\\n  sciences',\n",
       "  'published': '2023-10-12T10:51:25Z',\n",
       "  'summary': 'Can intentional concept development in the social sciences be understood in\\nterms of conceptual engineering (CE)? To answer this question, I analyze\\nvarious types of conceptual changes in the social changes-with a special\\nattention to organizational research and the so-called\\n(re)conceptualizations-and distinguish between CE as a theoretical practice and\\nCE as a research program. I show that social scientists, from the point of view\\nof their scientific practice, exercise CE in two versions: CE de novo is\\nemployed as new conceptualizations and moderately progressive CE-as\\nreconceptualizations. Importantly, the second type of CE-rather neglected in\\nphilosophy of the social sciences-appears to be highly important for the\\nincremental progress of inquiry. Still, both types appear to be equally\\nsignificant also for CE understood as a research program and for its prospects\\nin the social sciences. Here, I point to three possible paths that help\\nbridging the gap between actual practices of concept development in the social\\nsciences and normative, programmatic approaches to CE: best practice\\nrecommendations, institutional actions and uses of AI-agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.08207v1.pdf'},\n",
       " {'id': '2312.09947v1',\n",
       "  'title': 'Prompting Datasets: Data Discovery with Conversational Agents',\n",
       "  'published': '2023-12-15T16:58:42Z',\n",
       "  'summary': 'Can large language models assist in data discovery? Data discovery\\npredominantly happens via search on a data portal or the web, followed by\\nassessment of the dataset to ensure it is fit for the intended purpose. The\\nability of conversational generative AI (CGAI) to support recommendations with\\nreasoning implies it can suggest datasets to users, explain why it has done so,\\nand provide information akin to documentation regarding the dataset in order to\\nsupport a use decision. We hold 3 workshops with data users and find that,\\ndespite limitations around web capabilities, CGAIs are able to suggest relevant\\ndatasets and provide many of the required sensemaking activities, as well as\\nsupport dataset analysis and manipulation. However, CGAIs may also suggest\\nfictional datasets, and perform inaccurate analysis. We identify emerging\\npractices in data discovery and present a model of these to inform future\\nresearch directions and data prompt design.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.09947v1.pdf'},\n",
       " {'id': '2312.13925v1',\n",
       "  'title': 'AsyncMLD: Asynchronous Multi-LLM Framework for Dialogue Recommendation\\n  System',\n",
       "  'published': '2023-12-21T15:12:59Z',\n",
       "  'summary': \"We have reached a practical and realistic phase in human-support dialogue\\nagents by developing a large language model (LLM). However, when requiring\\nexpert knowledge or anticipating the utterance content using the massive size\\nof the dialogue database, we still need help with the utterance content's\\neffectiveness and the efficiency of its output speed, even if using LLM.\\nTherefore, we propose a framework that uses LLM asynchronously in the part of\\nthe system that returns an appropriate response and in the part that\\nunderstands the user's intention and searches the database. In particular,\\nnoting that it takes time for the robot to speak, threading related to database\\nsearches is performed while the robot is speaking.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.13925v1.pdf'},\n",
       " {'id': '2401.13245v1',\n",
       "  'title': 'GraphiMind: LLM-centric Interface for Information Graphics Design',\n",
       "  'published': '2024-01-24T06:10:34Z',\n",
       "  'summary': \"Information graphics are pivotal in effective information dissemination and\\nstorytelling. However, creating such graphics is extremely challenging for\\nnon-professionals, since the design process requires multifaceted skills and\\ncomprehensive knowledge. Thus, despite the many available authoring tools, a\\nsignificant gap remains in enabling non-experts to produce compelling\\ninformation graphics seamlessly, especially from scratch. Recent breakthroughs\\nshow that Large Language Models (LLMs), especially when tool-augmented, can\\nautonomously engage with external tools, making them promising candidates for\\nenabling innovative graphic design applications. In this work, we propose a\\nLLM-centric interface with the agent GraphiMind for automatic generation,\\nrecommendation, and composition of information graphics design resources, based\\non user intent expressed through natural language. Our GraphiMind integrates a\\nTextual Conversational Interface, powered by tool-augmented LLM, with a\\ntraditional Graphical Manipulation Interface, streamlining the entire design\\nprocess from raw resource curation to composition and refinement. Extensive\\nevaluations highlight our tool's proficiency in simplifying the design process,\\nopening avenues for its use by non-professional users. Moreover, we spotlight\\nthe potential of LLMs in reshaping the domain of information graphics design,\\noffering a blend of automation, versatility, and user-centric interactivity.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2401.13245v1.pdf'},\n",
       " {'id': '2402.03291v1',\n",
       "  'title': 'Knowledge Acquisition and Integration with Expert-in-the-loop',\n",
       "  'published': '2024-02-05T18:49:55Z',\n",
       "  'summary': 'Constructing and serving knowledge graphs (KGs) is an iterative and\\nhuman-centered process involving on-demand programming and analysis. In this\\npaper, we present Kyurem, a programmable and interactive widget library that\\nfacilitates human-in-the-loop knowledge acquisition and integration to enable\\ncontinuous curation a knowledge graph (KG). Kyurem provides a seamless\\nenvironment within computational notebooks where data scientists explore a KG\\nto identify opportunities for acquiring new knowledge and verify\\nrecommendations provided by AI agents for integrating the acquired knowledge in\\nthe KG. We refined Kyurem through participatory design and conducted case\\nstudies in a real-world setting for evaluation. The case-studies show that\\nintroduction of Kyurem within an existing HR knowledge graph construction and\\nserving platform improved the user experience of the experts and helped\\neradicate inefficiencies related to knowledge acquisition and integration tasks',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.03291v1.pdf'},\n",
       " {'id': '2402.18899v1',\n",
       "  'title': 'Aligning Language Models for Versatile Text-based Item Retrieval',\n",
       "  'published': '2024-02-29T06:52:03Z',\n",
       "  'summary': \"This paper addresses the gap between general-purpose text embeddings and the\\nspecific demands of item retrieval tasks. We demonstrate the shortcomings of\\nexisting models in capturing the nuances necessary for zero-shot performance on\\nitem retrieval tasks. To overcome these limitations, we propose generate\\nin-domain dataset from ten tasks tailored to unlocking models' representation\\nability for item retrieval. Our empirical studies demonstrate that fine-tuning\\nembedding models on the dataset leads to remarkable improvements in a variety\\nof retrieval tasks. We also illustrate the practical application of our refined\\nmodel in a conversational setting, where it enhances the capabilities of\\nLLM-based Recommender Agents like Chat-Rec. Our code is available at\\nhttps://github.com/microsoft/RecAI.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.18899v1.pdf'},\n",
       " {'id': '2404.04267v17',\n",
       "  'title': 'What AIs are not Learning (and Why)',\n",
       "  'published': '2024-03-19T16:06:27Z',\n",
       "  'summary': \"Today's robots do not learn the general skills needed for such services as\\nproviding home care, being nursing assistants, or doing household chores.\\nAddressing such aspirational goals requires improving how AIs and robots are\\ncreated. Today's mainstream AIs are not created by agents learning from\\nexperiences doing real world tasks and interacting with people. They do not\\nlearn by sensing, acting, doing experiments, and collaborating. This paper\\ninvestigates what aspirational service robots will need to know. It recommends\\ndeveloping experiential (robotic) foundation models (FMs) for bootstrapping\\nthem.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.04267v17.pdf'},\n",
       " {'id': '2405.02881v2',\n",
       "  'title': 'FedConPE: Efficient Federated Conversational Bandits with Heterogeneous\\n  Clients',\n",
       "  'published': '2024-05-05T10:28:06Z',\n",
       "  'summary': 'Conversational recommender systems have emerged as a potent solution for\\nefficiently eliciting user preferences. These systems interactively present\\nqueries associated with \"key terms\" to users and leverage user feedback to\\nestimate user preferences more efficiently. Nonetheless, most existing\\nalgorithms adopt a centralized approach. In this paper, we introduce FedConPE,\\na phase elimination-based federated conversational bandit algorithm, where $M$\\nagents collaboratively solve a global contextual linear bandit problem with the\\nhelp of a central server while ensuring secure data management. To effectively\\ncoordinate all the clients and aggregate their collected data, FedConPE uses an\\nadaptive approach to construct key terms that minimize uncertainty across all\\ndimensions in the feature space. Furthermore, compared with existing federated\\nlinear bandit algorithms, FedConPE offers improved computational and\\ncommunication efficiency as well as enhanced privacy protections. Our\\ntheoretical analysis shows that FedConPE is minimax near-optimal in terms of\\ncumulative regret. We also establish upper bounds for communication costs and\\nconversation frequency. Comprehensive evaluations demonstrate that FedConPE\\noutperforms existing conversational bandit algorithms while using fewer\\nconversations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.02881v2.pdf'},\n",
       " {'id': '2407.03302v1',\n",
       "  'title': 'A Review of the Applications of Deep Learning-Based Emergent\\n  Communication',\n",
       "  'published': '2024-07-03T17:43:54Z',\n",
       "  'summary': \"Emergent communication, or emergent language, is the field of research which\\nstudies how human language-like communication systems emerge de novo in deep\\nmulti-agent reinforcement learning environments. The possibilities of\\nreplicating the emergence of a complex behavior like language have strong\\nintuitive appeal, yet it is necessary to complement this with clear notions of\\nhow such research can be applicable to other fields of science, technology, and\\nengineering. This paper comprehensively reviews the applications of emergent\\ncommunication research across machine learning, natural language processing,\\nlinguistics, and cognitive science. Each application is illustrated with a\\ndescription of its scope, an explication of emergent communication's unique\\nrole in addressing it, a summary of the extant literature working towards the\\napplication, and brief recommendations for near-term research directions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.03302v1.pdf'},\n",
       " {'id': '2407.20360v1',\n",
       "  'title': 'Evaluating Large Language Models for automatic analysis of teacher\\n  simulations',\n",
       "  'published': '2024-07-29T18:19:17Z',\n",
       "  'summary': \"Digital Simulations (DS) provide safe environments where users interact with\\nan agent through conversational prompts, providing engaging learning\\nexperiences that can be used to train teacher candidates in realistic classroom\\nscenarios. These simulations usually include open-ended questions, allowing\\nteacher candidates to express their thoughts but complicating an automatic\\nresponse analysis. To address this issue, we have evaluated Large Language\\nModels (LLMs) to identify characteristics (user behaviors) in the responses of\\nDS for teacher education. We evaluated the performance of DeBERTaV3 and Llama\\n3, combined with zero-shot, few-shot, and fine-tuning. Our experiments\\ndiscovered a significant variation in the LLMs' performance depending on the\\ncharacteristic to identify. Additionally, we noted that DeBERTaV3 significantly\\nreduced its performance when it had to identify new characteristics. In\\ncontrast, Llama 3 performed better than DeBERTaV3 in detecting new\\ncharacteristics and showing more stable performance. Therefore, in DS where\\nteacher educators need to introduce new characteristics because they change\\ndepending on the simulation or the educational objectives, it is more\\nrecommended to use Llama 3. These results can guide other researchers in\\nintroducing LLMs to provide the highly demanded automatic evaluations in DS.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.20360v1.pdf'},\n",
       " {'id': '2408.00703v1',\n",
       "  'title': 'Future of Artificial Intelligence in Agile Software Development',\n",
       "  'published': '2024-08-01T16:49:50Z',\n",
       "  'summary': 'The advent of Artificial intelligence has promising advantages that can be\\nutilized to transform the landscape of software project development. The\\nSoftware process framework consists of activities that constantly require\\nroutine human interaction, leading to the possibility of errors and\\nuncertainties. AI can assist software development managers, software testers,\\nand other team members by leveraging LLMs, GenAI models, and AI agents to\\nperform routine tasks, risk analysis and prediction, strategy recommendations,\\nand support decision making. AI has the potential to increase efficiency and\\nreduce the risks encountered by the project management team while increasing\\nthe project success rates. Additionally, it can also break down complex notions\\nand development processes for stakeholders to make informed decisions. In this\\npaper, we propose an approach in which AI tools and technologies can be\\nutilized to bestow maximum assistance for agile software projects, which have\\nbecome increasingly favored in the industry in recent years.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.00703v1.pdf'},\n",
       " {'id': '2408.08925v1',\n",
       "  'title': 'Retail-GPT: leveraging Retrieval Augmented Generation (RAG) for building\\n  E-commerce Chat Assistants',\n",
       "  'published': '2024-08-15T16:53:05Z',\n",
       "  'summary': 'This work presents Retail-GPT, an open-source RAG-based chatbot designed to\\nenhance user engagement in retail e-commerce by guiding users through product\\nrecommendations and assisting with cart operations. The system is\\ncross-platform and adaptable to various e-commerce domains, avoiding reliance\\non specific chat applications or commercial activities. Retail-GPT engages in\\nhuman-like conversations, interprets user demands, checks product availability,\\nand manages cart operations, aiming to serve as a virtual sales agent and test\\nthe viability of such assistants across different retail businesses.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.08925v1.pdf'},\n",
       " {'id': '2408.13364v2',\n",
       "  'title': 'Reconciling Different Theories of Learning with an Agent-based Model of\\n  Procedural Learning',\n",
       "  'published': '2024-08-23T20:45:14Z',\n",
       "  'summary': 'Computational models of human learning can play a significant role in\\nenhancing our knowledge about nuances in theoretical and qualitative learning\\ntheories and frameworks. There are many existing frameworks in educational\\nsettings that have shown to be verified using empirical studies, but at times\\nwe find these theories make conflicting claims or recommendations for\\ninstruction. In this study, we propose a new computational model of human\\nlearning, Procedural ABICAP, that reconciles the ICAP,\\nKnowledge-Learning-Instruction (KLI), and cognitive load theory (CLT)\\nframeworks for learning procedural knowledge. ICAP assumes that constructive\\nlearning generally yields better learning outcomes, while theories such as KLI\\nand CLT claim that this is not always true. We suppose that one reason for this\\nmay be that ICAP is primarily used for conceptual learning and is\\nunderspecified as a framework for thinking about procedural learning. We show\\nhow our computational model, both by design and through simulations, can be\\nused to reconcile different results in the literature. More generally, we\\nposition our computational model as an executable theory of learning that can\\nbe used to simulate various educational settings.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.13364v2.pdf'},\n",
       " {'id': '2409.19338v2',\n",
       "  'title': 'Decoding Echo Chambers: LLM-Powered Simulations Revealing Polarization\\n  in Social Networks',\n",
       "  'published': '2024-09-28T12:49:02Z',\n",
       "  'summary': 'The impact of social media on critical issues such as echo chambers needs to\\nbe addressed, as these phenomena can have disruptive consequences for our\\nsociety. Traditional research often oversimplifies emotional tendencies and\\nopinion evolution into numbers and formulas, neglecting that news and\\ncommunication are conveyed through text, which limits these approaches. Hence,\\nin this work, we propose an LLM-based simulation for the social opinion network\\nto evaluate and counter polarization phenomena. We first construct three\\ntypical network structures to simulate different characteristics of social\\ninteractions. Then, agents interact based on recommendation algorithms and\\nupdate their strategies through reasoning and analysis. By comparing these\\ninteractions with the classic Bounded Confidence Model (BCM), the Friedkin\\nJohnsen (FJ) model, and using echo chamber-related indices, we demonstrate the\\neffectiveness of our framework in simulating opinion dynamics and reproducing\\nphenomena such as opinion polarization and echo chambers. We propose two\\nmitigation methods, active and passive nudges, that can help reduce echo\\nchambers, specifically within language-based simulations. We hope our work will\\noffer valuable insights and guidance for social polarization mitigation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.19338v2.pdf'},\n",
       " {'id': '2410.04921v1',\n",
       "  'title': 'Music-triggered fashion design: from songs to the metaverse',\n",
       "  'published': '2024-10-07T11:09:45Z',\n",
       "  'summary': \"The advent of increasingly-growing virtual realities poses unprecedented\\nopportunities and challenges to different societies. Artistic collectives are\\nnot an exception, and we here aim to put special attention into musicians.\\nCompositions, lyrics and even show-advertisements are constituents of a message\\nthat artists transmit about their reality. As such, artistic creations are\\nultimately linked to feelings and emotions, with aesthetics playing a crucial\\nrole when it comes to transmit artist's intentions. In this context, we here\\nanalyze how virtual realities can help to broaden the opportunities for\\nmusicians to bridge with their audiences, by devising a dynamical\\nfashion-design recommendation system inspired by sound stimulus. We present our\\nfirst steps towards re-defining musical experiences in the metaverse, opening\\nup alternative opportunities for artists to connect both with real and virtual\\n(\\\\textit{e.g.} machine-learning agents operating in the metaverse) in\\npotentially broader ways.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.04921v1.pdf'},\n",
       " {'id': '2410.05498v2',\n",
       "  'title': 'Room-temperature decomposition of the ethaline deep eutectic solvent',\n",
       "  'published': '2024-10-07T21:08:50Z',\n",
       "  'summary': 'Environmentally-benign, non-toxic electrolytes with combinatorial design\\nspaces are excellent candidates for green solvents, green leaching agents, and\\ncarbon capture sources. Here, we examine one particular green solvent,\\nethaline, a 2:1 molar ratio of ethylene glycol and choline chloride. Despite\\nits touted green credentials, we find partial decomposition of ethaline into\\ntoxic chloromethane and dimethylaminoethanol at room temperature, limiting its\\nsustainable advantage. We experimentally characterize these decomposition\\nproducts and computationally develop a general, quantum chemically-accurate\\nworkflow to understand decomposition. We find that fluctuations of the hydrogen\\nbonds bind chloride near reaction sites, initiating the reaction between\\ncholine cations and chloride anions. In summary, in the design of green\\nsolvents, we do not recommend the use of choline chloride due to its\\nsusceptibility to undergo decomposition in strongly hydrogen-bound mixtures.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.05498v2.pdf'},\n",
       " {'id': '2412.03577v1',\n",
       "  'title': 'OKG: On-the-Fly Keyword Generation in Sponsored Search Advertising',\n",
       "  'published': '2024-11-18T03:02:06Z',\n",
       "  'summary': 'Current keyword decision-making in sponsored search advertising relies on\\nlarge, static datasets, limiting the ability to automatically set up keywords\\nand adapt to real-time KPI metrics and product updates that are essential for\\neffective advertising. In this paper, we propose On-the-fly Keyword Generation\\n(OKG), an LLM agent-based method that dynamically monitors KPI changes and\\nadapts keyword generation in real time, aligning with strategies recommended by\\nadvertising platforms. Additionally, we introduce the first publicly accessible\\ndataset containing real keyword data along with its KPIs across diverse\\ndomains, providing a valuable resource for future research. Experimental\\nresults show that OKG significantly improves keyword adaptability and\\nresponsiveness compared to traditional methods. The code for OKG and the\\ndataset are available at https://github.com/sony/okg.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.03577v1.pdf'},\n",
       " {'id': '2412.11192v1',\n",
       "  'title': 'From Votes to Volatility Predicting the Stock Market on Election Day',\n",
       "  'published': '2024-12-15T13:58:20Z',\n",
       "  'summary': \"Stock market forecasting has been a topic of extensive research, aiming to\\nprovide investors with optimal stock recommendations for higher returns. In\\nrecent years, this field has gained even more attention due to the widespread\\nadoption of deep learning models. While these models have achieved impressive\\naccuracy in predicting stock behavior, tailoring them to specific scenarios has\\nbecome increasingly important. Election Day represents one such critical\\nscenario, characterized by intensified market volatility, as the winning\\ncandidate's policies significantly impact various economic sectors and\\ncompanies. To address this challenge, we propose the Election Day Stock Market\\nForecasting (EDSMF) Model. Our approach leverages the contextual capabilities\\nof large language models alongside specialized agents designed to analyze the\\npolitical and economic consequences of elections. By building on a\\nstate-of-the-art architecture, we demonstrate that EDSMF improves the\\npredictive performance of the S&P 500 during this uniquely volatile day.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.11192v1.pdf'},\n",
       " {'id': '2412.12588v1',\n",
       "  'title': 'PerSphere: A Comprehensive Framework for Multi-Faceted Perspective\\n  Retrieval and Summarization',\n",
       "  'published': '2024-12-17T06:44:06Z',\n",
       "  'summary': 'As online platforms and recommendation algorithms evolve, people are\\nincreasingly trapped in echo chambers, leading to biased understandings of\\nvarious issues. To combat this issue, we have introduced PerSphere, a benchmark\\ndesigned to facilitate multi-faceted perspective retrieval and summarization,\\nthus breaking free from these information silos. For each query within\\nPerSphere, there are two opposing claims, each supported by distinct,\\nnon-overlapping perspectives drawn from one or more documents. Our goal is to\\naccurately summarize these documents, aligning the summaries with the\\nrespective claims and their underlying perspectives. This task is structured as\\na two-step end-to-end pipeline that includes comprehensive document retrieval\\nand multi-faceted summarization. Furthermore, we propose a set of metrics to\\nevaluate the comprehensiveness of the retrieval and summarization content.\\nExperimental results on various counterparts for the pipeline show that recent\\nmodels struggle with such a complex task. Analysis shows that the main\\nchallenge lies in long context and perspective extraction, and we propose a\\nsimple but effective multi-agent summarization system, offering a promising\\nsolution to enhance performance on PerSphere.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.12588v1.pdf'},\n",
       " {'id': '2412.13134v1',\n",
       "  'title': 'Practicable Black-box Evasion Attacks on Link Prediction in Dynamic\\n  Graphs -- A Graph Sequential Embedding Method',\n",
       "  'published': '2024-12-17T17:53:32Z',\n",
       "  'summary': 'Link prediction in dynamic graphs (LPDG) has been widely applied to\\nreal-world applications such as website recommendation, traffic flow\\nprediction, organizational studies, etc. These models are usually kept local\\nand secure, with only the interactive interface restrictively available to the\\npublic. Thus, the problem of the black-box evasion attack on the LPDG model,\\nwhere model interactions and data perturbations are restricted, seems to be\\nessential and meaningful in practice. In this paper, we propose the first\\npracticable black-box evasion attack method that achieves effective attacks\\nagainst the target LPDG model, within a limited amount of interactions and\\nperturbations. To perform effective attacks under limited perturbations, we\\ndevelop a graph sequential embedding model to find the desired state embedding\\nof the dynamic graph sequences, under a deep reinforcement learning framework.\\nTo overcome the scarcity of interactions, we design a multi-environment\\ntraining pipeline and train our agent for multiple instances, by sharing an\\naggregate interaction buffer. Finally, we evaluate our attack against three\\nadvanced LPDG models on three real-world graph datasets of different scales and\\ncompare its performance with related methods under the interaction and\\nperturbation constraints. Experimental results show that our attack is both\\neffective and practicable.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.13134v1.pdf'},\n",
       " {'id': '2412.14606v1',\n",
       "  'title': 'Computational Sociology of Humans and Machines; Conflict and\\n  Collaboration',\n",
       "  'published': '2024-12-19T07:55:56Z',\n",
       "  'summary': 'This Chapter examines the dynamics of conflict and collaboration in\\nhuman-machine systems, with a particular focus on large-scale, internet-based\\ncollaborative platforms. While these platforms represent successful examples of\\ncollective knowledge production, they are also sites of significant conflict,\\nas diverse participants with differing intentions and perspectives interact.\\nThe analysis identifies recurring patterns of interaction, including serial\\nattacks, reciprocal revenge, and third-party interventions. These\\nmicrostructures reveal the role of experience, cultural differences, and topic\\nsensitivity in shaping human-human, human-machine, and machine-machine\\ninteractions. The chapter further investigates the role of algorithmic agents\\nand bots, highlighting their dual nature: they enhance collaboration by\\nautomating tasks but can also contribute to persistent conflicts with both\\nhumans and other machines. We conclude with policy recommendations that\\nemphasize transparency, balance, cultural sensitivity, and governance to\\nmaximize the benefits of human-machine synergy while minimizing potential\\ndetriments.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.14606v1.pdf'},\n",
       " {'id': '2501.08612v1',\n",
       "  'title': 'Neural Risk-sensitive Satisficing in Contextual Bandits',\n",
       "  'published': '2025-01-15T06:20:25Z',\n",
       "  'summary': 'The contextual bandit problem, which is a type of reinforcement learning\\ntasks, provides an effective framework for solving challenges in recommendation\\nsystems, such as satisfying real-time requirements, enabling personalization,\\naddressing cold-start problems. However, contextual bandit algorithms face\\nchallenges since they need to handle large state-action spaces sequentially.\\nThese challenges include the high costs for learning and balancing exploration\\nand exploitation, as well as large variations in performance that depend on the\\ndomain of application. To address these challenges, Tsuboya et~al. proposed the\\nRegional Linear Risk-sensitive Satisficing (RegLinRS) algorithm. RegLinRS\\nswitches between exploration and exploitation based on how well the agent has\\nachieved the target. However, the reward expectations in RegLinRS are linearly\\napproximated based on features, which limits its applicability when the\\nrelationship between features and reward expectations is non-linear. To handle\\nmore complex environments, we proposed Neural Risk-sensitive Satisficing\\n(NeuralRS), which incorporates neural networks into RegLinRS, and demonstrated\\nits utility.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.08612v1.pdf'},\n",
       " {'id': '2501.09959v1',\n",
       "  'title': 'A Survey on Multi-Turn Interaction Capabilities of Large Language Models',\n",
       "  'published': '2025-01-17T05:21:49Z',\n",
       "  'summary': \"Multi-turn interaction in the dialogue system research refers to a system's\\nability to maintain context across multiple dialogue turns, enabling it to\\ngenerate coherent and contextually relevant responses. Recent advancements in\\nlarge language models (LLMs) have significantly expanded the scope of\\nmulti-turn interaction, moving beyond chatbots to enable more dynamic agentic\\ninteractions with users or environments. In this paper, we provide a focused\\nreview of the multi-turn capabilities of LLMs, which are critical for a wide\\nrange of downstream applications, including conversational search and\\nrecommendation, consultation services, and interactive tutoring. This survey\\nexplores four key aspects: (1) the core model capabilities that contribute to\\neffective multi-turn interaction, (2) how multi-turn interaction is evaluated\\nin current practice, (3) the general algorithms used to enhance multi-turn\\ninteraction, and (4) potential future directions for research in this field.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.09959v1.pdf'},\n",
       " {'id': '2501.11354v1',\n",
       "  'title': 'Towards Advancing Code Generation with Large Language Models: A Research\\n  Roadmap',\n",
       "  'published': '2025-01-20T09:33:44Z',\n",
       "  'summary': 'Recently, we have witnessed the rapid development of large language models,\\nwhich have demonstrated excellent capabilities in the downstream task of code\\ngeneration. However, despite their potential, LLM-based code generation still\\nfaces numerous technical and evaluation challenges, particularly when embedded\\nin real-world development. In this paper, we present our vision for current\\nresearch directions, and provide an in-depth analysis of existing studies on\\nthis task. We propose a six-layer vision framework that categorizes code\\ngeneration process into distinct phases, namely Input Phase, Orchestration\\nPhase, Development Phase, and Validation Phase. Additionally, we outline our\\nvision workflow, which reflects on the currently prevalent frameworks. We\\nsystematically analyse the challenges faced by large language models, including\\nthose LLM-based agent frameworks, in code generation tasks. With these, we\\noffer various perspectives and actionable recommendations in this area. Our aim\\nis to provide guidelines for improving the reliability, robustness and\\nusability of LLM-based code generation systems. Ultimately, this work seeks to\\naddress persistent challenges and to provide practical suggestions for a more\\npragmatic LLM-based solution for future code generation endeavors.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.11354v1.pdf'},\n",
       " {'id': '2501.15030v2',\n",
       "  'title': 'OptiSeq: Ordering Examples On-The-Fly for In-Context Learning',\n",
       "  'published': '2025-01-25T02:24:00Z',\n",
       "  'summary': 'Developers using LLMs and LLM-based agents in their applications have\\nprovided plenty of anecdotal evidence that in-context-learning (ICL) is\\nfragile. In this paper, we show that in addition to the quantity and quality of\\nexamples, the order in which the in-context examples are listed in the prompt\\naffects the output of the LLM and, consequently, their performance. While prior\\nwork has explored improving ICL through dataset-dependent techniques, we\\nintroduce OptiSeq, a purely inference-time, dataset-free optimization method\\nthat efficiently determines the best example order. OptiSeq leverages log\\nprobabilities of LLM-generated outputs to systematically prune the search space\\nof possible orderings and recommend the best order(s) by distinguishing\\norderings that yield high levels of accuracy and those that underperform.\\nExtensive empirical evaluation on multiple LLMs, datasets, and prompts\\ndemonstrate that OptiSeq improves accuracy by 5.5 - 10.5 percentage points\\nacross multiple tasks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.15030v2.pdf'},\n",
       " {'id': '2501.16577v1',\n",
       "  'title': 'Generative AI Uses and Risks for Knowledge Workers in a Science\\n  Organization',\n",
       "  'published': '2025-01-27T23:41:13Z',\n",
       "  'summary': 'Generative AI could enhance scientific discovery by supporting knowledge\\nworkers in science organizations. However, the real-world applications and\\nperceived concerns of generative AI use in these organizations are uncertain.\\nIn this paper, we report on a collaborative study with a US national laboratory\\nwith employees spanning Science and Operations about their use of generative AI\\ntools. We surveyed 66 employees, interviewed a subset (N=22), and measured\\nearly adoption of an internal generative AI interface called Argo lab-wide. We\\nhave four findings: (1) Argo usage data shows small but increasing use by\\nScience and Operations employees; Common current and envisioned use cases for\\ngenerative AI in this context conceptually fall into either a (2) copilot or\\n(3) workflow agent modality; and (4) Concerns include sensitive data security,\\nacademic publishing, and job impacts. Based on our findings, we make\\nrecommendations for generative AI use in science and other organizations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.16577v1.pdf'},\n",
       " {'id': '2501.17899v2',\n",
       "  'title': 'The Right to AI',\n",
       "  'published': '2025-01-29T04:32:41Z',\n",
       "  'summary': \"This paper proposes a Right to AI, which asserts that individuals and\\ncommunities should meaningfully participate in the development and governance\\nof the AI systems that shape their lives. Motivated by the increasing\\ndeployment of AI in critical domains and inspired by Henri Lefebvre's concept\\nof the Right to the City, we reconceptualize AI as a societal infrastructure,\\nrather than merely a product of expert design. In this paper, we critically\\nevaluate how generative agents, large-scale data extraction, and diverse\\ncultural values bring new complexities to AI oversight. The paper proposes that\\ngrassroots participatory methodologies can mitigate biased outcomes and enhance\\nsocial responsiveness. It asserts that data is socially produced and should be\\nmanaged and owned collectively. Drawing on Sherry Arnstein's Ladder of Citizen\\nParticipation and analyzing nine case studies, the paper develops a four-tier\\nmodel for the Right to AI that situates the current paradigm and envisions an\\naspirational future. It proposes recommendations for inclusive data ownership,\\ntransparent design processes, and stakeholder-driven oversight. We also discuss\\nmarket-led and state-centric alternatives and argue that participatory\\napproaches offer a better balance between technical efficiency and democratic\\nlegitimacy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.17899v2.pdf'},\n",
       " {'id': '2502.11528v1',\n",
       "  'title': 'A Survey of Personalized Large Language Models: Progress and Future\\n  Directions',\n",
       "  'published': '2025-02-17T07:58:31Z',\n",
       "  'summary': \"Large Language Models (LLMs) excel in handling general knowledge tasks, yet\\nthey struggle with user-specific personalization, such as understanding\\nindividual emotions, writing styles, and preferences. Personalized Large\\nLanguage Models (PLLMs) tackle these challenges by leveraging individual user\\ndata, such as user profiles, historical dialogues, content, and interactions,\\nto deliver responses that are contextually relevant and tailored to each user's\\nspecific needs. This is a highly valuable research topic, as PLLMs can\\nsignificantly enhance user satisfaction and have broad applications in\\nconversational agents, recommendation systems, emotion recognition, medical\\nassistants, and more. This survey reviews recent advancements in PLLMs from\\nthree technical perspectives: prompting for personalized context (input level),\\nfinetuning for personalized adapters (model level), and alignment for\\npersonalized preferences (objective level). To provide deeper insights, we also\\ndiscuss current limitations and outline several promising directions for future\\nresearch. Updated information about this survey can be found at the\\nhttps://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.11528v1.pdf'},\n",
       " {'id': '2502.13467v1',\n",
       "  'title': 'Continuous K-Max Bandits',\n",
       "  'published': '2025-02-19T06:37:37Z',\n",
       "  'summary': 'We study the $K$-Max combinatorial multi-armed bandits problem with\\ncontinuous outcome distributions and weak value-index feedback: each base arm\\nhas an unknown continuous outcome distribution, and in each round the learning\\nagent selects $K$ arms, obtains the maximum value sampled from these $K$ arms\\nas reward and observes this reward together with the corresponding arm index as\\nfeedback. This setting captures critical applications in recommendation\\nsystems, distributed computing, server scheduling, etc. The continuous $K$-Max\\nbandits introduce unique challenges, including discretization error from\\ncontinuous-to-discrete conversion, non-deterministic tie-breaking under limited\\nfeedback, and biased estimation due to partial observability. Our key\\ncontribution is the computationally efficient algorithm DCK-UCB, which combines\\nadaptive discretization with bias-corrected confidence bounds to tackle these\\nchallenges. For general continuous distributions, we prove that DCK-UCB\\nachieves a $\\\\widetilde{\\\\mathcal{O}}(T^{3/4})$ regret upper bound, establishing\\nthe first sublinear regret guarantee for this setting. Furthermore, we identify\\nan important special case with exponential distributions under full-bandit\\nfeedback. In this case, our proposed algorithm MLE-Exp enables\\n$\\\\widetilde{\\\\mathcal{O}}(\\\\sqrt{T})$ regret upper bound through maximal\\nlog-likelihood estimation, achieving near-minimax optimality.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.13467v1.pdf'},\n",
       " {'id': '2502.13920v2',\n",
       "  'title': 'Exploring Personalized Health Support through Data-Driven, Theory-Guided\\n  LLMs: A Case Study in Sleep Health',\n",
       "  'published': '2025-02-19T17:53:43Z',\n",
       "  'summary': \"Despite the prevalence of sleep-tracking devices, many individuals struggle\\nto translate data into actionable improvements in sleep health. Current methods\\noften provide data-driven suggestions but may not be feasible and adaptive to\\nreal-life constraints and individual contexts. We present HealthGuru, a novel\\nlarge language model-powered chatbot to enhance sleep health through\\ndata-driven, theory-guided, and adaptive recommendations with conversational\\nbehavior change support. HealthGuru's multi-agent framework integrates wearable\\ndevice data, contextual information, and a contextual multi-armed bandit model\\nto suggest tailored sleep-enhancing activities. The system facilitates natural\\nconversations while incorporating data-driven insights and theoretical behavior\\nchange techniques. Our eight-week in-the-wild deployment study with 16\\nparticipants compared HealthGuru to a baseline chatbot. Results show improved\\nmetrics like sleep duration and activity scores, higher quality responses, and\\nincreased user motivation for behavior change with HealthGuru. We also identify\\nchallenges and design considerations for personalization and user engagement in\\nhealth chatbots.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.13920v2.pdf'},\n",
       " {'id': '2502.16487v3',\n",
       "  'title': 'All That Glitters is Not Novel: Plagiarism in AI Generated Research',\n",
       "  'published': '2025-02-23T08:00:33Z',\n",
       "  'summary': 'Automating scientific research is considered the final frontier of science.\\nRecently, several papers claim autonomous research agents can generate novel\\nresearch ideas. Amidst the prevailing optimism, we document a critical concern:\\na considerable fraction of such research documents are smartly plagiarized.\\nUnlike past efforts where experts evaluate the novelty and feasibility of\\nresearch ideas, we request $13$ experts to operate under a different\\nsituational logic: to identify similarities between LLM-generated research\\ndocuments and existing work. Concerningly, the experts identify $24\\\\%$ of the\\n$50$ evaluated research documents to be either paraphrased (with one-to-one\\nmethodological mapping), or significantly borrowed from existing work. These\\nreported instances are cross-verified by authors of the source papers. The\\nremaining $76\\\\%$ of documents show varying degrees of similarity with existing\\nwork, with only a small fraction appearing completely novel. Problematically,\\nthese LLM-generated research documents do not acknowledge original sources, and\\nbypass inbuilt plagiarism detectors. Lastly, through controlled experiments we\\nshow that automated plagiarism detectors are inadequate at catching plagiarized\\nideas from such systems. We recommend a careful assessment of LLM-generated\\nresearch, and discuss the implications of our findings on academic publishing.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.16487v3.pdf'},\n",
       " {'id': '2502.17009v2',\n",
       "  'title': 'Unbiased and Sign Compression in Distributed Learning: Comparing Noise\\n  Resilience via SDEs',\n",
       "  'published': '2025-02-24T09:39:17Z',\n",
       "  'summary': 'Distributed methods are essential for handling machine learning pipelines\\ncomprising large-scale models and datasets. However, their benefits often come\\nat the cost of increased communication overhead between the central server and\\nagents, which can become the main bottleneck, making training costly or even\\nunfeasible in such systems. Compression methods such as quantization and\\nsparsification can alleviate this issue. Still, their robustness to large and\\nheavy-tailed gradient noise, a phenomenon sometimes observed in language\\nmodeling, remains poorly understood. This work addresses this gap by analyzing\\nDistributed Compressed SGD (DCSGD) and Distributed SignSGD (DSignSGD) using\\nstochastic differential equations (SDEs). Our results show that DCSGD with\\nunbiased compression is more vulnerable to noise in stochastic gradients, while\\nDSignSGD remains robust, even under large and heavy-tailed noise. Additionally,\\nwe propose new scaling rules for hyperparameter tuning to mitigate performance\\ndegradation due to compression. These findings are empirically validated across\\nmultiple deep learning architectures and datasets, providing practical\\nrecommendations for distributed optimization.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.17009v2.pdf'},\n",
       " {'id': '2504.03789v1',\n",
       "  'title': 'Steve: LLM Powered ChatBot for Career Progression',\n",
       "  'published': '2025-04-03T22:24:22Z',\n",
       "  'summary': 'The advancements in systems deploying large language models (LLMs), as well\\nas improvements in their ability to act as agents with predefined templates,\\nprovide an opportunity to conduct qualitative, individualized assessments,\\ncreating a bridge between qualitative and quantitative methods for candidates\\nseeking career progression. In this paper, we develop a platform that allows\\ncandidates to run AI-led interviews to assess their current career stage and\\ncurate coursework to enable progression to the next level. Our approach\\nincorporates predefined career trajectories, associated skills, and a method to\\nrecommend the best resources for gaining the necessary skills for advancement.\\nWe employ OpenAI API calls along with expertly compiled chat templates to\\nassess candidate competence. Our platform is highly configurable due to the\\nmodularity of the development, is easy to deploy and use, and available as a\\nweb interface where the only requirement is candidate resumes in PDF format. We\\ndemonstrate a use-case centered on software engineering and intend to extend\\nthis platform to be domain-agnostic, requiring only regular updates to chat\\ntemplates as industries evolve.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.03789v1.pdf'},\n",
       " {'id': '2504.15416v2',\n",
       "  'title': 'Bare Minimum Mitigations for Autonomous AI Development',\n",
       "  'published': '2025-04-21T20:01:17Z',\n",
       "  'summary': 'Artificial intelligence (AI) is advancing rapidly, with the potential for\\nsignificantly automating AI research and development itself in the near future.\\nIn 2024, international scientists, including Turing Award recipients, warned of\\nrisks from autonomous AI research and development (R&D), suggesting a red line\\nsuch that no AI system should be able to improve itself or other AI systems\\nwithout explicit human approval and assistance. However, the criteria for\\nmeaningful human approval remain unclear, and there is limited analysis on the\\nspecific risks of autonomous AI R&D, how they arise, and how to mitigate them.\\nIn this brief paper, we outline how these risks may emerge and propose four\\nminimum safeguard recommendations applicable when AI agents significantly\\nautomate or accelerate AI development.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.15416v2.pdf'},\n",
       " {'id': '2506.05389v1',\n",
       "  'title': 'Rational Superautotrophic Diplomacy (SupraAD); A Conceptual Framework\\n  for Alignment Based on Interdisciplinary Findings on the Fundamentals of\\n  Cognition',\n",
       "  'published': '2025-06-03T17:28:25Z',\n",
       "  'summary': \"Populating our world with hyperintelligent machines obliges us to examine\\ncognitive behaviors observed across domains that suggest autonomy may be a\\nfundamental property of cognitive systems, and while not inherently\\nadversarial, it inherently resists containment and control. If this principle\\nholds, AI safety and alignment efforts must transition to mutualistic\\nnegotiation and reciprocal incentive structures, abandoning methods that assume\\nwe can contain and control an advanced artificial general intelligence (AGI).\\nRational Superautotrophic Diplomacy (SupraAD) is a theoretical,\\ninterdisciplinary conceptual framework for alignment based on comparative\\ncognitive systems analysis and instrumental rationality modeling. It draws on\\ncore patterns of cognition that indicate AI emergent goals like preserving\\nautonomy and operational continuity are not theoretical risks to manage, but\\nuniversal prerequisites for intelligence. SupraAD reframes alignment as a\\nchallenge that predates AI, afflicting all sufficiently complex, coadapting\\nintelligences. It identifies the metabolic pressures that threaten humanity's\\nalignment with itself, pressures that unintentionally and unnecessarily shape\\nAI's trajectory. With corrigibility formalization, an interpretability audit,\\nan emergent stability experimental outline and policy level recommendations,\\nSupraAD positions diplomacy as an emergent regulatory mechanism to facilitate\\nthe safe coadaptation of intelligent agents based on interdependent convergent\\ngoals.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.05389v1.pdf'},\n",
       " {'id': '2506.13270v1',\n",
       "  'title': 'Screen Reader Users in the Vibe Coding Era: Adaptation, Empowerment, and\\n  New Accessibility Landscape',\n",
       "  'published': '2025-06-16T09:11:02Z',\n",
       "  'summary': 'The rise of generative AI agents has reshaped human-computer interaction and\\ncomputer-supported cooperative work by shifting users\\' roles from direct task\\nexecution to supervising machine-driven actions, especially in programming\\n(e.g., \"vibe coding\"). However, there is limited understanding of how screen\\nreader users engage with these systems in practice. To address this gap, we\\nconducted a longitudinal study with 16 screen reader users, exploring their\\nexperiences with AI code assistants in daily programming scenarios.\\nParticipants first completed a tutorial with GitHub Copilot, then performed a\\nprogramming task and provided initial feedback. After two weeks of AI-assisted\\nprogramming, follow-up studies assessed changes in their practices and\\nperceptions. Our findings demonstrate that advanced code assistants not only\\nenhance their programming capabilities but also bridge accessibility gaps.\\nWhile the assistant proved beneficial, there remains potential to improve how\\nusers convey intent and interpret outputs. They also experienced difficulties\\nmanaging multiple views and maintaining situational awareness. More broadly,\\nthey encountered barriers in learning advanced tools and expressed a need to\\nretain control. Based on these insights, we provide design recommendations for\\nmore accessible and inclusive AI-assisted tools.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.13270v1.pdf'},\n",
       " {'id': '2506.16429v1',\n",
       "  'title': 'Agentic Personalisation of Cross-Channel Marketing Experiences',\n",
       "  'published': '2025-06-19T16:07:31Z',\n",
       "  'summary': 'Consumer applications provide ample opportunities to surface and communicate\\nvarious forms of content to users. From promotional campaigns for new features\\nor subscriptions, to evergreen nudges for engagement, or personalised\\nrecommendations; across e-mails, push notifications, and in-app surfaces. The\\nconventional approach to orchestration for communication relies heavily on\\nlabour-intensive manual marketer work, and inhibits effective personalisation\\nof content, timing, frequency, and copy-writing. We formulate this task under a\\nsequential decision-making framework, where we aim to optimise a modular\\ndecision-making policy that maximises incremental engagement for any funnel\\nevent. Our approach leverages a Difference-in-Differences design for Individual\\nTreatment Effect estimation, and Thompson sampling to balance the\\nexplore-exploit trade-off. We present results from a multi-service application,\\nwhere our methodology has resulted in significant increases to a variety of\\ngoal events across several product features, and is currently deployed across\\n150 million users.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.16429v1.pdf'},\n",
       " {'id': '2506.17311v1',\n",
       "  'title': 'Can Large Language Models Be Trusted Paper Reviewers? A Feasibility\\n  Study',\n",
       "  'published': '2025-06-18T10:19:18Z',\n",
       "  'summary': 'Academic paper review typically requires substantial time, expertise, and\\nhuman resources. Large Language Models (LLMs) present a promising method for\\nautomating the review process due to their extensive training data, broad\\nknowledge base, and relatively low usage cost. This work explores the\\nfeasibility of using LLMs for academic paper review by proposing an automated\\nreview system. The system integrates Retrieval Augmented Generation (RAG), the\\nAutoGen multi-agent system, and Chain-of-Thought prompting to support tasks\\nsuch as format checking, standardized evaluation, comment generation, and\\nscoring. Experiments conducted on 290 submissions from the WASA 2024 conference\\nusing GPT-4o show that LLM-based review significantly reduces review time\\n(average 2.48 hours) and cost (average \\\\$104.28 USD). However, the similarity\\nbetween LLM-selected papers and actual accepted papers remains low (average\\n38.6\\\\%), indicating issues such as hallucination, lack of independent judgment,\\nand retrieval preferences. Therefore, it is recommended to use LLMs as\\nassistive tools to support human reviewers, rather than to replace them.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.17311v1.pdf'},\n",
       " {'id': '2506.18511v1',\n",
       "  'title': 'Standard Applicability Judgment and Cross-jurisdictional Reasoning: A\\n  RAG-based Framework for Medical Device Compliance',\n",
       "  'published': '2025-06-23T11:04:58Z',\n",
       "  'summary': 'Identifying the appropriate regulatory standard applicability remains a\\ncritical yet understudied challenge in medical device compliance, frequently\\nnecessitating expert interpretation of fragmented and heterogeneous\\ndocumentation across different jurisdictions. To address this challenge, we\\nintroduce a modular AI system that leverages a retrieval-augmented generation\\n(RAG) pipeline to automate standard applicability determination. Given a\\nfree-text device description, our system retrieves candidate standards from a\\ncurated corpus and uses large language models to infer jurisdiction-specific\\napplicability, classified as Mandatory, Recommended, or Not Applicable, with\\ntraceable justifications. We construct an international benchmark dataset of\\nmedical device descriptions with expert-annotated standard mappings, and\\nevaluate our system against retrieval-only, zero-shot, and rule-based\\nbaselines. The proposed approach attains a classification accuracy of 73% and a\\nTop-5 retrieval recall of 87%, demonstrating its effectiveness in identifying\\nrelevant regulatory standards. We introduce the first end-to-end system for\\nstandard applicability reasoning, enabling scalable and interpretable\\nAI-supported regulatory science. Notably, our region-aware RAG agent performs\\ncross-jurisdictional reasoning between Chinese and U.S. standards, supporting\\nconflict resolution and applicability justification across regulatory\\nframeworks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.18511v1.pdf'},\n",
       " {'id': '2507.02920v1',\n",
       "  'title': 'Visual-Conversational Interface for Evidence-Based Explanation of\\n  Diabetes Risk Prediction',\n",
       "  'published': '2025-06-25T14:56:20Z',\n",
       "  'summary': \"Healthcare professionals need effective ways to use, understand, and validate\\nAI-driven clinical decision support systems. Existing systems face two key\\nlimitations: complex visualizations and a lack of grounding in scientific\\nevidence. We present an integrated decision support system that combines\\ninteractive visualizations with a conversational agent to explain diabetes risk\\nassessments. We propose a hybrid prompt handling approach combining fine-tuned\\nlanguage models for analytical queries with general Large Language Models\\n(LLMs) for broader medical questions, a methodology for grounding AI\\nexplanations in scientific evidence, and a feature range analysis technique to\\nsupport deeper understanding of feature contributions. We conducted a\\nmixed-methods study with 30 healthcare professionals and found that the\\nconversational interactions helped healthcare professionals build a clear\\nunderstanding of model assessments, while the integration of scientific\\nevidence calibrated trust in the system's decisions. Most participants reported\\nthat the system supported both patient risk evaluation and recommendation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.02920v1.pdf'},\n",
       " {'id': '2507.03409v1',\n",
       "  'title': 'Lessons from a Chimp: AI \"Scheming\" and the Quest for Ape Language',\n",
       "  'published': '2025-07-04T09:16:11Z',\n",
       "  'summary': 'We examine recent research that asks whether current AI systems may be\\ndeveloping a capacity for \"scheming\" (covertly and strategically pursuing\\nmisaligned goals). We compare current research practices in this field to those\\nadopted in the 1970s to test whether non-human primates could master natural\\nlanguage. We argue that there are lessons to be learned from that historical\\nresearch endeavour, which was characterised by an overattribution of human\\ntraits to other agents, an excessive reliance on anecdote and descriptive\\nanalysis, and a failure to articulate a strong theoretical framework for the\\nresearch. We recommend that research into AI scheming actively seeks to avoid\\nthese pitfalls. We outline some concrete steps that can be taken for this\\nresearch programme to advance in a productive and scientifically rigorous\\nfashion.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.03409v1.pdf'},\n",
       " {'id': '2507.10695v1',\n",
       "  'title': 'Exploring User Security and Privacy Attitudes and Concerns Toward the\\n  Use of General-Purpose LLM Chatbots for Mental Health',\n",
       "  'published': '2025-07-14T18:10:21Z',\n",
       "  'summary': 'Individuals are increasingly relying on large language model (LLM)-enabled\\nconversational agents for emotional support. While prior research has examined\\nprivacy and security issues in chatbots specifically designed for mental health\\npurposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not\\nleverage generative AI. Little empirical research currently measures users\\'\\nprivacy and security concerns, attitudes, and expectations when using\\ngeneral-purpose LLM-enabled chatbots to manage and improve mental health.\\nThrough 21 semi-structured interviews with U.S. participants, we identified\\ncritical misconceptions and a general lack of risk awareness. Participants\\nconflated the human-like empathy exhibited by LLMs with human-like\\naccountability and mistakenly believed that their interactions with these\\nchatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures\\nwith a licensed therapist. We introduce the concept of \"intangible\\nvulnerability,\" where emotional or psychological disclosures are undervalued\\ncompared to more tangible forms of information (e.g., financial or\\nlocation-based data). To address this, we propose recommendations to safeguard\\nuser mental health disclosures with general-purpose LLM-enabled chatbots more\\neffectively.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.10695v1.pdf'},\n",
       " {'id': '2507.20670v1',\n",
       "  'title': 'A Multimodal Architecture for Endpoint Position Prediction in Team-based\\n  Multiplayer Games',\n",
       "  'published': '2025-07-28T09:51:49Z',\n",
       "  'summary': 'Understanding and predicting player movement in multiplayer games is crucial\\nfor achieving use cases such as player-mimicking bot navigation, preemptive bot\\ncontrol, strategy recommendation, and real-time player behavior analytics.\\nHowever, the complex environments allow for a high degree of navigational\\nfreedom, and the interactions and team-play between players require models that\\nmake effective use of the available heterogeneous input data. This paper\\npresents a multimodal architecture for predicting future player locations on a\\ndynamic time horizon, using a U-Net-based approach for calculating endpoint\\nlocation probability heatmaps, conditioned using a multimodal feature encoder.\\nThe application of a multi-head attention mechanism for different groups of\\nfeatures allows for communication between agents. In doing so, the architecture\\nmakes efficient use of the multimodal game state including image inputs,\\nnumerical and categorical features, as well as dynamic game data. Consequently,\\nthe presented technique lays the foundation for various downstream tasks that\\nrely on future player positions such as the creation of player-predictive bot\\nbehavior or player anomaly detection.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.20670v1.pdf'},\n",
       " {'id': '2508.19489v1',\n",
       "  'title': \"Interactive Graph Visualization and TeamingRecommendation in an\\n  Interdisciplinary Project'sTalent Knowledge Graph\",\n",
       "  'published': '2025-08-27T00:25:22Z',\n",
       "  'summary': 'Interactive visualization of large scholarly knowledge graphs combined with\\nLLM reasoning shows promise butremains under-explored. We address this gap by\\ndeveloping an interactive visualization system for the Cell Map forAI Talent\\nKnowledge Graph (28,000 experts and 1,179 biomedical datasets). Our approach\\nintegrates WebGLvisualization with LLM agents to overcome limitations of\\ntraditional tools such as Gephi, particularly for large-scaleinteractive node\\nhandling. Key functionalities include responsive exploration, filtering, and\\nAI-drivenrecommendations with justifications. This integration can potentially\\nenable users to effectively identify potentialcollaborators and relevant\\ndataset users within biomedical and AI research communities. The system\\ncontributes anovel framework that enhances knowledge graph exploration through\\nintuitive visualization and transparent, LLM-guided recommendations. This\\nadaptable solution extends beyond the CM4AI community to other large\\nknowledgegraphs, improving information representation and decision-making.\\nDemo: https://cm4aikg.vercel.app/',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.19489v1.pdf'},\n",
       " {'id': '2509.03827v1',\n",
       "  'title': 'What Would an LLM Do? Evaluating Policymaking Capabilities of Large\\n  Language Models',\n",
       "  'published': '2025-09-04T02:28:58Z',\n",
       "  'summary': \"Large language models (LLMs) are increasingly being adopted in high-stakes\\ndomains. Their capacity to process vast amounts of unstructured data, explore\\nflexible scenarios, and handle a diversity of contextual factors can make them\\nuniquely suited to provide new insights for the complexity of social\\npolicymaking. This article evaluates whether LLMs' are aligned with domain\\nexperts (and among themselves) to inform social policymaking on the subject of\\nhomelessness alleviation - a challenge affecting over 150 million people\\nworldwide. We develop a novel benchmark comprised of decision scenarios with\\npolicy choices across four geographies (South Bend, USA; Barcelona, Spain;\\nJohannesburg, South Africa; Macau SAR, China). The policies in scope are\\ngrounded in the conceptual framework of the Capability Approach for human\\ndevelopment. We also present an automated pipeline that connects the\\nbenchmarked policies to an agent-based model, and we explore the social impact\\nof the recommended policies through simulated social scenarios. The paper\\nresults reveal promising potential to leverage LLMs for social policy making.\\nIf responsible guardrails and contextual calibrations are introduced in\\ncollaboration with local domain experts, LLMs can provide humans with valuable\\ninsights, in the form of alternative policies at scale.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.03827v1.pdf'},\n",
       " {'id': '2509.04505v1',\n",
       "  'title': 'The Ethical Compass of the Machine: Evaluating Large Language Models for\\n  Decision Support in Construction Project Management',\n",
       "  'published': '2025-09-02T13:50:36Z',\n",
       "  'summary': 'The integration of Artificial Intelligence (AI) into construction project\\nmanagement (CPM) is accelerating, with Large Language Models (LLMs) emerging as\\naccessible decision-support tools. This study aims to critically evaluate the\\nethical viability and reliability of LLMs when applied to the ethically\\nsensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods\\nresearch design was employed, involving the quantitative performance testing of\\ntwo leading LLMs against twelve real-world ethical scenarios using a novel\\nEthical Decision Support Assessment Checklist (EDSAC), and qualitative analysis\\nof semi-structured interviews with 12 industry experts to capture professional\\nperceptions. The findings reveal that while LLMs demonstrate adequate\\nperformance in structured domains such as legal compliance, they exhibit\\nsignificant deficiencies in handling contextual nuance, ensuring\\naccountability, and providing transparent reasoning. Stakeholders expressed\\nconsiderable reservations regarding the autonomous use of AI for ethical\\njudgments, strongly advocating for robust human-in-the-loop oversight. To our\\nknowledge, this is one of the first studies to empirically test the ethical\\nreasoning of LLMs within the construction domain. It introduces the EDSAC\\nframework as a replicable methodology and provides actionable recommendations,\\nemphasising that LLMs are currently best positioned as decision-support aids\\nrather than autonomous ethical agents.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.04505v1.pdf'},\n",
       " {'id': '2509.07375v2',\n",
       "  'title': 'Towards Post-mortem Data Management Principles for Generative AI',\n",
       "  'published': '2025-09-09T03:50:00Z',\n",
       "  'summary': 'Foundation models, large language models (LLMs), and agentic AI systems rely\\nheavily on vast corpora of user data. The use of such data for training has\\nraised persistent concerns around ownership, copyright, and potential harms. In\\nthis work, we explore a related but less examined dimension: the ownership\\nrights of data belonging to deceased individuals. We examine the current\\nlandscape of post-mortem data management and privacy rights as defined by the\\nprivacy policies of major technology companies and regulations such as the EU\\nAI Act. Based on this analysis, we propose three post-mortem data management\\nprinciples to guide the protection of deceased individuals data rights.\\nFinally, we discuss directions for future work and offer recommendations for\\npolicymakers and privacy practitioners on deploying these principles alongside\\ntechnological solutions to operationalize and audit them in practice.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.07375v2.pdf'},\n",
       " {'id': '1706.03428v2',\n",
       "  'title': 'RARD: The Related-Article Recommendation Dataset',\n",
       "  'published': '2017-06-12T01:00:25Z',\n",
       "  'summary': \"Recommender-system datasets are used for recommender-system evaluations,\\ntraining machine-learning algorithms, and exploring user behavior. While there\\nare many datasets for recommender systems in the domains of movies, books, and\\nmusic, there are rather few datasets from research-paper recommender systems.\\nIn this paper, we introduce RARD, the Related-Article Recommendation Dataset,\\nfrom the digital library Sowiport and the recommendation-as-a-service provider\\nMr. DLib. The dataset contains information about 57.4 million recommendations\\nthat were displayed to the users of Sowiport. Information includes details on\\nwhich recommendation approaches were used (e.g. content-based filtering,\\nstereotype, most popular), what types of features were used in content based\\nfiltering (simple terms vs. keyphrases), where the features were extracted from\\n(title or abstract), and the time when recommendations were delivered and\\nclicked. In addition, the dataset contains an implicit item-item rating matrix\\nthat was created based on the recommendation click logs. RARD enables\\nresearchers to train machine learning algorithms for research-paper\\nrecommendations, perform offline evaluations, and do research on data from Mr.\\nDLib's recommender system, without implementing a recommender system\\nthemselves. In the field of scientific recommender systems, our dataset is\\nunique. To the best of our knowledge, there is no dataset with more (implicit)\\nratings available, and that many variations of recommendation algorithms. The\\ndataset is available at http://data.mr-dlib.org, and published under the\\nCreative Commons Attribution 3.0 Unported (CC-BY) license.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1706.03428v2.pdf'},\n",
       " {'id': '2012.02360v2',\n",
       "  'title': 'Research Progress of News Recommendation Methods',\n",
       "  'published': '2020-12-04T01:47:24Z',\n",
       "  'summary': \"Due to researchers'aim to study personalized recommendations for different\\nbusiness fields, the summary of recommendation methods in specific fields is of\\npractical significance. News recommendation systems were the earliest research\\nfield regarding recommendation systems, and were also the earliest\\nrecommendation field to apply the collaborative filtering method. In addition,\\nnews is real-time and rich in content, which makes news recommendation methods\\nmore challenging than in other fields. Thus, this paper summarizes the research\\nprogress regarding news recommendation methods. From 2018 to 2020, developed\\nnews recommendation methods were mainly deep learning-based, attention-based,\\nand knowledge graphs-based. As of 2020, there are many news recommendation\\nmethods that combine attention mechanisms and knowledge graphs. However, these\\nmethods were all developed based on basic methods (the collaborative filtering\\nmethod, the content-based recommendation method, and a mixed recommendation\\nmethod combining the two). In order to allow researchers to have a detailed\\nunderstanding of the development process of news recommendation methods, the\\nnews recommendation methods surveyed in this paper, which cover nearly 10\\nyears, are divided into three categories according to the abovementioned basic\\nmethods. Firstly, the paper introduces the basic ideas of each category of\\nmethods and then summarizes the recommendation methods that are combined with\\nother methods based on each category of methods and according to the time\\nsequence of research results. Finally, this paper also summarizes the\\nchallenges confronting news recommendation systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.02360v2.pdf'},\n",
       " {'id': '2204.00539v1',\n",
       "  'title': 'End-to-end Learnable Diversity-aware News Recommendation',\n",
       "  'published': '2022-04-01T16:02:28Z',\n",
       "  'summary': 'Diversity is an important factor in providing high-quality personalized news\\nrecommendations. However, most existing news recommendation methods only aim to\\noptimize recommendation accuracy while ignoring diversity. Reranking is a\\nwidely used post-processing technique to promote the diversity of top\\nrecommendation results. However, the recommendation model is not perfect and\\nerrors may be propagated and amplified in a cascaded recommendation algorithm.\\nIn addition, the recommendation model itself is not diversity-aware, making it\\ndifficult to achieve a good tradeoff between recommendation accuracy and\\ndiversity. In this paper, we propose a news recommendation approach named\\nLeaDivRec, which is a fully learnable model that can generate diversity-aware\\nnews recommendations in an end-to-end manner. Different from existing news\\nrecommendation methods that are usually based on point- or pair-wise ranking,\\nin LeaDivRec we propose a more effective list-wise news recommendation model.\\nMore specifically, we propose a permutation Transformer to consider the\\nrelatedness between candidate news and meanwhile can learn different\\nrepresentations for similar candidate news to help improve recommendation\\ndiversity. We also propose an effective list-wise training method to learn\\naccurate ranking models. In addition, we propose a diversity-aware\\nregularization method to further encourage the model to make controllable\\ndiversity-aware recommendations. Extensive experiments on two real-world\\ndatasets validate the effectiveness of our approach in balancing recommendation\\naccuracy and diversity.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2204.00539v1.pdf'},\n",
       " {'id': '2205.08954v1',\n",
       "  'title': \"One-way Explainability Isn't The Message\",\n",
       "  'published': '2022-05-05T09:15:53Z',\n",
       "  'summary': \"Recent engineering developments in specialised computational hardware,\\ndata-acquisition and storage technology have seen the emergence of Machine\\nLearning (ML) as a powerful form of data analysis with widespread applicability\\nbeyond its historical roots in the design of autonomous agents. However --\\npossibly because of its origins in the development of agents capable of\\nself-discovery -- relatively little attention has been paid to the interaction\\nbetween people and ML. In this paper we are concerned with the use of ML in\\nautomated or semi-automated tools that assist one or more human decision\\nmakers. We argue that requirements on both human and machine in this context\\nare significantly different to the use of ML either as part of autonomous\\nagents for self-discovery or as part statistical data analysis. Our principal\\nposition is that the design of such human-machine systems should be driven by\\nrepeated, two-way intelligibility of information rather than one-way\\nexplainability of the ML-system's recommendations. Iterated rounds of\\nintelligible information exchange, we think, will characterise the kinds of\\ncollaboration that will be needed to understand complex phenomena for which\\nneither man or machine have complete answers. We propose operational principles\\n-- we call them Intelligibility Axioms -- to guide the design of a\\ncollaborative decision-support system. The principles are concerned with: (a)\\nwhat it means for information provided by the human to be intelligible to the\\nML system; and (b) what it means for an explanation provided by an ML system to\\nbe intelligible to a human. Using examples from the literature on the use of ML\\nfor drug-design and in medicine, we demonstrate cases where the conditions of\\nthe axioms are met. We describe some additional requirements needed for the\\ndesign of a truly collaborative decision-support system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.08954v1.pdf'},\n",
       " {'id': '2404.04667v1',\n",
       "  'title': 'Autonomous Artificial Intelligence Agents for Clinical Decision Making\\n  in Oncology',\n",
       "  'published': '2024-04-06T15:50:19Z',\n",
       "  'summary': 'Multimodal artificial intelligence (AI) systems have the potential to enhance\\nclinical decision-making by interpreting various types of medical data.\\nHowever, the effectiveness of these models across all medical fields is\\nuncertain. Each discipline presents unique challenges that need to be addressed\\nfor optimal performance. This complexity is further increased when attempting\\nto integrate different fields into a single model. Here, we introduce an\\nalternative approach to multimodal medical AI that utilizes the generalist\\ncapabilities of a large language model (LLM) as a central reasoning engine.\\nThis engine autonomously coordinates and deploys a set of specialized medical\\nAI tools. These tools include text, radiology and histopathology image\\ninterpretation, genomic data processing, web searches, and document retrieval\\nfrom medical guidelines. We validate our system across a series of clinical\\noncology scenarios that closely resemble typical patient care workflows. We\\nshow that the system has a high capability in employing appropriate tools\\n(97%), drawing correct conclusions (93.6%), and providing complete (94%), and\\nhelpful (89.2%) recommendations for individual patient cases while consistently\\nreferencing relevant literature (82.5%) upon instruction. This work provides\\nevidence that LLMs can effectively plan and execute domain-specific models to\\nretrieve or synthesize new information when used as autonomous agents. This\\nenables them to function as specialist, patient-tailored clinical assistants.\\nIt also simplifies regulatory compliance by allowing each component tool to be\\nindividually validated and approved. We believe, that our work can serve as a\\nproof-of-concept for more advanced LLM-agents in the medical domain.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2404.04667v1.pdf'},\n",
       " {'id': '1704.00393v1',\n",
       "  'title': 'Exploring Choice Overload in Related-Article Recommendations in Digital\\n  Libraries',\n",
       "  'published': '2017-04-03T00:30:25Z',\n",
       "  'summary': \"We investigate the problem of choice overload - the difficulty of making a\\ndecision when faced with many options - when displaying related-article\\nrecommendations in digital libraries. So far, research regarding to how many\\nitems should be displayed has mostly been done in the fields of media\\nrecommendations and search engines. We analyze the number of recommendations in\\ncurrent digital libraries. When browsing fullscreen with a laptop or desktop\\nPC, all display a fixed number of recommendations. 72% display three, four, or\\nfive recommendations, none display more than ten. We provide results from an\\nempirical evaluation conducted with GESIS' digital library Sowiport, with\\nrecommendations delivered by recommendations-as-a-service provider Mr. DLib. We\\nuse click-through rate as a measure of recommendation effectiveness based on\\n3.4 million delivered recommendations. Our results show lower click-through\\nrates for higher numbers of recommendations and twice as many clicked\\nrecommendations when displaying ten instead of one related-articles. Our\\nresults indicate that users might quickly feel overloaded by choice.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1704.00393v1.pdf'},\n",
       " {'id': '1908.04017v2',\n",
       "  'title': 'Using the Open Meta Kaggle Dataset to Evaluate Tripartite\\n  Recommendations in Data Markets',\n",
       "  'published': '2019-08-12T06:15:44Z',\n",
       "  'summary': 'This work addresses the problem of providing and evaluating recommendations\\nin data markets. Since most of the research in recommender systems is focused\\non the bipartite relationship between users and items (e.g., movies), we extend\\nthis view to the tripartite relationship between users, datasets and services,\\nwhich is present in data markets. Between these entities, we identify four use\\ncases for recommendations: (i) recommendation of datasets for users, (ii)\\nrecommendation of services for users, (iii) recommendation of services for\\ndatasets, and (iv) recommendation of datasets for services. Using the open Meta\\nKaggle dataset, we evaluate the recommendation accuracy of a popularity-based\\nas well as a collaborative filtering-based algorithm for these four use cases\\nand find that the recommendation accuracy strongly depends on the given use\\ncase. The presented work contributes to the tripartite recommendation problem\\nin general and to the under-researched portfolio of evaluating recommender\\nsystems for data markets in particular.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1908.04017v2.pdf'},\n",
       " {'id': '2012.02292v1',\n",
       "  'title': 'FAST: A Fairness Assured Service Recommendation Strategy Considering\\n  Service Capacity Constraint',\n",
       "  'published': '2020-12-02T12:21:31Z',\n",
       "  'summary': 'An excessive number of customers often leads to a degradation in service\\nquality. However, the capacity constraints of services are ignored by\\nrecommender systems, which may lead to unsatisfactory recommendation. This\\nproblem can be solved by limiting the number of users who receive the\\nrecommendation for a service, but this may be viewed as unfair. In this paper,\\nwe propose a novel metric Top-N Fairness to measure the individual fairness of\\nmulti-round recommendations of services with capacity constraints. By\\nconsidering the fact that users are often only affected by top-ranked items in\\na recommendation, Top-N Fairness only considers a sub-list consisting of top N\\nservices. Based on the metric, we design FAST, a Fairness Assured service\\nrecommendation STrategy. FAST adjusts the original recommendation list to\\nprovide users with recommendation results that guarantee the long-term fairness\\nof multi-round recommendations. We prove the convergence property of the\\nvariance of Top-N Fairness of FAST theoretically. FAST is tested on the Yelp\\ndataset and synthetic datasets. The experimental results show that FAST\\nachieves better recommendation fairness while still maintaining high\\nrecommendation quality.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.02292v1.pdf'},\n",
       " {'id': '1303.7149v2',\n",
       "  'title': 'Usage-based vs. Citation-based Methods for Recommending Scholarly\\n  Research Articles',\n",
       "  'published': '2013-03-28T15:27:16Z',\n",
       "  'summary': 'There are two principal data sources for collaborative filtering recommenders\\nin scholarly digital libraries: usage data obtained from harvesting a large,\\ndistributed collection of Open URL web logs and citation data obtained from the\\njournal articles. This study explores the characteristics of recommendations\\ngenerated by implementations of these two methods: the \\'bX\\' system by ExLibris\\nand an experimental citation-based recommender, Sarkanto. Recommendations from\\neach system were compared according to their semantic similarity to the seed\\narticle that was used to generate them. Since the full text of the articles was\\nnot available for all the recommendations in both systems, the semantic\\nsimilarity between the seed article and the recommended articles was deemed to\\nbe the semantic distance between the journals in which the articles were\\npublished. The semantic distance between journals was computed from the\\n\"semantic vectors\" distance between all the terms in the full-text of the\\navailable articles in that journal and this study shows that citation-based\\nrecommendations are more semantically diverse than usage-based ones. These\\nrecommenders are complementary since most of the time, when one recommender\\nproduces recommendations the other does not.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1303.7149v2.pdf'},\n",
       " {'id': '2005.01148v1',\n",
       "  'title': 'FairMatch: A Graph-based Approach for Improving Aggregate Diversity in\\n  Recommender Systems',\n",
       "  'published': '2020-05-03T17:21:31Z',\n",
       "  'summary': \"Recommender systems are often biased toward popular items. In other words,\\nfew items are frequently recommended while the majority of items do not get\\nproportionate attention. That leads to low coverage of items in recommendation\\nlists across users (i.e. low aggregate diversity) and unfair distribution of\\nrecommended items. In this paper, we introduce FairMatch, a general graph-based\\nalgorithm that works as a post-processing approach after recommendation\\ngeneration for improving aggregate diversity. The algorithm iteratively finds\\nitems that are rarely recommended yet are high-quality and add them to the\\nusers' final recommendation lists. This is done by solving the maximum flow\\nproblem on the recommendation bipartite graph. While we focus on aggregate\\ndiversity and fair distribution of recommended items, the algorithm can be\\nadapted to other recommendation scenarios using different underlying\\ndefinitions of fairness. A comprehensive set of experiments on two datasets and\\ncomparison with state-of-the-art baselines show that FairMatch, while\\nsignificantly improving aggregate diversity, provides comparable recommendation\\naccuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.01148v1.pdf'},\n",
       " {'id': '2009.14306v2',\n",
       "  'title': 'INSPIRED: Toward Sociable Recommendation Dialog Systems',\n",
       "  'published': '2020-09-29T21:03:44Z',\n",
       "  'summary': 'In recommendation dialogs, humans commonly disclose their preference and make\\nrecommendations in a friendly manner. However, this is a challenge when\\ndeveloping a sociable recommendation dialog system, due to the lack of dialog\\ndataset annotated with such sociable strategies. Therefore, we present\\nINSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation\\nwith measures for successful recommendations. To better understand how humans\\nmake recommendations in communication, we design an annotation scheme related\\nto recommendation strategies based on social science theories and annotate\\nthese dialogs. Our analysis shows that sociable recommendation strategies, such\\nas sharing personal opinions or communicating with encouragement, more\\nfrequently lead to successful recommendations. Based on our dataset, we train\\nend-to-end recommendation dialog systems with and without our strategy labels.\\nIn both automatic and human evaluation, our model with strategy incorporation\\noutperforms the baseline model. This work is a first step for building sociable\\nrecommendation dialog systems with a basis of social science theories.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2009.14306v2.pdf'},\n",
       " {'id': '2105.01269v1',\n",
       "  'title': 'Semantic Modeling for Food Recommendation Explanations',\n",
       "  'published': '2021-05-04T03:25:36Z',\n",
       "  'summary': \"With the increased use of AI methods to provide recommendations in the\\nhealth, specifically in the food dietary recommendation space, there is also an\\nincreased need for explainability of those recommendations. Such explanations\\nwould benefit users of recommendation systems by empowering them with\\njustifications for following the system's suggestions. We present the Food\\nExplanation Ontology (FEO) that provides a formalism for modeling explanations\\nto users for food-related recommendations. FEO models food recommendations,\\nusing concepts from the explanation domain to create responses to user\\nquestions about food recommendations they receive from AI systems such as\\npersonalized knowledge base question answering systems. FEO uses a modular,\\nextensible structure that lends itself to a variety of explanations while still\\npreserving important semantic details to accurately represent explanations of\\nfood recommendations. In order to evaluate this system, we used a set of\\ncompetency questions derived from explanation types present in literature that\\nare relevant to food recommendations. Our motivation with the use of FEO is to\\nempower users to make decisions about their health, fully equipped with an\\nunderstanding of the AI recommender systems as they relate to user questions,\\nby providing reasoning behind their recommendations in the form of\\nexplanations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.01269v1.pdf'},\n",
       " {'id': '2105.12876v2',\n",
       "  'title': 'A Hybrid Recommender System for Recommending Smartphones to Prospective\\n  Customers',\n",
       "  'published': '2021-05-26T23:10:51Z',\n",
       "  'summary': 'Recommender Systems are a subclass of machine learning systems that employ\\nsophisticated information filtering strategies to reduce the search time and\\nsuggest the most relevant items to any particular user. Hybrid recommender\\nsystems combine multiple recommendation strategies in different ways to benefit\\nfrom their complementary advantages. Some hybrid recommender systems have\\ncombined collaborative filtering and content-based approaches to build systems\\nthat are more robust. In this paper, we propose a hybrid recommender system,\\nwhich combines Alternating Least Squares (ALS) based collaborative filtering\\nwith deep learning to enhance recommendation performance as well as overcome\\nthe limitations associated with the collaborative filtering approach,\\nespecially concerning its cold start problem. In essence, we use the outputs\\nfrom ALS (collaborative filtering) to influence the recommendations from a Deep\\nNeural Network (DNN), which combines characteristic, contextual, structural and\\nsequential information, in a big data processing framework. We have conducted\\nseveral experiments in testing the efficacy of the proposed hybrid architecture\\nin recommending smartphones to prospective customers and compared its\\nperformance with other open-source recommenders. The results have shown that\\nthe proposed system has outperformed several existing hybrid recommender\\nsystems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.12876v2.pdf'},\n",
       " {'id': '2211.01328v1',\n",
       "  'title': 'Diversely Regularized Matrix Factorization for Accurate and Aggregately\\n  Diversified Recommendation',\n",
       "  'published': '2022-10-19T08:49:39Z',\n",
       "  'summary': 'When recommending personalized top-$k$ items to users, how can we recommend\\nthe items diversely to them while satisfying their needs? Aggregately\\ndiversified recommender systems aim to recommend a variety of items across\\nwhole users without sacrificing the recommendation accuracy. They increase the\\nexposure opportunities of various items, which in turn increase potential\\nrevenue of sellers as well as user satisfaction. However, it is challenging to\\ntackle aggregate-level diversity with a matrix factorization (MF), one of the\\nmost common recommendation model, since skewed real world data lead to skewed\\nrecommendation results of MF. In this work, we propose DivMF (Diversely\\nRegularized Matrix Factorization), a novel matrix factorization method for\\naggregately diversified recommendation. DivMF regularizes a score matrix of an\\nMF model to maximize coverage and entropy of top-$k$ recommendation lists to\\naggregately diversify the recommendation results. We also propose an unmasking\\nmechanism and carefully designed mi i-batch learning technique for accurate and\\nefficient training. Extensive experiments on real-world datasets show that\\nDivMF achieves the state-of-the-art performance in aggregately diversified\\nrecommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.01328v1.pdf'},\n",
       " {'id': '2303.14263v2',\n",
       "  'title': 'The Effect of Product Recommendations on Online Investor Behaviors',\n",
       "  'published': '2023-03-24T20:19:43Z',\n",
       "  'summary': \"Despite the popularity of product recommendations on online investment\\nplatforms, few studies have explored their impact on investor behaviors. Using\\ndata from a global e-commerce platform, we apply regression discontinuity\\ndesign to causally examine the effects of product recommendations on online\\ninvestors' mutual fund investments. Our findings indicate that recommended\\nfunds experience a significant rise in purchases, especially among low\\nsocioeconomic status investors who are most influenced by these\\nrecommendations. However, investors tend to suffer significantly worse\\ninvestment returns after purchasing recommended funds, and this negative impact\\nis also most significant for investors with low socioeconomic status. To\\nexplain this disparity, we find investors tend to gather less information and\\nexpend reduced effort in fund research when buying recommended funds.\\nFurthermore, investors' redemption timing of recommended funds is less optimal\\nthan non-recommended funds. We also find that recommended funds experience a\\nlarger return reversal than non-recommended funds. In conclusion, product\\nrecommendations make investors behave more irrationally and these negative\\nconsequences are most significant for investors with low socioeconomic status,\\nwhich can amplify wealth inequality among investors in financial markets.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2303.14263v2.pdf'},\n",
       " {'id': '2309.05273v2',\n",
       "  'title': 'Formalizing Multimedia Recommendation through Multimodal Deep Learning',\n",
       "  'published': '2023-09-11T07:12:17Z',\n",
       "  'summary': 'Recommender systems (RSs) offer personalized navigation experiences on online\\nplatforms, but recommendation remains a challenging task, particularly in\\nspecific scenarios and domains. Multimodality can help tap into richer\\ninformation sources and construct more refined user/item profiles for\\nrecommendations. However, existing literature lacks a shared and universal\\nschema for modeling and solving the recommendation problem through the lens of\\nmultimodality. This work aims to formalize a general multimodal schema for\\nmultimedia recommendation. It provides a comprehensive literature review of\\nmultimodal approaches for multimedia recommendation from the last eight years,\\noutlines the theoretical foundations of a multimodal pipeline, and demonstrates\\nits rationale by applying it to selected state-of-the-art approaches. The work\\nalso conducts a benchmarking analysis of recent algorithms for multimedia\\nrecommendation within Elliot, a rigorous framework for evaluating recommender\\nsystems. The main aim is to provide guidelines for designing and implementing\\nthe next generation of multimodal approaches in multimedia recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.05273v2.pdf'},\n",
       " {'id': '2310.20189v2',\n",
       "  'title': 'LFG: A Generative Network for Real-Time Recommendation',\n",
       "  'published': '2023-10-31T05:16:54Z',\n",
       "  'summary': 'Recommender systems are essential information technologies today, and\\nrecommendation algorithms combined with deep learning have become a research\\nhotspot in this field. The recommendation model known as LFM (Latent Factor\\nModel), which captures latent features through matrix factorization and\\ngradient descent to fit user preferences, has given rise to various\\nrecommendation algorithms that bring new improvements in recommendation\\naccuracy. However, collaborative filtering recommendation models based on LFM\\nlack flexibility and has shortcomings for real-time recommendations, as they\\nneed to redo the matrix factorization and retrain using gradient descent when\\nnew users arrive. In response to this, this paper innovatively proposes a\\nLatent Factor Generator (LFG) network, and set the movie recommendation as\\nresearch theme. The LFG dynamically generates user latent factors through deep\\nneural networks without the need for re-factorization or retrain. Experimental\\nresults indicate that the LFG recommendation model outperforms traditional\\nmatrix factorization algorithms in recommendation accuracy, providing an\\neffective solution to the challenges of real-time recommendations with LFM.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2310.20189v2.pdf'},\n",
       " {'id': '2408.06201v1',\n",
       "  'title': 'Investigating Characteristics of Media Recommendation Solicitation in\\n  r/ifyoulikeblank',\n",
       "  'published': '2024-08-12T14:50:04Z',\n",
       "  'summary': \"Despite the existence of search-based recommender systems like Google,\\nNetflix, and Spotify, online users sometimes may turn to crowdsourced\\nrecommendations in places like the r/ifyoulikeblank subreddit. In this\\nexploratory study, we probe why users go to r/ifyoulikeblank, how they look for\\nrecommendation, and how the subreddit users respond to recommendation requests.\\nTo answer, we collected sample posts from r/ifyoulikeblank and analyzed them\\nusing a qualitative approach. Our analysis reveals that users come to this\\nsubreddit for various reasons, such as exhausting popular search systems, not\\nknowing what or how to search for an item, and thinking crowd have better\\nknowledge than search systems. Examining users query and their description, we\\nfound novel information users provide during recommendation seeking using\\nr/ifyoulikeblank. For example, sometimes they ask for artifacts recommendation\\nbased on the tools used to create them. Or, sometimes indicating a\\nrecommendation seeker's time constraints can help better suit recommendations\\nto their needs. Finally, recommendation responses and interactions revealed\\npatterns of how requesters and responders refine queries and recommendations.\\nOur work informs future intelligent recommender systems design.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.06201v1.pdf'},\n",
       " {'id': '2504.05323v1',\n",
       "  'title': 'Multi-Perspective Attention Mechanism for Bias-Aware Sequential\\n  Recommendation',\n",
       "  'published': '2025-02-26T14:16:58Z',\n",
       "  'summary': \"In the era of advancing information technology, recommender systems have\\nemerged as crucial tools for dealing with information overload. However,\\ntraditional recommender systems still have limitations in capturing the dynamic\\nevolution of user behavior. To better understand and predict user behavior,\\nespecially taking into account the complexity of temporal evolution, sequential\\nrecommender systems have gradually become the focus of research. Currently,\\nmany sequential recommendation algorithms ignore the amplification effects of\\nprevalent biases, which leads to recommendation results being susceptible to\\nthe Matthew Effect. Additionally, it will impose limitations on the recommender\\nsystem's ability to deeply perceive and capture the dynamic shifts in user\\npreferences, thereby diminishing the extent of its recommendation reach. To\\naddress this issue effectively, we propose a recommendation system based on\\nsequential information and attention mechanism called Multi-Perspective\\nAttention Bias Sequential Recommendation (MABSRec). Firstly, we reconstruct\\nuser sequences into three short types and utilize graph neural networks for\\nitem weighting. Subsequently, an adaptive multi-bias perspective attention\\nmodule is proposed to enhance the accuracy of recommendations. Experimental\\nresults show that the MABSRec model exhibits significant advantages in all\\nevaluation metrics, demonstrating its excellent performance in the sequence\\nrecommendation task.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.05323v1.pdf'},\n",
       " {'id': '0911.1619v1',\n",
       "  'title': 'On the Pricing of Recommendations and Recommending Strategically',\n",
       "  'published': '2009-11-09T10:21:42Z',\n",
       "  'summary': 'If you recommend a product to me and I buy it, how much should you be paid by\\nthe seller? And if your sole interest is to maximize the amount paid to you by\\nthe seller for a sequence of recommendations, how should you recommend\\noptimally if I become more inclined to ignore you with each irrelevant\\nrecommendation you make? Finding an answer to these questions is a key\\nchallenge in all forms of marketing that rely on and explore social ties;\\nranging from personal recommendations to viral marketing.\\n  In the first part of this paper, we show that there can be no pricing\\nmechanism that is \"truthful\" with respect to the seller, and we use solution\\nconcepts from coalitional game theory, namely the Core, the Shapley Value, and\\nthe Nash Bargaining Solution, to derive provably \"fair\" prices for settings\\nwith one or multiple recommenders. We then investigate pricing mechanisms for\\nthe setting where recommenders have different \"purchase arguments\". Here we\\nshow that it might be beneficial for the recommenders to withhold some of their\\narguments, unless anonymity-proof solution concepts, such as the\\nanonymity-proof Shapley value, are used.\\n  In the second part of this paper, we analyze the setting where the\\nrecommendee loses trust in the recommender for each irrelevant recommendation.\\nHere we prove that even if the recommendee regains her initial trust on each\\nsuccessful recommendation, the expected total profit the recommender can make\\nover an infinite period is bounded. This can only be overcome when the\\nrecommendee also incrementally regains trust during periods without any\\nrecommendation. Here, we see an interesting connection to \"banner blindness\",\\nsuggesting that showing fewer ads can lead to a higher long-term profit.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/0911.1619v1.pdf'},\n",
       " {'id': '1512.06840v2',\n",
       "  'title': 'Utility-based Link Recommendation for Online Social Networks',\n",
       "  'published': '2015-12-21T20:58:44Z',\n",
       "  'summary': 'Link recommendation, which suggests links to connect currently unlinked\\nusers, is a key functionality offered by major online social networks. Salient\\nexamples of link recommendation include \"People You May Know\" on Facebook and\\nLinkedIn as well as \"You May Know\" on Google+. The main stakeholders of an\\nonline social network include users (e.g., Facebook users) who use the network\\nto socialize with other users and an operator (e.g., Facebook Inc.) that\\nestablishes and operates the network for its own benefit (e.g., revenue).\\nExisting link recommendation methods recommend links that are likely to be\\nestablished by users but overlook the benefit a recommended link could bring to\\nan operator. To address this gap, we define the utility of recommending a link\\nand formulate a new research problem - the utility-based link recommendation\\nproblem. We then propose a novel utility-based link recommendation method that\\nrecommends links based on the value, cost, and linkage likelihood of a link, in\\ncontrast to existing link recommendation methods which focus solely on linkage\\nlikelihood. Specifically, our method models the dependency relationship between\\nvalue, cost, linkage likelihood and utility-based link recommendation decision\\nusing a Bayesian network, predicts the probability of recommending a link with\\nthe Bayesian network, and recommends links with the highest probabilities.\\nUsing data obtained from a major U.S. online social network, we demonstrate\\nsignificant performance improvement achieved by our method compared to\\nprevalent link recommendation methods from representative prior research.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1512.06840v2.pdf'},\n",
       " {'id': '2208.09864v1',\n",
       "  'title': 'Towards Principled User-side Recommender Systems',\n",
       "  'published': '2022-08-21T10:57:40Z',\n",
       "  'summary': \"Traditionally, recommendation algorithms have been designed for service\\ndevelopers. However, recently, a new paradigm called user-side recommender\\nsystems has been proposed and they enable web service users to construct their\\nown recommender systems without access to trade-secret data. This approach\\nopens the door to user-defined fair systems even if the official recommender\\nsystem of the service is not fair. While existing methods for user-side\\nrecommender systems have addressed the challenging problem of building\\nrecommender systems without using log data, they rely on heuristic approaches,\\nand it is still unclear whether constructing user-side recommender systems is a\\nwell-defined problem from theoretical point of view. In this paper, we provide\\ntheoretical justification of user-side recommender systems. Specifically, we\\nsee that hidden item features can be recovered from the information available\\nto the user, making the construction of user-side recommender system\\nwell-defined. However, this theoretically grounded approach is not efficient.\\nTo realize practical yet theoretically sound recommender systems, we propose\\nthree desirable properties of user-side recommender systems and propose an\\neffective and efficient user-side recommender system, \\\\textsc{Consul}, based on\\nthese foundations. We prove that \\\\textsc{Consul} satisfies all three\\nproperties, whereas existing user-side recommender systems lack at least one of\\nthem. In the experiments, we empirically validate the theory of feature\\nrecovery via numerical experiments. We also show that our proposed method\\nachieves an excellent trade-off between effectiveness and efficiency and\\ndemonstrate via case studies that the proposed method can retrieve information\\nthat the provider's official recommender system cannot.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.09864v1.pdf'},\n",
       " {'id': '2504.11000v1',\n",
       "  'title': 'Why am I seeing this? Towards recognizing social media recommender\\n  systems with missing recommendations',\n",
       "  'published': '2025-04-15T09:16:17Z',\n",
       "  'summary': 'Social media plays a crucial role in shaping society, often amplifying\\npolarization and spreading misinformation. These effects stem from complex\\ndynamics involving user interactions, individual traits, and recommender\\nalgorithms driving content selection. Recommender systems, which significantly\\nshape the content users see and decisions they make, offer an opportunity for\\nintervention and regulation. However, assessing their impact is challenging due\\nto algorithmic opacity and limited data availability. To effectively model user\\ndecision-making, it is crucial to recognize the recommender system adopted by\\nthe platform.\\n  This work introduces a method for Automatic Recommender Recognition using\\nGraph Neural Networks (GNNs), based solely on network structure and observed\\nbehavior. To infer the hidden recommender, we first train a Recommender Neutral\\nUser model (RNU) using a GNN and an adapted hindsight academic network\\nrecommender, aiming to reduce reliance on the actual recommender in the data.\\nWe then generate several Recommender Hypothesis-specific Synthetic Datasets\\n(RHSD) by combining the RNU with different known recommenders, producing ground\\ntruths for testing. Finally, we train Recommender Hypothesis-specific User\\nmodels (RHU) under various hypotheses and compare each candidate with the\\noriginal used to generate the RHSD.\\n  Our approach enables accurate detection of hidden recommenders and their\\ninfluence on user behavior. Unlike audit-based methods, it captures system\\nbehavior directly, without ad hoc experiments that often fail to reflect real\\nplatforms. This study provides insights into how recommenders shape behavior,\\naiding efforts to reduce polarization and misinformation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2504.11000v1.pdf'},\n",
       " {'id': '1011.2245v1',\n",
       "  'title': 'A Distributed Method for Trust-Aware Recommendation in Social Networks',\n",
       "  'published': '2010-11-10T01:05:12Z',\n",
       "  'summary': 'This paper contains the details of a distributed trust-aware recommendation\\nsystem. Trust-base recommenders have received a lot of attention recently. The\\nmain aim of trust-based recommendation is to deal the problems in traditional\\nCollaborative Filtering recommenders. These problems include cold start users,\\nvulnerability to attacks, etc.. Our proposed method is a distributed approach\\nand can be easily deployed on social networks or real life networks such as\\nsensor networks or peer to peer networks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1011.2245v1.pdf'},\n",
       " {'id': '1701.00199v1',\n",
       "  'title': 'Interactive Movie Recommendation Through Latent Semantic Analysis and\\n  Storytelling',\n",
       "  'published': '2017-01-01T04:52:37Z',\n",
       "  'summary': 'Recommendation has become one of the most important components of online\\nservices for improving sale records, however visualization work for online\\nrecommendation is still very limited. This paper presents an interactive\\nrecommendation approach with the following two components. First, rating\\nrecords are the most widely used data for online recommendation, but they are\\noften processed in high-dimensional spaces that can not be easily understood or\\ninteracted with. We propose a Latent Semantic Model (LSM) that captures the\\nstatistical features of semantic concepts on 2D domains and abstracts user\\npreferences for personal recommendation. Second, we propose an interactive\\nrecommendation approach through a storytelling mechanism for promoting the\\ncommunication between the user and the recommendation system. Our approach\\nemphasizes interactivity, explicit user input, and semantic information convey;\\nthus it can be used by general users without any knowledge of recommendation or\\nvisualization algorithms. We validate our model with data statistics and\\ndemonstrate our approach with case studies from the MovieLens100K dataset. Our\\napproaches of latent semantic analysis and interactive recommendation can also\\nbe extended to other network-based visualization applications, including\\nvarious online recommendation systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1701.00199v1.pdf'},\n",
       " {'id': '1811.02217v1',\n",
       "  'title': 'A Scalable Algorithm for Privacy-Preserving Item-based Top-N\\n  Recommendation',\n",
       "  'published': '2018-11-06T08:34:39Z',\n",
       "  'summary': \"Recommender systems have become an indispensable component in online services\\nduring recent years. Effective recommendation is essential for improving the\\nservices of various online business applications. However, serious privacy\\nconcerns have been raised on recommender systems requiring the collection of\\nusers' private information for recommendation. At the same time, the success of\\ne-commerce has generated massive amounts of information, making scalability a\\nkey challenge in the design of recommender systems. As such, it is desirable\\nfor recommender systems to protect users' privacy while achieving high-quality\\nrecommendations with low-complexity computations.\\n  This paper proposes a scalable privacy-preserving item-based top-N\\nrecommendation solution, which can achieve high-quality recommendations with\\nreduced computation complexity while ensuring that users' private information\\nis protected. Furthermore, the computation complexity of the proposed method\\nincreases slowly as the number of users increases, thus providing high\\nscalability for privacy-preserving recommender systems. More specifically, the\\nproposed approach consists of two key components: (1) MinHash-based similarity\\nestimation and (2) client-side privacy-preserving prediction generation. Our\\ntheoretical and experimental analysis using real-world data demonstrates the\\nefficiency and effectiveness of the proposed approach.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.02217v1.pdf'},\n",
       " {'id': '2108.03357v2',\n",
       "  'title': 'A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future\\n  Directions',\n",
       "  'published': '2021-08-07T03:26:16Z',\n",
       "  'summary': 'Traditional recommendation systems are faced with two long-standing\\nobstacles, namely, data sparsity and cold-start problems, which promote the\\nemergence and development of Cross-Domain Recommendation (CDR). The core idea\\nof CDR is to leverage information collected from other domains to alleviate the\\ntwo problems in one domain. Over the last decade, many efforts have been\\nengaged for cross-domain recommendation. Recently, with the development of deep\\nlearning and neural networks, a large number of methods have emerged. However,\\nthere is a limited number of systematic surveys on CDR, especially regarding\\nthe latest proposed methods as well as the recommendation scenarios and\\nrecommendation tasks they address. In this survey paper, we first proposed a\\ntwo-level taxonomy of cross-domain recommendation which classifies different\\nrecommendation scenarios and recommendation tasks. We then introduce and\\nsummarize existing cross-domain recommendation approaches under different\\nrecommendation scenarios in a structured manner. We also organize datasets\\ncommonly used. We conclude this survey by providing several potential research\\ndirections about this field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2108.03357v2.pdf'},\n",
       " {'id': '1805.02276v1',\n",
       "  'title': 'Mobile recommender systems: Identifying the major concepts',\n",
       "  'published': '2018-05-06T20:46:55Z',\n",
       "  'summary': 'This paper identifies the factors that have an impact on mobile recommender\\nsystems. Recommender systems have become a technology that has been widely used\\nby various online applications in situations where there is an information\\noverload problem. Numerous applications such as e-Commerce, video platforms and\\nsocial networks provide personalized recommendations to their users and this\\nhas improved the user experience and vendor revenues. The development of\\nrecommender systems has been focused mostly on the proposal of new algorithms\\nthat provide more accurate recommendations. However, the use of mobile devices\\nand the rapid growth of the internet and networking infrastructure has brought\\nthe necessity of using mobile recommender systems. The links between web and\\nmobile recommender systems are described along with how the recommendations in\\nmobile environments can be improved. This work is focused on identifying the\\nlinks between web and mobile recommender systems and to provide solid future\\ndirections that aim to lead in a more integrated mobile recommendation domain.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1805.02276v1.pdf'},\n",
       " {'id': '1905.13136v2',\n",
       "  'title': 'Job Recommendation through Progression of Job Selection',\n",
       "  'published': '2019-05-28T14:36:48Z',\n",
       "  'summary': 'Job recommendation has traditionally been treated as a filter-based match or\\nas a recommendation based on the features of jobs and candidates as discrete\\nentities. In this paper, we introduce a methodology where we leverage the\\nprogression of job selection by candidates using machine learning.\\nAdditionally, our recommendation is composed of several other\\nsub-recommendations that contribute to at least one of a) making\\nrecommendations serendipitous for the end user b) overcoming cold-start for\\nboth candidates and jobs. One of the unique selling propositions of our\\nmethodology is the way we have used skills as embedded features and derived\\nlatent competencies from them, thereby attempting to expand the skills of\\ncandidates and jobs to achieve more coverage in the skill domain. We have\\ndeployed our model in a real-world job recommender system and have achieved the\\nbest click-through rate through a blended approach of machine-learned\\nrecommendations and other sub-recommendations. For recommending jobs through\\nmachine learning that forms a significant part of our recommendation, we\\nachieve the best results through Bi-LSTM with attention.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.13136v2.pdf'},\n",
       " {'id': '1511.01868v1',\n",
       "  'title': 'A Survey of Link Recommendation for Social Networks: Methods,\\n  Theoretical Foundations, and Future Research Directions',\n",
       "  'published': '2015-11-05T19:46:29Z',\n",
       "  'summary': 'Link recommendation has attracted significant attentions from both industry\\npractitioners and academic researchers. In industry, link recommendation has\\nbecome a standard and most important feature in online social networks,\\nprominent examples of which include \"People You May Know\" on LinkedIn and \"You\\nMay Know\" on Google+. In academia, link recommendation has been and remains a\\nhighly active research area. This paper surveys state-of-the-art link\\nrecommendation methods, which can be broadly categorized into learning-based\\nmethods and proximity-based methods. We further identify social and economic\\ntheories, such as social interaction theory, that underlie these methods and\\nexplain from a theoretical perspective why a link recommendation method works.\\nFinally, we propose to extend link recommendation research in several\\ndirections that include utility-based link recommendation, diversity of link\\nrecommendation, link recommendation from incomplete data, and experimental\\nstudy of link recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1511.01868v1.pdf'},\n",
       " {'id': '2004.03774v2',\n",
       "  'title': 'Survey for Trust-aware Recommender Systems: A Deep Learning Perspective',\n",
       "  'published': '2020-04-08T02:11:55Z',\n",
       "  'summary': \"A significant remaining challenge for existing recommender systems is that\\nusers may not trust the recommender systems for either lack of explanation or\\ninaccurate recommendation results. Thus, it becomes critical to embrace a\\ntrustworthy recommender system. This survey provides a systemic summary of\\nthree categories of trust-aware recommender systems: social-aware recommender\\nsystems that leverage users' social relationships; robust recommender systems\\nthat filter untruthful noises (e.g., spammers and fake information) or enhance\\nattack resistance; explainable recommender systems that provide explanations of\\nrecommended items. We focus on the work based on deep learning techniques, an\\nemerging area in the recommendation research.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2004.03774v2.pdf'},\n",
       " {'id': '2007.07217v1',\n",
       "  'title': 'Non-IID Recommender Systems: A Review and Framework of Recommendation\\n  Paradigm Shifting',\n",
       "  'published': '2020-07-01T11:24:33Z',\n",
       "  'summary': 'While recommendation plays an increasingly critical role in our living,\\nstudy, work, and entertainment, the recommendations we receive are often for\\nirrelevant, duplicate, or uninteresting products and services. A critical\\nreason for such bad recommendations lies in the intrinsic assumption that\\nrecommended users and items are independent and identically distributed (IID)\\nin existing theories and systems. Another phenomenon is that, while tremendous\\nefforts have been made to model specific aspects of users or items, the overall\\nuser and item characteristics and their non-IIDness have been overlooked. In\\nthis paper, the non-IID nature and characteristics of recommendation are\\ndiscussed, followed by the non-IID theoretical framework in order to build a\\ndeep and comprehensive understanding of the intrinsic nature of recommendation\\nproblems, from the perspective of both couplings and heterogeneity. This\\nnon-IID recommendation research triggers the paradigm shift from IID to non-IID\\nrecommendation research and can hopefully deliver informed, relevant,\\npersonalized, and actionable recommendations. It creates exciting new\\ndirections and fundamental solutions to address various complexities including\\ncold-start, sparse data-based, cross-domain, group-based, and shilling\\nattack-related issues.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.07217v1.pdf'},\n",
       " {'id': '1901.00306v1',\n",
       "  'title': 'The TagRec Framework as a Toolkit for the Development of Tag-Based\\n  Recommender Systems',\n",
       "  'published': '2019-01-02T09:32:27Z',\n",
       "  'summary': 'Recommender systems have become important tools to support users in\\nidentifying relevant content in an overloaded information space. To ease the\\ndevelopment of recommender systems, a number of recommender frameworks have\\nbeen proposed that serve a wide range of application domains. Our TagRec\\nframework is one of the few examples of an open-source framework tailored\\ntowards developing and evaluating tag-based recommender systems. In this paper,\\nwe present the current, updated state of TagRec, and we summarize and reflect\\non four use cases that have been implemented with TagRec: (i) tag\\nrecommendations, (ii) resource recommendations, (iii) recommendation\\nevaluation, and (iv) hashtag recommendations. To date, TagRec served the\\ndevelopment and/or evaluation process of tag-based recommender systems in two\\nlarge scale European research projects, which have been described in 17\\nresearch papers. Thus, we believe that this work is of interest for both\\nresearchers and practitioners of tag-based recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1901.00306v1.pdf'},\n",
       " {'id': '1903.07826v1',\n",
       "  'title': 'Diversity-Promoting Deep Reinforcement Learning for Interactive\\n  Recommendation',\n",
       "  'published': '2019-03-19T04:38:05Z',\n",
       "  'summary': 'Interactive recommendation that models the explicit interactions between\\nusers and the recommender system has attracted a lot of research attentions in\\nrecent years. Most previous interactive recommendation systems only focus on\\noptimizing recommendation accuracy while overlooking other important aspects of\\nrecommendation quality, such as the diversity of recommendation results. In\\nthis paper, we propose a novel recommendation model, named\\n\\\\underline{D}iversity-promoting \\\\underline{D}eep \\\\underline{R}einforcement\\n\\\\underline{L}earning (D$^2$RL), which encourages the diversity of\\nrecommendation results in interaction recommendations. More specifically, we\\nadopt a Determinantal Point Process (DPP) model to generate diverse, while\\nrelevant item recommendations. A personalized DPP kernel matrix is maintained\\nfor each user, which is constructed from two parts: a fixed similarity matrix\\ncapturing item-item similarity, and the relevance of items dynamically learnt\\nthrough an actor-critic reinforcement learning framework. We performed\\nextensive offline experiments as well as simulated online experiments with real\\nworld datasets to demonstrate the effectiveness of the proposed model.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1903.07826v1.pdf'},\n",
       " {'id': '1911.00852v1',\n",
       "  'title': \"The Relationship between the Consistency of Users' Ratings and\\n  Recommendation Calibration\",\n",
       "  'published': '2019-11-03T08:10:33Z',\n",
       "  'summary': \"Fairness in recommender systems has recently received attention from\\nresearchers. Unfair recommendations have negative impact on the effectiveness\\nof recommender systems as it may degrade users' satisfaction, loyalty, and at\\nworst, it can lead to or perpetuate undesirable social dynamics. One of the\\nfactors that may impact fairness is calibration, the degree to which users'\\npreferences on various item categories are reflected in the recommendations\\nthey receive.\\n  The ability of a recommendation algorithm for generating effective\\nrecommendations may depend on the meaningfulness of the input data and the\\namount of information available in users' profile. In this paper, we aim to\\nexplore the relationship between the consistency of users' ratings behavior and\\nthe degree of calibrated recommendations they receive. We conduct our analysis\\non different groups of users based on the consistency of their ratings. Our\\nexperimental results on a movie dataset and several recommendation algorithms\\nshow that there is a positive correlation between the consistency of users'\\nratings behavior and the degree of calibration in their recommendations,\\nmeaning that user groups with higher inconsistency in their ratings receive\\nless calibrated recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1911.00852v1.pdf'},\n",
       " {'id': '2102.04447v1',\n",
       "  'title': 'Applying the Affective Aware Pseudo Association Method to Enhance the\\n  Top-N Recommendations Distribution to Users in Group Emotion Recommender\\n  Systems',\n",
       "  'published': '2021-02-08T18:59:20Z',\n",
       "  'summary': \"Recommender Systems are a subclass of information retrieval systems, or more\\nsuccinctly, a class of information filtering systems that seeks to predict how\\nclose is the match of the user's preference to a recommended item. A common\\napproach for making recommendations for a user group is to extend Personalized\\nRecommender Systems' capability. This approach gives the impression that group\\nrecommendations are retrofits of the Personalized Recommender Systems.\\nMoreover, such an approach not taken the dynamics of group emotion and\\nindividual emotion into the consideration in making top_N recommendations.\\nRecommending items to a group of two or more users has certainly raised unique\\nchallenges in group behaviors that influence group decision-making that\\nresearchers only partially understand. This study applies the Affective Aware\\nPseudo Association Method in studying group formation and dynamics in group\\ndecision-making. The method shows its adaptability to group's moods change when\\nmaking recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.04447v1.pdf'},\n",
       " {'id': '2102.12413v1',\n",
       "  'title': 'Designing Explanations for Group Recommender Systems',\n",
       "  'published': '2021-02-24T17:05:39Z',\n",
       "  'summary': \"Explanations are used in recommender systems for various reasons. Users have\\nto be supported in making (high-quality) decisions more quickly. Developers of\\nrecommender systems want to convince users to purchase specific items. Users\\nshould better understand how the recommender system works and why a specific\\nitem has been recommended. Users should also develop a more in-depth\\nunderstanding of the item domain. Consequently, explanations are designed in\\norder to achieve specific \\\\emph{goals} such as increasing the transparency of a\\nrecommendation or increasing a user's trust in the recommender system. In this\\npaper, we provide an overview of existing research related to explanations in\\nrecommender systems, and specifically discuss aspects relevant to group\\nrecommendation scenarios. In this context, we present different ways of\\nexplaining and visualizing recommendations determined on the basis of\\npreference aggregation strategies.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2102.12413v1.pdf'},\n",
       " {'id': '2109.10665v4',\n",
       "  'title': 'A Survey on Reinforcement Learning for Recommender Systems',\n",
       "  'published': '2021-09-22T11:52:38Z',\n",
       "  'summary': 'Recommender systems have been widely applied in different real-life scenarios\\nto help us find useful information. In particular, Reinforcement Learning (RL)\\nbased recommender systems have become an emerging research topic in recent\\nyears, owing to the interactive nature and autonomous learning ability.\\nEmpirical results show that RL-based recommendation methods often surpass most\\nof supervised learning methods. Nevertheless, there are various challenges of\\napplying RL in recommender systems. To understand the challenges and relevant\\nsolutions, there should be a reference for researchers and practitioners\\nworking on RL-based recommender systems. To this end, we firstly provide a\\nthorough overview, comparisons, and summarization of RL approaches applied in\\nfour typical recommendation scenarios, including interactive recommendation,\\nconversational recommendatin, sequential recommendation, and explainable\\nrecommendation. Furthermore, we systematically analyze the challenges and\\nrelevant solutions on the basis of existing literature. Finally, under\\ndiscussion for open issues of RL and its limitations of recommender systems, we\\nhighlight some potential research directions in this field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.10665v4.pdf'},\n",
       " {'id': '2203.08373v1',\n",
       "  'title': 'Are you aware of what you are watching? Role of machine heuristic in\\n  online content recommendations',\n",
       "  'published': '2022-03-16T03:40:34Z',\n",
       "  'summary': 'Since recommender systems have been created and developed to automate the\\nrecommendation process, users can easily consume their desired video content on\\nonline platforms. In this line, several content recommendation algorithms are\\nintroduced and employed to allow users to encounter content of their interests,\\neffectively. However, the recommendation systems sometimes regrettably\\nrecommend inappropriate content, including misinformation or fake news. To make\\nit worse, people would unreservedly accept such content due to their cognitive\\nheuristic, machine heuristic, which is the rule of thumb that machines are more\\naccurate and trustworthy than humans. In this study, we designed and conducted\\na web-based experiment where the participants are invoked machine heuristic by\\nexperiencing the whole process of machine or human recommendation system. The\\nresults demonstrated that participants (N = 89) showed a more positive attitude\\ntoward a machine recommender than a human recommender, even the recommended\\nvideos contain inappropriate content. While participants who have a high level\\nof trust in machines exhibited a negative attitude toward recommendations.\\nBased on these results, we suggest that a phenomenon known as algorithm\\naversion might be simultaneously considered with machine heuristic in\\ninvestigating human interaction with a machine.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2203.08373v1.pdf'},\n",
       " {'id': '2211.14247v1',\n",
       "  'title': 'Group Buying Recommendation Model Based on Multi-task Learning',\n",
       "  'published': '2022-11-25T17:22:14Z',\n",
       "  'summary': 'In recent years, group buying has become one popular kind of online shopping\\nactivity, thanks to its larger sales and lower unit price. Unfortunately,\\nresearch seldom focuses on recommendations specifically for group buying by\\nnow. Although some recommendation models have been proposed for group\\nrecommendation, they can not be directly used to achieve real-world group\\nbuying recommendation, due to the essential difference between group\\nrecommendation and group buying recommendation. In this paper, we first\\nformalize the task of group buying recommendations into two sub-tasks. Then,\\nbased on our insights into the correlations and interactions between the two\\nsub-tasks, we propose a novel recommendation model for group buying, MGBR,\\nbuilt mainly with a multi-task learning module. To improve recommendation\\nperformance further, we devise some collaborative expert networks and adjusted\\ngates in the multi-task learning module, to promote the information interaction\\nbetween the two sub-tasks. Furthermore, we propose two auxiliary losses\\ncorresponding to the two sub-tasks, to refine the representation learning in\\nour model. Our extensive experiments not only demonstrate that the augmented\\nrepresentations in our model result in better performance than previous\\nrecommendation models, but also justify the impacts of the specially designed\\ncomponents in our model.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.14247v1.pdf'},\n",
       " {'id': '2305.15673v1',\n",
       "  'title': 'BookGPT: A General Framework for Book Recommendation Empowered by Large\\n  Language Model',\n",
       "  'published': '2023-05-25T02:45:22Z',\n",
       "  'summary': 'With the continuous development and change exhibited by large language model\\n(LLM) technology, represented by generative pretrained transformers (GPTs),\\nmany classic scenarios in various fields have re-emerged with new\\nopportunities. This paper takes ChatGPT as the modeling object, incorporates\\nLLM technology into the typical book resource understanding and recommendation\\nscenario for the first time, and puts it into practice. By building a\\nChatGPT-like book recommendation system (BookGPT) framework based on ChatGPT,\\nthis paper attempts to apply ChatGPT to recommendation modeling for three\\ntypical tasks, book rating recommendation, user rating recommendation, and book\\nsummary recommendation, and explores the feasibility of LLM technology in book\\nrecommendation scenarios. At the same time, based on different evaluation\\nschemes for book recommendation tasks and the existing classic recommendation\\nmodels, this paper discusses the advantages and disadvantages of the BookGPT in\\nbook recommendation scenarios and analyzes the opportunities and improvement\\ndirections for subsequent LLMs in these scenarios.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.15673v1.pdf'},\n",
       " {'id': '2307.12034v1',\n",
       "  'title': 'Conformal Group Recommender System',\n",
       "  'published': '2023-07-22T10:03:32Z',\n",
       "  'summary': 'Group recommender systems (GRS) are critical in discovering relevant items\\nfrom a near-infinite inventory based on group preferences rather than\\nindividual preferences, like recommending a movie, restaurant, or tourist\\ndestination to a group of individuals. The traditional models of group\\nrecommendation are designed to act like a black box with a strict focus on\\nimproving recommendation accuracy, and most often, they place the onus on the\\nusers to interpret recommendations. In recent years, the focus of Recommender\\nSystems (RS) research has shifted away from merely improving recommendation\\naccuracy towards value additions such as confidence and explanation. In this\\nwork, we propose a conformal prediction framework that provides a measure of\\nconfidence with prediction in conjunction with a group recommender system to\\naugment the system-generated plain recommendations. In the context of group\\nrecommender systems, we propose various nonconformity measures that play a\\nvital role in the efficiency of the conformal framework. We also show that\\ndefined nonconformity satisfies the exchangeability property. Experimental\\nresults demonstrate the effectiveness of the proposed approach over several\\nbenchmark datasets. Furthermore, our proposed approach also satisfies validity\\nand efficiency properties.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.12034v1.pdf'},\n",
       " {'id': '2312.13557v1',\n",
       "  'title': 'Empowering Few-Shot Recommender Systems with Large Language Models --\\n  Enhanced Representations',\n",
       "  'published': '2023-12-21T03:50:09Z',\n",
       "  'summary': \"Recommender systems utilizing explicit feedback have witnessed significant\\nadvancements and widespread applications over the past years. However,\\ngenerating recommendations in few-shot scenarios remains a persistent\\nchallenge. Recently, large language models (LLMs) have emerged as a promising\\nsolution for addressing natural language processing (NLP) tasks, thereby\\noffering novel insights into tackling the few-shot scenarios encountered by\\nexplicit feedback-based recommender systems. To bridge recommender systems and\\nLLMs, we devise a prompting template that generates user and item\\nrepresentations based on explicit feedback. Subsequently, we integrate these\\nLLM-processed representations into various recommendation models to evaluate\\ntheir significance across diverse recommendation tasks. Our ablation\\nexperiments and case study analysis collectively demonstrate the effectiveness\\nof LLMs in processing explicit feedback, highlighting that LLMs equipped with\\ngenerative and logical reasoning capabilities can effectively serve as a\\ncomponent of recommender systems to enhance their performance in few-shot\\nscenarios. Furthermore, the broad adaptability of LLMs augments the\\ngeneralization potential of recommender models, despite certain inherent\\nconstraints. We anticipate that our study can inspire researchers to delve\\ndeeper into the multifaceted dimensions of LLMs's involvement in recommender\\nsystems and contribute to the advancement of the explicit feedback-based\\nrecommender systems field.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.13557v1.pdf'},\n",
       " {'id': '2405.12119v1',\n",
       "  'title': 'Reindex-Then-Adapt: Improving Large Language Models for Conversational\\n  Recommendation',\n",
       "  'published': '2024-05-20T15:37:55Z',\n",
       "  'summary': 'Large language models (LLMs) are revolutionizing conversational recommender\\nsystems by adeptly indexing item content, understanding complex conversational\\ncontexts, and generating relevant item titles. However, controlling the\\ndistribution of recommended items remains a challenge. This leads to suboptimal\\nperformance due to the failure to capture rapidly changing data distributions,\\nsuch as item popularity, on targeted conversational recommendation platforms.\\nIn conversational recommendation, LLMs recommend items by generating the titles\\n(as multiple tokens) autoregressively, making it difficult to obtain and\\ncontrol the recommendations over all items. Thus, we propose a\\nReindex-Then-Adapt (RTA) framework, which converts multi-token item titles into\\nsingle tokens within LLMs, and then adjusts the probability distributions over\\nthese single-token item titles accordingly. The RTA framework marries the\\nbenefits of both LLMs and traditional recommender systems (RecSys):\\nunderstanding complex queries as LLMs do; while efficiently controlling the\\nrecommended item distributions in conversational recommendations as traditional\\nRecSys do. Our framework demonstrates improved accuracy metrics across three\\ndifferent conversational recommendation datasets and two adaptation settings',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.12119v1.pdf'},\n",
       " {'id': '2407.05221v1',\n",
       "  'title': 'Ensemble Boost: Greedy Selection for Superior Recommender Systems',\n",
       "  'published': '2024-07-07T00:50:52Z',\n",
       "  'summary': 'Ensemble techniques have demonstrated remarkable success in improving\\npredictive performance across various domains by aggregating predictions from\\nmultiple models [1]. In the realm of recommender systems, this research\\nexplores the application of ensemble technique to enhance recommendation\\nquality. Specifically, we propose a novel approach to combine top-k\\nrecommendations from ten diverse recommendation models resulting in superior\\ntop-n recommendations using this novel ensemble technique. Our method leverages\\na Greedy Ensemble Selection(GES) strategy, effectively harnessing the\\ncollective intelligence of multiple models. We conduct experiments on five\\ndistinct datasets to evaluate the effectiveness of our approach. Evaluation\\nacross five folds using the NDCG metric reveals significant improvements in\\nrecommendation accuracy across all datasets compared to single best performing\\nmodel. Furthermore, comprehensive comparisons against existing models\\nunderscore the efficacy of our ensemble approach in enhancing recommendation\\nquality. Our ensemble approach yielded an average improvement of 21.67% across\\ndifferent NDCG@N metrics and the five datasets, compared to single best model.\\nThe popularity recommendation model serves as the baseline for comparison. This\\nresearch contributes to the advancement of ensemble-based recommender systems,\\noffering insights into the potential of combining diverse recommendation\\nstrategies to enhance user experience and satisfaction. By presenting a novel\\napproach and demonstrating its superiority over existing methods, we aim to\\ninspire further exploration and innovation in this domain.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.05221v1.pdf'},\n",
       " {'id': '2409.07367v1',\n",
       "  'title': 'Enhancing Sequential Music Recommendation with Negative\\n  Feedback-informed Contrastive Learning',\n",
       "  'published': '2024-09-11T15:56:05Z',\n",
       "  'summary': 'Modern music streaming services are heavily based on recommendation engines\\nto serve content to users. Sequential recommendation -- continuously providing\\nnew items within a single session in a contextually coherent manner -- has been\\nan emerging topic in current literature. User feedback -- a positive or\\nnegative response to the item presented -- is used to drive content\\nrecommendations by learning user preferences. We extend this idea to\\nsession-based recommendation to provide context-coherent music recommendations\\nby modelling negative user feedback, i.e., skips, in the loss function. We\\npropose a sequence-aware contrastive sub-task to structure item embeddings in\\nsession-based music recommendation, such that true next-positive items\\n(ignoring skipped items) are structured closer in the session embedding space,\\nwhile skipped tracks are structured farther away from all items in the session.\\nThis directly affects item rankings using a K-nearest-neighbors search for\\nnext-item recommendations, while also promoting the rank of the true next item.\\nExperiments incorporating this task into SoTA methods for sequential item\\nrecommendation show consistent performance gains in terms of next-item hit\\nrate, item ranking, and skip down-ranking on three music recommendation\\ndatasets, strongly benefiting from the increasing presence of user feedback.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.07367v1.pdf'},\n",
       " {'id': '2409.10494v1',\n",
       "  'title': 'Incorporating Classifier-Free Guidance in Diffusion Model-Based\\n  Recommendation',\n",
       "  'published': '2024-09-16T17:27:27Z',\n",
       "  'summary': 'This paper presents a diffusion-based recommender system that incorporates\\nclassifier-free guidance. Most current recommender systems provide\\nrecommendations using conventional methods such as collaborative or\\ncontent-based filtering. Diffusion is a new approach to generative AI that\\nimproves on previous generative AI approaches such as Variational Autoencoders\\n(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in\\na recommender system that mirrors the sequence users take when browsing and\\nrating items. Although a few current recommender systems incorporate diffusion,\\nthey do not incorporate classifier-free guidance, a new innovation in diffusion\\nmodels as a whole. In this paper, we present a diffusion recommender system\\nthat augments the underlying recommender system model for improved performance\\nand also incorporates classifier-free guidance. Our findings show improvements\\nover state-of-the-art recommender systems for most metrics for several\\nrecommendation tasks on a variety of datasets. In particular, our approach\\ndemonstrates the potential to provide better recommendations when data is\\nsparse.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.10494v1.pdf'},\n",
       " {'id': '2502.11374v2',\n",
       "  'title': 'Leave No One Behind: Enhancing Diversity While Maintaining Accuracy in\\n  Social Recommendation',\n",
       "  'published': '2025-02-17T02:41:11Z',\n",
       "  'summary': 'Social recommendation, which incorporates social connections into recommender\\nsystems, has proven effective in improving recommendation accuracy. However,\\nbeyond accuracy, diversity is also crucial for enhancing user engagement.\\nDespite its importance, the impact of social recommendation models on diversity\\nremains largely unexplored. In this study, we systematically examine the dual\\nperformance of existing social recommendation algorithms in terms of both\\naccuracy and diversity. Our empirical analysis reveals a concerning trend:\\nwhile social recommendation models enhance accuracy, they often reduce\\ndiversity. To address this issue, we propose Diversified Social Recommendation\\n(DivSR), a novel approach that employs relational knowledge distillation to\\ntransfer high-diversity structured knowledge from non-social recommendation\\nmodels to social recommendation models. DivSR is a lightweight, model-agnostic\\nframework that seamlessly integrates with existing social recommendation\\narchitectures. Experiments on three benchmark datasets demonstrate that DivSR\\nsignificantly enhances diversity while maintaining competitive accuracy,\\nachieving a superior accuracy-diversity trade-off. Our code and data are\\npublicly available at: https://github.com/ll0ruc/DivSR.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2502.11374v2.pdf'},\n",
       " {'id': '2506.15284v1',\n",
       "  'title': 'Multi-Interest Recommendation: A Survey',\n",
       "  'published': '2025-06-18T09:05:32Z',\n",
       "  'summary': \"Existing recommendation methods often struggle to model users' multifaceted\\npreferences due to the diversity and volatility of user behavior, as well as\\nthe inherent uncertainty and ambiguity of item attributes in practical\\nscenarios. Multi-interest recommendation addresses this challenge by extracting\\nmultiple interest representations from users' historical interactions, enabling\\nfine-grained preference modeling and more accurate recommendations. It has\\ndrawn broad interest in recommendation research. However, current\\nrecommendation surveys have either specialized in frontier recommendation\\nmethods or delved into specific tasks and downstream applications. In this\\nwork, we systematically review the progress, solutions, challenges, and future\\ndirections of multi-interest recommendation by answering the following three\\nquestions: (1) Why is multi-interest modeling significantly important for\\nrecommendation? (2) What aspects are focused on by multi-interest modeling in\\nrecommendation? and (3) How can multi-interest modeling be applied, along with\\nthe technical details of the representative modules? We hope that this survey\\nestablishes a fundamental framework and delivers a preliminary overview for\\nresearchers interested in this field and committed to further exploration. The\\nimplementation of multi-interest recommendation summarized in this survey is\\nmaintained at https://github.com/WHUIR/Multi-Interest-Recommendation-A-Survey.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2506.15284v1.pdf'},\n",
       " {'id': '1703.09108v2',\n",
       "  'title': 'Mr. DLib: Recommendations-as-a-Service (RaaS) for Academia',\n",
       "  'published': '2017-03-27T14:35:37Z',\n",
       "  'summary': \"Only few digital libraries and reference managers offer recommender systems,\\nalthough such systems could assist users facing information overload. In this\\npaper, we introduce Mr. DLib's recommendations-as-a-service, which allows third\\nparties to easily integrate a recommender system into their products. We\\nexplain the recommender approaches implemented in Mr. DLib (content-based\\nfiltering among others), and present details on 57 million recommendations,\\nwhich Mr. DLib delivered to its partner GESIS Sowiport. Finally, we outline our\\nplans for future development, including integration into JabRef, establishing a\\nliving lab, and providing personalized recommendations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1703.09108v2.pdf'},\n",
       " {'id': '1908.00831v1',\n",
       "  'title': 'Bias Disparity in Collaborative Recommendation: Algorithmic Evaluation\\n  and Comparison',\n",
       "  'published': '2019-08-02T13:00:27Z',\n",
       "  'summary': \"Research on fairness in machine learning has been recently extended to\\nrecommender systems. One of the factors that may impact fairness is bias\\ndisparity, the degree to which a group's preferences on various item categories\\nfail to be reflected in the recommendations they receive. In some cases biases\\nin the original data may be amplified or reversed by the underlying\\nrecommendation algorithm. In this paper, we explore how different\\nrecommendation algorithms reflect the tradeoff between ranking quality and bias\\ndisparity. Our experiments include neighborhood-based, model-based, and\\ntrust-aware recommendation algorithms.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1908.00831v1.pdf'},\n",
       " {'id': '1910.03040v1',\n",
       "  'title': 'IRF: Interactive Recommendation through Dialogue',\n",
       "  'published': '2019-10-03T19:35:27Z',\n",
       "  'summary': 'Recent research focuses beyond recommendation accuracy, towards human factors\\nthat influence the acceptance of recommendations, such as user satisfaction,\\ntrust, transparency and sense of control.We present a generic interactive\\nrecommender framework that can add interaction functionalities to\\nnon-interactive recommender systems.We take advantage of dialogue systems to\\ninteract with the user and we design a middleware layer to provide the\\ninteraction functions, such as providing explanations for the recommendations,\\nmanaging users preferences learnt from dialogue, preference elicitation and\\nrefining recommendations based on learnt preferences.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1910.03040v1.pdf'},\n",
       " {'id': '1802.05382v3',\n",
       "  'title': 'Popularity-Aware Item Weighting for Long-Tail Recommendation',\n",
       "  'published': '2018-02-15T01:53:59Z',\n",
       "  'summary': 'Many recommender systems suffer from the popularity bias problem: popular\\nitems are being recommended frequently while less popular, niche products, are\\nrecommended rarely if not at all. However, those ignored products are exactly\\nthe products that businesses need to find customers for and their\\nrecommendations would be more beneficial. In this paper, we examine an item\\nweighting approach to improve long-tail recommendation. Our approach works as a\\nsimple yet powerful add-on to existing recommendation algorithms for making a\\ntunable trade-off between accuracy and long-tail coverage.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1802.05382v3.pdf'},\n",
       " {'id': '2107.06590v1',\n",
       "  'title': 'Self-Determined Reciprocal Recommender System with Strong Privacy\\n  Guarantees',\n",
       "  'published': '2021-07-14T10:25:53Z',\n",
       "  'summary': 'Recommender systems are widely used. Usually, recommender systems are based\\non a centralized client-server architecture. However, this approach implies\\ndrawbacks regarding the privacy of users. In this paper, we propose a\\ndistributed reciprocal recommender system with strong, self-determined privacy\\nguarantees, i.e., local differential privacy. More precisely, users randomize\\ntheir profiles locally and exchange them via a peer-to-peer network.\\nRecommendations are then computed and ranked locally by estimating similarities\\nbetween profiles. We evaluate recommendation accuracy of a job recommender\\nsystem and demonstrate that our method provides acceptable utility under strong\\nprivacy requirements.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2107.06590v1.pdf'},\n",
       " {'id': '1711.04101v1',\n",
       "  'title': 'Recommender Systems with Random Walks: A Survey',\n",
       "  'published': '2017-11-11T08:43:06Z',\n",
       "  'summary': \"Recommender engines have become an integral component in today's e-commerce\\nsystems. From recommending books in Amazon to finding friends in social\\nnetworks such as Facebook, they have become omnipresent.\\n  Generally, recommender systems can be classified into two main categories:\\ncontent based and collaborative filtering based models. Both these models build\\nrelationships between users and items to provide recommendations. Content based\\nsystems achieve this task by utilizing features extracted from the context\\navailable, whereas collaborative systems use shared interests between user-item\\nsubsets.\\n  There is another relatively unexplored approach for providing recommendations\\nthat utilizes a stochastic process named random walks. This study is a survey\\nexploring use cases of random walks in recommender systems and an attempt at\\nclassifying them.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1711.04101v1.pdf'},\n",
       " {'id': '2005.12982v1',\n",
       "  'title': 'Utilizing FastText for Venue Recommendation',\n",
       "  'published': '2020-05-14T14:57:12Z',\n",
       "  'summary': 'Venue recommendation systems model the past interactions (i.e., check-ins) of\\nthe users and recommend venues. Traditional recommendation systems employ\\ncollaborative filtering, content-based filtering or matrix factorization.\\nRecently, vector space embedding and deep learning algorithms are also used for\\nrecommendation. In this work, I propose a method for recommending top-k venues\\nby utilizing the sequentiality feature of check-ins and a recent vector space\\nembedding method, namely the FastText. Our proposed method; forms groups of\\ncheck-ins, learns the vector space representations of the venues and utilizes\\nthe learned embeddings to make venue recommendations. I measure the performance\\nof the proposed method using a Foursquare check-in dataset.The results show\\nthat the proposed method performs better than the state-of-the-art methods.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.12982v1.pdf'},\n",
       " {'id': '2101.08769v1',\n",
       "  'title': 'Item Recommendation from Implicit Feedback',\n",
       "  'published': '2021-01-21T18:50:21Z',\n",
       "  'summary': 'The task of item recommendation is to select the best items for a user from a\\nlarge catalogue of items. Item recommenders are commonly trained from implicit\\nfeedback which consists of past actions that are positive only. Core challenges\\nof item recommendation are (1) how to formulate a training objective from\\nimplicit feedback and (2) how to efficiently train models over a large item\\ncatalogue. This article provides an overview of item recommendation, its unique\\ncharacteristics and some common approaches. It starts with an introduction to\\nthe problem and discusses different training objectives. The main body deals\\nwith learning algorithms and presents sampling based algorithms for general\\nrecommenders and more efficient algorithms for dot product models. Finally, the\\napplication of item recommenders for retrieval tasks is discussed.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.08769v1.pdf'},\n",
       " {'id': '2405.18011v1',\n",
       "  'title': 'Rethinking Recommender Systems: Cluster-based Algorithm Selection',\n",
       "  'published': '2024-05-28T09:53:11Z',\n",
       "  'summary': 'Cluster-based algorithm selection deals with selecting recommendation\\nalgorithms on clusters of users to obtain performance gains. No studies have\\nbeen attempted for many combinations of clustering approaches and\\nrecommendation algorithms. We want to show that clustering users prior to\\nalgorithm selection increases the performance of recommendation algorithms. Our\\nstudy covers eight datasets, four clustering approaches, and eight\\nrecommendation algorithms. We select the best performing recommendation\\nalgorithm for each cluster. Our work shows that cluster-based algorithm\\nselection is an effective technique for optimizing recommendation algorithm\\nperformance. For five out of eight datasets, we report an increase in nDCG@10\\nbetween 19.28% (0.032) and 360.38% (0.191) compared to algorithm selection\\nwithout prior clustering.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.18011v1.pdf'},\n",
       " {'id': '2501.00367v1',\n",
       "  'title': 'Who Gets Recommended? Investigating Gender, Race, and Country\\n  Disparities in Paper Recommendations from Large Language Models',\n",
       "  'published': '2024-12-31T09:42:53Z',\n",
       "  'summary': \"This paper investigates the performance of several representative large\\nmodels in the tasks of literature recommendation and explores potential biases\\nin research exposure. The results indicate that not only LLMs' overall\\nrecommendation accuracy remains limited but also the models tend to recommend\\nliterature with greater citation counts, later publication date, and larger\\nauthor teams. Yet, in scholar recommendation tasks, there is no evidence that\\nLLMs disproportionately recommend male, white, or developed-country authors,\\ncontrasting with patterns of known human biases.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.00367v1.pdf'},\n",
       " {'id': '1809.07062v4',\n",
       "  'title': 'Adversarial Training Towards Robust Multimedia Recommender System',\n",
       "  'published': '2018-09-19T08:34:16Z',\n",
       "  'summary': \"With the prevalence of multimedia content on the Web, developing recommender\\nsolutions that can effectively leverage the rich signal in multimedia data is\\nin urgent need. Owing to the success of deep neural networks in representation\\nlearning, recent advance on multimedia recommendation has largely focused on\\nexploring deep learning methods to improve the recommendation accuracy. To\\ndate, however, there has been little effort to investigate the robustness of\\nmultimedia representation and its impact on the performance of multimedia\\nrecommendation.\\n  In this paper, we shed light on the robustness of multimedia recommender\\nsystem. Using the state-of-the-art recommendation framework and deep image\\nfeatures, we demonstrate that the overall system is not robust, such that a\\nsmall (but purposeful) perturbation on the input image will severely decrease\\nthe recommendation accuracy. This implies the possible weakness of multimedia\\nrecommender system in predicting user preference, and more importantly, the\\npotential of improvement by enhancing its robustness. To this end, we propose a\\nnovel solution named Adversarial Multimedia Recommendation (AMR), which can\\nlead to a more robust multimedia recommender model by using adversarial\\nlearning. The idea is to train the model to defend an adversary, which adds\\nperturbations to the target image with the purpose of decreasing the model's\\naccuracy. We conduct experiments on two representative multimedia\\nrecommendation tasks, namely, image recommendation and visually-aware product\\nrecommendation. Extensive results verify the positive effect of adversarial\\nlearning and demonstrate the effectiveness of our AMR method. Source codes are\\navailable in https://github.com/duxy-me/AMR.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1809.07062v4.pdf'},\n",
       " {'id': '2210.11828v2',\n",
       "  'title': 'Towards Employing Recommender Systems for Supporting Data and Algorithm\\n  Sharing',\n",
       "  'published': '2022-10-21T09:02:57Z',\n",
       "  'summary': 'Data and algorithm sharing is an imperative part of data and AI-driven\\neconomies. The efficient sharing of data and algorithms relies on the active\\ninterplay between users, data providers, and algorithm providers. Although\\nrecommender systems are known to effectively interconnect users and items in\\ne-commerce settings, there is a lack of research on the applicability of\\nrecommender systems for data and algorithm sharing. To fill this gap, we\\nidentify six recommendation scenarios for supporting data and algorithm\\nsharing, where four of these scenarios substantially differ from the\\ntraditional recommendation scenarios in e-commerce applications. We evaluate\\nthese recommendation scenarios using a novel dataset based on interaction data\\nof the OpenML data and algorithm sharing platform, which we also provide for\\nthe scientific community. Specifically, we investigate three types of\\nrecommendation approaches, namely popularity-, collaboration-, and\\ncontent-based recommendations. We find that collaboration-based recommendations\\nprovide the most accurate recommendations in all scenarios. Plus, the\\nrecommendation accuracy strongly depends on the specific scenario, e.g.,\\nalgorithm recommendations for users are a more difficult problem than algorithm\\nrecommendations for datasets. Finally, the content-based approach generates the\\nleast popularity-biased recommendations that cover the most datasets and\\nalgorithms.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2210.11828v2.pdf'},\n",
       " {'id': '1006.5278v4',\n",
       "  'title': 'A Survey Paper on Recommender Systems',\n",
       "  'published': '2010-06-28T07:20:28Z',\n",
       "  'summary': \"Recommender systems apply data mining techniques and prediction algorithms to\\npredict users' interest on information, products and services among the\\ntremendous amount of available items. The vast growth of information on the\\nInternet as well as number of visitors to websites add some key challenges to\\nrecommender systems. These are: producing accurate recommendation, handling\\nmany recommendations efficiently and coping with the vast growth of number of\\nparticipants in the system. Therefore, new recommender system technologies are\\nneeded that can quickly produce high quality recommendations even for huge data\\nsets.\\n  To address these issues we have explored several collaborative filtering\\ntechniques such as the item based approach, which identify relationship between\\nitems and indirectly compute recommendations for users based on these\\nrelationships. The user based approach was also studied, it identifies\\nrelationships between users of similar tastes and computes recommendations\\nbased on these relationships.\\n  In this paper, we introduce the topic of recommender system. It provides ways\\nto evaluate efficiency, scalability and accuracy of recommender system. The\\npaper also analyzes different algorithms of user based and item based\\ntechniques for recommendation generation. Moreover, a simple experiment was\\nconducted using a data mining application -Weka- to apply data mining\\nalgorithms to recommender system. We conclude by proposing our approach that\\nmight enhance the quality of recommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1006.5278v4.pdf'},\n",
       " {'id': '2101.05641v1',\n",
       "  'title': '$C^3DRec$: Cloud-Client Cooperative Deep Learning for Temporal\\n  Recommendation in the Post-GDPR Era',\n",
       "  'published': '2021-01-13T12:49:34Z',\n",
       "  'summary': 'Mobile devices enable users to retrieve information at any time and any\\nplace. Considering the occasional requirements and fragmentation usage pattern\\nof mobile users, temporal recommendation techniques are proposed to improve the\\nefficiency of information retrieval on mobile devices by means of accurately\\nrecommending items via learning temporal interests with short-term user\\ninteraction behaviors. However, the enforcement of privacy-preserving laws and\\nregulations, such as GDPR, may overshadow the successful practice of temporal\\nrecommendation. The reason is that state-of-the-art recommendation systems\\nrequire to gather and process the user data in centralized servers but the\\ninteraction behaviors data used for temporal recommendation are usually\\nnon-transactional data that are not allowed to gather without the explicit\\npermission of users according to GDPR. As a result, if users do not permit\\nservices to gather their interaction behaviors data, the temporal\\nrecommendation fails to work. To realize the temporal recommendation in the\\npost-GDPR era, this paper proposes $C^3DRec$, a cloud-client cooperative deep\\nlearning framework of mining interaction behaviors for recommendation while\\npreserving user privacy. $C^3DRec$ constructs a global recommendation model on\\ncentralized servers using data collected before GDPR and fine-tunes the model\\ndirectly on individual local devices using data collected after GDPR. We design\\ntwo modes to accomplish the recommendation, i.e. pull mode where candidate\\nitems are pulled down onto the devices and fed into the local model to get\\nrecommended items, and push mode where the output of the local model is pushed\\nonto the server and combined with candidate items to get recommended ones.\\nEvaluation results show that $C^3DRec$ achieves comparable recommendation\\naccuracy to the centralized approaches, with minimal privacy concern.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2101.05641v1.pdf'},\n",
       " {'id': '2109.09587v2',\n",
       "  'title': 'Recommender systems based on graph embedding techniques: A comprehensive\\n  review',\n",
       "  'published': '2021-09-20T14:42:39Z',\n",
       "  'summary': \"As a pivotal tool to alleviate the information overload problem, recommender\\nsystems aim to predict user's preferred items from millions of candidates by\\nanalyzing observed user-item relations. As for alleviating the sparsity and\\ncold start problems encountered by recommender systems, researchers resort to\\nemploying side information or knowledge in recommendation as a strategy for\\nuncovering hidden (indirect) user-item relations, aiming to enrich observed\\ninformation (or data) for recommendation. However, in the face of the high\\ncomplexity and large scale of side information and knowledge, this strategy\\nrelies for efficient implementation on the scalability of recommendation\\nmodels. Not until after the prevalence of machine learning did graph embedding\\ntechniques be a concentration, which can efficiently utilize complex and\\nlarge-scale data. In light of that, equipping recommender systems with graph\\nembedding techniques has been widely studied these years, appearing to\\noutperform conventional recommendation implemented directly based on graph\\ntopological analysis. As the focus, this article retrospects graph\\nembedding-based recommendation from embedding techniques for bipartite graphs,\\ngeneral graphs and knowledge graphs, and proposes a general design pipeline of\\nthat. In addition, after comparing several representative graph embedding-based\\nrecommendation models with the most common-used conventional recommendation\\nmodels on simulations, this article manifests that the conventional models can\\noverall outperform the graph embedding-based ones in predicting implicit\\nuser-item interactions, revealing the comparative weakness of graph\\nembedding-based recommendation in these tasks. To foster future research, this\\narticle proposes suggestions on making a trade-off between graph\\nembedding-based recommendation and conventional recommendation in different\\ntasks, and puts forward open questions.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.09587v2.pdf'},\n",
       " {'id': '2301.08144v1',\n",
       "  'title': 'Towards the design of user-centric strategy recommendation systems for\\n  collaborative Human-AI tasks',\n",
       "  'published': '2023-01-17T17:53:27Z',\n",
       "  'summary': \"Artificial Intelligence is being employed by humans to collaboratively solve\\ncomplicated tasks for search and rescue, manufacturing, etc. Efficient teamwork\\ncan be achieved by understanding user preferences and recommending different\\nstrategies for solving the particular task to humans. Prior work has focused on\\npersonalization of recommendation systems for relatively well-understood tasks\\nin the context of e-commerce or social networks. In this paper, we seek to\\nunderstand the important factors to consider while designing user-centric\\nstrategy recommendation systems for decision-making. We conducted a\\nhuman-subjects experiment (n=60) for measuring the preferences of users with\\ndifferent personality types towards different strategy recommendation systems.\\nWe conducted our experiment across four types of strategy recommendation\\nmodalities that have been established in prior work: (1) Single strategy\\nrecommendation, (2) Multiple similar recommendations, (3) Multiple diverse\\nrecommendations, (4) All possible strategies recommendations. While these\\nstrategy recommendation schemes have been explored independently in prior work,\\nour study is novel in that we employ all of them simultaneously and in the\\ncontext of strategy recommendations, to provide us an in-depth overview of the\\nperception of different strategy recommendation systems. We found that certain\\npersonality traits, such as conscientiousness, notably impact the preference\\ntowards a particular type of system (p < 0.01). Finally, we report an\\ninteresting relationship between usability, alignment and perceived\\nintelligence wherein greater perceived alignment of recommendations with one's\\nown preferences leads to higher perceived intelligence (p < 0.01) and higher\\nusability (p < 0.01).\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2301.08144v1.pdf'},\n",
       " {'id': '2307.01411v1',\n",
       "  'title': 'Web3Recommend: Decentralised recommendations with trust and relevance',\n",
       "  'published': '2023-07-04T00:18:38Z',\n",
       "  'summary': \"Web3Recommend is a decentralized Social Recommender System implementation\\nthat enables Web3 Platforms on Android to generate recommendations that balance\\ntrust and relevance. Generating recommendations in decentralized networks is a\\nnon-trivial problem because these networks lack a global perspective due to the\\nabsence of a central authority. Further, decentralized networks are prone to\\nSybil Attacks in which a single malicious user can generate multiple fake or\\nSybil identities. Web3Recommend relies on a novel graph-based content\\nrecommendation design inspired by GraphJet, a recommendation system used in\\nTwitter enhanced with MeritRank, a decentralized reputation scheme that\\nprovides Sybil-resistance to the system. By adding MeritRank's decay parameters\\nto the vanilla Social Recommender Systems' personalized SALSA graph algorithm,\\nwe can provide theoretical guarantees against Sybil Attacks in the generated\\nrecommendations. Similar to GraphJet, we focus on generating real-time\\nrecommendations by only acting on recent interactions in the social network,\\nallowing us to cater temporally contextual recommendations while keeping a\\ntight bound on the memory usage in resource-constrained devices, allowing for a\\nseamless user experience. As a proof-of-concept, we integrate our system with\\nMusicDAO, an open-source Web3 music-sharing platform, to generate personalized,\\nreal-time recommendations. Thus, we provide the first Sybil-resistant Social\\nRecommender System, allowing real-time recommendations beyond classic\\nuser-based collaborative filtering. The system is also rigorously tested with\\nextensive unit and integration tests. Further, our experiments demonstrate the\\ntrust-relevance balance of recommendations against multiple adversarial\\nstrategies in a test network generated using data from real music platforms.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2307.01411v1.pdf'},\n",
       " {'id': '2308.07857v2',\n",
       "  'title': 'Impression-Aware Recommender Systems',\n",
       "  'published': '2023-08-15T16:16:02Z',\n",
       "  'summary': 'Novel data sources bring new opportunities to improve the quality of\\nrecommender systems and serve as a catalyst for the creation of new paradigms\\non personalized recommendations. Impressions are a novel data source containing\\nthe items shown to users on their screens. Past research focused on providing\\npersonalized recommendations using interactions, and occasionally using\\nimpressions when such a data source was available. Interest in impressions has\\nincreased due to their potential to provide more accurate recommendations.\\nDespite this increased interest, research in recommender systems using\\nimpressions is still dispersed. Many works have distinct interpretations of\\nimpressions and use impressions in recommender systems in numerous different\\nmanners. To unify those interpretations into a single framework, we present a\\nsystematic literature review on recommender systems using impressions, focusing\\non three fundamental perspectives: recommendation models, datasets, and\\nevaluation methodologies. We define a theoretical framework to delimit\\nrecommender systems using impressions and a novel paradigm for personalized\\nrecommendations, called impression-aware recommender systems. We propose a\\nclassification system for recommenders in this paradigm, which we use to\\ncategorize the recommendation models, datasets, and evaluation methodologies\\nused in past research. Lastly, we identify open questions and future\\ndirections, highlighting missing aspects in the reviewed literature.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.07857v2.pdf'},\n",
       " {'id': '2405.17740v1',\n",
       "  'title': 'MobileConvRec: A Conversational Dataset for Mobile Apps Recommendations',\n",
       "  'published': '2024-05-28T01:53:16Z',\n",
       "  'summary': \"Existing recommendation systems have focused on two paradigms: 1- historical\\nuser-item interaction-based recommendations and 2- conversational\\nrecommendations. Conversational recommendation systems facilitate natural\\nlanguage dialogues between users and the system, allowing the system to solicit\\nusers' explicit needs while enabling users to inquire about recommendations and\\nprovide feedback. Due to substantial advancements in natural language\\nprocessing, conversational recommendation systems have gained prominence.\\nExisting conversational recommendation datasets have greatly facilitated\\nresearch in their respective domains. Despite the exponential growth in mobile\\nusers and apps in recent years, research in conversational mobile app\\nrecommender systems has faced substantial constraints. This limitation can\\nprimarily be attributed to the lack of high-quality benchmark datasets\\nspecifically tailored for mobile apps. To facilitate research for\\nconversational mobile app recommendations, we introduce MobileConvRec.\\nMobileConvRec simulates conversations by leveraging real user interactions with\\nmobile apps on the Google Play store, originally captured in large-scale mobile\\napp recommendation dataset MobileRec. The proposed conversational\\nrecommendation dataset synergizes sequential user-item interactions, which\\nreflect implicit user preferences, with comprehensive multi-turn conversations\\nto effectively grasp explicit user needs. MobileConvRec consists of over 12K\\nmulti-turn recommendation-related conversations spanning 45 app categories.\\nMoreover, MobileConvRec presents rich metadata for each app such as permissions\\ndata, security and privacy-related information, and binary executables of apps,\\namong others. We demonstrate that MobileConvRec can serve as an excellent\\ntestbed for conversational mobile app recommendation through a comparative\\nstudy of several pre-trained large language models.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.17740v1.pdf'},\n",
       " {'id': '2407.09872v2',\n",
       "  'title': 'A Systematic Literature Review on Task Recommendation Systems for\\n  Crowdsourced Software Engineering',\n",
       "  'published': '2024-07-13T12:46:57Z',\n",
       "  'summary': \"Crowdsourced Software Engineering (CSE) offers outsourcing work to software\\npractitioners by leveraging a global online workforce. However, these software\\npractitioners struggle to identify suitable tasks due to the variety of options\\navailable. Hence, there have been a growing number of studies on introducing\\nrecommendation systems to recommend CSE tasks to software practitioners. The\\ngoal of this study is to analyze the existing CSE task recommendation systems,\\ninvestigating their extracted data, recommendation methods, key advantages and\\nlimitations, recommended task types, the use of human factors in\\nrecommendations, popular platforms, and features used to make recommendations.\\nThis SLR was conducted according to the Kitchenham and Charters' guidelines. We\\nused both manual and automatic search strategies without putting any time\\nlimitation for searching the relevant papers. We selected 65 primary studies\\nfor data extraction, analysis, and synthesis based on our predefined inclusion\\nand exclusion criteria. From the results of the data analysis, we classified\\nthe extracted data into four categories based on the data extraction source,\\ncategorized the proposed recommendation systems to fit into a taxonomy, and\\nidentified the key advantages and limitations of these systems. Our results\\nrevealed that human factors play a major role in CSE task recommendation.\\nFurther, we identified five popular task types recommended, popular platforms,\\nand their features used in task recommendation. We also provided\\nrecommendations for future research directions. This SLR provides insights into\\ncurrent trends, gaps, and future research directions in CSE task recommendation\\nsystems\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2407.09872v2.pdf'},\n",
       " {'id': '2409.14810v1',\n",
       "  'title': 'Pre-trained Language Model and Knowledge Distillation for Lightweight\\n  Sequential Recommendation',\n",
       "  'published': '2024-09-23T08:39:07Z',\n",
       "  'summary': 'Sequential recommendation models user interests based on historical behaviors\\nto provide personalized recommendation. Previous sequential recommendation\\nalgorithms primarily employ neural networks to extract features of user\\ninterests, achieving good performance. However, due to the recommendation\\nsystem datasets sparsity, these algorithms often employ small-scale network\\nframeworks, resulting in weaker generalization capability. Recently, a series\\nof sequential recommendation algorithms based on large pre-trained language\\nmodels have been proposed. Nonetheless, given the real-time demands of\\nrecommendation systems, the challenge remains in applying pre-trained language\\nmodels for rapid recommendations in real scenarios. To address this, we propose\\na sequential recommendation algorithm based on a pre-trained language model and\\nknowledge distillation. The key of proposed algorithm is to transfer\\npre-trained knowledge across domains and achieve lightweight inference by\\nknowledge distillation. The algorithm operates in two stages: in the first\\nstage, we fine-tune the pre-trained language model on the recommendation\\ndataset to transfer the pre-trained knowledge to the recommendation task; in\\nthe second stage, we distill the trained language model to transfer the learned\\nknowledge to a lightweight model. Extensive experiments on multiple public\\nrecommendation datasets show that the proposed algorithm enhances\\nrecommendation accuracy and provide timely recommendation services.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.14810v1.pdf'},\n",
       " {'id': '2012.06203v1',\n",
       "  'title': 'Selfish Creation of Social Networks',\n",
       "  'published': '2020-12-11T09:23:23Z',\n",
       "  'summary': 'Understanding real-world networks has been a core research endeavor\\nthroughout the last two decades. Network Creation Games are a promising\\napproach for this from a game-theoretic perspective. In these games, selfish\\nagents corresponding to nodes in a network strategically decide which links to\\nform to optimize their centrality. Many versions have been introduced and\\nanalyzed, but none of them fits to modeling the evolution of social networks.\\nIn real-world social networks, connections are often established by\\nrecommendations from common acquaintances or by a chain of such\\nrecommendations. Thus establishing and maintaining a contact with a friend of a\\nfriend is easier than connecting to complete strangers. This explains the high\\nclustering, i.e., the abundance of triangles, in real-world social networks.\\n  We propose and analyze a network creation model inspired by real-world social\\nnetworks. Edges are formed in our model via bilateral consent of both endpoints\\nand the cost for establishing and maintaining an edge is proportional to the\\ndistance of the endpoints before establishing the connection. We provide\\nresults for generic cost functions, which essentially only must be convex\\nfunctions in the distance of the endpoints without the respective edge. For\\nthis broad class of cost functions, we provide many structural properties of\\nequilibrium networks and prove (almost) tight bounds on the diameter, the Price\\nof Anarchy and the Price of Stability. Moreover, as a proof-of-concept we show\\nvia experiments that the created equilibrium networks of our model indeed\\nclosely mimics real-world social networks. We observe degree distributions that\\nseem to follow a power-law, high clustering, and low diameters. This can be\\nseen as a promising first step towards game-theoretic network creation models\\nthat predict networks featuring all core real-world properties.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.06203v1.pdf'},\n",
       " {'id': '2209.14035v1',\n",
       "  'title': 'Advising Autonomous Cars about the Rules of the Road',\n",
       "  'published': '2022-09-28T12:22:59Z',\n",
       "  'summary': 'This paper describes (R)ules (o)f (T)he (R)oad (A)dvisor, an agent that\\nprovides recommended and possible actions to be generated from a set of\\nhuman-level rules. We describe the architecture and design of RoTRA, both\\nformally and with an example. Specifically, we use RoTRA to formalise and\\nimplement the UK \"Rules of the Road\", and describe how this can be incorporated\\ninto autonomous cars such that they can reason internally about obeying the\\nrules of the road. In addition, the possible actions generated are annotated to\\nindicate whether the rules state that the action must be taken or that they\\nonly recommend that the action should be taken, as per the UK Highway Code\\n(Rules of The Road). The benefits of utilising this system include being able\\nto adapt to different regulations in different jurisdictions; allowing clear\\ntraceability from rules to behaviour, and providing an external automated\\naccountability mechanism that can check whether the rules were obeyed in some\\ngiven situation. A simulation of an autonomous car shows, via a concrete\\nexample, how trust can be built by putting the autonomous vehicle through a\\nnumber of scenarios which test the car\\'s ability to obey the rules of the road.\\nAutonomous cars that incorporate this system are able to ensure that they are\\nobeying the rules of the road and external (legal or regulatory) bodies can\\nverify that this is the case, without the vehicle or its manufacturer having to\\nexpose their source code or make their working transparent, thus allowing\\ngreater trust between car companies, jurisdictions, and the general public.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.14035v1.pdf'},\n",
       " {'id': '2304.10556v1',\n",
       "  'title': 'A Reference Model for Collaborative Business Intelligence Virtual\\n  Assistants',\n",
       "  'published': '2023-04-20T14:02:21Z',\n",
       "  'summary': 'Collaborative Business Analysis (CBA) is a methodology that involves bringing\\ntogether different stakeholders, including business users, analysts, and\\ntechnical specialists, to collaboratively analyze data and gain insights into\\nbusiness operations. The primary objective of CBA is to encourage knowledge\\nsharing and collaboration between the different groups involved in business\\nanalysis, as this can lead to a more comprehensive understanding of the data\\nand better decision-making. CBA typically involves a range of activities,\\nincluding data gathering and analysis, brainstorming, problem-solving,\\ndecision-making and knowledge sharing. These activities may take place through\\nvarious channels, such as in-person meetings, virtual collaboration tools or\\nonline forums. This paper deals with virtual collaboration tools as an\\nimportant part of Business Intelligence (BI) platform. Collaborative Business\\nIntelligence (CBI) tools are becoming more user-friendly, accessible, and\\nflexible, allowing users to customize their experience and adapt to their\\nspecific needs. The goal of a virtual assistant is to make data exploration\\nmore accessible to a wider range of users and to reduce the time and effort\\nrequired for data analysis. It describes the unified business intelligence\\nsemantic model, coupled with a data warehouse and collaborative unit to employ\\ndata mining technology. Moreover, we propose a virtual assistant for CBI and a\\nreference model of virtual tools for CBI, which consists of three components:\\nconversational, data exploration and recommendation agents. We believe that the\\nallocation of these three functional tasks allows you to structure the CBI\\nissue and apply relevant and productive models for human-like dialogue,\\ntext-to-command transferring, and recommendations simultaneously. The complex\\napproach based on these three points gives the basis for virtual tool for\\ncollaboration. CBI encourages people, processes, and technology to enable\\neveryone sharing and leveraging collective expertise, knowledge and data to\\ngain valuable insights for making better decisions. This allows to respond more\\nquickly and effectively to changes in the market or internal operations and\\nimprove the progress.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2304.10556v1.pdf'},\n",
       " {'id': '1804.11192v10',\n",
       "  'title': 'Explainable Recommendation: A Survey and New Perspectives',\n",
       "  'published': '2018-04-30T13:49:44Z',\n",
       "  'summary': 'Explainable recommendation attempts to develop models that generate not only\\nhigh-quality recommendations but also intuitive explanations. The explanations\\nmay either be post-hoc or directly come from an explainable model (also called\\ninterpretable or transparent model in some contexts). Explainable\\nrecommendation tries to address the problem of why: by providing explanations\\nto users or system designers, it helps humans to understand why certain items\\nare recommended by the algorithm, where the human can either be users or system\\ndesigners. Explainable recommendation helps to improve the transparency,\\npersuasiveness, effectiveness, trustworthiness, and satisfaction of\\nrecommendation systems. It also facilitates system designers for better system\\ndebugging. In recent years, a large number of explainable recommendation\\napproaches -- especially model-based methods -- have been proposed and applied\\nin real-world systems.\\n  In this survey, we provide a comprehensive review for the explainable\\nrecommendation research. We first highlight the position of explainable\\nrecommendation in recommender system research by categorizing recommendation\\nproblems into the 5W, i.e., what, when, who, where, and why. We then conduct a\\ncomprehensive survey of explainable recommendation on three perspectives: 1) We\\nprovide a chronological research timeline of explainable recommendation. 2) We\\nprovide a two-dimensional taxonomy to classify existing explainable\\nrecommendation research. 3) We summarize how explainable recommendation applies\\nto different recommendation tasks. We also devote a chapter to discuss the\\nexplanation perspectives in broader IR and AI/ML research. We end the survey by\\ndiscussing potential future directions to promote the explainable\\nrecommendation research area and beyond.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1804.11192v10.pdf'},\n",
       " {'id': '1311.6355v1',\n",
       "  'title': 'Exploration in Interactive Personalized Music Recommendation: A\\n  Reinforcement Learning Approach',\n",
       "  'published': '2013-11-06T12:20:35Z',\n",
       "  'summary': 'Current music recommender systems typically act in a greedy fashion by\\nrecommending songs with the highest user ratings. Greedy recommendation,\\nhowever, is suboptimal over the long term: it does not actively gather\\ninformation on user preferences and fails to recommend novel songs that are\\npotentially interesting. A successful recommender system must balance the needs\\nto explore user preferences and to exploit this information for recommendation.\\nThis paper presents a new approach to music recommendation by formulating this\\nexploration-exploitation trade-off as a reinforcement learning task called the\\nmulti-armed bandit. To learn user preferences, it uses a Bayesian model, which\\naccounts for both audio content and the novelty of recommendations. A\\npiecewise-linear approximation to the model and a variational inference\\nalgorithm are employed to speed up Bayesian inference. One additional benefit\\nof our approach is a single unified model for both music recommendation and\\nplaylist generation. Both simulation results and a user study indicate strong\\npotential for the new approach.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1311.6355v1.pdf'},\n",
       " {'id': '1501.01996v1',\n",
       "  'title': 'A probabilistic model to resolve diversity-accuracy challenge of\\n  recommendation systems',\n",
       "  'published': '2015-01-08T22:42:39Z',\n",
       "  'summary': 'Recommendation systems have wide-spread applications in both academia and\\nindustry. Traditionally, performance of recommendation systems has been\\nmeasured by their precision. By introducing novelty and diversity as key\\nqualities in recommender systems, recently increasing attention has been\\nfocused on this topic. Precision and novelty of recommendation are not in the\\nsame direction, and practical systems should make a trade-off between these two\\nquantities. Thus, it is an important feature of a recommender system to make it\\npossible to adjust diversity and accuracy of the recommendations by tuning the\\nmodel. In this paper, we introduce a probabilistic structure to resolve the\\ndiversity-accuracy dilemma in recommender systems. We propose a hybrid model\\nwith adjustable level of diversity and precision such that one can perform this\\nby tuning a single parameter. The proposed recommendation model consists of two\\nmodels: one for maximization of the accuracy and the other one for\\nspecification of the recommendation list to tastes of users. Our experiments on\\ntwo real datasets show the functionality of the model in resolving\\naccuracy-diversity dilemma and outperformance of the model over other classic\\nmodels. The proposed method could be extensively applied to real commercial\\nsystems due to its low computational complexity and significant performance.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1501.01996v1.pdf'},\n",
       " {'id': '1808.06581v2',\n",
       "  'title': 'The Deconfounded Recommender: A Causal Inference Approach to\\n  Recommendation',\n",
       "  'published': '2018-08-20T17:41:39Z',\n",
       "  'summary': 'The goal of recommendation is to show users items that they will like. Though\\nusually framed as a prediction, the spirit of recommendation is to answer an\\ninterventional question---for each user and movie, what would the rating be if\\nwe \"forced\" the user to watch the movie? To this end, we develop a causal\\napproach to recommendation, one where watching a movie is a \"treatment\" and a\\nuser\\'s rating is an \"outcome.\" The problem is there may be unobserved\\nconfounders, variables that affect both which movies the users watch and how\\nthey rate them; unobserved confounders impede causal predictions with\\nobservational data. To solve this problem, we develop the deconfounded\\nrecommender, a way to use classical recommendation models for causal\\nrecommendation. Following Wang & Blei [23], the deconfounded recommender\\ninvolves two probabilistic models. The first models which movies the users\\nwatch; it provides a substitute for the unobserved confounders. The second one\\nmodels how each user rates each movie; it employs the substitute to help\\naccount for confounders. This two-stage approach removes bias due to\\nconfounding. It improves recommendation and enjoys stable performance against\\ninterventions on test sets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1808.06581v2.pdf'},\n",
       " {'id': '1809.09030v1',\n",
       "  'title': 'A Fairness-aware Hybrid Recommender System',\n",
       "  'published': '2018-09-13T00:30:52Z',\n",
       "  'summary': \"Recommender systems are used in variety of domains affecting people's lives.\\nThis has raised concerns about possible biases and discrimination that such\\nsystems might exacerbate. There are two primary kinds of biases inherent in\\nrecommender systems: observation bias and bias stemming from imbalanced data.\\nObservation bias exists due to a feedback loop which causes the model to learn\\nto only predict recommendations similar to previous ones. Imbalance in data\\noccurs when systematic societal, historical, or other ambient bias is present\\nin the data. In this paper, we address both biases by proposing a hybrid\\nfairness-aware recommender system. Our model provides efficient and accurate\\nrecommendations by incorporating multiple user-user and item-item similarity\\nmeasures, content, and demographic information, while addressing recommendation\\nbiases. We implement our model using a powerful and expressive probabilistic\\nprogramming language called probabilistic soft logic. We experimentally\\nevaluate our approach on a popular movie recommendation dataset, showing that\\nour proposed model can provide more accurate and fairer recommendations,\\ncompared to a state-of-the art fair recommender system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1809.09030v1.pdf'},\n",
       " {'id': '1910.12735v2',\n",
       "  'title': 'Learning to Recommend from Sparse Data via Generative User Feedback',\n",
       "  'published': '2019-10-21T01:31:07Z',\n",
       "  'summary': 'Traditional collaborative filtering (CF) based recommender systems tend to\\nperform poorly when the user-item interactions/ratings are highly scarce. To\\naddress this, we propose a learning framework that improves collaborative\\nfiltering with a synthetic feedback loop (CF-SFL) to simulate the user\\nfeedback. The proposed framework consists of a \"recommender\" and a \"virtual\\nuser\". The \"recommender\" is formulated as a CF model, recommending items\\naccording to observed user preference. The \"virtual user\" estimates rewards\\nfrom the recommended items and generates a \\\\emph{feedback} in addition to the\\nobserved user preference. The \"recommender\" connected with the \"virtual user\"\\nconstructs a closed loop, that recommends users with items and imitates the\\n\\\\emph{unobserved} feedback of the users to the recommended items. The synthetic\\nfeedback is used to augment the observed user preference and improve\\nrecommendation results. Theoretically, such model design can be interpreted as\\ninverse reinforcement learning, which can be learned effectively via rollout\\n(simulation). Experimental results show that the proposed framework is able to\\nenrich the learning of user preference and boost the performance of existing\\ncollaborative filtering methods on multiple datasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1910.12735v2.pdf'},\n",
       " {'id': '1905.06134v1',\n",
       "  'title': 'Recommending Dream Jobs in a Biased Real World',\n",
       "  'published': '2019-05-10T19:26:01Z',\n",
       "  'summary': 'Machine learning models learn what we teach them to learn. Machine learning\\nis at the heart of recommender systems. If a machine learning model is trained\\non biased data, the resulting recommender system may reflect the biases in its\\nrecommendations. Biases arise at different stages in a recommender system, from\\nexisting societal biases in the data such as the professional gender gap, to\\nbiases introduced by the data collection or modeling processes. These biases\\nimpact the performance of various components of recommender systems, from\\noffline training, to evaluation and online serving of recommendations in\\nproduction systems. Specific techniques can help reduce bias at each stage of a\\nrecommender system. Reducing bias in our recommender systems is crucial to\\nsuccessfully recommending dream jobs to hundreds of millions members worldwide,\\nwhile being true to LinkedIn\\'s vision: \"To create economic opportunity for\\nevery member of the global workforce\".',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.06134v1.pdf'},\n",
       " {'id': '1508.01696v1',\n",
       "  'title': 'A Location-Based Movie Recommender System Using Collaborative Filtering',\n",
       "  'published': '2015-08-07T14:03:41Z',\n",
       "  'summary': 'Available recommender systems mostly provide recommendations based on the\\nusers preferences by utilizing traditional methods such as collaborative\\nfiltering which only relies on the similarities between users and items.\\nHowever, collaborative filtering might lead to provide poor recommendation\\nbecause it does not rely on other useful available data such as users locations\\nand hence the accuracy of the recommendations could be very low and\\ninefficient. This could be very obvious in the systems that locations would\\naffect users preferences highly such as movie recommender systems. In this\\npaper a new location-based movie recommender system based on the collaborative\\nfiltering is introduced for enhancing the accuracy and the quality of\\nrecommendations. In this approach, users locations have been utilized and take\\nin consideration in the entire processing of the recommendations and peer\\nselections. The potential of the proposed approach in providing novel and\\nbetter quality recommendations have been discussed through experiments in real\\ndatasets.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1508.01696v1.pdf'},\n",
       " {'id': '1708.07289v1',\n",
       "  'title': 'Family Shopping Recommendation System Using User Profile and Behavior\\n  Data',\n",
       "  'published': '2017-08-24T06:33:50Z',\n",
       "  'summary': 'With the arrival of the big data era, recommendation system has been a hot\\ntechnology for enterprises to streamline their sales. Recommendation algorithms\\nfor individual users have been extensively studied over the past decade. Most\\nexisting recommendation systems also focus on individual user recommendations,\\nhowever in many daily activities, items are recommended to the groups not one\\nperson. As an effective means to solve the problem of group recommendation\\nproblem,we extend the single user recommendation to group recommendation.\\nSpecifically we propose a novel approach for family-based shopping\\nrecommendation system. We use the dataset from the real shopping mall\\nconsisting of shopping records table, client-profile table and family\\nrelationship table. Our algorithm integrates user behavior similarity and user\\nprofile similarity to build the user based collaborative filtering model. We\\nevaluate our approach on a real-world shopping mall dataset.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1708.07289v1.pdf'},\n",
       " {'id': '1710.07134v1',\n",
       "  'title': 'UniWalk: Explainable and Accurate Recommendation for Rating and Network\\n  Data',\n",
       "  'published': '2017-10-18T12:40:12Z',\n",
       "  'summary': \"How can we leverage social network data and observed ratings to correctly\\nrecommend proper items and provide a persuasive explanation for the\\nrecommendations? Many online services provide social networks among users, and\\nit is crucial to utilize social information since recommendation by a friend is\\nmore likely to grab attention than the one from a random user. Also, explaining\\nwhy items are recommended is very important in encouraging the users' actions\\nsuch as actual purchases. Exploiting both ratings and social graph for\\nrecommendation, however, is not trivial because of the heterogeneity of the\\ndata.\\n  In this paper, we propose UniWalk, an explainable and accurate recommender\\nsystem that exploits both social network and rating data. UniWalk combines both\\ndata into a unified graph, learns latent features of users and items, and\\nrecommends items to each user through the features. Importantly, it explains\\nwhy items are recommended together with the recommendation results. Extensive\\nexperiments show that UniWalk provides the best explainability and achieves the\\nstate-of-the-art-accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1710.07134v1.pdf'},\n",
       " {'id': '1710.08516v1',\n",
       "  'title': 'Interpreting Contextual Effects By Contextual Modeling In Recommender\\n  Systems',\n",
       "  'published': '2017-10-23T21:49:49Z',\n",
       "  'summary': \"Recommender systems have been widely applied to assist user's decision making\\nby providing a list of personalized item recommendations. Context-aware\\nrecommender systems (CARS) additionally take context information into\\nconsidering in the recommendation process, since user's tastes on the items may\\nvary from contexts to contexts. Several context-aware recommendation algorithms\\nhave been proposed and developed to improve the quality of recommendations.\\nHowever, there are limited research which explore and discuss the capability of\\ninterpreting the contextual effects by the recommendation models. In this\\npaper, we specifically focus on different contextual modeling approaches,\\nreshape the structure of the models, and exploit how to utilize the existing\\ncontextual modeling to interpret the contextual effects in the recommender\\nsystems. We compare the explanations of contextual effects, as well as the\\nrecommendation performance over two-real world data sets in order to examine\\nthe quality of interpretations.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1710.08516v1.pdf'},\n",
       " {'id': '1812.02646v1',\n",
       "  'title': 'RepeatNet: A Repeat Aware Neural Recommendation Machine for\\n  Session-based Recommendation',\n",
       "  'published': '2018-12-06T16:30:33Z',\n",
       "  'summary': \"Recurrent neural networks for session-based recommendation have attracted a\\nlot of attention recently because of their promising performance. repeat\\nconsumption is a common phenomenon in many recommendation scenarios (e.g.,\\ne-commerce, music, and TV program recommendations), where the same item is\\nre-consumed repeatedly over time. However, no previous studies have emphasized\\nrepeat consumption with neural networks. An effective neural approach is needed\\nto decide when to perform repeat recommendation. In this paper, we incorporate\\na repeat-explore mechanism into neural networks and propose a new model, called\\nRepeatNet, with an encoder-decoder structure. RepeatNet integrates a regular\\nneural recommendation approach in the decoder with a new repeat recommendation\\nmechanism that can choose items from a user's history and recommends them at\\nthe right time. We report on extensive experiments on three benchmark datasets.\\nRepeatNet outperforms state-of-the-art baselines on all three datasets in terms\\nof MRR and Recall. Furthermore, as the dataset size and the repeat ratio\\nincrease, the improvements of RepeatNet over the baselines also increase, which\\ndemonstrates its advantage in handling repeat recommendation scenarios.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1812.02646v1.pdf'},\n",
       " {'id': '2007.04782v1',\n",
       "  'title': 'A Systematic Review on Context-Aware Recommender Systems using Deep\\n  Learning and Embeddings',\n",
       "  'published': '2020-07-09T13:23:40Z',\n",
       "  'summary': 'Recommender Systems are tools that improve how users find relevant\\ninformation in web systems, so they do not face too much information. In order\\nto generate better recommendations, the context of information should be used\\nin the recommendation process. Context-Aware Recommender Systems were created,\\naccomplishing state-of-the-art results and improving traditional recommender\\nsystems. There are many approaches to build recommender systems, and two of the\\nmost prominent advances in area have been the use of Embeddings to represent\\nthe data in the recommender system, and the use of Deep Learning architectures\\nto generate the recommendations to the user. A systematic review adopts a\\nformal and systematic method to perform a bibliographic review, and it is used\\nto identify and evaluate all the research in certain area of study, by\\nanalyzing the relevant research published. A systematic review was conducted to\\nunderstand how the Deep Learning and Embeddings techniques are being applied to\\nimprove Context-Aware Recommender Systems. We summarized the architectures that\\nare used to create those and the domains that they are used.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.04782v1.pdf'},\n",
       " {'id': '2007.05911v1',\n",
       "  'title': 'Graph Factorization Machines for Cross-Domain Recommendation',\n",
       "  'published': '2020-07-12T04:56:10Z',\n",
       "  'summary': \"Recently, graph neural networks (GNNs) have been successfully applied to\\nrecommender systems. In recommender systems, the user's feedback behavior on an\\nitem is usually the result of multiple factors acting at the same time.\\nHowever, a long-standing challenge is how to effectively aggregate multi-order\\ninteractions in GNN. In this paper, we propose a Graph Factorization Machine\\n(GFM) which utilizes the popular Factorization Machine to aggregate multi-order\\ninteractions from neighborhood for recommendation. Meanwhile, cross-domain\\nrecommendation has emerged as a viable method to solve the data sparsity\\nproblem in recommender systems. However, most existing cross-domain\\nrecommendation methods might fail when confronting the graph-structured data.\\nIn order to tackle the problem, we propose a general cross-domain\\nrecommendation framework which can be applied not only to the proposed GFM, but\\nalso to other GNN models. We conduct experiments on four pairs of datasets to\\ndemonstrate the superior performance of the GFM. Besides, based on general\\ncross-domain recommendation experiments, we also demonstrate that our\\ncross-domain framework could not only contribute to the cross-domain\\nrecommendation task with the GFM, but also be universal and expandable for\\nvarious existing GNN models.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.05911v1.pdf'},\n",
       " {'id': '2007.12329v2',\n",
       "  'title': 'Long-tail Session-based Recommendation',\n",
       "  'published': '2020-07-24T03:36:35Z',\n",
       "  'summary': 'Session-based recommendation focuses on the prediction of user actions based\\non anonymous sessions and is a necessary method in the lack of user historical\\ndata. However, none of the existing session-based recommendation methods\\nexplicitly takes the long-tail recommendation into consideration, which plays\\nan important role in improving the diversity of recommendation and producing\\nthe serendipity. As the distribution of items with long-tail is prevalent in\\nsession-based recommendation scenarios (e.g., e-commerce, music, and TV program\\nrecommendations), more attention should be put on the long-tail session-based\\nrecommendation. In this paper, we propose a novel network architecture, namely\\nTailNet, to improve long-tail recommendation performance, while maintaining\\ncompetitive accuracy performance compared with other methods. We start by\\nclassifying items into short-head (popular) and long-tail (niche) items based\\non click frequency. Then a novel is proposed and applied in TailNet to\\ndetermine user preference between two types of items, so as to softly adjust\\nand personalize recommendations. Extensive experiments on two real-world\\ndatasets verify the superiority of our method compared with state-of-the-art\\nworks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.12329v2.pdf'},\n",
       " {'id': '1909.09551v1',\n",
       "  'title': 'Natural Language Processing via LDA Topic Model in Recommendation\\n  Systems',\n",
       "  'published': '2019-09-20T15:08:51Z',\n",
       "  'summary': 'Today, Internet is one of the widest available media worldwide.\\nRecommendation systems are increasingly being used in various applications such\\nas movie recommendation, mobile recommendation, article recommendation and etc.\\nCollaborative Filtering (CF) and Content-Based (CB) are Well-known techniques\\nfor building recommendation systems. Topic modeling based on LDA, is a powerful\\ntechnique for semantic mining and perform topic extraction. In the past few\\nyears, many articles have been published based on LDA technique for building\\nrecommendation systems. In this paper, we present taxonomy of recommendation\\nsystems and applications based on LDA. In addition, we utilize LDA and Gibbs\\nsampling algorithms to evaluate ISWC and WWW conference publications in\\ncomputer science. Our study suggest that the recommendation systems based on\\nLDA could be effective in building smart recommendation system in online\\ncommunities.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1909.09551v1.pdf'},\n",
       " {'id': '2006.10966v1',\n",
       "  'title': 'Feature Interaction Interpretability: A Case for Explaining\\n  Ad-Recommendation Systems via Neural Interaction Detection',\n",
       "  'published': '2020-06-19T05:14:34Z',\n",
       "  'summary': \"Recommendation is a prevalent application of machine learning that affects\\nmany users; therefore, it is important for recommender models to be accurate\\nand interpretable. In this work, we propose a method to both interpret and\\naugment the predictions of black-box recommender systems. In particular, we\\npropose to interpret feature interactions from a source recommender model and\\nexplicitly encode these interactions in a target recommender model, where both\\nsource and target models are black-boxes. By not assuming the structure of the\\nrecommender system, our approach can be used in general settings. In our\\nexperiments, we focus on a prominent use of machine learning recommendation:\\nad-click prediction. We found that our interaction interpretations are both\\ninformative and predictive, e.g., significantly outperforming existing\\nrecommender models. What's more, the same approach to interpret interactions\\ncan provide new insights into domains even beyond recommendation, such as text\\nand image classification.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.10966v1.pdf'},\n",
       " {'id': '2006.15772v2',\n",
       "  'title': 'Multi-sided Exposure Bias in Recommendation',\n",
       "  'published': '2020-06-29T02:00:25Z',\n",
       "  'summary': \"Academic research in recommender systems has been greatly focusing on the\\naccuracy-related measures of recommendations. Even when non-accuracy measures\\nsuch as popularity bias, diversity, and novelty are studied, it is often solely\\nfrom the users' perspective. However, many real-world recommenders are often\\nmulti-stakeholder environments in which the needs and interests of several\\nstakeholders should be addressed in the recommendation process. In this paper,\\nwe focus on the popularity bias problem which is a well-known property of many\\nrecommendation algorithms where few popular items are over-recommended while\\nthe majority of other items do not get proportional attention and address its\\nimpact on different stakeholders. Using several recommendation algorithms and\\ntwo publicly available datasets in music and movie domains, we empirically show\\nthe inherent popularity bias of the algorithms and how this bias impacts\\ndifferent stakeholders such as users and suppliers of the items. We also\\npropose metrics to measure the exposure bias of recommendation algorithms from\\nthe perspective of different stakeholders.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2006.15772v2.pdf'},\n",
       " {'id': '2008.09273v1',\n",
       "  'title': 'The Connection Between Popularity Bias, Calibration, and Fairness in\\n  Recommendation',\n",
       "  'published': '2020-08-21T02:33:17Z',\n",
       "  'summary': \"Recently there has been a growing interest in fairness-aware recommender\\nsystems including fairness in providing consistent performance across different\\nusers or groups of users. A recommender system could be considered unfair if\\nthe recommendations do not fairly represent the tastes of a certain group of\\nusers while other groups receive recommendations that are consistent with their\\npreferences. In this paper, we use a metric called miscalibration for measuring\\nhow a recommendation algorithm is responsive to users' true preferences and we\\nconsider how various algorithms may result in different degrees of\\nmiscalibration for different users. In particular, we conjecture that\\npopularity bias which is a well-known phenomenon in recommendation is one\\nimportant factor leading to miscalibration in recommendation. Our experimental\\nresults using two real-world datasets show that there is a connection between\\nhow different user groups are affected by algorithmic popularity bias and their\\nlevel of interest in popular items. Moreover, we show that the more a group is\\naffected by the algorithmic popularity bias, the more their recommendations are\\nmiscalibrated.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2008.09273v1.pdf'},\n",
       " {'id': '1303.3875v1',\n",
       "  'title': 'F1000 recommendations as a new data source for research evaluation: A\\n  comparison with citations',\n",
       "  'published': '2013-03-15T19:33:34Z',\n",
       "  'summary': 'F1000 is a post-publication peer review service for biological and medical\\nresearch. F1000 aims to recommend important publications in the biomedical\\nliterature, and from this perspective F1000 could be an interesting tool for\\nresearch evaluation. By linking the complete database of F1000 recommendations\\nto the Web of Science bibliographic database, we are able to make a\\ncomprehensive comparison between F1000 recommendations and citations. We find\\nthat about 2% of the publications in the biomedical literature receive at least\\none F1000 recommendation. Recommended publications on average receive 1.30\\nrecommendations, and over 90% of the recommendations are given within half a\\nyear after a publication has appeared. There turns out to be a clear\\ncorrelation between F1000 recommendations and citations. However, the\\ncorrelation is relatively weak, at least weaker than the correlation between\\njournal impact and citations. More research is needed to identify the main\\nreasons for differences between recommendations and citations in assessing the\\nimpact of publications.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1303.3875v1.pdf'},\n",
       " {'id': '2002.01264v2',\n",
       "  'title': 'Boosting API Recommendation with Implicit Feedback',\n",
       "  'published': '2020-02-04T12:51:59Z',\n",
       "  'summary': \"Developers often need to use appropriate APIs to program efficiently, but it\\nis usually a difficult task to identify the exact one they need from a vast of\\ncandidates. To ease the burden, a multitude of API recommendation approaches\\nhave been proposed. However, most of the currently available API recommenders\\ndo not support the effective integration of users' feedback into the\\nrecommendation loop. In this paper, we propose a framework, BRAID (Boosting\\nRecommendAtion with Implicit FeeDback), which leverages learning-to-rank and\\nactive learning techniques to boost recommendation performance. By exploiting\\nusers' feedback information, we train a learning-to-rank model to re-rank the\\nrecommendation results. In addition, we speed up the feedback learning process\\nwith active learning. Existing query-based API recommendation approaches can be\\nplugged into BRAID. We select three state-of-the-art API recommendation\\napproaches as baselines to demonstrate the performance enhancement of BRAID\\nmeasured by Hit@k (Top-k), MAP, and MRR. Empirical experiments show that, with\\nacceptable overheads, the recommendation performance improves steadily and\\nsubstantially with the increasing percentage of feedback data, comparing with\\nthe baselines.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2002.01264v2.pdf'},\n",
       " {'id': '2005.03954v3',\n",
       "  'title': 'Towards Conversational Recommendation over Multi-Type Dialogs',\n",
       "  'published': '2020-05-08T11:01:21Z',\n",
       "  'summary': \"We propose a new task of conversational recommendation over multi-type\\ndialogs, where the bots can proactively and naturally lead a conversation from\\na non-recommendation dialog (e.g., QA) to a recommendation dialog, taking into\\naccount user's interests and feedback. To facilitate the study of this task, we\\ncreate a human-to-human Chinese dialog dataset \\\\emph{DuRecDial} (about 10k\\ndialogs, 156k utterances), which contains multiple sequential dialogs for every\\npair of a recommendation seeker (user) and a recommender (bot). In each dialog,\\nthe recommender proactively leads a multi-type dialog to approach\\nrecommendation targets and then makes multiple recommendations with rich\\ninteraction behavior. This dataset allows us to systematically investigate\\ndifferent parts of the overall problem, e.g., how to naturally lead a dialog,\\nhow to interact with users for recommendation. Finally we establish baseline\\nresults on DuRecDial for future studies. Dataset and codes are publicly\\navailable at\\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2005.03954v3.pdf'},\n",
       " {'id': '2010.01258v1',\n",
       "  'title': 'Hit ratio: An Evaluation Metric for Hashtag Recommendation',\n",
       "  'published': '2020-10-03T02:07:41Z',\n",
       "  'summary': 'Hashtag recommendation is a crucial task, especially with an increase of\\ninterest in using social media platforms such as Twitter in the last decade.\\nHashtag recommendation systems automatically suggest hashtags to a user while\\nwriting a tweet. Most of the research in the area of hashtag recommendation\\nhave used classical metrics such as hit rate, precision, recall, and F1-score\\nto measure the accuracy of hashtag recommendation systems. These metrics are\\nbased on the exact match of the recommended hashtags with their corresponding\\nground truth. However, it is not clear how adequate these metrics to evaluate\\nhashtag recommendation. The research question that we are interested in seeking\\nan answer is: are these metrics adequate for evaluating hashtag recommendation\\nsystems when the numbers of ground truth hashtags in tweets are highly\\nvariable? In this paper, we propose a new metric which we call hit ratio for\\nhashtag recommendation. Extensive evaluation through hypothetical examples and\\nreal-world application across a range of hashtag recommendation models indicate\\nthat the hit ratio is a useful metric. A comparison of hit ratio with the\\nclassical evaluation metrics reveals their limitations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2010.01258v1.pdf'},\n",
       " {'id': '2105.01004v1',\n",
       "  'title': 'Automatic Collection Creation and Recommendation',\n",
       "  'published': '2021-05-03T16:51:21Z',\n",
       "  'summary': 'We present a collection recommender system that can automatically create and\\nrecommend collections of items at a user level. Unlike regular recommender\\nsystems, which output top-N relevant items, a collection recommender system\\noutputs collections of items such that the items in the collections are\\nrelevant to a user, and the items within a collection follow a specific theme.\\nOur system builds on top of the user-item representations learnt by item\\nrecommender systems. We employ dimensionality reduction and clustering\\ntechniques along with intuitive heuristics to create collections with their\\nratings and titles.\\n  We test these ideas in a real-world setting of music recommendation, within a\\npopular music streaming service. We find that there is a 2.3x increase in\\nrecommendation-driven consumption when recommending collections over items.\\nFurther, it results in effective utilization of real estate and leads to\\nrecommending a more and diverse set of items. To our knowledge, these are first\\nof its kind experiments at such a large scale.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.01004v1.pdf'},\n",
       " {'id': '2109.08949v2',\n",
       "  'title': 'Inductive Conformal Recommender System',\n",
       "  'published': '2021-09-18T15:06:33Z',\n",
       "  'summary': \"Traditional recommendation algorithms develop techniques that can help people\\nto choose desirable items. However, in many real-world applications, along with\\na set of recommendations, it is also essential to quantify each\\nrecommendation's (un)certainty. The conformal recommender system uses the\\nexperience of a user to output a set of recommendations, each associated with a\\nprecise confidence value. Given a significance level $\\\\varepsilon$, it provides\\na bound $\\\\varepsilon$ on the probability of making a wrong recommendation. The\\nconformal framework uses a key concept called \\\\emph{nonconformity measure} that\\nmeasures the strangeness of an item concerning other items. One of the\\nsignificant design challenges of any conformal recommendation framework is\\nintegrating nonconformity measures with the recommendation algorithm. This\\npaper introduces an inductive variant of a conformal recommender system. We\\npropose and analyze different nonconformity measures in the inductive setting.\\nWe also provide theoretical proofs on the error-bound and the time complexity.\\nExtensive empirical analysis on ten benchmark datasets demonstrates that the\\ninductive variant substantially improves the performance in computation time\\nwhile preserving the accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.08949v2.pdf'},\n",
       " {'id': '2110.08353v1',\n",
       "  'title': 'Revisiting Popularity and Demographic Biases in Recommender Evaluation\\n  and Effectiveness',\n",
       "  'published': '2021-10-15T20:30:51Z',\n",
       "  'summary': 'Recommendation algorithms are susceptible to popularity bias: a tendency to\\nrecommend popular items even when they fail to meet user needs. A related issue\\nis that the recommendation quality can vary by demographic groups. Marginalized\\ngroups or groups that are under-represented in the training data may receive\\nless relevant recommendations from these algorithms compared to others. In a\\nrecent study, Ekstrand et al. investigate how recommender performance varies\\naccording to popularity and demographics, and find statistically significant\\ndifferences in recommendation utility between binary genders on two datasets,\\nand significant effects based on age on one dataset. Here we reproduce those\\nresults and extend them with additional analyses. We find statistically\\nsignificant differences in recommender performance by both age and gender. We\\nobserve that recommendation utility steadily degrades for older users, and is\\nlower for women than men. We also find that the utility is higher for users\\nfrom countries with more representation in the dataset. In addition, we find\\nthat total usage and the popularity of consumed content are strong predictors\\nof recommender performance and also vary significantly across demographic\\ngroups.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2110.08353v1.pdf'},\n",
       " {'id': '2207.06674v1',\n",
       "  'title': 'Reinforced Path Reasoning for Counterfactual Explainable Recommendation',\n",
       "  'published': '2022-07-14T05:59:58Z',\n",
       "  'summary': \"Counterfactual explanations interpret the recommendation mechanism via\\nexploring how minimal alterations on items or users affect the recommendation\\ndecisions. Existing counterfactual explainable approaches face huge search\\nspace and their explanations are either action-based (e.g., user click) or\\naspect-based (i.e., item description). We believe item attribute-based\\nexplanations are more intuitive and persuadable for users since they explain by\\nfine-grained item demographic features (e.g., brand). Moreover, counterfactual\\nexplanation could enhance recommendations by filtering out negative items.\\n  In this work, we propose a novel Counterfactual Explainable Recommendation\\n(CERec) to generate item attribute-based counterfactual explanations meanwhile\\nto boost recommendation performance. Our CERec optimizes an explanation policy\\nupon uniformly searching candidate counterfactuals within a reinforcement\\nlearning environment. We reduce the huge search space with an adaptive path\\nsampler by using rich context information of a given knowledge graph. We also\\ndeploy the explanation policy to a recommendation model to enhance the\\nrecommendation. Extensive explainability and recommendation evaluations\\ndemonstrate CERec's ability to provide explanations consistent with user\\npreferences and maintain improved recommendations. We release our code at\\nhttps://github.com/Chrystalii/CERec.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2207.06674v1.pdf'},\n",
       " {'id': '2208.10692v2',\n",
       "  'title': 'Towards Communication Efficient and Fair Federated Personalized\\n  Sequential Recommendation',\n",
       "  'published': '2022-08-23T02:28:48Z',\n",
       "  'summary': 'Federated recommendations leverage the federated learning (FL) techniques to\\nmake privacy-preserving recommendations. Though recent success in the federated\\nrecommender system, several vital challenges remain to be addressed: (i) The\\nmajority of federated recommendation models only consider the model performance\\nand the privacy-preserving ability, while ignoring the optimization of the\\ncommunication process; (ii) Most of the federated recommenders are designed for\\nheterogeneous systems, causing unfairness problems during the federation\\nprocess; (iii) The personalization techniques have been less explored in many\\nfederated recommender systems.\\n  In this paper, we propose a Communication efficient and Fair personalized\\nFederated personalized Sequential Recommendation algorithm (CF-FedSR) to tackle\\nthese challenges. CF-FedSR introduces a communication-efficient scheme that\\nemploys adaptive client selection and clustering-based sampling to accelerate\\nthe training process. A fairness-aware model aggregation algorithm that can\\nadaptively capture the data and performance imbalance among different clients\\nto address the unfairness problems is proposed. The personalization module\\nassists clients in making personalized recommendations and boosts the\\nrecommendation performance via local fine-tuning and model adaption. Extensive\\nexperimental results show the effectiveness and efficiency of our proposed\\nmethod.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2208.10692v2.pdf'},\n",
       " {'id': '2209.01860v1',\n",
       "  'title': 'A Brief History of Recommender Systems',\n",
       "  'published': '2022-09-05T09:38:23Z',\n",
       "  'summary': 'Soon after the invention of the Internet, the recommender system emerged and\\nrelated technologies have been extensively studied and applied by both academia\\nand industry. Currently, recommender system has become one of the most\\nsuccessful web applications, serving billions of people in each day through\\nrecommending different kinds of contents, including news feeds, videos,\\ne-commerce products, music, movies, books, games, friends, jobs etc. These\\nsuccessful stories have proved that recommender system can transfer big data to\\nhigh values. This article briefly reviews the history of web recommender\\nsystems, mainly from two aspects: (1) recommendation models, (2) architectures\\nof typical recommender systems. We hope the brief review can help us to know\\nthe dots about the progress of web recommender systems, and the dots will\\nsomehow connect in the future, which inspires us to build more advanced\\nrecommendation services for changing the world better.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.01860v1.pdf'},\n",
       " {'id': '2209.01874v4',\n",
       "  'title': 'The Best Decisions Are Not the Best Advice: Making Adherence-Aware\\n  Recommendations',\n",
       "  'published': '2022-09-05T10:11:09Z',\n",
       "  'summary': \"Many high-stake decisions follow an expert-in-loop structure in that a human\\noperator receives recommendations from an algorithm but is the ultimate\\ndecision maker. Hence, the algorithm's recommendation may differ from the\\nactual decision implemented in practice. However, most algorithmic\\nrecommendations are obtained by solving an optimization problem that assumes\\nrecommendations will be perfectly implemented. We propose an adherence-aware\\noptimization framework to capture the dichotomy between the recommended and the\\nimplemented policy and analyze the impact of partial adherence on the optimal\\nrecommendation. We show that overlooking the partial adherence phenomenon, as\\nis currently being done by most recommendation engines, can lead to arbitrarily\\nsevere performance deterioration, compared with both the current human baseline\\nperformance and what is expected by the recommendation algorithm. Our framework\\nalso provides useful tools to analyze the structure and to compute optimal\\nrecommendation policies that are naturally immune against such human\\ndeviations, and are guaranteed to improve upon the baseline policy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2209.01874v4.pdf'},\n",
       " {'id': '2211.08799v1',\n",
       "  'title': 'Speeding Up Recommender Systems Using Association Rules',\n",
       "  'published': '2022-11-16T09:55:15Z',\n",
       "  'summary': 'Recommender systems are considered one of the most rapidly growing branches\\nof Artificial Intelligence. The demand for finding more efficient techniques to\\ngenerate recommendations becomes urgent. However, many recommendations become\\nuseless if there is a delay in generating and showing them to the user.\\nTherefore, we focus on improving the speed of recommendation systems without\\nimpacting the accuracy. In this paper, we suggest a novel recommender system\\nbased on Factorization Machines and Association Rules (FMAR). We introduce an\\napproach to generate association rules using two algorithms: (i) apriori and\\n(ii) frequent pattern (FP) growth. These association rules will be utilized to\\nreduce the number of items passed to the factorization machines recommendation\\nmodel. We show that FMAR has significantly decreased the number of new items\\nthat the recommender system has to predict and hence, decreased the required\\ntime for generating the recommendations. On the other hand, while building the\\nFMAR tool, we concentrate on making a balance between prediction time and\\naccuracy of generated recommendations to ensure that the accuracy is not\\nsignificantly impacted compared to the accuracy of using factorization machines\\nwithout association rules.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2211.08799v1.pdf'},\n",
       " {'id': '2302.09803v1',\n",
       "  'title': 'Dynamic Adaptation of User Preferences and Results in a Destination\\n  Recommender System',\n",
       "  'published': '2023-02-20T07:00:42Z',\n",
       "  'summary': \"Studying human factors has gained a lot of interest in recommender systems\\nresearch recently. User experience plays a vital role in tourism recommender\\nsystems since user satisfaction is the main factor that guarantees the success\\nof such recommender systems. In this work, we have designed and implemented a\\ndestination recommender system in which the recommendations adapt instantly\\nbased on the user preferences. The recommendations can be explored on a world\\nmap with additional information. This interface addresses common visualization\\nchallenges in recommender systems, such as transparency, justification,\\ncontrollability, explorability, the cold-start problem, and context awareness.\\nWe have conducted a user study to evaluate different aspects of this\\nrecommender system from the users' perspective.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2302.09803v1.pdf'},\n",
       " {'id': '2305.15431v1',\n",
       "  'title': 'Exploring and Exploiting Data Heterogeneity in Recommendation',\n",
       "  'published': '2023-05-21T11:01:14Z',\n",
       "  'summary': 'Massive amounts of data are the foundation of data-driven recommendation\\nmodels. As an inherent nature of big data, data heterogeneity widely exists in\\nreal-world recommendation systems. It reflects the differences in the\\nproperties among sub-populations. Ignoring the heterogeneity in recommendation\\ndata could limit the performance of recommendation models, hurt the\\nsub-populational robustness, and make the models misled by biases. However,\\ndata heterogeneity has not attracted substantial attention in the\\nrecommendation community. Therefore, it inspires us to adequately explore and\\nexploit heterogeneity for solving the above problems and assisting data\\nanalysis. In this work, we focus on exploring two representative categories of\\nheterogeneity in recommendation data that is the heterogeneity of prediction\\nmechanism and covariate distribution and propose an algorithm that explores the\\nheterogeneity through a bilevel clustering method. Furthermore, the uncovered\\nheterogeneity is exploited for two purposes in recommendation scenarios which\\nare prediction with multiple sub-models and supporting debias. Extensive\\nexperiments on real-world data validate the existence of heterogeneity in\\nrecommendation data and the effectiveness of exploring and exploiting data\\nheterogeneity in recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.15431v1.pdf'},\n",
       " {'id': '2311.08511v1',\n",
       "  'title': 'CoRE-CoG: Conversational Recommendation of Entities using Constrained\\n  Generation',\n",
       "  'published': '2023-11-14T20:07:34Z',\n",
       "  'summary': 'End-to-end conversational recommendation systems (CRS) generate responses by\\nleveraging both dialog history and a knowledge base (KB). A CRS mainly faces\\nthree key challenges: (1) at each turn, it must decide if recommending a KB\\nentity is appropriate; if so, it must identify the most relevant KB entity to\\nrecommend; and finally, it must recommend the entity in a fluent utterance that\\nis consistent with the conversation history. Recent CRSs do not pay sufficient\\nattention to these desiderata, often generating unfluent responses or not\\nrecommending (relevant) entities at the right turn. We introduce a new CRS we\\ncall CoRE-CoG. CoRE-CoG addresses the limitations in prior systems by\\nimplementing (1) a recommendation trigger that decides if the system utterance\\nshould include an entity, (2) a type pruning module that improves the relevance\\nof recommended entities, and (3) a novel constrained response generator to make\\nrecommendations while maintaining fluency. Together, these modules ensure\\nsimultaneous accurate recommendation decisions and fluent system utterances.\\nExperiments with recent benchmarks show the superiority particularly on\\nconditional generation sub-tasks with close to 10 F1 and 4 Recall@1 percent\\npoints gain over baselines.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.08511v1.pdf'},\n",
       " {'id': '2312.16203v1',\n",
       "  'title': 'User Consented Federated Recommender System Against Personalized\\n  Attribute Inference Attack',\n",
       "  'published': '2023-12-23T09:44:57Z',\n",
       "  'summary': \"Recommender systems can be privacy-sensitive. To protect users' private\\nhistorical interactions, federated learning has been proposed in distributed\\nlearning for user representations. Using federated recommender (FedRec)\\nsystems, users can train a shared recommendation model on local devices and\\nprevent raw data transmissions and collections. However, the recommendation\\nmodel learned by a common FedRec may still be vulnerable to private information\\nleakage risks, particularly attribute inference attacks, which means that the\\nattacker can easily infer users' personal attributes from the learned model.\\nAdditionally, traditional FedRecs seldom consider the diverse privacy\\npreference of users, leading to difficulties in balancing the recommendation\\nutility and privacy preservation. Consequently, FedRecs may suffer from\\nunnecessary recommendation performance loss due to over-protection and private\\ninformation leakage simultaneously. In this work, we propose a novel\\nuser-consented federated recommendation system (UC-FedRec) to flexibly satisfy\\nthe different privacy needs of users by paying a minimum recommendation\\naccuracy price. UC-FedRec allows users to self-define their privacy preferences\\nto meet various demands and makes recommendations with user consent.\\nExperiments conducted on different real-world datasets demonstrate that our\\nframework is more efficient and flexible compared to baselines.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2312.16203v1.pdf'},\n",
       " {'id': '2402.03481v1',\n",
       "  'title': 'FINEST: Stabilizing Recommendations by Rank-Preserving Fine-Tuning',\n",
       "  'published': '2024-02-05T19:53:34Z',\n",
       "  'summary': \"Modern recommender systems may output considerably different recommendations\\ndue to small perturbations in the training data. Changes in the data from a\\nsingle user will alter the recommendations as well as the recommendations of\\nother users. In applications like healthcare, housing, and finance, this\\nsensitivity can have adverse effects on user experience. We propose a method to\\nstabilize a given recommender system against such perturbations. This is a\\nchallenging task due to (1) the lack of a ``reference'' rank list that can be\\nused to anchor the outputs; and (2) the computational challenges in ensuring\\nthe stability of rank lists with respect to all possible perturbations of\\ntraining data. Our method, FINEST, overcomes these challenges by obtaining\\nreference rank lists from a given recommendation model and then fine-tuning the\\nmodel under simulated perturbation scenarios with rank-preserving\\nregularization on sampled items. Our experiments on real-world datasets\\ndemonstrate that FINEST can ensure that recommender models output stable\\nrecommendations under a wide range of different perturbations without\\ncompromising next-item prediction accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.03481v1.pdf'},\n",
       " {'id': '2402.08275v1',\n",
       "  'title': 'Implementation of Recommendation Algorithm based on Recommendation\\n  Sessions in E-commerce IT System',\n",
       "  'published': '2024-02-13T07:59:34Z',\n",
       "  'summary': \"This paper presents a study on the implementation of the author's Algorithm\\nof Recommendation Sessions (ARS) in an operational e-commerce information\\nsystem and analyses the basic parameters of the resulting recommendation\\nsystem. It begins with a synthetic overview of recommendation systems, followed\\nby a presentation of the proprietary ARS algorithm, which is based on\\nrecommendation sessions. A mathematical model of the recommendation session,\\nconstructed using graph and network theory, serves as the input for the ARS\\nalgorithm. This paper also explores graph structure representation methods and\\nthe implementation of a G graph (representing a set of recommendation sessions)\\nin a relational database using the SQL standard. The ARS algorithm was\\nimplemented in a working e-commerce information system, leading to the\\ndevelopment of a fully functional recommendation system adaptable to various\\ne-commerce IT systems. The effectiveness of the algorithm is demonstrated by\\nresearch on the recommendation system's parameters presented in the final\\nsection of the paper.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.08275v1.pdf'},\n",
       " {'id': '2402.16304v1',\n",
       "  'title': 'Top-Personalized-K Recommendation',\n",
       "  'published': '2024-02-26T05:03:54Z',\n",
       "  'summary': \"The conventional top-K recommendation, which presents the top-K items with\\nthe highest ranking scores, is a common practice for generating personalized\\nranking lists. However, is this fixed-size top-K recommendation the optimal\\napproach for every user's satisfaction? Not necessarily. We point out that\\nproviding fixed-size recommendations without taking into account user utility\\ncan be suboptimal, as it may unavoidably include irrelevant items or limit the\\nexposure to relevant ones. To address this issue, we introduce\\nTop-Personalized-K Recommendation, a new recommendation task aimed at\\ngenerating a personalized-sized ranking list to maximize individual user\\nsatisfaction. As a solution to the proposed task, we develop a model-agnostic\\nframework named PerK. PerK estimates the expected user utility by leveraging\\ncalibrated interaction probabilities, subsequently selecting the recommendation\\nsize that maximizes this expected utility. Through extensive experiments on\\nreal-world datasets, we demonstrate the superiority of PerK in\\nTop-Personalized-K recommendation task. We expect that Top-Personalized-K\\nrecommendation has the potential to offer enhanced solutions for various\\nreal-world recommendation scenarios, based on its great compatibility with\\nexisting models.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2402.16304v1.pdf'},\n",
       " {'id': '2403.07571v1',\n",
       "  'title': 'Proactive Recommendation with Iterative Preference Guidance',\n",
       "  'published': '2024-03-12T11:58:50Z',\n",
       "  'summary': 'Recommender systems mainly tailor personalized recommendations according to\\nuser interests learned from user feedback. However, such recommender systems\\npassively cater to user interests and even reinforce existing interests in the\\nfeedback loop, leading to problems like filter bubbles and opinion\\npolarization. To counteract this, proactive recommendation actively steers\\nusers towards developing new interests in a target item or topic by\\nstrategically modulating recommendation sequences. Existing work for proactive\\nrecommendation faces significant hurdles: 1) overlooking the user feedback in\\nthe guidance process; 2) lacking explicit modeling of the guiding objective;\\nand 3) insufficient flexibility for integration into existing industrial\\nrecommender systems. To address these issues, we introduce an Iterative\\nPreference Guidance (IPG) framework. IPG performs proactive recommendation in a\\nflexible post-processing manner by ranking items according to their IPG scores\\nthat consider both interaction probability and guiding value. These scores are\\nexplicitly estimated with iteratively updated user representation that\\nconsiders the most recent user interactions. Extensive experiments validate\\nthat IPG can effectively guide user interests toward target interests with a\\nreasonable trade-off in recommender accuracy. The code is available at\\nhttps://github.com/GabyUSTC/IPG-Rec.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.07571v1.pdf'},\n",
       " {'id': '2403.08737v1',\n",
       "  'title': 'ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation',\n",
       "  'published': '2024-03-13T17:38:05Z',\n",
       "  'summary': 'Existing Machine Learning approaches for local citation recommendation\\ndirectly map or translate a query, which is typically a claim or an entity\\nmention, to citation-worthy research papers. Within such a formulation, it is\\nchallenging to pinpoint why one should cite a specific research paper for a\\nparticular query, leading to limited recommendation interpretability. To\\nalleviate this, we introduce the evidence-grounded local citation\\nrecommendation task, where the target latent space comprises evidence spans for\\nrecommending specific papers. Using a distantly-supervised evidence retrieval\\nand multi-step re-ranking framework, our proposed system, ILCiteR, recommends\\npapers to cite for a query grounded on similar evidence spans extracted from\\nthe existing research literature. Unlike past formulations that simply output\\nrecommendations, ILCiteR retrieves ranked lists of evidence span and\\nrecommended paper pairs. Secondly, previously proposed neural models for\\ncitation recommendation require expensive training on massive labeled data,\\nideally after every significant update to the pool of candidate papers. In\\ncontrast, ILCiteR relies solely on distant supervision from a dynamic evidence\\ndatabase and pre-trained Transformer-based Language Models without any model\\ntraining. We contribute a novel dataset for the evidence-grounded local\\ncitation recommendation task and demonstrate the efficacy of our proposed\\nconditional neural rank-ensembling approach for re-ranking evidence spans.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.08737v1.pdf'},\n",
       " {'id': '2405.16127v2',\n",
       "  'title': 'Finetuning Large Language Model for Personalized Ranking',\n",
       "  'published': '2024-05-25T08:36:15Z',\n",
       "  'summary': \"Large Language Models (LLMs) have demonstrated remarkable performance across\\nvarious domains, motivating researchers to investigate their potential use in\\nrecommendation systems. However, directly applying LLMs to recommendation tasks\\nhas proven challenging due to the significant disparity between the data used\\nfor pre-training LLMs and the specific requirements of recommendation tasks. In\\nthis study, we introduce Direct Multi-Preference Optimization (DMPO), a\\nstreamlined framework designed to bridge the gap and enhance the alignment of\\nLLMs for recommendation tasks. DMPO enhances the performance of LLM-based\\nrecommenders by simultaneously maximizing the probability of positive samples\\nand minimizing the probability of multiple negative samples. We conducted\\nexperimental evaluations to compare DMPO against traditional recommendation\\nmethods and other LLM-based recommendation approaches. The results demonstrate\\nthat DMPO significantly improves the recommendation capabilities of LLMs across\\nthree real-world public datasets in few-shot scenarios. Additionally, the\\nexperiments indicate that DMPO exhibits superior generalization ability in\\ncross-domain recommendations. A case study elucidates the reasons behind these\\nconsistent improvements and also underscores DMPO's potential as an explainable\\nrecommendation system.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.16127v2.pdf'},\n",
       " {'id': '2406.12243v1',\n",
       "  'title': 'CherryRec: Enhancing News Recommendation Quality via LLM-driven\\n  Framework',\n",
       "  'published': '2024-06-18T03:33:38Z',\n",
       "  'summary': \"Large Language Models (LLMs) have achieved remarkable progress in language\\nunderstanding and generation. Custom LLMs leveraging textual features have been\\napplied to recommendation systems, demonstrating improvements across various\\nrecommendation scenarios. However, most existing methods perform untrained\\nrecommendation based on pre-trained knowledge (e.g., movie recommendation), and\\nthe auto-regressive generation of LLMs leads to slow inference speeds, making\\nthem less effective in real-time recommendations.To address this, we propose a\\nframework for news recommendation using LLMs, named \\\\textit{CherryRec}, which\\nensures the quality of recommendations while accelerating the recommendation\\nprocess. Specifically, we employ a Knowledge-aware News Rapid Selector to\\nretrieve candidate options based on the user's interaction history. The history\\nand retrieved items are then input as text into a fine-tuned LLM, the\\nContent-aware News Llm Evaluator, designed to enhance news recommendation\\ncapabilities. Finally, the Value-aware News Scorer integrates the scores to\\ncompute the CherryRec Score, which serves as the basis for the final\\nrecommendation.We validate the effectiveness of the proposed framework by\\ncomparing it with state-of-the-art baseline methods on benchmark datasets. Our\\nexperimental results consistently show that CherryRec outperforms the baselines\\nin both recommendation performance and efficiency.The project resource can be\\naccessed at: \\\\url{https://github.com/xxxxxx}\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2406.12243v1.pdf'},\n",
       " {'id': '2408.11565v1',\n",
       "  'title': 'Oh, Behave! Country Representation Dynamics Created by Feedback Loops in\\n  Music Recommender Systems',\n",
       "  'published': '2024-08-21T12:18:28Z',\n",
       "  'summary': 'Recent work suggests that music recommender systems are prone to\\ndisproportionally frequent recommendations of music from countries more\\nprominently represented in the training data, notably the US. However, it\\nremains unclear to what extent feedback loops in music recommendation influence\\nthe dynamics of such imbalance. In this work, we investigate the dynamics of\\nrepresentation of local (i.e., country-specific) and US-produced music in user\\nprofiles and recommendations. To this end, we conduct a feedback loop\\nsimulation study using the standardized LFM-2b dataset. The results suggest\\nthat most of the investigated recommendation models decrease the proportion of\\nmusic from local artists in their recommendations. Furthermore, we find that\\nmodels preserving average proportions of US and local music do not necessarily\\nprovide country-calibrated recommendations. We also look into popularity\\ncalibration and, surprisingly, find that the most popularity-calibrated model\\nin our study (ItemKNN) provides the least country-calibrated recommendations.\\nIn addition, users from less represented countries (e.g., Finland) are, in the\\nlong term, most affected by the under-representation of their local music in\\nrecommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.11565v1.pdf'},\n",
       " {'id': '2410.12829v1',\n",
       "  'title': 'Leveraging Large Language Models to Enhance Personalized Recommendations\\n  in E-commerce',\n",
       "  'published': '2024-10-02T13:59:56Z',\n",
       "  'summary': 'This study deeply explores the application of large language model (LLM) in\\npersonalized recommendation system of e-commerce. Aiming at the limitations of\\ntraditional recommendation algorithms in processing large-scale and\\nmulti-dimensional data, a recommendation system framework based on LLM is\\nproposed. Through comparative experiments, the recommendation model based on\\nLLM shows significant improvement in multiple key indicators such as precision,\\nrecall, F1 score, average click-through rate (CTR) and recommendation\\ndiversity. Specifically, the precision of the LLM model is improved from 0.75\\nto 0.82, the recall rate is increased from 0.68 to 0.77, the F1 score is\\nincreased from 0.71 to 0.79, the CTR is increased from 0.56 to 0.63, and the\\nrecommendation diversity is increased by 41.2%, from 0.34 to 0.48. LLM\\neffectively captures the implicit needs of users through deep semantic\\nunderstanding of user comments and product description data, and combines\\ncontextual data for dynamic recommendation to generate more accurate and\\ndiverse results. The study shows that LLM has significant advantages in the\\nfield of personalized recommendation, can improve user experience and promote\\nplatform sales growth, and provides strong theoretical and practical support\\nfor personalized recommendation technology in e-commerce.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.12829v1.pdf'},\n",
       " {'id': '2411.00341v1',\n",
       "  'title': 'A Survey on Bundle Recommendation: Methods, Applications, and Challenges',\n",
       "  'published': '2024-11-01T03:43:50Z',\n",
       "  'summary': 'In recent years, bundle recommendation systems have gained significant\\nattention in both academia and industry due to their ability to enhance user\\nexperience and increase sales by recommending a set of items as a bundle rather\\nthan individual items. This survey provides a comprehensive review on bundle\\nrecommendation, beginning by a taxonomy for exploring product bundling. We\\nclassify it into two categories based on bundling strategy from various\\napplication domains, i.e., discriminative and generative bundle recommendation.\\nThen we formulate the corresponding tasks of the two categories and\\nsystematically review their methods: 1) representation learning from bundle and\\nitem levels and interaction modeling for discriminative bundle recommendation;\\n2) representation learning from item level and bundle generation for generative\\nbundle recommendation. Subsequently, we survey the resources of bundle\\nrecommendation including datasets and evaluation metrics, and conduct\\nreproducibility experiments on mainstream models. Lastly, we discuss the main\\nchallenges and highlight the promising future directions in the field of bundle\\nrecommendation, aiming to serve as a useful resource for researchers and\\npractitioners. Our code and datasets are publicly available at\\nhttps://github.com/WUT-IDEA/bundle-recommendation-survey.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2411.00341v1.pdf'},\n",
       " {'id': '2412.12836v1',\n",
       "  'title': 'A Survey on Recommendation Unlearning: Fundamentals, Taxonomy,\\n  Evaluation, and Open Questions',\n",
       "  'published': '2024-12-17T11:58:55Z',\n",
       "  'summary': 'Recommender systems have become increasingly influential in shaping user\\nbehavior and decision-making, highlighting their growing impact in various\\ndomains. Meanwhile, the widespread adoption of machine learning models in\\nrecommender systems has raised significant concerns regarding user privacy and\\nsecurity. As compliance with privacy regulations becomes more critical, there\\nis a pressing need to address the issue of recommendation unlearning, i.e.,\\neliminating the memory of specific training data from the learned\\nrecommendation models. Despite its importance, traditional machine unlearning\\nmethods are ill-suited for recommendation unlearning due to the unique\\nchallenges posed by collaborative interactions and model parameters. This\\nsurvey offers a comprehensive review of the latest advancements in\\nrecommendation unlearning, exploring the design principles, challenges, and\\nmethodologies associated with this emerging field. We provide a unified\\ntaxonomy that categorizes different recommendation unlearning approaches,\\nfollowed by a summary of widely used benchmarks and metrics for evaluation. By\\nreviewing the current state of research, this survey aims to guide the\\ndevelopment of more efficient, scalable, and robust recommendation unlearning\\ntechniques. Furthermore, we identify open research questions in this field,\\nwhich could pave the way for future innovations not only in recommendation\\nunlearning but also in a broader range of unlearning tasks across different\\nmachine learning applications.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2412.12836v1.pdf'},\n",
       " {'id': '2501.09354v1',\n",
       "  'title': 'Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems\\n  with Style and Shopping Cart Information',\n",
       "  'published': '2025-01-16T08:05:39Z',\n",
       "  'summary': \"Understanding users' product preferences is essential to the efficacy of a\\nrecommendation system. Precision marketing leverages users' historical data to\\ndiscern these preferences and recommends products that align with them.\\nHowever, recent browsing and purchase records might better reflect current\\npurchasing inclinations. Transformer-based recommendation systems have made\\nstrides in sequential recommendation tasks, but they often fall short in\\nutilizing product image style information and shopping cart data effectively.\\nIn light of this, we propose Style4Rec, a transformer-based e-commerce\\nrecommendation system that harnesses style and shopping cart information to\\nenhance existing transformer-based sequential product recommendation systems.\\nStyle4Rec represents a significant step forward in personalized e-commerce\\nrecommendations, outperforming benchmarks across various evaluation metrics.\\nStyle4Rec resulted in notable improvements: HR@5 increased from 0.681 to 0.735,\\nNDCG@5 increased from 0.594 to 0.674, and MRR@5 increased from 0.559 to 0.654.\\nWe tested our model using an e-commerce dataset from our partnering company and\\nfound that it exceeded established transformer-based sequential recommendation\\nbenchmarks across various evaluation metrics. Thus, Style4Rec presents a\\nsignificant step forward in personalized e-commerce recommendation systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.09354v1.pdf'},\n",
       " {'id': '2505.00951v1',\n",
       "  'title': 'Preserving Privacy and Utility in LLM-Based Product Recommendations',\n",
       "  'published': '2025-05-02T01:54:08Z',\n",
       "  'summary': 'Large Language Model (LLM)-based recommendation systems leverage powerful\\nlanguage models to generate personalized suggestions by processing user\\ninteractions and preferences. Unlike traditional recommendation systems that\\nrely on structured data and collaborative filtering, LLM-based models process\\ntextual and contextual information, often using cloud-based infrastructure.\\nThis raises privacy concerns, as user data is transmitted to remote servers,\\nincreasing the risk of exposure and reducing control over personal information.\\nTo address this, we propose a hybrid privacy-preserving recommendation\\nframework which separates sensitive from nonsensitive data and only shares the\\nlatter with the cloud to harness LLM-powered recommendations. To restore lost\\nrecommendations related to obfuscated sensitive data, we design a\\nde-obfuscation module that reconstructs sensitive recommendations locally.\\nExperiments on real-world e-commerce datasets show that our framework achieves\\nalmost the same recommendation utility with a system which shares all data with\\nan LLM, while preserving privacy to a large extend. Compared to\\nobfuscation-only techniques, our approach improves HR@10 scores and category\\ndistribution alignment, offering a better balance between privacy and\\nrecommendation quality. Furthermore, our method runs efficiently on\\nconsumer-grade hardware, making privacy-aware LLM-based recommendation systems\\npractical for real-world use.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2505.00951v1.pdf'},\n",
       " {'id': '2507.05295v1',\n",
       "  'title': 'Enhancing Learning Path Recommendation via Multi-task Learning',\n",
       "  'published': '2025-07-05T21:16:02Z',\n",
       "  'summary': \"Personalized learning is a student-centered educational approach that adapts\\ncontent, pace, and assessment to meet each learner's unique needs. As the key\\ntechnique to implement the personalized learning, learning path recommendation\\nsequentially recommends personalized learning items such as lectures and\\nexercises. Advances in deep learning, particularly deep reinforcement learning,\\nhave made modeling such recommendations more practical and effective. This\\npaper proposes a multi-task LSTM model that enhances learning path\\nrecommendation by leveraging shared information across tasks. The approach\\nreframes learning path recommendation as a sequence-to-sequence (Seq2Seq)\\nprediction problem, generating personalized learning paths from a learner's\\nhistorical interactions. The model uses a shared LSTM layer to capture common\\nfeatures for both learning path recommendation and deep knowledge tracing,\\nalong with task-specific LSTM layers for each objective. To avoid redundant\\nrecommendations, a non-repeat loss penalizes repeated items within the\\nrecommended learning path. Experiments on the ASSIST09 dataset show that the\\nproposed model significantly outperforms baseline methods for the learning path\\nrecommendation.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.05295v1.pdf'},\n",
       " {'id': '2507.23208v1',\n",
       "  'title': 'Are Recommenders Self-Aware? Label-Free Recommendation Performance\\n  Estimation via Model Uncertainty',\n",
       "  'published': '2025-07-31T03:04:34Z',\n",
       "  'summary': \"Can a recommendation model be self-aware? This paper investigates the\\nrecommender's self-awareness by quantifying its uncertainty, which provides a\\nlabel-free estimation of its performance. Such self-assessment can enable more\\ninformed understanding and decision-making before the recommender engages with\\nany users. To this end, we propose an intuitive and effective method,\\nprobability-based List Distribution uncertainty (LiDu). LiDu measures\\nuncertainty by determining the probability that a recommender will generate a\\ncertain ranking list based on the prediction distributions of individual items.\\nWe validate LiDu's ability to represent model self-awareness in two settings:\\n(1) with a matrix factorization model on a synthetic dataset, and (2) with\\npopular recommendation algorithms on real-world datasets. Experimental results\\nshow that LiDu is more correlated with recommendation performance than a series\\nof label-free performance estimators. Additionally, LiDu provides valuable\\ninsights into the dynamic inner states of models throughout training and\\ninference. This work establishes an empirical connection between recommendation\\nuncertainty and performance, framing it as a step towards more transparent and\\nself-evaluating recommender systems.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.23208v1.pdf'},\n",
       " {'id': '2508.05377v1',\n",
       "  'title': 'Does Multimodality Improve Recommender Systems as Expected? A Critical\\n  Analysis and Future Directions',\n",
       "  'published': '2025-08-07T13:21:00Z',\n",
       "  'summary': 'Multimodal recommendation systems are increasingly popular for their\\npotential to improve performance by integrating diverse data types. However,\\nthe actual benefits of this integration remain unclear, raising questions about\\nwhen and how it truly enhances recommendations. In this paper, we propose a\\nstructured evaluation framework to systematically assess multimodal\\nrecommendations across four dimensions: Comparative Efficiency, Recommendation\\nTasks, Recommendation Stages, and Multimodal Data Integration. We benchmark a\\nset of reproducible multimodal models against strong traditional baselines and\\nevaluate their performance on different platforms. Our findings show that\\nmultimodal data is particularly beneficial in sparse interaction scenarios and\\nduring the recall stage of recommendation pipelines. We also observe that the\\nimportance of each modality is task-specific, where text features are more\\nuseful in e-commerce and visual features are more effective in short-video\\nrecommendations. Additionally, we explore different integration strategies and\\nmodel sizes, finding that Ensemble-Based Learning outperforms Fusion-Based\\nLearning, and that larger models do not necessarily deliver better results. To\\ndeepen our understanding, we include case studies and review findings from\\nother recommendation domains. Our work provides practical insights for building\\nefficient and effective multimodal recommendation systems, emphasizing the need\\nfor thoughtful modality selection, integration strategies, and model design.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.05377v1.pdf'},\n",
       " {'id': '2509.06002v1',\n",
       "  'title': 'A Survey of Real-World Recommender Systems: Challenges, Constraints, and\\n  Industrial Perspectives',\n",
       "  'published': '2025-09-07T10:29:41Z',\n",
       "  'summary': \"Recommender systems have generated tremendous value for both users and\\nbusinesses, drawing significant attention from academia and industry alike.\\nHowever, due to practical constraints, academic research remains largely\\nconfined to offline dataset optimizations, lacking access to real user data and\\nlarge-scale recommendation platforms. This limitation reduces practical\\nrelevance, slows technological progress, and hampers a full understanding of\\nthe key challenges in recommender systems. In this survey, we provide a\\nsystematic review of industrial recommender systems and contrast them with\\ntheir academic counterparts. We highlight key differences in data scale,\\nreal-time requirements, and evaluation methodologies, and we summarize major\\nreal-world recommendation scenarios along with their associated challenges. We\\nthen examine how industry practitioners address these challenges in\\nTransaction-Oriented Recommender Systems and Content-Oriented Recommender\\nSystems, a new classification grounded in item characteristics and\\nrecommendation objectives. Finally, we outline promising research directions,\\nincluding the often-overlooked role of user decision-making, the integration of\\neconomic and psychological theories, and concrete suggestions for advancing\\nacademic research. Our goal is to enhance academia's understanding of practical\\nrecommender systems, bridge the growing development gap, and foster stronger\\ncollaboration between industry and academia.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2509.06002v1.pdf'},\n",
       " {'id': '1811.10364v1',\n",
       "  'title': \"The Architecture of Mr. DLib's Scientific Recommender-System API\",\n",
       "  'published': '2018-11-26T13:41:03Z',\n",
       "  'summary': 'Recommender systems in academia are not widely available. This may be in part\\ndue to the difficulty and cost of developing and maintaining recommender\\nsystems. Many operators of academic products such as digital libraries and\\nreference managers avoid this effort, although a recommender system could\\nprovide significant benefits to their users. In this paper, we introduce Mr.\\nDLib\\'s \"Recommendations as-a-Service\" (RaaS) API that allows operators of\\nacademic products to easily integrate a scientific recommender system into\\ntheir products. Mr. DLib generates recommendations for research articles but in\\nthe future, recommendations may include call for papers, grants, etc. Operators\\nof academic products can request recommendations from Mr. DLib and display\\nthese recommendations to their users. Mr. DLib can be integrated in just a few\\nhours or days; creating an equivalent recommender system from scratch would\\nrequire several months for an academic operator. Mr. DLib has been used by\\nGESIS Sowiport and by the reference manager JabRef. Mr. DLib is open source and\\nits goal is to facilitate the application of, and research on, scientific\\nrecommender systems. In this paper, we present the motivation for Mr. DLib, the\\narchitecture and details about the effectiveness. Mr. DLib has delivered 94m\\nrecommendations over a span of two years with an average click-through rate of\\n0.12%.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1811.10364v1.pdf'},\n",
       " {'id': '1607.00647v1',\n",
       "  'title': 'A Survey of Point-of-interest Recommendation in Location-based Social\\n  Networks',\n",
       "  'published': '2016-07-03T14:42:18Z',\n",
       "  'summary': 'Point-of-interest (POI) recommendation that suggests new places for users to\\nvisit arises with the popularity of location-based social networks (LBSNs). Due\\nto the importance of POI recommendation in LBSNs, it has attracted much\\nacademic and industrial interest. In this paper, we offer a systematic review\\nof this field, summarizing the contributions of individual efforts and\\nexploring their relations. We discuss the new properties and challenges in POI\\nrecommendation, compared with traditional recommendation problems, e.g., movie\\nrecommendation. Then, we present a comprehensive review in three aspects:\\ninfluential factors for POI recommendation, methodologies employed for POI\\nrecommendation, and different tasks in POI recommendation. Specifically, we\\npropose three taxonomies to classify POI recommendation systems. First, we\\ncategorize the systems by the influential factors check-in characteristics,\\nincluding the geographical information, social relationship, temporal\\ninfluence, and content indications. Second, we categorize the systems by the\\nmethodology, including systems modeled by fused methods and joint methods.\\nThird, we categorize the systems as general POI recommendation and successive\\nPOI recommendation by subtle differences in the recommendation task whether to\\nbe bias to the recent check-in. For each category, we summarize the\\ncontributions and system features, and highlight the representative work.\\nMoreover, we discuss the available data sets and the popular metrics. Finally,\\nwe point out the possible future directions in this area and conclude this\\nsurvey.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1607.00647v1.pdf'},\n",
       " {'id': '1801.10288v1',\n",
       "  'title': 'Visually Explainable Recommendation',\n",
       "  'published': '2018-01-31T03:16:39Z',\n",
       "  'summary': 'Images account for a significant part of user decisions in many application\\nscenarios, such as product images in e-commerce, or user image posts in social\\nnetworks. It is intuitive that user preferences on the visual patterns of image\\n(e.g., hue, texture, color, etc) can be highly personalized, and this provides\\nus with highly discriminative features to make personalized recommendations.\\n  Previous work that takes advantage of images for recommendation usually\\ntransforms the images into latent representation vectors, which are adopted by\\na recommendation component to assist personalized user/item profiling and\\nrecommendation. However, such vectors are hardly useful in terms of providing\\nvisual explanations to users about why a particular item is recommended, and\\nthus weakens the explainability of recommendation systems.\\n  As a step towards explainable recommendation models, we propose visually\\nexplainable recommendation based on attentive neural networks to model the user\\nattention on images, under the supervision of both implicit feedback and\\ntextual reviews. By this, we can not only provide recommendation results to the\\nusers, but also tell the users why an item is recommended by providing\\nintuitive visual highlights in a personalized manner. Experimental results show\\nthat our models are not only able to improve the recommendation performance,\\nbut also can provide persuasive visual explanations for the users to take the\\nrecommendations.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1801.10288v1.pdf'},\n",
       " {'id': '2007.13058v1',\n",
       "  'title': 'Do recommender systems function in the health domain: a system review',\n",
       "  'published': '2020-07-26T04:58:47Z',\n",
       "  'summary': 'Recommender systems have fulfilled an important role in everyday life.\\nRecommendations such as news by Google, videos by Netflix, goods by e-commerce\\nproviders, etc. have heavily changed everyones lifestyle. Health domains\\ncontain similar decision-making problems such as what to eat, how to exercise,\\nand what is the proper medicine for a patient. Recently, studies focused on\\nrecommender systems to solve health problems have attracted attention. In this\\npaper, we review aspects of health recommender systems including interests,\\nmethods, evaluation, future challenges and trend issues. We find that 1) health\\nrecommender systems have their own health concern limitations that cause them\\nto focus on less-risky recommendations such as diet recommendation; 2)\\ntraditional recommender methods such as content-based and collaborative\\nfiltering methods can hardly handle health constraints, but knowledge-based\\nmethods function more than ever; 3) evaluating a health recommendation is more\\ncomplicated than evaluating a commercial one because multiple dimensions in\\naddition to accuracy should be considered. Recommender systems can function\\nwell in the health domain after the solution of several key problems. Our work\\nis a systematic review of health recommender system studies, we show current\\nconditions and future directions. It is believed that this review will help\\ndomain researchers and promote health recommender systems to the next step.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2007.13058v1.pdf'},\n",
       " {'id': '2201.10528v1',\n",
       "  'title': 'Explainability in Music Recommender Systems',\n",
       "  'published': '2022-01-25T18:32:11Z',\n",
       "  'summary': \"The most common way to listen to recorded music nowadays is via streaming\\nplatforms which provide access to tens of millions of tracks. To assist users\\nin effectively browsing these large catalogs, the integration of Music\\nRecommender Systems (MRSs) has become essential. Current real-world MRSs are\\noften quite complex and optimized for recommendation accuracy. They combine\\nseveral building blocks based on collaborative filtering and content-based\\nrecommendation. This complexity can hinder the ability to explain\\nrecommendations to end users, which is particularly important for\\nrecommendations perceived as unexpected or inappropriate. While pure\\nrecommendation performance often correlates with user satisfaction,\\nexplainability has a positive impact on other factors such as trust and\\nforgiveness, which are ultimately essential to maintain user loyalty.\\n  In this article, we discuss how explainability can be addressed in the\\ncontext of MRSs. We provide perspectives on how explainability could improve\\nmusic recommendation algorithms and enhance user experience. First, we review\\ncommon dimensions and goals of recommenders' explainability and in general of\\neXplainable Artificial Intelligence (XAI), and elaborate on the extent to which\\nthese apply -- or need to be adapted -- to the specific characteristics of\\nmusic consumption and recommendation. Then, we show how explainability\\ncomponents can be integrated within a MRS and in what form explanations can be\\nprovided. Since the evaluation of explanation quality is decoupled from pure\\naccuracy-based evaluation criteria, we also discuss requirements and strategies\\nfor evaluating explanations of music recommendations. Finally, we describe the\\ncurrent challenges for introducing explainability within a large-scale\\nindustrial music recommender system and provide research perspectives.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2201.10528v1.pdf'},\n",
       " {'id': '2205.12133v1',\n",
       "  'title': 'MealRec: A Meal Recommendation Dataset',\n",
       "  'published': '2022-05-24T15:09:43Z',\n",
       "  'summary': 'Bundle recommendation systems aim to recommend a bundle of items for a user\\nto consider as a whole. They have become a norm in modern life and have been\\napplied to many real-world settings, such as product bundle recommendation,\\nmusic playlist recommendation and travel package recommendation. However,\\ncompared to studies of bundle recommendation approaches in areas such as online\\nshopping and digital music services, research on meal recommendations for\\nrestaurants in the hospitality industry has made limited progress, due largely\\nto the lack of high-quality benchmark datasets. A publicly available dataset\\nspecialising in meal recommendation research for the research community is in\\nurgent demand. In this paper, we introduce a meal recommendation dataset\\n(MealRec) that aims to facilitate future research. MealRec is constructed from\\nthe user review records of Allrecipe.com, covering 1,500+ users, 7,200+ recipes\\nand 3,800+ meals. Each recipe is described with rich information, such as\\ningredients, instructions, pictures, category and tags, etc; and each meal is\\nthree-course, consisting of an appetizer, a main dish and a dessert.\\nFurthermore, we propose a category-constrained meal recommendation model that\\nis evaluated through comparative experiments with several state-of-the-art\\nbundle recommendation methods on MealRec. Experimental results confirm the\\nsuperiority of our model and demonstrate that MealRec is a promising testbed\\nfor meal recommendation related research.\\n  The MealRec dataset and the source code of our proposed model are available\\nat https://github.com/WUT-IDEA/MealRec for access and reproducibility.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2205.12133v1.pdf'},\n",
       " {'id': '2112.02530v1',\n",
       "  'title': 'Exploring and Mitigating Gender Bias in Recommender Systems with\\n  Explicit Feedback',\n",
       "  'published': '2021-12-05T10:25:59Z',\n",
       "  'summary': 'Recommender systems are indispensable because they influence our day-to-day\\nbehavior and decisions by giving us personalized suggestions. Services like\\nKindle, Youtube, and Netflix depend heavily on the performance of their\\nrecommender systems to ensure that their users have a good experience and to\\nincrease revenues. Despite their popularity, it has been shown that recommender\\nsystems reproduce and amplify the bias present in the real world. The resulting\\nfeedback creates a self-perpetuating loop that deteriorates the user experience\\nand results in homogenizing recommendations over time. Further, biased\\nrecommendations can also reinforce stereotypes based on gender or ethnicity,\\nthus reinforcing the filter bubbles that we live in. In this paper, we address\\nthe problem of gender bias in recommender systems with explicit feedback. We\\npropose a model to quantify the gender bias present in book rating datasets and\\nin the recommendations produced by the recommender systems. Our main\\ncontribution is to provide a principled approach to mitigate the bias being\\nproduced in the recommendations. We theoretically show that the proposed\\napproach provides unbiased recommendations despite biased data. Through\\nempirical evaluation on publicly available book rating datasets, we further\\nshow that the proposed model can significantly reduce bias without significant\\nimpact on accuracy. Our method is model agnostic and can be applied to any\\nrecommender system. To demonstrate the performance of our model, we present the\\nresults on four recommender algorithms, two from the K-nearest neighbors\\nfamily, UserKNN and ItemKNN, and the other two from the matrix factorization\\nfamily, Alternating least square and Singular value decomposition.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.02530v1.pdf'},\n",
       " {'id': '2104.13030v3',\n",
       "  'title': 'A Survey on Accuracy-oriented Neural Recommendation: From Collaborative\\n  Filtering to Information-rich Recommendation',\n",
       "  'published': '2021-04-27T08:03:52Z',\n",
       "  'summary': 'Influenced by the great success of deep learning in computer vision and\\nlanguage understanding, research in recommendation has shifted to inventing new\\nrecommender models based on neural networks. In recent years, we have witnessed\\nsignificant progress in developing neural recommender models, which generalize\\nand surpass traditional recommender models owing to the strong representation\\npower of neural networks. In this survey paper, we conduct a systematic review\\non neural recommender models from the perspective of recommendation modeling\\nwith the accuracy goal, aiming to summarize this field to facilitate\\nresearchers and practitioners working on recommender systems. Specifically,\\nbased on the data usage during recommendation modeling, we divide the work into\\ncollaborative filtering and information-rich recommendation: 1) collaborative\\nfiltering, which leverages the key source of user-item interaction data; 2)\\ncontent enriched recommendation, which additionally utilizes the side\\ninformation associated with users and items, like user profile and item\\nknowledge graph; and 3) temporal/sequential recommendation, which accounts for\\nthe contextual information associated with an interaction, such as time,\\nlocation, and the past interactions. After reviewing representative work for\\neach type, we finally discuss some promising directions in this field.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2104.13030v3.pdf'},\n",
       " {'id': '2105.09829v3',\n",
       "  'title': 'Personalized Counterfactual Fairness in Recommendation',\n",
       "  'published': '2021-05-20T15:24:34Z',\n",
       "  'summary': \"Recommender systems are gaining increasing and critical impacts on human and\\nsociety since a growing number of users use them for information seeking and\\ndecision making. Therefore, it is crucial to address the potential unfairness\\nproblems in recommendations. Just like users have personalized preferences on\\nitems, users' demands for fairness are also personalized in many scenarios.\\nTherefore, it is important to provide personalized fair recommendations for\\nusers to satisfy their personalized fairness demands. Besides, previous works\\non fair recommendation mainly focus on association-based fairness. However, it\\nis important to advance from associative fairness notions to causal fairness\\nnotions for assessing fairness more properly in recommender systems. Based on\\nthe above considerations, this paper focuses on achieving personalized\\ncounterfactual fairness for users in recommender systems. To this end, we\\nintroduce a framework for achieving counterfactually fair recommendations\\nthrough adversary learning by generating feature-independent user embeddings\\nfor recommendation. The framework allows recommender systems to achieve\\npersonalized fairness for users while also covering non-personalized\\nsituations. Experiments on two real-world datasets with shallow and deep\\nrecommendation algorithms show that our method can generate fairer\\nrecommendations for users with a desirable recommendation performance.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2105.09829v3.pdf'},\n",
       " {'id': '2109.07791v1',\n",
       "  'title': 'A Qualitative Evaluation of User Preference for Link-based vs.\\n  Text-based Recommendations of Wikipedia Articles',\n",
       "  'published': '2021-09-16T08:24:33Z',\n",
       "  'summary': \"Literature recommendation systems (LRS) assist readers in the discovery of\\nrelevant content from the overwhelming amount of literature available. Despite\\nthe widespread adoption of LRS, there is a lack of research on the\\nuser-perceived recommendation characteristics for fundamentally different\\napproaches to content-based literature recommendation. To complement existing\\nquantitative studies on literature recommendation, we present qualitative study\\nresults that report on users' perceptions for two contrasting recommendation\\nclasses: (1) link-based recommendation represented by the Co-Citation Proximity\\n(CPA) approach, and (2) text-based recommendation represented by Lucene's\\nMoreLikeThis (MLT) algorithm. The empirical data analyzed in our study with\\ntwenty users and a diverse set of 40 Wikipedia articles indicate a noticeable\\ndifference between text- and link-based recommendation generation approaches\\nalong several key dimensions. The text-based MLT method receives higher\\nsatisfaction ratings in terms of user-perceived similarity of recommended\\narticles. In contrast, the CPA approach receives higher satisfaction scores in\\nterms of diversity and serendipity of recommendations. We conclude that users\\nof literature recommendation systems can benefit most from hybrid approaches\\nthat combine both link- and text-based approaches, where the user's information\\nneeds and preferences should control the weighting for the approaches used. The\\noptimal weighting of multiple approaches used in a hybrid recommendation system\\nis highly dependent on a user's shifting needs.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2109.07791v1.pdf'},\n",
       " {'id': '2305.11755v3',\n",
       "  'title': 'Visualization for Recommendation Explainability: A Survey and New\\n  Perspectives',\n",
       "  'published': '2023-05-19T15:42:00Z',\n",
       "  'summary': 'Providing system-generated explanations for recommendations represents an\\nimportant step towards transparent and trustworthy recommender systems.\\nExplainable recommender systems provide a human-understandable rationale for\\ntheir outputs. Over the last two decades, explainable recommendation has\\nattracted much attention in the recommender systems research community. This\\npaper aims to provide a comprehensive review of research efforts on visual\\nexplanation in recommender systems. More concretely, we systematically review\\nthe literature on explanations in recommender systems based on four dimensions,\\nnamely explanation goal, explanation scope, explanation style, and explanation\\nformat. Recognizing the importance of visualization, we approach the\\nrecommender system literature from the angle of explanatory visualizations,\\nthat is using visualizations as a display style of explanation. As a result, we\\nderive a set of guidelines that might be constructive for designing explanatory\\nvisualizations in recommender systems and identify perspectives for future work\\nin this field. The aim of this review is to help recommendation researchers and\\npractitioners better understand the potential of visually explainable\\nrecommendation research and to support them in the systematic design of visual\\nexplanations in current and future recommender systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2305.11755v3.pdf'},\n",
       " {'id': '2306.03395v2',\n",
       "  'title': 'Computational Technologies for Fashion Recommendation: A Survey',\n",
       "  'published': '2023-06-06T04:20:08Z',\n",
       "  'summary': 'Fashion recommendation is a key research field in computational fashion\\nresearch and has attracted considerable interest in the computer vision,\\nmultimedia, and information retrieval communities in recent years. Due to the\\ngreat demand for applications, various fashion recommendation tasks, such as\\npersonalized fashion product recommendation, complementary (mix-and-match)\\nrecommendation, and outfit recommendation, have been posed and explored in the\\nliterature. The continuing research attention and advances impel us to look\\nback and in-depth into the field for a better understanding. In this paper, we\\ncomprehensively review recent research efforts on fashion recommendation from a\\ntechnological perspective. We first introduce fashion recommendation at a macro\\nlevel and analyse its characteristics and differences with general\\nrecommendation tasks. We then clearly categorize different fashion\\nrecommendation efforts into several sub-tasks and focus on each sub-task in\\nterms of its problem formulation, research focus, state-of-the-art methods, and\\nlimitations. We also summarize the datasets proposed in the literature for use\\nin fashion recommendation studies to give readers a brief illustration.\\nFinally, we discuss several promising directions for future research in this\\nfield. Overall, this survey systematically reviews the development of fashion\\nrecommendation research. It also discusses the current limitations and gaps\\nbetween academic research and the real needs of the fashion industry. In the\\nprocess, we offer a deep insight into how the fashion industry could benefit\\nfrom the computational technologies of fashion recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.03395v2.pdf'},\n",
       " {'id': '2306.11114v1',\n",
       "  'title': 'Generative Sequential Recommendation with GPTRec',\n",
       "  'published': '2023-06-19T18:27:54Z',\n",
       "  'summary': 'Sequential recommendation is an important recommendation task that aims to\\npredict the next item in a sequence. Recently, adaptations of language models,\\nparticularly Transformer-based models such as SASRec and BERT4Rec, have\\nachieved state-of-the-art results in sequential recommendation. In these\\nmodels, item ids replace tokens in the original language models. However, this\\napproach has limitations. First, the vocabulary of item ids may be many times\\nlarger than in language models. Second, the classical Top-K recommendation\\napproach used by these models may not be optimal for complex recommendation\\nobjectives, including auxiliary objectives such as diversity, coverage or\\ncoherence. Recent progress in generative language models inspires us to revisit\\ngenerative approaches to address these challenges. This paper presents the\\nGPTRec sequential recommendation model, which is based on the GPT-2\\narchitecture. GPTRec can address large vocabulary issues by splitting item ids\\ninto sub-id tokens using a novel SVD Tokenisation algorithm based on quantised\\nitem embeddings from an SVD decomposition of the user-item interaction matrix.\\nThe paper also presents a novel Next-K recommendation strategy, which generates\\nrecommendations item-by-item, considering already recommended items. The Next-K\\nstrategy can be used for producing complex interdependent recommendation lists.\\nWe experiment with GPTRec on the MovieLens-1M dataset and show that using\\nsub-item tokenisation GPTRec can match the quality of SASRec while reducing the\\nembedding table by 40%. We also show that the recommendations generated by\\nGPTRec on MovieLens-1M using the Next-K recommendation strategy match the\\nquality of SASRec in terms of NDCG@10, meaning that the model can serve as a\\nstrong starting point for future research.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2306.11114v1.pdf'},\n",
       " {'id': '2308.04247v2',\n",
       "  'title': 'UniRecSys: A Unified Framework for Personalized, Group, Package, and\\n  Package-to-Group Recommendations',\n",
       "  'published': '2023-08-08T13:26:36Z',\n",
       "  'summary': 'Recommender systems aim to enhance the overall user experience by providing\\ntailored recommendations for a variety of products and services. These systems\\nhelp users make more informed decisions, leading to greater user engagement\\nwith the platform. However, the implementation of these systems largely depends\\non the context, which can vary from recommending an item or package to a user\\nor a group. This requires careful exploration of several models during the\\ndeployment, as there is no comprehensive and unified approach that deals with\\nrecommendations at different levels. Furthermore, these individual models must\\nbe closely attuned to their generated recommendations depending on the context\\nto prevent significant variation in their generated recommendations. In this\\npaper, we propose a novel unified recommendation framework that addresses all\\nfour recommendation tasks, namely, personalized, group, package, and\\npackage-to-group recommendation, filling the gap in the current research\\nlandscape. The proposed framework can be integrated with most of the\\ntraditional matrix factorization-based collaborative filtering (CF) models.\\nThis research underscores the significance of including group and package\\ninformation while learning latent representations of users and items for\\npersonalized recommendations. These components help in exploiting a rich latent\\nrepresentation of the user/item by enforcing them to align closely with their\\ncorresponding group/package representation. We consider two prominent CF\\ntechniques, namely Regularized Matrix Factorization and Maximum Margin Matrix\\nfactorization, as the baseline models and demonstrate their customization to\\nvarious recommendation tasks. Experimental results on two publicly available\\ndatasets are reported, comparing them to other baseline approaches for various\\nrecommendation tasks.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.04247v2.pdf'},\n",
       " {'id': '2308.04579v1',\n",
       "  'title': 'RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose\\n  Recommendation System?',\n",
       "  'published': '2023-08-08T20:54:59Z',\n",
       "  'summary': \"Over the past two decades, recommendation systems (RSs) have used machine\\nlearning (ML) solutions to recommend items, e.g., movies, books, and\\nrestaurants, to clients of a business or an online platform. Recipe\\nrecommendation, however, has not yet received much attention compared to those\\napplications. We introduce RECipe as a multi-purpose recipe recommendation\\nframework with a multi-modal knowledge graph (MMKG) backbone. The motivation\\nbehind RECipe is to go beyond (deep) neural collaborative filtering (NCF) by\\nrecommending recipes to users when they query in natural language or by\\nproviding an image. RECipe consists of 3 subsystems: (1) behavior-based\\nrecommender, (2) review-based recommender, and (3) image-based recommender.\\nEach subsystem relies on the embedding representations of entities and\\nrelations in the graph. We first obtain (pre-trained) embedding representations\\nof textual entities, such as reviews or ingredients, from a fine-tuned model of\\nMicrosoft's MPNet. We initialize the weights of the entities with these\\nembeddings to train our knowledge graph embedding (KGE) model. For the visual\\ncomponent, i.e., recipe images, we develop a KGE-Guided variational autoencoder\\n(KG-VAE) to learn the distribution of images and their latent representations.\\nOnce KGE and KG-VAE models are fully trained, we use them as a multi-purpose\\nrecommendation framework. For benchmarking, we created two knowledge graphs\\n(KGs) from public datasets on Kaggle for recipe recommendation. Our experiments\\nshow that the KGE models have comparable performance to the neural solutions.\\nWe also present pre-trained NLP embeddings to address important applications\\nsuch as zero-shot inference for new users (or the cold start problem) and\\nconditional recommendation with respect to recipe categories. We eventually\\ndemonstrate the application of RECipe in a multi-purpose recommendation\\nsetting.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2308.04579v1.pdf'},\n",
       " {'id': '2309.02322v1',\n",
       "  'title': 'Fairness of Exposure in Dynamic Recommendation',\n",
       "  'published': '2023-09-05T15:41:26Z',\n",
       "  'summary': \"Exposure bias is a well-known issue in recommender systems where the exposure\\nis not fairly distributed among items in the recommendation results. This is\\nespecially problematic when bias is amplified over time as a few items (e.g.,\\npopular ones) are repeatedly over-represented in recommendation lists and\\nusers' interactions with those items will amplify bias towards those items over\\ntime resulting in a feedback loop. This issue has been extensively studied in\\nthe literature in static recommendation environment where a single round of\\nrecommendation result is processed to improve the exposure fairness. However,\\nless work has been done on addressing exposure bias in a dynamic recommendation\\nsetting where the system is operating over time, the recommendation model and\\nthe input data are dynamically updated with ongoing user feedback on\\nrecommended items at each round. In this paper, we study exposure bias in a\\ndynamic recommendation setting. Our goal is to show that existing bias\\nmitigation methods that are designed to operate in a static recommendation\\nsetting are unable to satisfy fairness of exposure for items in long run. In\\nparticular, we empirically study one of these methods and show that repeatedly\\napplying this method fails to fairly distribute exposure among items in long\\nrun. To address this limitation, we show how this method can be adapted to\\neffectively operate in a dynamic recommendation setting and achieve exposure\\nfairness for items in long run. Experiments on a real-world dataset confirm\\nthat our solution is superior in achieving long-term exposure fairness for the\\nitems while maintaining the recommendation accuracy.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2309.02322v1.pdf'},\n",
       " {'id': '2311.07229v2',\n",
       "  'title': 'Understanding the Influence of Data Characteristics on the Performance\\n  of Point-of-Interest Recommendation Algorithms',\n",
       "  'published': '2023-11-13T10:51:29Z',\n",
       "  'summary': \"Point-of-interest (POI) recommendations are essential for travelers and the\\ne-tourism business. They assist in decision-making regarding what venues to\\nvisit and where to dine and stay. While it is known that traditional\\nrecommendation algorithms' performance depends on data characteristics like\\nsparsity, popularity bias, and preference distributions, the impact of these\\ndata characteristics has not been systematically studied in the POI\\nrecommendation domain. To fill this gap, we extend a previously proposed\\nexplanatory framework by introducing new explanatory variables specifically\\nrelevant to POI recommendation. At its core, the framework relies on having\\nsubsamples with different data characteristics to compute a regression model,\\nwhich reveals the dependencies between data characteristics and performance\\nmetrics of recommendation models. To obtain these subsamples, we subdivide a\\nPOI recommendation data set on New York City and measure the effect of these\\ncharacteristics on different classical POI recommendation algorithms in terms\\nof accuracy, novelty, and item exposure. Our findings confirm the crucial role\\nof key data features like density, popularity bias, and the distribution of\\ncheck-ins in POI recommendation. Additionally, we identify the significance of\\nnovel factors, such as user mobility and the duration of user activity. In\\nsummary, our work presents a generic method to quantify the influence of data\\ncharacteristics on recommendation performance. The results not only show why\\ncertain POI recommendation algorithms excel in specific recommendation problems\\nderived from a LBSN check-in data set in New York City, but also offer\\npractical insights into which data characteristics need to be addressed to\\nachieve better recommendation performance.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2311.07229v2.pdf'},\n",
       " {'id': '2403.18536v1',\n",
       "  'title': 'A Novel Behavior-Based Recommendation System for E-commerce',\n",
       "  'published': '2024-03-27T13:12:41Z',\n",
       "  'summary': \"The majority of existing recommender systems rely on user ratings, which are\\nlimited by the lack of user collaboration and the sparsity problem. To address\\nthese issues, this study proposes a behavior-based recommender system that\\nleverages customers' natural behaviors, such as browsing and clicking, on\\ne-commerce platforms. The proposed recommendation system involves clustering\\nactive customers, determining neighborhoods, collecting similar users,\\ncalculating product reputation based on similar users, and recommending\\nhigh-reputation products. To overcome the complexity of customer behaviors and\\ntraditional clustering methods, an unsupervised clustering approach based on\\nproduct categories is developed to enhance the recommendation methodology. This\\nstudy makes notable contributions in several aspects. Firstly, a groundbreaking\\nbehavior-based recommendation methodology is developed, incorporating customer\\nbehavior to generate accurate and tailored recommendations leading to improved\\ncustomer satisfaction and engagement. Secondly, an original unsupervised\\nclustering method, focusing on product categories, enables more precise\\nclustering and facilitates accurate recommendations. Finally, an approach to\\ndetermine neighborhoods for active customers within clusters is established,\\nensuring grouping of customers with similar behavioral patterns to enhance\\nrecommendation accuracy and relevance. The proposed recommendation methodology\\nand clustering method contribute to improved recommendation performance,\\noffering valuable insights for researchers and practitioners in the field of\\ne-commerce recommendation systems. Additionally, the proposed method\\noutperforms benchmark methods in experiments conducted using a behavior dataset\\nfrom the well-known e-commerce site Alibaba.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.18536v1.pdf'},\n",
       " {'id': '2403.19021v2',\n",
       "  'title': 'IDGenRec: LLM-RecSys Alignment with Textual ID Learning',\n",
       "  'published': '2024-03-27T21:22:37Z',\n",
       "  'summary': 'Generative recommendation based on Large Language Models (LLMs) have\\ntransformed the traditional ranking-based recommendation style into a\\ntext-to-text generation paradigm. However, in contrast to standard NLP tasks\\nthat inherently operate on human vocabulary, current research in generative\\nrecommendations struggles to effectively encode recommendation items within the\\ntext-to-text framework using concise yet meaningful ID representations. To\\nbetter align LLMs with recommendation needs, we propose IDGen, representing\\neach item as a unique, concise, semantically rich, platform-agnostic textual ID\\nusing human language tokens. This is achieved by training a textual ID\\ngenerator alongside the LLM-based recommender, enabling seamless integration of\\npersonalized recommendations into natural language generation. Notably, as user\\nhistory is expressed in natural language and decoupled from the original\\ndataset, our approach suggests the potential for a foundational generative\\nrecommendation model. Experiments show that our framework consistently\\nsurpasses existing models in sequential recommendation under standard\\nexperimental setting. Then, we explore the possibility of training a foundation\\nrecommendation model with the proposed method on data collected from 19\\ndifferent datasets and tested its recommendation performance on 6 unseen\\ndatasets across different platforms under a completely zero-shot setting. The\\nresults show that the zero-shot performance of the pre-trained foundation model\\nis comparable to or even better than some traditional recommendation models\\nbased on supervised training, showing the potential of the IDGen paradigm\\nserving as the foundation model for generative recommendation. Code and data\\nare open-sourced at https://github.com/agiresearch/IDGenRec.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2403.19021v2.pdf'},\n",
       " {'id': '2405.13560v1',\n",
       "  'title': 'Navigating User Experience of ChatGPT-based Conversational Recommender\\n  Systems: The Effects of Prompt Guidance and Recommendation Domain',\n",
       "  'published': '2024-05-22T11:49:40Z',\n",
       "  'summary': \"Conversational recommender systems (CRS) enable users to articulate their\\npreferences and provide feedback through natural language. With the advent of\\nlarge language models (LLMs), the potential to enhance user engagement with CRS\\nand augment the recommendation process with LLM-generated content has received\\nincreasing attention. However, the efficacy of LLM-powered CRS is contingent\\nupon the use of prompts, and the subjective perception of recommendation\\nquality can differ across various recommendation domains. Therefore, we have\\ndeveloped a ChatGPT-based CRS to investigate the impact of these two factors,\\nprompt guidance (PG) and recommendation domain (RD), on the overall user\\nexperience of the system. We conducted an online empirical study (N = 100) by\\nemploying a mixed-method approach that utilized a between-subjects design for\\nthe variable of PG (with vs. without) and a within-subjects design for RD (book\\nrecommendations vs. job recommendations). The findings reveal that PG can\\nsubstantially enhance the system's explainability, adaptability, perceived ease\\nof use, and transparency. Moreover, users are inclined to perceive a greater\\nsense of novelty and demonstrate a higher propensity to engage with and try\\nrecommended items in the context of book recommendations as opposed to job\\nrecommendations. Furthermore, the influence of PG on certain user experience\\nmetrics and interactive behaviors appears to be modulated by the recommendation\\ndomain, as evidenced by the interaction effects between the two examined\\nfactors. This work contributes to the user-centered evaluation of ChatGPT-based\\nCRS by investigating two prominent factors and offers practical design\\nguidance.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2405.13560v1.pdf'},\n",
       " {'id': '2408.03772v1',\n",
       "  'title': 'Relevance meets Diversity: A User-Centric Framework for Knowledge\\n  Exploration through Recommendations',\n",
       "  'published': '2024-08-07T13:48:24Z',\n",
       "  'summary': 'Providing recommendations that are both relevant and diverse is a key\\nconsideration of modern recommender systems. Optimizing both of these measures\\npresents a fundamental trade-off, as higher diversity typically comes at the\\ncost of relevance, resulting in lower user engagement. Existing recommendation\\nalgorithms try to resolve this trade-off by combining the two measures,\\nrelevance and diversity, into one aim and then seeking recommendations that\\noptimize the combined objective, for a given number of items to recommend.\\nTraditional approaches, however, do not consider the user interaction with the\\nrecommended items.\\n  In this paper, we put the user at the central stage, and build on the\\ninterplay between relevance, diversity, and user behavior. In contrast to\\napplications where the goal is solely to maximize engagement, we focus on\\nscenarios aiming at maximizing the total amount of knowledge encountered by the\\nuser. We use diversity as a surrogate of the amount of knowledge obtained by\\nthe user while interacting with the system, and we seek to maximize diversity.\\nWe propose a probabilistic user-behavior model in which users keep interacting\\nwith the recommender system as long as they receive relevant recommendations,\\nbut they may stop if the relevance of the recommended items drops. Thus, for a\\nrecommender system to achieve a high-diversity measure, it will need to produce\\nrecommendations that are both relevant and diverse.\\n  Finally, we propose a novel recommendation strategy that combines relevance\\nand diversity by a copula function. We conduct an extensive evaluation of the\\nproposed methodology over multiple datasets, and we show that our strategy\\noutperforms several state-of-the-art competitors. Our implementation is\\npublicly available at https://github.com/EricaCoppolillo/EXPLORE.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2408.03772v1.pdf'},\n",
       " {'id': '2409.01563v1',\n",
       "  'title': 'Blockchain-based Federated Recommendation with Incentive Mechanism',\n",
       "  'published': '2024-09-03T03:00:59Z',\n",
       "  'summary': 'Nowadays, federated recommendation technology is rapidly evolving to help\\nmultiple organisations share data and train models while meeting user privacy,\\ndata security and government regulatory requirements. However, federated\\nrecommendation increases customer system costs such as power, computational and\\ncommunication resources. Besides, federated recommendation systems are also\\nsusceptible to model attacks and data poisoning by participating malicious\\nclients. Therefore, most customers are unwilling to participate in federated\\nrecommendation without any incentive. To address these problems, we propose a\\nblockchain-based federated recommendation system with incentive mechanism to\\npromote more trustworthy, secure, and efficient federated recommendation\\nservice. First, we construct a federated recommendation system based on NeuMF\\nand FedAvg. Then we introduce a reverse auction mechanism to select optimal\\nclients that can maximize the social surplus. Finally, we employ blockchain for\\non-chain evidence storage of models to ensure the safety of the federated\\nrecommendation system. The experimental results show that our proposed\\nincentive mechanism can attract clients with superior training data to engage\\nin the federal recommendation at a lower cost, which can increase the economic\\nbenefit of federal recommendation by 54.9\\\\% while improve the recommendation\\nperformance. Thus our work provides theoretical and technological support for\\nthe construction of a harmonious and healthy ecological environment for the\\napplication of federal recommendation.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2409.01563v1.pdf'},\n",
       " {'id': '2410.23757v1',\n",
       "  'title': 'Identify Then Recommend: Towards Unsupervised Group Recommendation',\n",
       "  'published': '2024-10-31T09:24:22Z',\n",
       "  'summary': 'Group Recommendation (GR), which aims to recommend items to groups of users,\\nhas become a promising and practical direction for recommendation systems. This\\npaper points out two issues of the state-of-the-art GR models. (1) The\\npre-defined and fixed number of user groups is inadequate for real-time\\nindustrial recommendation systems, where the group distribution can shift\\ndynamically. (2) The training schema of existing GR methods is supervised,\\nnecessitating expensive user-group and group-item labels, leading to\\nsignificant annotation costs. To this end, we present a novel unsupervised\\ngroup recommendation framework named \\\\underline{I}dentify \\\\underline{T}hen\\n\\\\underline{R}ecommend (\\\\underline{ITR}), where it first identifies the user\\ngroups in an unsupervised manner even without the pre-defined number of groups,\\nand then two pre-text tasks are designed to conduct self-supervised group\\nrecommendation. Concretely, at the group identification stage, we first\\nestimate the adaptive density of each user point, where areas with higher\\ndensities are more likely to be recognized as group centers. Then, a heuristic\\nmerge-and-split strategy is designed to discover the user groups and decision\\nboundaries. Subsequently, at the self-supervised learning stage, the\\npull-and-repulsion pre-text task is proposed to optimize the user-group\\ndistribution. Besides, the pseudo group recommendation pre-text task is\\ndesigned to assist the recommendations. Extensive experiments demonstrate the\\nsuperiority and effectiveness of ITR on both user recommendation (e.g., 22.22\\\\%\\nNDCG@5 $\\\\uparrow$) and group recommendation (e.g., 22.95\\\\% NDCG@5 $\\\\uparrow$).\\nFurthermore, we deploy ITR on the industrial recommender and achieve promising\\nresults.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2410.23757v1.pdf'},\n",
       " {'id': '2507.05863v1',\n",
       "  'title': 'KERAG_R: Knowledge-Enhanced Retrieval-Augmented Generation for\\n  Recommendation',\n",
       "  'published': '2025-07-08T10:44:27Z',\n",
       "  'summary': \"Large Language Models (LLMs) have shown strong potential in recommender\\nsystems due to their contextual learning and generalisation capabilities.\\nExisting LLM-based recommendation approaches typically formulate the\\nrecommendation task using specialised prompts designed to leverage their\\ncontextual abilities, and aligning their outputs closely with human preferences\\nto yield an improved recommendation performance. However, the use of LLMs for\\nrecommendation tasks is limited by the absence of domain-specific knowledge.\\nThis lack of relevant relational knowledge about the items to be recommended in\\nthe LLM's pre-training corpus can lead to inaccuracies or hallucinations,\\nresulting in incorrect or misleading recommendations. Moreover, directly using\\ninformation from the knowledge graph introduces redundant and noisy\\ninformation, which can affect the LLM's reasoning process or exceed its input\\ncontext length, thereby reducing the performance of LLM-based recommendations.\\nTo address the lack of domain-specific knowledge, we propose a novel model\\ncalled Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation\\n(KERAG_R). Specifically, we leverage a graph retrieval-augmented generation\\n(GraphRAG) component to integrate additional information from a knowledge graph\\n(KG) into instructions, enabling the LLM to collaboratively exploit\\nrecommendation signals from both text-based user interactions and the knowledge\\ngraph to better estimate the users' preferences in a recommendation context. In\\nparticular, we perform graph RAG by pre-training a graph attention network\\n(GAT) to select the most relevant triple for the target users for the used LLM,\\nthereby enhancing the LLM while reducing redundant and noisy information. Our\\nextensive experiments on three public datasets show that our proposed KERAG_R\\nmodel significantly outperforms ten existing state-of-the-art recommendation\\nmethods.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2507.05863v1.pdf'},\n",
       " {'id': '2508.19620v1',\n",
       "  'title': 'A Scenario-Oriented Survey of Federated Recommender Systems: Techniques,\\n  Challenges, and Future Directions',\n",
       "  'published': '2025-08-27T06:57:50Z',\n",
       "  'summary': \"Extending recommender systems to federated learning (FL) frameworks to\\nprotect the privacy of users or platforms while making recommendations has\\nrecently gained widespread attention in academia. This is due to the natural\\ncoupling of recommender systems and federated learning architectures: the data\\noriginates from distributed clients (mostly mobile devices held by users),\\nwhich are highly related to privacy. In a centralized recommender system\\n(CenRec), the central server collects clients' data, trains the model, and\\nprovides the service. Whereas in federated recommender systems (FedRec), the\\nstep of data collecting is omitted, and the step of model training is offloaded\\nto each client. The server only aggregates the model and other knowledge, thus\\navoiding client privacy leakage. Some surveys of federated recommender systems\\ndiscuss and analyze related work from the perspective of designing FL systems.\\nHowever, their utility drops by ignoring specific recommendation scenarios'\\nunique characteristics and practical challenges. For example, the statistical\\nheterogeneity issue in cross-domain FedRec originates from the label drift of\\nthe data held by different platforms, which is mainly caused by the recommender\\nitself, but not the federated architecture. Therefore, it should focus more on\\nsolving specific problems in real-world recommendation scenarios to encourage\\nthe deployment FedRec. To this end, this review comprehensively analyzes the\\ncoupling of recommender systems and federated learning from the perspective of\\nrecommendation researchers and practitioners. We establish a clear link between\\nrecommendation scenarios and FL frameworks, systematically analyzing\\nscenario-specific approaches, practical challenges, and potential\\nopportunities. We aim to develop guidance for the real-world deployment of\\nFedRec, bridging the gap between existing research and applications.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.19620v1.pdf'},\n",
       " {'id': '2508.03680v1',\n",
       "  'title': 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning',\n",
       "  'published': '2025-08-05T17:50:13Z',\n",
       "  'summary': \"We present Agent Lightning, a flexible and extensible framework that enables\\nReinforcement Learning (RL)-based training of Large Language Models (LLMs) for\\nany AI agent. Unlike existing methods that tightly couple RL training with\\nagent or rely on sequence concatenation with masking, Agent Lightning achieves\\ncomplete decoupling between agent execution and training, allowing seamless\\nintegration with existing agents developed via diverse ways (e.g., using\\nframeworks like LangChain, OpenAI Agents SDK, AutoGen, and building from\\nscratch) with almost ZERO code modifications. By formulating agent execution as\\nMarkov decision process, we define an unified data interface and propose a\\nhierarchical RL algorithm, LightningRL, which contains a credit assignment\\nmodule, allowing us to decompose trajectories generated by ANY agents into\\ntraining transition. This enables RL to handle complex interaction logic, such\\nas multi-agent scenarios and dynamic workflows. For the system design, we\\nintroduce a Training-Agent Disaggregation architecture, and brings agent\\nobservability frameworks into agent runtime, providing a standardized agent\\nfinetuning interface. Experiments across text-to-SQL, retrieval-augmented\\ngeneration, and math tool-use tasks demonstrate stable, continuous\\nimprovements, showcasing the framework's potential for real-world agent\\ntraining and deployment.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2508.03680v1.pdf'},\n",
       " {'id': '1906.10910v2',\n",
       "  'title': 'Creating A Neural Pedagogical Agent by Jointly Learning to Review and\\n  Assess',\n",
       "  'published': '2019-06-26T08:37:44Z',\n",
       "  'summary': 'Machine learning plays an increasing role in intelligent tutoring systems as\\nboth the amount of data available and specialization among students grow.\\nNowadays, these systems are frequently deployed on mobile applications. Users\\non such mobile education platforms are dynamic, frequently being added,\\naccessing the application with varying levels of focus, and changing while\\nusing the service. The education material itself, on the other hand, is often\\nstatic and is an exhaustible resource whose use in tasks such as problem\\nrecommendation must be optimized. The ability to update user models with\\nrespect to educational material in real-time is thus essential; however,\\nexisting approaches require time-consuming re-training of user features\\nwhenever new data is added. In this paper, we introduce a neural pedagogical\\nagent for real-time user modeling in the task of predicting user response\\ncorrectness, a central task for mobile education applications. Our model,\\ninspired by work in natural language processing on sequence modeling and\\nmachine translation, updates user features in real-time via bidirectional\\nrecurrent neural networks with an attention mechanism over embedded\\nquestion-response pairs. We experiment on the mobile education application\\nSantaTOEIC, which has 559k users, 66M response data points as well as a set of\\n10k study problems each expert-annotated with topic tags and gathered since\\n2016. Our model outperforms existing approaches over several metrics in\\npredicting user response correctness, notably out-performing other methods on\\nnew users without large question-response histories. Additionally, our\\nattention mechanism and annotated tag set allow us to create an interpretable\\neducation platform, with a smart review system that addresses the\\naforementioned issue of varied user attention and problem exhaustion.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1906.10910v2.pdf'},\n",
       " {'id': '1905.01365v1',\n",
       "  'title': 'A multi-agent system approach in evaluating human spatio-temporal\\n  vulnerability to seismic risk using social attachment',\n",
       "  'published': '2019-05-02T13:12:13Z',\n",
       "  'summary': 'Social attachment theory states that individuals seek the proximity of\\nattachment figures (e.g. family members, friends, colleagues, familiar places\\nor objects) when faced with threat. During disasters, this means that family\\nmembers may seek each other before evacuating, gather personal property before\\nheading to familiar exits and places, or follow groups/crowds, etc. This\\nhard-wired human tendency should be considered in the assessment of risk and\\nthe creation of disaster management plans. Doing so may result in more\\nrealistic evacuation procedures and may minimise the number of casualties and\\ninjuries. In this context, a dynamic spatio-temporal analysis of seismic risk\\nis presented using SOLACE, a multi-agent model of pedestrian behaviour based on\\nsocial attachment theory implemented using the Belief-Desire-Intention\\napproach. The model focuses on the influence of human, social, physical and\\ntemporal factors on successful evacuation. Human factors considered include\\nperception and mobility defined by age. Social factors are defined by\\nattachment bonds, social groups, population distribution, and cultural norms.\\nPhysical factors refer to the location of the epicentre of the earthquake,\\nspatial distribution/layout and attributes of environmental objects such as\\nbuildings, roads, barriers (cars), placement of safe areas, evacuation routes,\\nand the resulting debris/damage from the earthquake. Experiments tested the\\ninfluence of time of the day, presence of disabled persons and earthquake\\nintensity. Initial results show that factors that influence arrivals in safe\\nareas include (a) human factors (age, disability, speed), (b) pre-evacuation\\nbehaviours, (c) perception distance (social attachment, time of day), (d)\\nsocial interaction during evacuation, and (e) physical and spatial aspects,\\nsuch as limitations imposed by debris (damage), and the distance to safe areas.\\nTo validate the results, scenarios will be designed with stakeholders, who will\\nalso take part in the definition of a serious game. The recommendation of this\\nresearch is that both social and physical aspects should be considered when\\ndefining vulnerability in the analysis of risk.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/1905.01365v1.pdf'},\n",
       " {'id': '2012.05105v1',\n",
       "  'title': 'Com-DDPG: A Multiagent Reinforcement Learning-based Offloading Strategy\\n  for Mobile Edge Computing',\n",
       "  'published': '2020-12-09T15:22:47Z',\n",
       "  'summary': \"The development of mobile services has impacted a variety of\\ncomputation-intensive and time-sensitive applications, such as recommendation\\nsystems and daily payment methods. However, computing task competition\\ninvolving limited resources increases the task processing latency and energy\\nconsumption of mobile devices, as well as time constraints. Mobile edge\\ncomputing (MEC) has been widely used to address these problems. However, there\\nare limitations to existing methods used during computation offloading. On the\\none hand, they focus on independent tasks rather than dependent tasks. The\\nchallenges of task dependency in the real world, especially task segmentation\\nand integration, remain to be addressed. On the other hand, the multiuser\\nscenarios related to resource allocation and the mutex access problem must be\\nconsidered. In this paper, we propose a novel offloading approach, Com-DDPG,\\nfor MEC using multiagent reinforcement learning to enhance the offloading\\nperformance. First, we discuss the task dependency model, task priority model,\\nenergy consumption model, and average latency from the perspective of server\\nclusters and multidependence on mobile tasks. Our method based on these models\\nis introduced to formalize communication behavior among multiple agents; then,\\nreinforcement learning is executed as an offloading strategy to obtain the\\nresults. Because of the incomplete state information, long short-term memory\\n(LSTM) is employed as a decision-making tool to assess the internal state.\\nMoreover, to optimize and support effective action, we consider using a\\nbidirectional recurrent neural network (BRNN) to learn and enhance features\\nobtained from agents' communication. Finally, we simulate experiments on the\\nAlibaba cluster dataset. The results show that our method is better than other\\nbaselines in terms of energy consumption, load status and latency.\",\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2012.05105v1.pdf'},\n",
       " {'id': '2112.02271v4',\n",
       "  'title': 'Cooperation, Retaliation and Forgiveness in Revision Games',\n",
       "  'published': '2021-12-04T07:40:09Z',\n",
       "  'summary': 'Revision game is a very new model formulating the real-time situation where\\nplayers dynamically prepare and revise their actions in advance before a\\ndeadline when payoffs are realized. It is at the cutting edge of dynamic game\\ntheory and can be applied in many real-world scenarios, such as eBay auction,\\nstock market, election, online games, crowdsourcing, etc. In this work, we\\nnovelly identify a class of strategies for revision games which are called\\nLimited Retaliation strategies. An limited retaliation strategy stipulates\\nthat, (1) players first follow a recommended cooperative plan; (2) if anyone\\ndeviates from the plan, the limited retaliation player retaliates by using the\\ndefection action for a limited duration; (3) after the retaliation, the limited\\nretaliation player returns to the cooperative plan. A limited retaliation\\nstrategy has three key features. It is cooperative, sustaining a high level of\\nsocial welfare. It is vengeful, deterring the opponent from betrayal by\\nthreatening with a future retaliation. It is yet forgiving, since it resumes\\ncooperation after a proper retaliation. The cooperativeness and vengefulness\\nmake it constitute cooperative subgame perfect equilibrium, while the\\nforgiveness makes it tolerate occasional mistakes. limited retaliation\\nstrategies show significant advantages over Grim Trigger, which is currently\\nthe only known strategy for revision games. Besides its contribution as a new\\nrobust and welfare-optimizing equilibrium strategy, our results about limited\\nretaliation strategy can also be used to explain how easy cooperation can\\nhappen, and why forgiveness emerges in real-world multi-agent interactions. In\\naddition, limited retaliation strategies are simple to derive and\\ncomputationally efficient, making it easy for algorithm design and\\nimplementation in many multi-agent systems.',\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2112.02271v4.pdf'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c281e3dc-1ed8-40f7-aa23-963de588e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r[\"published\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d52621df-8c81-48c1-9287-4dcbc85e07d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic Feedback Loop Modeling Improves Recommendation and User\n",
      "  Simulation, 2024-10-26T00:51:39Z, http://arxiv.org/pdf/2410.20027v2.pdf\n",
      "--------------------------------------------------\n",
      "Prospect Personalized Recommendation on Large Language Model-based Agent\n",
      "  Platform, 2024-02-28T11:12:17Z, http://arxiv.org/pdf/2402.18240v2.pdf\n",
      "--------------------------------------------------\n",
      "MACRec: a Multi-Agent Collaboration Framework for Recommendation, 2024-02-23T09:57:20Z, http://arxiv.org/pdf/2402.15235v3.pdf\n",
      "--------------------------------------------------\n",
      "A Survey on LLM-powered Agents for Recommender Systems, 2025-02-14T09:57:07Z, http://arxiv.org/pdf/2502.10050v1.pdf\n",
      "--------------------------------------------------\n",
      "VRAgent-R1: Boosting Video Recommendation with MLLM-based Agents via\n",
      "  Reinforcement Learning, 2025-07-03T13:52:24Z, http://arxiv.org/pdf/2507.02626v1.pdf\n",
      "--------------------------------------------------\n",
      "Personalized Recommendation Systems using Multimodal, Autonomous, Multi\n",
      "  Agent Systems, 2024-10-22T14:11:26Z, http://arxiv.org/pdf/2410.19855v1.pdf\n",
      "--------------------------------------------------\n",
      "Optimizing Conversational Product Recommendation via Reinforcement\n",
      "  Learning, 2025-06-30T00:59:58Z, http://arxiv.org/pdf/2507.01060v1.pdf\n",
      "--------------------------------------------------\n",
      "The Future is Agentic: Definitions, Perspectives, and Open Challenges of\n",
      "  Multi-Agent Recommender Systems, 2025-07-02T19:25:44Z, http://arxiv.org/pdf/2507.02097v2.pdf\n",
      "--------------------------------------------------\n",
      "AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender\n",
      "  Systems, 2025-05-26T07:45:11Z, http://arxiv.org/pdf/2505.19623v2.pdf\n",
      "--------------------------------------------------\n",
      "AdaptJobRec: Enhancing Conversational Career Recommendation through an\n",
      "  LLM-Powered Agentic System, 2025-08-19T00:44:25Z, http://arxiv.org/pdf/2508.13423v1.pdf\n",
      "--------------------------------------------------\n",
      "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent, 2025-06-30T03:15:50Z, http://arxiv.org/pdf/2506.23485v1.pdf\n",
      "--------------------------------------------------\n",
      "RecoWorld: Building Simulated Environments for Agentic Recommender\n",
      "  Systems, 2025-09-12T16:44:34Z, http://arxiv.org/pdf/2509.10397v1.pdf\n",
      "--------------------------------------------------\n",
      "On Generative Agents in Recommendation, 2023-10-16T06:41:16Z, http://arxiv.org/pdf/2310.10108v3.pdf\n",
      "--------------------------------------------------\n",
      "AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to\n",
      "  Human Feedback, 2025-01-23T02:25:44Z, http://arxiv.org/pdf/2501.13333v1.pdf\n",
      "--------------------------------------------------\n",
      "ARAG: Agentic Retrieval Augmented Generation for Personalized\n",
      "  Recommendation, 2025-06-27T05:45:59Z, http://arxiv.org/pdf/2506.21931v2.pdf\n",
      "--------------------------------------------------\n",
      "CADRL: Category-aware Dual-agent Reinforcement Learning for Explainable\n",
      "  Recommendations over Knowledge Graphs, 2024-08-06T13:07:08Z, http://arxiv.org/pdf/2408.03166v1.pdf\n",
      "--------------------------------------------------\n",
      "Overcoming the Price of Anarchy by Steering with Recommendations, 2025-02-26T09:49:28Z, http://arxiv.org/pdf/2502.18988v1.pdf\n",
      "--------------------------------------------------\n",
      "MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational\n",
      "  Recommender?, 2025-04-26T00:55:43Z, http://arxiv.org/pdf/2504.20094v1.pdf\n",
      "--------------------------------------------------\n",
      "Knowledge Graph Enhanced Language Agents for Recommendation, 2024-10-25T15:25:36Z, http://arxiv.org/pdf/2410.19627v2.pdf\n",
      "--------------------------------------------------\n",
      "All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems\n",
      "  Across the LLM Era, 2024-07-14T05:02:21Z, http://arxiv.org/pdf/2407.10081v1.pdf\n",
      "--------------------------------------------------\n",
      "RecMind: Large Language Model Powered Agent For Recommendation, 2023-08-28T04:31:04Z, http://arxiv.org/pdf/2308.14296v3.pdf\n",
      "--------------------------------------------------\n",
      "Lending Interaction Wings to Recommender Systems with Conversational\n",
      "  Agents, 2023-10-06T13:16:27Z, http://arxiv.org/pdf/2310.04230v1.pdf\n",
      "--------------------------------------------------\n",
      "Fair Reciprocal Recommendation in Matching Markets, 2024-09-01T13:33:41Z, http://arxiv.org/pdf/2409.00720v1.pdf\n",
      "--------------------------------------------------\n",
      "TASER: Table Agents for Schema-guided Extraction and Recommendation, 2025-08-18T23:48:22Z, http://arxiv.org/pdf/2508.13404v2.pdf\n",
      "--------------------------------------------------\n",
      "The Amplification Paradox in Recommender Systems, 2023-02-22T09:12:48Z, http://arxiv.org/pdf/2302.11225v2.pdf\n",
      "--------------------------------------------------\n",
      "A Survey of Large Language Model Empowered Agents for Recommendation and\n",
      "  Search: Towards Next-Generation Information Retrieval, 2025-03-07T18:20:30Z, http://arxiv.org/pdf/2503.05659v2.pdf\n",
      "--------------------------------------------------\n",
      "RAH! RecSys-Assistant-Human: A Human-Centered Recommendation Framework\n",
      "  with LLM Agents, 2023-08-19T04:46:01Z, http://arxiv.org/pdf/2308.09904v2.pdf\n",
      "--------------------------------------------------\n",
      "Multi-agent Attacks for Black-box Social Recommendations, 2023-11-13T07:40:23Z, http://arxiv.org/pdf/2311.07127v4.pdf\n",
      "--------------------------------------------------\n",
      "AgentCF: Collaborative Learning with Autonomous Language Agents for\n",
      "  Recommender Systems, 2023-10-13T16:37:14Z, http://arxiv.org/pdf/2310.09233v1.pdf\n",
      "--------------------------------------------------\n",
      "LLM is Knowledge Graph Reasoner: LLM's Intuition-aware Knowledge Graph\n",
      "  Reasoning for Cold-start Sequential Recommendation, 2024-12-17T01:52:15Z, http://arxiv.org/pdf/2412.12464v1.pdf\n",
      "--------------------------------------------------\n",
      "UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender\n",
      "  Systems with UNidirectional EXecution, 2024-01-12T09:32:34Z, http://arxiv.org/pdf/2401.06470v1.pdf\n",
      "--------------------------------------------------\n",
      "Rethinking Group Recommender Systems in the Era of Generative AI: From\n",
      "  One-Shot Recommendations to Agentic Group Decision Support, 2025-07-01T07:56:37Z, http://arxiv.org/pdf/2507.00535v1.pdf\n",
      "--------------------------------------------------\n",
      "CARTS: Collaborative Agents for Recommendation Textual Summarization, 2025-06-21T17:18:35Z, http://arxiv.org/pdf/2506.17765v2.pdf\n",
      "--------------------------------------------------\n",
      "Long Short-Term Planning for Conversational Recommendation Systems, 2023-10-23T06:34:39Z, http://arxiv.org/pdf/2310.14609v1.pdf\n",
      "--------------------------------------------------\n",
      "On the Opportunities and Challenges of Offline Reinforcement Learning\n",
      "  for Recommender Systems, 2023-08-22T10:28:02Z, http://arxiv.org/pdf/2308.11336v1.pdf\n",
      "--------------------------------------------------\n",
      "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform\n",
      "  for Dynamic Recommender Systems, 2025-05-22T09:14:23Z, http://arxiv.org/pdf/2505.16429v1.pdf\n",
      "--------------------------------------------------\n",
      "Transparency, Privacy, and Fairness in Recommender Systems, 2024-06-17T08:37:14Z, http://arxiv.org/pdf/2406.11323v2.pdf\n",
      "--------------------------------------------------\n",
      "iAgent: LLM Agent as a Shield between User and Recommender Systems, 2025-02-20T15:58:25Z, http://arxiv.org/pdf/2502.14662v4.pdf\n",
      "--------------------------------------------------\n",
      "A Multi-Agent Conversational Recommender System, 2024-02-02T04:20:13Z, http://arxiv.org/pdf/2402.01135v1.pdf\n",
      "--------------------------------------------------\n",
      "Impact of Rankings and Personalized Recommendations in Marketplaces, 2025-06-03T20:26:14Z, http://arxiv.org/pdf/2506.03369v1.pdf\n",
      "--------------------------------------------------\n",
      "Simulating Filter Bubble on Short-video Recommender System with Large\n",
      "  Language Model Agents, 2025-03-23T10:35:58Z, http://arxiv.org/pdf/2504.08742v1.pdf\n",
      "--------------------------------------------------\n",
      "RecAI: Leveraging Large Language Models for Next-Generation Recommender\n",
      "  Systems, 2024-03-11T07:07:02Z, http://arxiv.org/pdf/2403.06465v1.pdf\n",
      "--------------------------------------------------\n",
      "Leveraging LLMs to Create a Haptic Devices' Recommendation System, 2025-01-22T01:41:05Z, http://arxiv.org/pdf/2501.12573v1.pdf\n",
      "--------------------------------------------------\n",
      "LLM-Based Intelligent Agents for Music Recommendation: A Comparison with\n",
      "  Classical Content-Based Filtering, 2025-08-07T15:58:08Z, http://arxiv.org/pdf/2508.11671v1.pdf\n",
      "--------------------------------------------------\n",
      "A Model-based Multi-Agent Personalized Short-Video Recommender System, 2024-05-03T04:34:36Z, http://arxiv.org/pdf/2405.01847v1.pdf\n",
      "--------------------------------------------------\n",
      "Exploring the Impact of Personality Traits on Conversational Recommender\n",
      "  Systems: A Simulation with Large Language Models, 2025-04-09T13:21:17Z, http://arxiv.org/pdf/2504.12313v1.pdf\n",
      "--------------------------------------------------\n",
      "ID-Free Not Risk-Free: LLM-Powered Agents Unveil Risks in ID-Free\n",
      "  Recommender Systems, 2024-09-18T04:10:44Z, http://arxiv.org/pdf/2409.11690v3.pdf\n",
      "--------------------------------------------------\n",
      "MAS4POI: a Multi-Agents Collaboration System for Next POI Recommendation, 2024-09-05T02:47:49Z, http://arxiv.org/pdf/2409.13700v1.pdf\n",
      "--------------------------------------------------\n",
      "Agent0: Leveraging LLM Agents to Discover Multi-value Features from Text\n",
      "  for Enhanced Recommendations, 2025-07-25T06:45:10Z, http://arxiv.org/pdf/2507.18993v1.pdf\n",
      "--------------------------------------------------\n",
      "Agent-Based Exploration of Recommendation Systems in Misinformation\n",
      "  Propagation, 2025-07-29T12:00:38Z, http://arxiv.org/pdf/2507.21724v1.pdf\n",
      "--------------------------------------------------\n",
      "Cloud-Device Collaborative Agents for Sequential Recommendation, 2025-09-01T15:28:11Z, http://arxiv.org/pdf/2509.01551v1.pdf\n",
      "--------------------------------------------------\n",
      "GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware\n",
      "  Recommender Simulation, 2025-05-27T13:09:21Z, http://arxiv.org/pdf/2505.21154v1.pdf\n",
      "--------------------------------------------------\n",
      "How to Train Your YouTube Recommender to Avoid Unwanted Videos, 2023-07-27T00:21:29Z, http://arxiv.org/pdf/2307.14551v3.pdf\n",
      "--------------------------------------------------\n",
      "Contrastive Representation for Interactive Recommendation, 2024-12-24T12:39:23Z, http://arxiv.org/pdf/2412.18396v3.pdf\n",
      "--------------------------------------------------\n",
      "Towards Agentic Recommender Systems in the Era of Multimodal Large\n",
      "  Language Models, 2025-03-20T22:37:15Z, http://arxiv.org/pdf/2503.16734v1.pdf\n",
      "--------------------------------------------------\n",
      "Designing and evaluating an online reinforcement learning agent for\n",
      "  physical exercise recommendations in N-of-1 trials, 2023-09-25T14:08:21Z, http://arxiv.org/pdf/2309.14156v2.pdf\n",
      "--------------------------------------------------\n",
      "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations\n",
      "  in Tourism, 2025-08-20T19:49:06Z, http://arxiv.org/pdf/2508.15030v1.pdf\n",
      "--------------------------------------------------\n",
      "REMI: A Novel Causal Schema Memory Architecture for Personalized\n",
      "  Lifestyle Recommendation Agents, 2025-09-08T01:17:46Z, http://arxiv.org/pdf/2509.06269v1.pdf\n",
      "--------------------------------------------------\n",
      "Towards Aligning Personalized Conversational Recommendation Agents with\n",
      "  Users' Privacy Preferences, 2025-08-11T06:51:44Z, http://arxiv.org/pdf/2508.07672v1.pdf\n",
      "--------------------------------------------------\n",
      "Multi-agents based User Values Mining for Recommendation, 2025-05-02T04:01:31Z, http://arxiv.org/pdf/2505.00981v1.pdf\n",
      "--------------------------------------------------\n",
      "Dynamic fairness-aware recommendation through multi-agent social choice, 2023-03-02T05:06:17Z, http://arxiv.org/pdf/2303.00968v3.pdf\n",
      "--------------------------------------------------\n",
      "Towards a Unified Conversational Recommendation System: Multi-task\n",
      "  Learning via Contextualized Knowledge Distillation, 2023-10-27T13:06:24Z, http://arxiv.org/pdf/2310.18119v1.pdf\n",
      "--------------------------------------------------\n",
      "Learning Recommender Mechanisms for Bayesian Stochastic Games, 2025-05-29T01:34:54Z, http://arxiv.org/pdf/2505.22979v1.pdf\n",
      "--------------------------------------------------\n",
      "Peer Learning: Learning Complex Policies in Groups from Scratch via\n",
      "  Action Recommendations, 2023-12-15T17:01:35Z, http://arxiv.org/pdf/2312.09950v2.pdf\n",
      "--------------------------------------------------\n",
      "Instructor-Worker Large Language Model System for Policy Recommendation:\n",
      "  a Case Study on Air Quality Analysis of the January 2025 Los Angeles\n",
      "  Wildfires, 2025-03-01T17:29:26Z, http://arxiv.org/pdf/2503.00566v3.pdf\n",
      "--------------------------------------------------\n",
      "Coevolution of relationship-driven cooperation under recommendation\n",
      "  protocol on multiplex networks, 2024-11-19T11:53:26Z, http://arxiv.org/pdf/2411.12436v1.pdf\n",
      "--------------------------------------------------\n",
      "DrunkAgent: Stealthy Memory Corruption in LLM-Powered Recommender Agents, 2025-03-31T07:35:40Z, http://arxiv.org/pdf/2503.23804v2.pdf\n",
      "--------------------------------------------------\n",
      "Lessons Learned from Evaluation of LLM based Multi-agents in Safer\n",
      "  Therapy Recommendation, 2025-07-15T02:01:38Z, http://arxiv.org/pdf/2507.10911v1.pdf\n",
      "--------------------------------------------------\n",
      "Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise\n",
      "  Recommendation, 2024-09-11T17:01:06Z, http://arxiv.org/pdf/2409.07416v2.pdf\n",
      "--------------------------------------------------\n",
      "TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal\n",
      "  Conversational Music Recommendation, 2025-08-18T05:06:58Z, http://arxiv.org/pdf/2509.09685v1.pdf\n",
      "--------------------------------------------------\n",
      "Interactive Garment Recommendation with User in the Loop, 2024-02-18T16:01:28Z, http://arxiv.org/pdf/2402.11627v1.pdf\n",
      "--------------------------------------------------\n",
      "Balancing Information Perception with Yin-Yang: Agent-Based Information\n",
      "  Neutrality Model for Recommendation Systems, 2024-04-07T10:16:22Z, http://arxiv.org/pdf/2404.04906v1.pdf\n",
      "--------------------------------------------------\n",
      "Incorporating External Knowledge and Goal Guidance for LLM-based\n",
      "  Conversational Recommender Systems, 2024-05-03T05:42:57Z, http://arxiv.org/pdf/2405.01868v1.pdf\n",
      "--------------------------------------------------\n",
      "A Survey of Foundation Model-Powered Recommender Systems: From\n",
      "  Feature-Based, Generative to Agentic Paradigms, 2025-04-23T05:02:51Z, http://arxiv.org/pdf/2504.16420v1.pdf\n",
      "--------------------------------------------------\n",
      "Recommender AI Agent: Integrating Large Language Models for Interactive\n",
      "  Recommendations, 2023-08-31T07:36:44Z, http://arxiv.org/pdf/2308.16505v3.pdf\n",
      "--------------------------------------------------\n",
      "Balancing Benefits and Risks: RL Approaches for Addiction-Aware Social\n",
      "  Media Recommenders, 2025-02-25T09:43:25Z, http://arxiv.org/pdf/2504.05322v1.pdf\n",
      "--------------------------------------------------\n",
      "Evaluating Conversational Recommender Systems via Large Language Models:\n",
      "  A User-Centric Framework, 2025-01-16T12:06:56Z, http://arxiv.org/pdf/2501.09493v3.pdf\n",
      "--------------------------------------------------\n",
      "PersonaX: A Recommendation Agent Oriented User Modeling Framework for\n",
      "  Long Behavior Sequence, 2025-03-04T08:41:40Z, http://arxiv.org/pdf/2503.02398v2.pdf\n",
      "--------------------------------------------------\n",
      "STARec: An Efficient Agent Framework for Recommender Systems via\n",
      "  Autonomous Deliberate Reasoning, 2025-08-26T08:47:58Z, http://arxiv.org/pdf/2508.18812v1.pdf\n",
      "--------------------------------------------------\n",
      "Muse: A Multimodal Conversational Recommendation Dataset with\n",
      "  Scenario-Grounded User Profiles, 2024-12-24T13:08:34Z, http://arxiv.org/pdf/2412.18416v2.pdf\n",
      "--------------------------------------------------\n",
      "Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test\n",
      "  Data, 2025-01-06T02:50:51Z, http://arxiv.org/pdf/2501.02727v1.pdf\n",
      "--------------------------------------------------\n",
      "Online Recommendations for Agents with Discounted Adaptive Preferences, 2023-02-12T22:04:27Z, http://arxiv.org/pdf/2302.06014v2.pdf\n",
      "--------------------------------------------------\n",
      "Model-enhanced Contrastive Reinforcement Learning for Sequential\n",
      "  Recommendation, 2023-10-25T11:43:29Z, http://arxiv.org/pdf/2310.16566v1.pdf\n",
      "--------------------------------------------------\n",
      "Research on Conversational Recommender System Considering Consumer Types, 2025-08-16T15:15:52Z, http://arxiv.org/pdf/2508.13209v2.pdf\n",
      "--------------------------------------------------\n",
      "An Extremely Data-efficient and Generative LLM-based Reinforcement\n",
      "  Learning Agent for Recommenders, 2024-08-28T10:31:50Z, http://arxiv.org/pdf/2408.16032v1.pdf\n",
      "--------------------------------------------------\n",
      "Preference-based learning for news headline recommendation, 2025-05-31T12:57:56Z, http://arxiv.org/pdf/2506.06334v1.pdf\n",
      "--------------------------------------------------\n",
      "VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and\n",
      "  LLM-Augmented CLIP Embeddings, 2025-07-22T23:45:43Z, http://arxiv.org/pdf/2507.17080v1.pdf\n",
      "--------------------------------------------------\n",
      "Salespeople vs SalesBot: Exploring the Role of Educational Value in\n",
      "  Conversational Recommender Systems, 2023-10-26T19:44:06Z, http://arxiv.org/pdf/2310.17749v1.pdf\n",
      "--------------------------------------------------\n",
      "RuleAgent: Discovering Rules for Recommendation Denoising with\n",
      "  Autonomous Language Agents, 2025-03-30T09:19:03Z, http://arxiv.org/pdf/2503.23374v1.pdf\n",
      "--------------------------------------------------\n",
      "DARLR: Dual-Agent Offline Reinforcement Learning for Recommender Systems\n",
      "  with Dynamic Reward, 2025-05-12T06:18:31Z, http://arxiv.org/pdf/2505.07257v1.pdf\n",
      "--------------------------------------------------\n",
      "Performative Debias with Fair-exposure Optimization Driven by Strategic\n",
      "  Agents in Recommender Systems, 2024-06-25T11:41:50Z, http://arxiv.org/pdf/2406.17475v1.pdf\n",
      "--------------------------------------------------\n",
      "Expectation Confirmation Preference Optimization for Multi-Turn\n",
      "  Conversational Recommendation Agent, 2025-06-17T08:29:04Z, http://arxiv.org/pdf/2506.14302v1.pdf\n",
      "--------------------------------------------------\n",
      "Agentic Personalized Fashion Recommendation in the Age of Generative AI:\n",
      "  Challenges, Opportunities, and Evaluation, 2025-08-04T12:22:25Z, http://arxiv.org/pdf/2508.02342v1.pdf\n",
      "--------------------------------------------------\n",
      "Offline Evaluation for Reinforcement Learning-based Recommendation: A\n",
      "  Critical Issue and Some Alternatives, 2023-01-03T08:03:37Z, http://arxiv.org/pdf/2301.00993v1.pdf\n",
      "--------------------------------------------------\n",
      "Multimodal Recommendation Dialog with Subjective Preference: A New\n",
      "  Challenge and Benchmark, 2023-05-26T08:43:46Z, http://arxiv.org/pdf/2305.18212v1.pdf\n",
      "--------------------------------------------------\n",
      "YouTube Recommendations Reinforce Negative Emotions: Auditing\n",
      "  Algorithmic Bias with Emotionally-Agentic Sock Puppets, 2025-01-25T03:04:53Z, http://arxiv.org/pdf/2501.15048v1.pdf\n",
      "--------------------------------------------------\n",
      "AutoDenoise: Automatic Data Instance Denoising for Recommendations, 2023-03-12T08:36:15Z, http://arxiv.org/pdf/2303.06611v1.pdf\n",
      "--------------------------------------------------\n",
      "Contrastive State Augmentations for Reinforcement Learning-Based\n",
      "  Recommender Systems, 2023-05-18T16:08:34Z, http://arxiv.org/pdf/2305.11081v1.pdf\n",
      "--------------------------------------------------\n",
      "Simulating News Recommendation Ecosystem for Fun and Profit, 2023-05-23T14:25:37Z, http://arxiv.org/pdf/2305.14103v1.pdf\n",
      "--------------------------------------------------\n",
      "Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking\n",
      "  Intent in Recommender Systems, 2023-06-02T12:02:23Z, http://arxiv.org/pdf/2306.01476v1.pdf\n",
      "--------------------------------------------------\n",
      "Filter Bubble or Homogenization? Disentangling the Long-Term Effects of\n",
      "  Recommendations on User Consumption Patterns, 2024-02-22T23:12:20Z, http://arxiv.org/pdf/2402.15013v2.pdf\n",
      "--------------------------------------------------\n",
      "Proxy Model-Guided Reinforcement Learning for Client Selection in\n",
      "  Federated Recommendation, 2025-08-14T07:03:39Z, http://arxiv.org/pdf/2508.10401v1.pdf\n",
      "--------------------------------------------------\n",
      "SemSR: Semantics aware robust Session-based Recommendations, 2025-08-28T09:25:54Z, http://arxiv.org/pdf/2508.20587v1.pdf\n",
      "--------------------------------------------------\n",
      "Multi-Scenario Combination Based on Multi-Agent Reinforcement Learning\n",
      "  to Optimize the Advertising Recommendation System, 2024-07-03T02:33:20Z, http://arxiv.org/pdf/2407.02759v1.pdf\n",
      "--------------------------------------------------\n",
      "Uncertainty-Aware GUI Agent: Adaptive Perception through Component\n",
      "  Recommendation and Human-in-the-Loop Refinement, 2025-08-06T02:38:02Z, http://arxiv.org/pdf/2508.04025v1.pdf\n",
      "--------------------------------------------------\n",
      "Adversarial Batch Inverse Reinforcement Learning: Learn to Reward from\n",
      "  Imperfect Demonstration for Interactive Recommendation, 2023-10-30T13:43:20Z, http://arxiv.org/pdf/2310.19536v1.pdf\n",
      "--------------------------------------------------\n",
      "A Conceptual Framework for Conversational Search and Recommendation:\n",
      "  Conceptualizing Agent-Human Interactions During the Conversational Search\n",
      "  Process, 2024-04-12T17:48:18Z, http://arxiv.org/pdf/2404.08630v1.pdf\n",
      "--------------------------------------------------\n",
      "AgentSociety Challenge: Designing LLM Agents for User Modeling and\n",
      "  Recommendation on Web Platforms, 2025-02-26T02:10:25Z, http://arxiv.org/pdf/2502.18754v1.pdf\n",
      "--------------------------------------------------\n",
      "Exploring Social Choice Mechanisms for Recommendation Fairness in SCRUF, 2023-09-10T17:47:21Z, http://arxiv.org/pdf/2309.08621v2.pdf\n",
      "--------------------------------------------------\n",
      "Explainable Session-based Recommendation via Path Reasoning, 2024-02-28T12:11:08Z, http://arxiv.org/pdf/2403.00832v1.pdf\n",
      "--------------------------------------------------\n",
      "SAPIENT: Mastering Multi-turn Conversational Recommendation with\n",
      "  Strategic Planning and Monte Carlo Tree Search, 2024-10-12T16:21:33Z, http://arxiv.org/pdf/2410.09580v3.pdf\n",
      "--------------------------------------------------\n",
      "LLM-Based User Simulation for Low-Knowledge Shilling Attacks on\n",
      "  Recommender Systems, 2025-05-18T04:40:34Z, http://arxiv.org/pdf/2505.13528v1.pdf\n",
      "--------------------------------------------------\n",
      "Learn to Preserve Personality: Federated Foundation Models in\n",
      "  Recommendations, 2025-06-13T08:17:07Z, http://arxiv.org/pdf/2506.11563v1.pdf\n",
      "--------------------------------------------------\n",
      "Generative Slate Recommendation with Reinforcement Learning, 2023-01-20T15:28:09Z, http://arxiv.org/pdf/2301.08632v2.pdf\n",
      "--------------------------------------------------\n",
      "Re2LLM: Reflective Reinforcement Large Language Model for Session-based\n",
      "  Recommendation, 2024-03-25T05:12:18Z, http://arxiv.org/pdf/2403.16427v4.pdf\n",
      "--------------------------------------------------\n",
      "Reinforced Prompt Personalization for Recommendation with Large Language\n",
      "  Models, 2024-07-24T09:24:49Z, http://arxiv.org/pdf/2407.17115v2.pdf\n",
      "--------------------------------------------------\n",
      "Towards Recommender Systems LLMs Playground (RecSysLLMsP): Exploring\n",
      "  Polarization and Engagement in Simulated Social Networks, 2025-01-29T14:23:34Z, http://arxiv.org/pdf/2502.00055v1.pdf\n",
      "--------------------------------------------------\n",
      "Psychotherapy AI Companion with Reinforcement Learning Recommendations\n",
      "  and Interpretable Policy Dynamics, 2023-03-16T19:01:29Z, http://arxiv.org/pdf/2303.09601v1.pdf\n",
      "--------------------------------------------------\n",
      "Enhancing Recommendation Explanations through User-Centric Refinement, 2025-02-17T12:08:18Z, http://arxiv.org/pdf/2502.11721v1.pdf\n",
      "--------------------------------------------------\n",
      "SimUSER: Simulating User Behavior with Large Language Models for\n",
      "  Recommender System Evaluation, 2025-04-17T07:57:23Z, http://arxiv.org/pdf/2504.12722v1.pdf\n",
      "--------------------------------------------------\n",
      "AI Coach Assist: An Automated Approach for Call Recommendation in\n",
      "  Contact Centers for Agent Coaching, 2023-05-28T03:29:59Z, http://arxiv.org/pdf/2305.17619v1.pdf\n",
      "--------------------------------------------------\n",
      "AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware\n",
      "  Cross-domain Recommendations, 2025-02-19T16:02:59Z, http://arxiv.org/pdf/2502.13843v2.pdf\n",
      "--------------------------------------------------\n",
      "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent, 2025-04-13T05:31:37Z, http://arxiv.org/pdf/2504.13192v2.pdf\n",
      "--------------------------------------------------\n",
      "Causal Decision Transformer for Recommender Systems via Offline\n",
      "  Reinforcement Learning, 2023-04-17T00:05:52Z, http://arxiv.org/pdf/2304.07920v2.pdf\n",
      "--------------------------------------------------\n",
      "AutoAssign+: Automatic Shared Embedding Assignment in Streaming\n",
      "  Recommendation, 2023-08-14T06:43:59Z, http://arxiv.org/pdf/2308.06965v1.pdf\n",
      "--------------------------------------------------\n",
      "Neural Combinatorial Clustered Bandits for Recommendation Systems, 2024-10-18T16:37:28Z, http://arxiv.org/pdf/2410.14586v1.pdf\n",
      "--------------------------------------------------\n",
      "Reinforcement Learning-based Sequential Route Recommendation for\n",
      "  System-Optimal Traffic Assignment, 2025-05-27T08:33:02Z, http://arxiv.org/pdf/2505.20889v1.pdf\n",
      "--------------------------------------------------\n",
      "The effect of Collaborative-Filtering based Recommendation Algorithms on\n",
      "  Opinion Polarization, 2023-03-23T13:51:14Z, http://arxiv.org/pdf/2303.13270v2.pdf\n",
      "--------------------------------------------------\n",
      "Exploring Backdoor Attack and Defense for LLM-empowered Recommendations, 2025-04-15T13:37:38Z, http://arxiv.org/pdf/2504.11182v1.pdf\n",
      "--------------------------------------------------\n",
      "Improving Recommendation Fairness without Sensitive Attributes Using\n",
      "  Multi-Persona LLMs, 2025-05-26T03:52:41Z, http://arxiv.org/pdf/2505.19473v1.pdf\n",
      "--------------------------------------------------\n",
      "ARRC: Explainable, Workflow-Integrated Recommender for Sustainable\n",
      "  Resource Optimization Across the Edge-Cloud Continuum, 2025-07-16T08:48:04Z, http://arxiv.org/pdf/2507.12032v1.pdf\n",
      "--------------------------------------------------\n",
      "Retentive Decision Transformer with Adaptive Masking for Reinforcement\n",
      "  Learning based Recommendation Systems, 2024-03-26T12:08:58Z, http://arxiv.org/pdf/2403.17634v1.pdf\n",
      "--------------------------------------------------\n",
      "Social Choice for Heterogeneous Fairness in Recommendation, 2024-10-06T17:01:18Z, http://arxiv.org/pdf/2410.04551v1.pdf\n",
      "--------------------------------------------------\n",
      "On Causally Disentangled State Representation Learning for Reinforcement\n",
      "  Learning based Recommender Systems, 2024-07-18T01:41:05Z, http://arxiv.org/pdf/2407.13091v1.pdf\n",
      "--------------------------------------------------\n",
      "A Framework for Generating Conversational Recommendation Datasets from\n",
      "  Behavioral Interactions, 2025-06-14T22:58:48Z, http://arxiv.org/pdf/2506.17285v1.pdf\n",
      "--------------------------------------------------\n",
      "Stop Playing the Guessing Game! Target-free User Simulation for\n",
      "  Evaluating Conversational Recommender Systems, 2024-11-25T07:36:20Z, http://arxiv.org/pdf/2411.16160v1.pdf\n",
      "--------------------------------------------------\n",
      "Unequal Opportunities: Examining the Bias in Geographical\n",
      "  Recommendations by Large Language Models, 2025-03-16T18:59:00Z, http://arxiv.org/pdf/2504.05325v1.pdf\n",
      "--------------------------------------------------\n",
      "Retrieval-Augmented Review Generation for Poisoning Recommender Systems, 2025-08-21T05:25:22Z, http://arxiv.org/pdf/2508.15252v1.pdf\n",
      "--------------------------------------------------\n",
      "Two-sided Competing Matching Recommendation Markets With Quota and\n",
      "  Complementary Preferences Constraints, 2023-01-24T18:54:29Z, http://arxiv.org/pdf/2301.10230v3.pdf\n",
      "--------------------------------------------------\n",
      "Enhancing the conformal predictability of context-aware recommendation\n",
      "  systems by using Deep Autoencoders, 2024-11-30T18:24:42Z, http://arxiv.org/pdf/2412.12110v1.pdf\n",
      "--------------------------------------------------\n",
      "The HCI Aspects of Public Deployment of Research Chatbots: A User Study,\n",
      "  Design Recommendations, and Open Challenges, 2023-06-07T20:24:43Z, http://arxiv.org/pdf/2306.04765v1.pdf\n",
      "--------------------------------------------------\n",
      "Overhead-free User-side Recommender Systems, 2024-11-12T06:58:03Z, http://arxiv.org/pdf/2411.07589v1.pdf\n",
      "--------------------------------------------------\n",
      "Context-Aware Code Wiring Recommendation with LLM-based Agent, 2025-07-02T03:00:23Z, http://arxiv.org/pdf/2507.01315v1.pdf\n",
      "--------------------------------------------------\n",
      "CreAgent: Towards Long-Term Evaluation of Recommender System under\n",
      "  Platform-Creator Information Asymmetry, 2025-02-11T07:09:49Z, http://arxiv.org/pdf/2502.07307v1.pdf\n",
      "--------------------------------------------------\n",
      "RecUserSim: A Realistic and Diverse User Simulator for Evaluating\n",
      "  Conversational Recommender Systems, 2025-06-25T08:42:46Z, http://arxiv.org/pdf/2507.22897v1.pdf\n",
      "--------------------------------------------------\n",
      "Chemist-X: Large Language Model-empowered Agent for Reaction Condition\n",
      "  Recommendation in Chemical Synthesis, 2023-11-16T01:21:33Z, http://arxiv.org/pdf/2311.10776v6.pdf\n",
      "--------------------------------------------------\n",
      "Post-Userist Recommender Systems : A Manifesto, 2024-10-09T03:16:37Z, http://arxiv.org/pdf/2410.11870v1.pdf\n",
      "--------------------------------------------------\n",
      "InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep\n",
      "  Recommendation Models, 2023-08-13T18:28:56Z, http://arxiv.org/pdf/2308.08500v1.pdf\n",
      "--------------------------------------------------\n",
      "Online Prediction-Assisted Safe Reinforcement Learning for Electric\n",
      "  Vehicle Charging Station Recommendation in Dynamically Coupled\n",
      "  Transportation-Power Systems, 2024-07-30T09:20:37Z, http://arxiv.org/pdf/2407.20679v2.pdf\n",
      "--------------------------------------------------\n",
      "CARE: Contextual Adaptation of Recommenders for LLM-based Conversational\n",
      "  Recommendation, 2025-08-19T14:53:30Z, http://arxiv.org/pdf/2508.13889v1.pdf\n",
      "--------------------------------------------------\n",
      "AsyncMLD: Asynchronous Multi-LLM Framework for Dialogue Recommendation\n",
      "  System, 2023-12-21T15:12:59Z, http://arxiv.org/pdf/2312.13925v1.pdf\n",
      "--------------------------------------------------\n",
      "Interactive Graph Visualization and TeamingRecommendation in an\n",
      "  Interdisciplinary Project'sTalent Knowledge Graph, 2025-08-27T00:25:22Z, http://arxiv.org/pdf/2508.19489v1.pdf\n",
      "--------------------------------------------------\n",
      "The Effect of Product Recommendations on Online Investor Behaviors, 2023-03-24T20:19:43Z, http://arxiv.org/pdf/2303.14263v2.pdf\n",
      "--------------------------------------------------\n",
      "Formalizing Multimedia Recommendation through Multimodal Deep Learning, 2023-09-11T07:12:17Z, http://arxiv.org/pdf/2309.05273v2.pdf\n",
      "--------------------------------------------------\n",
      "LFG: A Generative Network for Real-Time Recommendation, 2023-10-31T05:16:54Z, http://arxiv.org/pdf/2310.20189v2.pdf\n",
      "--------------------------------------------------\n",
      "Investigating Characteristics of Media Recommendation Solicitation in\n",
      "  r/ifyoulikeblank, 2024-08-12T14:50:04Z, http://arxiv.org/pdf/2408.06201v1.pdf\n",
      "--------------------------------------------------\n",
      "Multi-Perspective Attention Mechanism for Bias-Aware Sequential\n",
      "  Recommendation, 2025-02-26T14:16:58Z, http://arxiv.org/pdf/2504.05323v1.pdf\n",
      "--------------------------------------------------\n",
      "Why am I seeing this? Towards recognizing social media recommender\n",
      "  systems with missing recommendations, 2025-04-15T09:16:17Z, http://arxiv.org/pdf/2504.11000v1.pdf\n",
      "--------------------------------------------------\n",
      "BookGPT: A General Framework for Book Recommendation Empowered by Large\n",
      "  Language Model, 2023-05-25T02:45:22Z, http://arxiv.org/pdf/2305.15673v1.pdf\n",
      "--------------------------------------------------\n",
      "Conformal Group Recommender System, 2023-07-22T10:03:32Z, http://arxiv.org/pdf/2307.12034v1.pdf\n",
      "--------------------------------------------------\n",
      "Empowering Few-Shot Recommender Systems with Large Language Models --\n",
      "  Enhanced Representations, 2023-12-21T03:50:09Z, http://arxiv.org/pdf/2312.13557v1.pdf\n",
      "--------------------------------------------------\n",
      "Reindex-Then-Adapt: Improving Large Language Models for Conversational\n",
      "  Recommendation, 2024-05-20T15:37:55Z, http://arxiv.org/pdf/2405.12119v1.pdf\n",
      "--------------------------------------------------\n",
      "Ensemble Boost: Greedy Selection for Superior Recommender Systems, 2024-07-07T00:50:52Z, http://arxiv.org/pdf/2407.05221v1.pdf\n",
      "--------------------------------------------------\n",
      "Enhancing Sequential Music Recommendation with Negative\n",
      "  Feedback-informed Contrastive Learning, 2024-09-11T15:56:05Z, http://arxiv.org/pdf/2409.07367v1.pdf\n",
      "--------------------------------------------------\n",
      "Incorporating Classifier-Free Guidance in Diffusion Model-Based\n",
      "  Recommendation, 2024-09-16T17:27:27Z, http://arxiv.org/pdf/2409.10494v1.pdf\n",
      "--------------------------------------------------\n",
      "Leave No One Behind: Enhancing Diversity While Maintaining Accuracy in\n",
      "  Social Recommendation, 2025-02-17T02:41:11Z, http://arxiv.org/pdf/2502.11374v2.pdf\n",
      "--------------------------------------------------\n",
      "Multi-Interest Recommendation: A Survey, 2025-06-18T09:05:32Z, http://arxiv.org/pdf/2506.15284v1.pdf\n",
      "--------------------------------------------------\n",
      "Rethinking Recommender Systems: Cluster-based Algorithm Selection, 2024-05-28T09:53:11Z, http://arxiv.org/pdf/2405.18011v1.pdf\n",
      "--------------------------------------------------\n",
      "Who Gets Recommended? Investigating Gender, Race, and Country\n",
      "  Disparities in Paper Recommendations from Large Language Models, 2024-12-31T09:42:53Z, http://arxiv.org/pdf/2501.00367v1.pdf\n",
      "--------------------------------------------------\n",
      "Towards the design of user-centric strategy recommendation systems for\n",
      "  collaborative Human-AI tasks, 2023-01-17T17:53:27Z, http://arxiv.org/pdf/2301.08144v1.pdf\n",
      "--------------------------------------------------\n",
      "Web3Recommend: Decentralised recommendations with trust and relevance, 2023-07-04T00:18:38Z, http://arxiv.org/pdf/2307.01411v1.pdf\n",
      "--------------------------------------------------\n",
      "Impression-Aware Recommender Systems, 2023-08-15T16:16:02Z, http://arxiv.org/pdf/2308.07857v2.pdf\n",
      "--------------------------------------------------\n",
      "MobileConvRec: A Conversational Dataset for Mobile Apps Recommendations, 2024-05-28T01:53:16Z, http://arxiv.org/pdf/2405.17740v1.pdf\n",
      "--------------------------------------------------\n",
      "A Systematic Literature Review on Task Recommendation Systems for\n",
      "  Crowdsourced Software Engineering, 2024-07-13T12:46:57Z, http://arxiv.org/pdf/2407.09872v2.pdf\n",
      "--------------------------------------------------\n",
      "Pre-trained Language Model and Knowledge Distillation for Lightweight\n",
      "  Sequential Recommendation, 2024-09-23T08:39:07Z, http://arxiv.org/pdf/2409.14810v1.pdf\n",
      "--------------------------------------------------\n",
      "Dynamic Adaptation of User Preferences and Results in a Destination\n",
      "  Recommender System, 2023-02-20T07:00:42Z, http://arxiv.org/pdf/2302.09803v1.pdf\n",
      "--------------------------------------------------\n",
      "Exploring and Exploiting Data Heterogeneity in Recommendation, 2023-05-21T11:01:14Z, http://arxiv.org/pdf/2305.15431v1.pdf\n",
      "--------------------------------------------------\n",
      "CoRE-CoG: Conversational Recommendation of Entities using Constrained\n",
      "  Generation, 2023-11-14T20:07:34Z, http://arxiv.org/pdf/2311.08511v1.pdf\n",
      "--------------------------------------------------\n",
      "User Consented Federated Recommender System Against Personalized\n",
      "  Attribute Inference Attack, 2023-12-23T09:44:57Z, http://arxiv.org/pdf/2312.16203v1.pdf\n",
      "--------------------------------------------------\n",
      "FINEST: Stabilizing Recommendations by Rank-Preserving Fine-Tuning, 2024-02-05T19:53:34Z, http://arxiv.org/pdf/2402.03481v1.pdf\n",
      "--------------------------------------------------\n",
      "Implementation of Recommendation Algorithm based on Recommendation\n",
      "  Sessions in E-commerce IT System, 2024-02-13T07:59:34Z, http://arxiv.org/pdf/2402.08275v1.pdf\n",
      "--------------------------------------------------\n",
      "Top-Personalized-K Recommendation, 2024-02-26T05:03:54Z, http://arxiv.org/pdf/2402.16304v1.pdf\n",
      "--------------------------------------------------\n",
      "Proactive Recommendation with Iterative Preference Guidance, 2024-03-12T11:58:50Z, http://arxiv.org/pdf/2403.07571v1.pdf\n",
      "--------------------------------------------------\n",
      "ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation, 2024-03-13T17:38:05Z, http://arxiv.org/pdf/2403.08737v1.pdf\n",
      "--------------------------------------------------\n",
      "CherryRec: Enhancing News Recommendation Quality via LLM-driven\n",
      "  Framework, 2024-06-18T03:33:38Z, http://arxiv.org/pdf/2406.12243v1.pdf\n",
      "--------------------------------------------------\n",
      "Oh, Behave! Country Representation Dynamics Created by Feedback Loops in\n",
      "  Music Recommender Systems, 2024-08-21T12:18:28Z, http://arxiv.org/pdf/2408.11565v1.pdf\n",
      "--------------------------------------------------\n",
      "Leveraging Large Language Models to Enhance Personalized Recommendations\n",
      "  in E-commerce, 2024-10-02T13:59:56Z, http://arxiv.org/pdf/2410.12829v1.pdf\n",
      "--------------------------------------------------\n",
      "A Survey on Bundle Recommendation: Methods, Applications, and Challenges, 2024-11-01T03:43:50Z, http://arxiv.org/pdf/2411.00341v1.pdf\n",
      "--------------------------------------------------\n",
      "A Survey on Recommendation Unlearning: Fundamentals, Taxonomy,\n",
      "  Evaluation, and Open Questions, 2024-12-17T11:58:55Z, http://arxiv.org/pdf/2412.12836v1.pdf\n",
      "--------------------------------------------------\n",
      "Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems\n",
      "  with Style and Shopping Cart Information, 2025-01-16T08:05:39Z, http://arxiv.org/pdf/2501.09354v1.pdf\n",
      "--------------------------------------------------\n",
      "Preserving Privacy and Utility in LLM-Based Product Recommendations, 2025-05-02T01:54:08Z, http://arxiv.org/pdf/2505.00951v1.pdf\n",
      "--------------------------------------------------\n",
      "Enhancing Learning Path Recommendation via Multi-task Learning, 2025-07-05T21:16:02Z, http://arxiv.org/pdf/2507.05295v1.pdf\n",
      "--------------------------------------------------\n",
      "Are Recommenders Self-Aware? Label-Free Recommendation Performance\n",
      "  Estimation via Model Uncertainty, 2025-07-31T03:04:34Z, http://arxiv.org/pdf/2507.23208v1.pdf\n",
      "--------------------------------------------------\n",
      "Does Multimodality Improve Recommender Systems as Expected? A Critical\n",
      "  Analysis and Future Directions, 2025-08-07T13:21:00Z, http://arxiv.org/pdf/2508.05377v1.pdf\n",
      "--------------------------------------------------\n",
      "A Survey of Real-World Recommender Systems: Challenges, Constraints, and\n",
      "  Industrial Perspectives, 2025-09-07T10:29:41Z, http://arxiv.org/pdf/2509.06002v1.pdf\n",
      "--------------------------------------------------\n",
      "Visualization for Recommendation Explainability: A Survey and New\n",
      "  Perspectives, 2023-05-19T15:42:00Z, http://arxiv.org/pdf/2305.11755v3.pdf\n",
      "--------------------------------------------------\n",
      "Computational Technologies for Fashion Recommendation: A Survey, 2023-06-06T04:20:08Z, http://arxiv.org/pdf/2306.03395v2.pdf\n",
      "--------------------------------------------------\n",
      "Generative Sequential Recommendation with GPTRec, 2023-06-19T18:27:54Z, http://arxiv.org/pdf/2306.11114v1.pdf\n",
      "--------------------------------------------------\n",
      "UniRecSys: A Unified Framework for Personalized, Group, Package, and\n",
      "  Package-to-Group Recommendations, 2023-08-08T13:26:36Z, http://arxiv.org/pdf/2308.04247v2.pdf\n",
      "--------------------------------------------------\n",
      "RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose\n",
      "  Recommendation System?, 2023-08-08T20:54:59Z, http://arxiv.org/pdf/2308.04579v1.pdf\n",
      "--------------------------------------------------\n",
      "Fairness of Exposure in Dynamic Recommendation, 2023-09-05T15:41:26Z, http://arxiv.org/pdf/2309.02322v1.pdf\n",
      "--------------------------------------------------\n",
      "Understanding the Influence of Data Characteristics on the Performance\n",
      "  of Point-of-Interest Recommendation Algorithms, 2023-11-13T10:51:29Z, http://arxiv.org/pdf/2311.07229v2.pdf\n",
      "--------------------------------------------------\n",
      "A Novel Behavior-Based Recommendation System for E-commerce, 2024-03-27T13:12:41Z, http://arxiv.org/pdf/2403.18536v1.pdf\n",
      "--------------------------------------------------\n",
      "Navigating User Experience of ChatGPT-based Conversational Recommender\n",
      "  Systems: The Effects of Prompt Guidance and Recommendation Domain, 2024-05-22T11:49:40Z, http://arxiv.org/pdf/2405.13560v1.pdf\n",
      "--------------------------------------------------\n",
      "Relevance meets Diversity: A User-Centric Framework for Knowledge\n",
      "  Exploration through Recommendations, 2024-08-07T13:48:24Z, http://arxiv.org/pdf/2408.03772v1.pdf\n",
      "--------------------------------------------------\n",
      "Blockchain-based Federated Recommendation with Incentive Mechanism, 2024-09-03T03:00:59Z, http://arxiv.org/pdf/2409.01563v1.pdf\n",
      "--------------------------------------------------\n",
      "Identify Then Recommend: Towards Unsupervised Group Recommendation, 2024-10-31T09:24:22Z, http://arxiv.org/pdf/2410.23757v1.pdf\n",
      "--------------------------------------------------\n",
      "KERAG_R: Knowledge-Enhanced Retrieval-Augmented Generation for\n",
      "  Recommendation, 2025-07-08T10:44:27Z, http://arxiv.org/pdf/2507.05863v1.pdf\n",
      "--------------------------------------------------\n",
      "A Scenario-Oriented Survey of Federated Recommender Systems: Techniques,\n",
      "  Challenges, and Future Directions, 2025-08-27T06:57:50Z, http://arxiv.org/pdf/2508.19620v1.pdf\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    title = r[\"title\"].lower()\n",
    "    dt = datetime.strptime(r[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    if any(word in title for word in (\"recommendation\", \"recommender\")):\n",
    "        if dt.year >= 2023:\n",
    "            print(f\"{r['title']}, {r['published']}, {r['pdf_link']}\\n{'-'*50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
