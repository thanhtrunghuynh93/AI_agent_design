{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f6a9f4-5282-4f41-83e2-2e5d15a24f4d",
   "metadata": {},
   "source": [
    "# Agentic AI: Smart assistant\n",
    "5 steps loop: \n",
    "- Get the mission: Goal\n",
    "- Scan the scene: Gather needed context/information\n",
    "- Think through: Plan\n",
    "- Take action: Execute plan\n",
    "- Learn and get better: Revise + Learn\n",
    "\n",
    "Evolution: LLM => RAG => Agentic AI\n",
    "Agentic AI: team of specialized agents working in concert to achieve complex goal\n",
    "\n",
    "# 3 level of AI agent complexity:\n",
    "- Level 0: The core reasoning engine LLM - The LLM is able to reasoned based on its own knowledge, but lacks of updated data\n",
    "- Level 1: The connected problem-solver - The LLM becomes a functional agent by connecting with external tool to gather data\n",
    "- Level 2: The strategic problem-solver - The LLM agent moves beyond single-tool use to tackle complex, multi-part problems\n",
    "- Level 3: Collaborative AI-agents - The specialized LLM agents work together to handle a compex problem\n",
    "\n",
    "# 5 visions of agentic AI:\n",
    "- Generalist AI: AI agents will evolve from narrow specialists into true generalists capable of managing complex, ambiguous, and long-term goals with high reliability.\n",
    "- Deep personalization and proactive goal discovery: AI agents will become deep personalized assistant and proactive partners\n",
    "- Embodiment and Physical world interaction: AI agents is not just virtual assistant, but are embedded to the physical systems\n",
    "- Agent-driven economy: Autonomous AI agents participate in the economy and replace human labours\n",
    "- Goal-driven, metamorphic multi-agent system: AI agents that have the ability to analyze its own performance and modify the topology of its multi-agent workforce, creating, duplicating, or removing agents as needed to form the most effective team for the task at hand.\n",
    "  \n",
    "This evolution happens at multiple levels:\n",
    "+ Architectural Modification: At the deepest level, individual agents can rewrite their own source code and re-architect their internal structures for higher efficiency, as in the original hypothesis.\n",
    "+ Instructional Modification: At a higher level, the system continuously performs automatic prompt engineering and context engineering. It refines the instructions and information given to each agent, ensuring they are operating with optimal guidance without any human intervention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706ebb5f-361e-443a-8899-edb805069668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40beda9a-7d07-4402-9139-806b6c397e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b707c1-8c16-4eb4-a0c8-b32757813d30",
   "metadata": {},
   "source": [
    "# Chaining\n",
    "- The core idea is to break down the original, daunting problem into a sequence of smaller, more manageable sub-problems.\n",
    "- Each sub-problem is addressed individually through a specifically designed prompt, and the output generated from one prompt is strategically fed as input into the subsequent prompt in the chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e244d044-9fe5-4e9a-83d9-f2ba4aee17e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "1. Dell XPS 15 - $1,799\n",
      "   - Processor: 3.5 GHz octa-core\n",
      "   - RAM: 16GB\n",
      "   - Storage: 1TB NVMe SSD\n",
      "\n",
      "2. HP Spectre x360 - $1,499\n",
      "   - Processor: 3.5 GHz octa-core\n",
      "   - RAM: 16GB\n",
      "   - Storage: 1TB NVMe SSD\n",
      "\n",
      "3. Lenovo ThinkPad X1 Carbon - $1,699\n",
      "   - Processor: 3.5 GHz octa-core\n",
      "   - RAM: 16GB\n",
      "   - Storage: 1TB NVMe SSD\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Language Model (using ChatOpenAI is recommended)\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# --- Prompt 1: Extract Information ---\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "    \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")\n",
    "\n",
    "# --- Prompt 2: Transform to JSON ---\n",
    "prompt_transform = ChatPromptTemplate.from_template(\n",
    "    \"Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\\n\\n{specifications}\"\n",
    ")\n",
    "\n",
    "prompt_goal = ChatPromptTemplate.from_template(\"Give me some laptop suggestion (model and price) with the following details:\\n\\n{details}\")\n",
    "\n",
    "# --- Build the Chain using LCEL ---\n",
    "# The StrOutputParser() converts the LLM's message output to a simple string.\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
    "\n",
    "spec_chain = (\n",
    "    {\"specifications\": extraction_chain}\n",
    "    | prompt_transform\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "full_chain = (\n",
    "    {\"details\": spec_chain}\n",
    "    | prompt_goal\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    ")\n",
    "\n",
    "# --- Run the Chain ---\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "\n",
    "# Execute the chain with the input text dictionary.\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f79fc9-2035-4950-9aa8-45a70644f1d3",
   "metadata": {},
   "source": [
    "# Routing\n",
    "- Routing introduces conditional logic into an agent's operational framework, enabling a shift from a fixed execution path to a model where the agent dynamically evaluates specific criteria to select from a set of possible subsequent actions. \n",
    "- This allows for more flexible and context-aware system behavior.\n",
    "- Here’s a concise summary of your passage:\n",
    "\n",
    "**Routing Pattern Core:**\n",
    "The central mechanism evaluates input and directs the flow. It can be implemented via:\n",
    "\n",
    "1. **LLM-based Routing** – Prompt the LLM to classify input and return a route identifier (flexible, but generative).\n",
    "2. **Embedding-based Routing** – Compare query embeddings with route embeddings for semantic similarity (meaning-driven).\n",
    "3. **Rule-based Routing** – Use explicit logic or keyword rules (fast, deterministic, but rigid).\n",
    "4. **ML Model-based Routing** – Train a discriminative classifier on labeled data; routing is encoded in learned weights (specialized, supervised, distinct from LLM prompts).\n",
    "\n",
    "👉 Together, these cover generative, semantic, deterministic, and supervised approaches to routing.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d5a689b-d1f8-4ff5-b793-f194fd044cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Simulated Sub-Agent Handlers (equivalent to ADK sub_agents) ---\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableBranch\n",
    "\n",
    "def booking_handler(request: str) -> str:\n",
    "    \"\"\"Simulates the Booking Agent handling a request.\"\"\"\n",
    "    print(\"\\n--- DELEGATING TO BOOKING HANDLER ---\")\n",
    "    return f\"Booking Handler processed request: '{request}'. Result: Simulated booking action.\"\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    \"\"\"Simulates the Info Agent handling a request.\"\"\"\n",
    "    print(\"\\n--- DELEGATING TO INFO HANDLER ---\")\n",
    "    return f\"Info Handler processed request: '{request}'. Result: Simulated information retrieval.\"\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    \"\"\"Handles requests that couldn't be delegated.\"\"\"\n",
    "    print(\"\\n--- HANDLING UNCLEAR REQUEST ---\")\n",
    "    return f\"Coordinator could not delegate request: '{request}'. Please clarify.\"\n",
    "\n",
    "# --- Define Coordinator Router Chain (equivalent to ADK coordinator's instruction) ---\n",
    "# This chain decides which handler to delegate to.\n",
    "coordinator_router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Analyze the user's request and determine which specialist handler should process it.\n",
    "     - If the request is related to booking flights or hotels, output 'booker'.\n",
    "     - For all other general information questions, output 'info'.\n",
    "     - If the request is unclear or doesn't fit either category, output 'unclear'.\n",
    "     ONLY output one word: 'booker', 'info', or 'unclear'.\"\"\"),\n",
    "    (\"user\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature=0)\n",
    "coordinator_router_chain = coordinator_router_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Use RunnableBranch to route based on the router chain's output.\n",
    "\n",
    "# Define the branches for the RunnableBranch\n",
    "branches = {\n",
    "    \"booker\": RunnablePassthrough.assign(output=lambda x: booking_handler(x['request']['user_input'])),\n",
    "    \"info\": RunnablePassthrough.assign(output=lambda x: info_handler(x['request']['user_input'])),\n",
    "    \"unclear\": RunnablePassthrough.assign(output=lambda x: unclear_handler(x['request']['user_input'])),\n",
    "}\n",
    "\n",
    "# Create the RunnableBranch. It takes the output of the router chain\n",
    "# and routes the original input ('request') to the corresponding handler.\n",
    "delegation_branch = RunnableBranch(\n",
    "    (lambda x: x['decision'].strip() == 'booker', branches[\"booker\"]), # Added .strip()\n",
    "    (lambda x: x['decision'].strip() == 'info', branches[\"info\"]),     # Added .strip()\n",
    "    branches[\"unclear\"] # Default branch for 'unclear' or any other output\n",
    ")\n",
    "\n",
    "# Combine the router chain and the delegation branch into a single runnable\n",
    "# The router chain's output ('decision') is passed along with the original input ('request')\n",
    "# to the delegation_branch.\n",
    "coordinator_agent = {\n",
    "    \"decision\": coordinator_router_chain,\n",
    "    \"request\": RunnablePassthrough()\n",
    "} | delegation_branch | (lambda x: x['output']) # Extract the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42a7b98d-cd8a-47df-bb45-1b68bd1aafad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running with a booking request ---\n",
      "\n",
      "--- DELEGATING TO BOOKING HANDLER ---\n",
      "Final Result A: Booking Handler processed request: 'Book me a flight to London.'. Result: Simulated booking action.\n",
      "\n",
      "--- Running with an info request ---\n",
      "\n",
      "--- DELEGATING TO INFO HANDLER ---\n",
      "Final Result B: Info Handler processed request: 'What is the capital of Italy?'. Result: Simulated information retrieval.\n",
      "\n",
      "--- Running with an unclear request ---\n",
      "\n",
      "--- HANDLING UNCLEAR REQUEST ---\n",
      "Final Result C: Coordinator could not delegate request: 'Sing me a song'. Please clarify.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running with a booking request ---\")\n",
    "request_a = \"Book me a flight to London.\"\n",
    "result_a = coordinator_agent.invoke({\"user_input\": request_a})\n",
    "print(f\"Final Result A: {result_a}\")\n",
    "\n",
    "print(\"\\n--- Running with an info request ---\")\n",
    "request_b = \"What is the capital of Italy?\"\n",
    "result_b = coordinator_agent.invoke({\"user_input\": request_b})\n",
    "print(f\"Final Result B: {result_b}\")\n",
    "\n",
    "print(\"\\n--- Running with an unclear request ---\")\n",
    "request_c = \"Sing me a song\"\n",
    "result_c = coordinator_agent.invoke({\"user_input\": request_c})\n",
    "print(f\"Final Result C: {result_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397862f-4c95-44ad-a377-eddf5875fe04",
   "metadata": {},
   "source": [
    "# Parallelization\n",
    "Parallelization boosts agent performance by running independent tasks simultaneously instead of sequentially. Key applications include:\n",
    "\n",
    "1. **Information Gathering** – Collect data from multiple sources at once (e.g., news, stocks, social media).\n",
    "2. **Data Processing** – Apply different analyses concurrently (e.g., sentiment, keywords, categorization).\n",
    "3. **Multi-API Interaction** – Query several APIs/tools in parallel (e.g., flights, hotels, events).\n",
    "4. **Content Generation** – Create different content components simultaneously (e.g., email parts).\n",
    "5. **Validation** – Run multiple checks at the same time (e.g., email, phone, address).\n",
    "6. **Multi-Modal Processing** – Analyze different input modalities in parallel (e.g., text + image).\n",
    "7. **Option Generation (A/B Testing)** – Produce multiple variations concurrently for quick comparison.\n",
    "\n",
    "👉 **Benefit:** Faster, more comprehensive, and more responsive agents through concurrent execution of independent tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2929ac86-a234-4962-ab96-e9378bd808fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Parallel LangChain Example for Topic: 'The history of space exploration' ---\n",
      "\n",
      "--- Final Response ---\n",
      "The history of space exploration is a fascinating journey that has seen significant milestones, technological advancements, and challenges overcome by astronauts and scientists. \n",
      "\n",
      "One of the key milestones in space exploration was the first human landing on the moon in 1969 during the Apollo 11 mission. This historic event, led by NASA, demonstrated humanity's ability to travel beyond Earth and marked a significant achievement in space exploration.\n",
      "\n",
      "The development of space stations, such as the International Space Station (ISS), has also been a crucial advancement in space exploration. The ISS serves as a research laboratory where astronauts from different countries live and work together in space, conducting experiments that help us understand the effects of long-duration space travel on the human body and test technologies for future missions.\n",
      "\n",
      "Exploration of other planets in our solar system, like Mars, has been another important aspect of space exploration. Robotic missions, such as the Mars rovers, have provided valuable data about the red planet's geology, atmosphere, and potential for supporting life. These missions have paved the way for future human missions to Mars and beyond.\n",
      "\n",
      "The evolution of technology in space exploration has been remarkable, from the early days of the Space Race to modern missions. Advances in spacecraft design, propulsion systems, communication technologies, and robotics have enabled us to explore farther into space and gather more data than ever before.\n",
      "\n",
      "Despite the achievements in space exploration, astronauts and scientists have faced significant challenges and obstacles. These include the risks associated with space travel, such as exposure to radiation and microgravity, as well as the complexities of conducting experiments in a harsh environment. However, through rigorous training, innovative problem-solving, and international collaboration, these challenges have been overcome, leading to groundbreaking discoveries and advancements in our understanding of the universe.\n",
      "\n",
      "In conclusion, the history of space exploration is a testament to human curiosity, ingenuity, and perseverance. From the first moon landing to the exploration of Mars and beyond, space exploration has expanded our knowledge of the cosmos and inspired future generations to continue pushing the boundaries of what is possible in outer space.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableParallel, RunnablePassthrough\n",
    "import asyncio\n",
    "\n",
    "# --- Define Independent Chains --\n",
    "# These three chains represent distinct tasks that can be executed in parallel.\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "summarize_chain: Runnable = (\n",
    "   ChatPromptTemplate.from_messages([\n",
    "       (\"system\", \"Summarize the following topic concisely:\"),\n",
    "       (\"user\", \"{topic}\")\n",
    "   ])\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "questions_chain: Runnable = (\n",
    "   ChatPromptTemplate.from_messages([       (\"system\", \"Generate three interesting questions about the following topic:\"),\n",
    "       (\"user\", \"{topic}\")\n",
    "   ])\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "terms_chain: Runnable = (\n",
    "   ChatPromptTemplate.from_messages([\n",
    "       (\"system\", \"Identify 5-10 key terms from the following topic, separated by commas:\"),\n",
    "       (\"user\", \"{topic}\")\n",
    "   ])\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Build the Parallel + Synthesis Chain ---\n",
    "\n",
    "# 1. Define the block of tasks to run in parallel. The results of these,\n",
    "#    along with the original topic, will be fed into the next step.\n",
    "map_chain = RunnableParallel(\n",
    "   {\n",
    "       \"summary\": summarize_chain,\n",
    "       \"questions\": questions_chain,\n",
    "       \"key_terms\": terms_chain,\n",
    "       \"topic\": RunnablePassthrough(),  # Pass the original topic through\n",
    "   }\n",
    ")\n",
    "\n",
    "# 2. Define the final synthesis prompt which will combine the parallel results.\n",
    "synthesis_prompt = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", \"\"\"Based on the following information:\n",
    "    Summary: {summary}\n",
    "    Related Questions: {questions}\n",
    "    Key Terms: {key_terms}\n",
    "    Synthesize a comprehensive answer.\"\"\"),\n",
    "   (\"user\", \"Original topic: {topic}\")\n",
    "])\n",
    "\n",
    "# 3. Construct the full chain by piping the parallel results directly\n",
    "#    into the synthesis prompt, followed by the LLM and output parser.\n",
    "full_parallel_chain = map_chain | synthesis_prompt | llm | StrOutputParser()\n",
    "\n",
    "# --- Run the Chain ---\n",
    "async def run_parallel_example(topic: str) -> None:\n",
    "   \"\"\"\n",
    "   Asynchronously invokes the parallel processing chain with a specific topic\n",
    "   and prints the synthesized result.\n",
    "\n",
    "   Args:\n",
    "       topic: The input topic to be processed by the LangChain chains.\n",
    "   \"\"\"\n",
    "   if not llm:\n",
    "       print(\"LLM not initialized. Cannot run example.\")\n",
    "       return\n",
    "\n",
    "   print(f\"\\n--- Running Parallel LangChain Example for Topic: '{topic}' ---\")\n",
    "   try:\n",
    "       # The input to `ainvoke` is the single 'topic' string, \n",
    "       # then passed to each runnable in the `map_chain`.\n",
    "       response = await full_parallel_chain.ainvoke(topic)\n",
    "       print(\"\\n--- Final Response ---\")\n",
    "       print(response)\n",
    "   except Exception as e:\n",
    "       print(f\"\\nAn error occurred during chain execution: {e}\")\n",
    "\n",
    "test_topic = \"The history of space exploration\"\n",
    "# In Python 3.7+, asyncio.run is the standard way to run an async function.\n",
    "await run_parallel_example(test_topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d71422-d7cf-4791-9ab9-6ab85fdcd8b4",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "Reflection introduces a feedback loop where the agent critiques and improves its own outputs. It is especially useful when quality, accuracy, or complex constraints matter.\n",
    "\n",
    "* **Creative Writing** – Draft → critique → rewrite → repeat → produces polished content.\n",
    "* **Code Generation** – Write code → test/analyze → fix → improves robustness.\n",
    "* **Complex Problem Solving** – Evaluate steps → backtrack/refine → handles intricate reasoning.\n",
    "* **Summarization** – Draft summary → compare to source → refine → ensures accuracy/completeness.\n",
    "* **Planning** – Propose plan → evaluate feasibility → revise → creates effective strategies.\n",
    "* **Conversational Agents** – Review conversation → adjust response → yields coherent, natural dialogue.\n",
    "\n",
    "👉 **Benefit:** Reflection acts as meta-cognition, letting agents learn from and refine their outputs, leading to more reliable, intelligent, and high-quality results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5411c884-d49e-4559-9c58-42684f741936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= REFLECTION LOOP: ITERATION 1 =========================\n",
      "\n",
      ">>> STAGE 1: GENERATING initial code...\n",
      "\n",
      "--- Generated Code (v1) ---\n",
      "```python\n",
      "def calculate_factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\n",
      "    The factorial of 0 is defined as 1.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be calculated.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the input integer n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If the input is a negative integer.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    \n",
      "    factorial = 1\n",
      "    for i in range(2, n + 1):\n",
      "        factorial *= i\n",
      "    \n",
      "    return factorial\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Docstring**: The function includes a docstring that explains its purpose, parameters, return value, and potential exceptions.\n",
      "2. **Edge Case Handling**: The function correctly handles the edge case where `n` is 0 by initializing `factorial` to 1 and using a loop that starts from 2.\n",
      "3. **Invalid Input Handling**: The function raises a `ValueError` if the input `n` is negative, as factorials are not defined for negative numbers.\n",
      "4. **Loop for Calculation**: The function uses a loop to calculate the factorial for positive integers greater than 1.\n",
      "\n",
      ">>> STAGE 2: REFLECTING on the generated code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trunght/anaconda3/envs/llm/lib/python3.10/http/cookiejar.py:1237: RuntimeWarning: coroutine 'run_parallel_example' was never awaited\n",
      "  obj.items\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Critique ---\n",
      "- **Type Checking**: The function does not check if the input `n` is an integer. If a non-integer type (like a float or string) is passed, it will raise a `TypeError` during the comparison `if n < 0:`. Consider adding a type check at the beginning of the function to ensure `n` is an integer.\n",
      "- **Performance**: The current implementation is efficient for small values of `n`, but for very large values, it could be optimized using iterative or recursive methods with memoization or using Python's built-in `math.factorial` function.\n",
      "- **Docstring Improvement**: While the docstring is clear, it could be enhanced by specifying that the function only accepts integer inputs explicitly.\n",
      "- **Testing Edge Cases**: Ensure that the function is tested with edge cases such as `n = 0`, `n = 1`, and very large values of `n` to confirm its correctness and performance.\n",
      "- **Python Built-in Function**: Consider mentioning in the docstring or comments that Python's standard library provides a built-in function `math.factorial` which can be used for calculating factorials, as it is optimized and handles large numbers efficiently.\n",
      "\n",
      "========================= REFLECTION LOOP: ITERATION 2 =========================\n",
      "\n",
      ">>> STAGE 1: REFINING code based on previous critique...\n",
      "\n",
      "--- Generated Code (v2) ---\n",
      "Certainly! Here's the refined version of the `calculate_factorial` function, incorporating the critiques:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def calculate_factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\n",
      "    The factorial of 0 is defined as 1.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be calculated. Must be an integer.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the input integer n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If the input is a negative integer.\n",
      "    TypeError: If the input is not an integer.\n",
      "\n",
      "    Note:\n",
      "    For large values of n, consider using Python's built-in `math.factorial` for better performance.\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"Input must be an integer.\")\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    \n",
      "    # Using Python's built-in function for better performance and simplicity\n",
      "    return math.factorial(n)\n",
      "```\n",
      "\n",
      "### Key Improvements:\n",
      "1. **Type Checking**: Added a check to ensure that the input `n` is an integer, raising a `TypeError` if it is not.\n",
      "2. **Performance**: Utilized Python's built-in `math.factorial` function, which is optimized for performance and handles large numbers efficiently.\n",
      "3. **Docstring Enhancement**: Updated the docstring to specify that the input must be an integer and added a note about using the built-in function for large values.\n",
      "4. **Error Handling**: The function now raises appropriate exceptions for invalid inputs, ensuring robustness.\n",
      "\n",
      "This refined version is more robust, efficient, and clear in its documentation and functionality.\n",
      "\n",
      ">>> STAGE 2: REFLECTING on the generated code...\n",
      "\n",
      "--- Critique ---\n",
      "- **Redundant Note in Docstring**: The note about using Python's built-in `math.factorial` is unnecessary since the function already uses it. This could be removed to avoid confusion.\n",
      "- **Docstring Clarity**: The docstring could be more concise. The explanation of the factorial could be simplified, as the concept is well-known.\n",
      "- **Edge Case Handling**: While the function handles negative numbers and non-integers, it does not explicitly handle the case where `n` is a float that is an integer value (e.g., `5.0`). This should be considered, as `5.0` is technically a float but represents an integer value.\n",
      "- **Code Style**: The code is generally well-written, but the docstring could be formatted to adhere more closely to PEP 257, which suggests a one-line summary followed by a more detailed explanation if necessary.\n",
      "\n",
      "========================= REFLECTION LOOP: ITERATION 3 =========================\n",
      "\n",
      ">>> STAGE 1: REFINING code based on previous critique...\n",
      "\n",
      "--- Generated Code (v3) ---\n",
      "Certainly! Here's the refined version of the `calculate_factorial` function, addressing the latest critiques:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def calculate_factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be calculated.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the input integer n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If the input is a negative integer.\n",
      "    TypeError: If the input is not an integer or a float representing an integer.\n",
      "    \"\"\"\n",
      "    if isinstance(n, float) and n.is_integer():\n",
      "        n = int(n)\n",
      "    elif not isinstance(n, int):\n",
      "        raise TypeError(\"Input must be an integer or a float representing an integer.\")\n",
      "    \n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    \n",
      "    return math.factorial(n)\n",
      "```\n",
      "\n",
      "### Key Improvements:\n",
      "1. **Redundant Note Removed**: The note about using `math.factorial` was removed from the docstring since the function already uses it.\n",
      "2. **Docstring Clarity**: The docstring is now more concise, focusing on the essential information.\n",
      "3. **Edge Case Handling**: The function now checks if `n` is a float that represents an integer (e.g., `5.0`) and converts it to an integer. This ensures that such inputs are handled correctly.\n",
      "4. **Code Style**: The docstring is formatted to provide a clear one-line summary followed by detailed information, adhering to PEP 257 guidelines.\n",
      "\n",
      "This version of the function is more robust and clear, handling a wider range of inputs while maintaining simplicity and efficiency.\n",
      "\n",
      ">>> STAGE 2: REFLECTING on the generated code...\n",
      "\n",
      "--- Critique ---\n",
      "- **Unnecessary Import**: The `math` module is imported, but the task can be accomplished without it by using a simple loop or recursion. If the use of `math.factorial` is intentional for efficiency, it should be explicitly stated in the docstring.\n",
      "  \n",
      "- **Type Checking**: The current implementation allows floats that represent whole numbers (e.g., `5.0`). While this is handled, the task requirement only specifies accepting an integer. If the task strictly requires an integer, allowing floats might be unnecessary.\n",
      "\n",
      "- **Docstring Improvement**: The docstring could be more explicit about the acceptance of floats that represent integers, as this is not a typical expectation for a function that calculates factorials.\n",
      "\n",
      "- **Edge Case Handling**: While the function handles negative numbers and non-integers, it does not explicitly handle the case where `n` is `None`. Although not specified in the task, it might be beneficial to handle this case explicitly.\n",
      "\n",
      "- **Code Style**: The function could benefit from a more detailed explanation in the docstring about why floats representing integers are accepted, as this is not a common practice for factorial calculations.\n",
      "\n",
      "- **Efficiency Note**: If the use of `math.factorial` is for efficiency, it might be worth mentioning in the docstring that this approach is chosen for its performance benefits over a manual implementation.\n",
      "\n",
      "Overall, while the function is robust and handles a variety of inputs, it could be improved by aligning more closely with the task requirements and providing clearer documentation on its behavior.\n",
      "\n",
      "============================== FINAL RESULT ==============================\n",
      "\n",
      "Final refined code after the reflection process:\n",
      "\n",
      "Certainly! Here's the refined version of the `calculate_factorial` function, addressing the latest critiques:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def calculate_factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be calculated.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the input integer n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If the input is a negative integer.\n",
      "    TypeError: If the input is not an integer or a float representing an integer.\n",
      "    \"\"\"\n",
      "    if isinstance(n, float) and n.is_integer():\n",
      "        n = int(n)\n",
      "    elif not isinstance(n, int):\n",
      "        raise TypeError(\"Input must be an integer or a float representing an integer.\")\n",
      "    \n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    \n",
      "    return math.factorial(n)\n",
      "```\n",
      "\n",
      "### Key Improvements:\n",
      "1. **Redundant Note Removed**: The note about using `math.factorial` was removed from the docstring since the function already uses it.\n",
      "2. **Docstring Clarity**: The docstring is now more concise, focusing on the essential information.\n",
      "3. **Edge Case Handling**: The function now checks if `n` is a float that represents an integer (e.g., `5.0`) and converts it to an integer. This ensures that such inputs are handled correctly.\n",
      "4. **Code Style**: The docstring is formatted to provide a clear one-line summary followed by detailed information, adhering to PEP 257 guidelines.\n",
      "\n",
      "This version of the function is more robust and clear, handling a wider range of inputs while maintaining simplicity and efficiency.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Initialize the Chat LLM. We use gpt-4o for better reasoning.\n",
    "# A lower temperature is used for more deterministic outputs.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "def run_reflection_loop():\n",
    "   \"\"\"\n",
    "   Demonstrates a multi-step AI reflection loop to progressively improve a Python function.\n",
    "   \"\"\"\n",
    "   # --- The Core Task ---\n",
    "   task_prompt = \"\"\"\n",
    "   Your task is to create a Python function named `calculate_factorial`.\n",
    "   This function should do the following:\n",
    "   1.  Accept a single integer `n` as input.\n",
    "   2.  Calculate its factorial (n!).\n",
    "   3.  Include a clear docstring explaining what the function does.\n",
    "   4.  Handle edge cases: The factorial of 0 is 1.\n",
    "   5.  Handle invalid input: Raise a ValueError if the input is a negative number.\n",
    "   \"\"\"\n",
    "   # --- The Reflection Loop ---\n",
    "   max_iterations = 3\n",
    "   current_code = \"\"\n",
    "   # We will build a conversation history to provide context in each step.\n",
    "   message_history = [HumanMessage(content=task_prompt)]\n",
    "\n",
    "   for i in range(max_iterations):\n",
    "       print(\"\\n\" + \"=\"*25 + f\" REFLECTION LOOP: ITERATION {i + 1} \" + \"=\"*25)\n",
    "\n",
    "       # --- 1. GENERATE / REFINE STAGE ---\n",
    "       # In the first iteration, it generates. In subsequent iterations, it refines.\n",
    "       if i == 0:\n",
    "           print(\"\\n>>> STAGE 1: GENERATING initial code...\")\n",
    "           # The first message is just the task prompt.\n",
    "           response = llm.invoke(message_history)\n",
    "           current_code = response.content\n",
    "       else:\n",
    "           print(\"\\n>>> STAGE 1: REFINING code based on previous critique...\")\n",
    "           # The message history now contains the task, \n",
    "           # the last code, and the last critique.\n",
    "           # We instruct the model to apply the critiques.\n",
    "           message_history.append(HumanMessage(content=\"Please refine the code using the critiques provided.\"))\n",
    "           response = llm.invoke(message_history)\n",
    "           current_code = response.content\n",
    "\n",
    "       print(\"\\n--- Generated Code (v\" + str(i + 1) + \") ---\\n\" + current_code)\n",
    "       message_history.append(response) # Add the generated code to history\n",
    "\n",
    "       # --- 2. REFLECT STAGE ---\n",
    "       print(\"\\n>>> STAGE 2: REFLECTING on the generated code...\")\n",
    "\n",
    "       # Create a specific prompt for the reflector agent.\n",
    "       # This asks the model to act as a senior code reviewer.\n",
    "       reflector_prompt = [\n",
    "           SystemMessage(content=\"\"\"\n",
    "               You are a senior software engineer and an expert \n",
    "               in Python.\n",
    "               Your role is to perform a meticulous code review.\n",
    "               Critically evaluate the provided Python code based \n",
    "               on the original task requirements.\n",
    "               Look for bugs, style issues, missing edge cases, \n",
    "               and areas for improvement.\n",
    "               If the code is perfect and meets all requirements,\n",
    "               respond with the single phrase 'CODE_IS_PERFECT'.\n",
    "               Otherwise, provide a bulleted list of your critiques.\n",
    "           \"\"\"),\n",
    "           HumanMessage(content=f\"Original Task:\\n{task_prompt}\\n\\nCode to Review:\\n{current_code}\")\n",
    "       ]\n",
    "\n",
    "       critique_response = llm.invoke(reflector_prompt)\n",
    "       critique = critique_response.content\n",
    "\n",
    "       # --- 3. STOPPING CONDITION ---\n",
    "       if \"CODE_IS_PERFECT\" in critique:\n",
    "           print(\"\\n--- Critique ---\\nNo further critiques found. The code is satisfactory.\")\n",
    "           break\n",
    "\n",
    "       print(\"\\n--- Critique ---\\n\" + critique)\n",
    "       # Add the critique to the history for the next refinement loop.\n",
    "       message_history.append(HumanMessage(content=f\"Critique of the previous code:\\n{critique}\"))\n",
    "\n",
    "   print(\"\\n\" + \"=\"*30 + \" FINAL RESULT \" + \"=\"*30)\n",
    "   print(\"\\nFinal refined code after the reflection process:\\n\")\n",
    "   print(current_code)\n",
    "\n",
    "run_reflection_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d06ee3d-59ce-4012-98b2-fe7f13929f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= REFLECTION ITERATION 1 =========================\n",
      "\n",
      ">>> STAGE 1: GENERATE/REFINE\n",
      "\n",
      "--- Generated Code ---\n",
      " Here is the complete Python code for the `calculate_factorial` function, which meets all the specified requirements:\n",
      "\n",
      "```python\n",
      "def calculate_factorial(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\n",
      "    It is denoted as n! and defined as:\n",
      "    - n! = n * (n-1) * (n-2) * ... * 1 for n > 0\n",
      "    - 0! = 1\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer for which to calculate the factorial.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the given integer n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If n is a negative integer.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Input must be a non-negative integer.\")\n",
      "    elif n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        factorial = 1\n",
      "        for i in range(1, n + 1):\n",
      "            factorial *= i\n",
      "        return factorial\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Docstring**: The function includes a detailed docstring that explains what the function does, its parameters, return value, and exceptions raised.\n",
      "2. **Edge Case Handling**: The function correctly handles the case where `n` is 0 by returning 1.\n",
      "3. **Invalid Input Handling**: It raises a `ValueError` if the input is a negative integer.\n",
      "4. **Factorial Calculation**: The function uses a loop to calculate the factorial for positive integers.\n",
      "\n",
      "This implementation is efficient and clear, adhering to best practices in Python programming.\n",
      "\n",
      ">>> STAGE 2: REFLECT\n",
      "\n",
      "--- Critique ---\n",
      "No further critiques. CODE_IS_PERFECT\n",
      "\n",
      "============================== FINAL RESULT ==============================\n",
      "\n",
      "Final refined code:\n",
      "\n",
      "Here is the complete Python code for the `calculate_factorial` function, which meets all the specified requirements:\n",
      "\n",
      "```python\n",
      "def calculate_factorial(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\n",
      "    It is denoted as n! and defined as:\n",
      "    - n! = n * (n-1) * (n-2) * ... * 1 for n > 0\n",
      "    - 0! = 1\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer for which to calculate the factorial.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the given integer n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If n is a negative integer.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Input must be a non-negative integer.\")\n",
      "    elif n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        factorial = 1\n",
      "        for i in range(1, n + 1):\n",
      "            factorial *= i\n",
      "        return factorial\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Docstring**: The function includes a detailed docstring that explains what the function does, its parameters, return value, and exceptions raised.\n",
      "2. **Edge Case Handling**: The function correctly handles the case where `n` is 0 by returning 1.\n",
      "3. **Invalid Input Handling**: It raises a `ValueError` if the input is a negative integer.\n",
      "4. **Factorial Calculation**: The function uses a loop to calculate the factorial for positive integers.\n",
      "\n",
      "This implementation is efficient and clear, adhering to best practices in Python programming.\n"
     ]
    }
   ],
   "source": [
    "#Rewrite the code in LangChain\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "TASK_PROMPT = \"\"\"\n",
    "Your task is to create a Python function named `calculate_factorial`.\n",
    "This function should:\n",
    "1) Accept a single integer `n` as input.\n",
    "2) Calculate its factorial (n!).\n",
    "3) Include a clear docstring.\n",
    "4) Handle edge case: factorial(0) == 1.\n",
    "5) Handle invalid input: raise ValueError if n < 0.\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Writer (generate/refine) ----------\n",
    "writer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a senior Python developer. You will write or refine code based on a task and (optionally) critique.\"),\n",
    "    (\"human\",\n",
    "     \"TASK:\\n{task}\\n\\n\"\n",
    "     \"PREVIOUS_CODE (may be empty):\\n{previous_code}\\n\\n\"\n",
    "     \"CRITIQUE (may be empty):\\n{critique}\\n\\n\"\n",
    "     \"Write the best possible complete Python code now.\")\n",
    "])\n",
    "writer_chain = writer_prompt | llm | parser\n",
    "\n",
    "# ---------- Reviewer (reflection) ----------\n",
    "reviewer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a meticulous Python code reviewer. \"\n",
    "     \"Evaluate against the task. If the code fully meets requirements, reply EXACTLY: CODE_IS_PERFECT. \"\n",
    "     \"Else, return a concise bullet list of issues and improvements.\"),\n",
    "    (\"human\",\n",
    "     \"TASK:\\n{task}\\n\\nCODE TO REVIEW:\\n{code}\")\n",
    "])\n",
    "reviewer_chain = reviewer_prompt | llm | parser\n",
    "\n",
    "# ---------- Reflection loop ----------\n",
    "def run_reflection_loop(max_iterations: int = 3):\n",
    "    current_code = \"\"\n",
    "    critique = \"\"\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        print(\"\\n\" + \"=\"*25 + f\" REFLECTION ITERATION {i+1} \" + \"=\"*25)\n",
    "\n",
    "        # 1) Generate / Refine\n",
    "        print(\"\\n>>> STAGE 1: GENERATE/REFINE\")\n",
    "        current_code = writer_chain.invoke({\n",
    "            \"task\": TASK_PROMPT,\n",
    "            \"previous_code\": current_code,\n",
    "            \"critique\": critique\n",
    "        })\n",
    "        print(\"\\n--- Generated Code ---\\n\", current_code)\n",
    "\n",
    "        # 2) Reflect\n",
    "        print(\"\\n>>> STAGE 2: REFLECT\")\n",
    "        critique = reviewer_chain.invoke({\n",
    "            \"task\": TASK_PROMPT,\n",
    "            \"code\": current_code\n",
    "        })\n",
    "        if \"CODE_IS_PERFECT\" in critique:\n",
    "            print(\"\\n--- Critique ---\\nNo further critiques. CODE_IS_PERFECT\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n--- Critique ---\\n\", critique)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30 + \" FINAL RESULT \" + \"=\"*30)\n",
    "    print(\"\\nFinal refined code:\\n\")\n",
    "    print(current_code)\n",
    "\n",
    "# Run\n",
    "run_reflection_loop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c2fc4-466a-4c23-806e-e5836aefc2ee",
   "metadata": {},
   "source": [
    "# Tool Use\n",
    "Tool use enables agents to move beyond text generation, letting them act, query, and interact with external systems.\n",
    "\n",
    "* **Information Retrieval** – Call APIs (e.g., weather) → fetch real-time data → give user-friendly answers.\n",
    "* **Databases & APIs** – Query/update structured data (e.g., inventory, orders) → deliver accurate status.\n",
    "* **Calculations & Analysis** – Use calculators, data APIs, or libraries → perform numeric/financial reasoning.\n",
    "* **Communications** – Trigger email, messaging, or notifications → act as a personal assistant.\n",
    "* **Code Execution** – Run snippets via interpreters → analyze and explain program behavior.\n",
    "* **System Control** – Interact with devices/IoT (e.g., smart lights) → take real-world actions.\n",
    "\n",
    "👉 **Benefit:** Tool use transforms an LLM from a text-only model into a true **agent** that can sense, reason, and act in digital or physical environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96b8f354-366a-4cd2-a421-8e18157c68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be1da2ec-2701-41a9-9e33-3d6ebdc536e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "# --- LLM & parser ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# --- Define a Tool ---\n",
    "def _normalize(s: str) -> str:\n",
    "    # lowercase, strip punctuation & extra spaces\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "@tool\n",
    "def search_information(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Provides factual information on a given topic. Use this tool to find answers to questions\n",
    "    like 'What is the capital of France?' or 'What is the weather in London?'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🛠️ Tool Called: search_information with query: '{query}' ---\")\n",
    "    normalized = _normalize(query)\n",
    "\n",
    "    simulated_results = {\n",
    "        \"weather in london\": \"The weather in London is currently cloudy with a temperature of 15°C.\",\n",
    "        \"capital of france\": \"The capital of France is Paris.\",\n",
    "        \"population of earth\": \"The estimated population of Earth is around 8 billion people.\",\n",
    "        \"tallest mountain\": \"Mount Everest is the tallest mountain above sea level.\",\n",
    "    }\n",
    "    result = simulated_results.get(normalized, f\"Simulated search result for '{query}': No specific information found, but the topic seems interesting.\")\n",
    "    print(f\"--- TOOL RESULT: {result} ---\")\n",
    "    return result\n",
    "\n",
    "tools = [search_information]\n",
    "\n",
    "# --- Prompt for tool-calling agent ---\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. If a tool is relevant, call it; otherwise answer directly.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),  # required for tool use traces\n",
    "])\n",
    "\n",
    "# --- Create agent and executor ---\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# --- Async runner helpers ---\n",
    "async def run_agent_with_tool(query: str):\n",
    "    print(f\"\\n--- 🏃 Running Agent with Query: '{query}' ---\")\n",
    "    try:\n",
    "        response = await agent_executor.ainvoke({\"input\": query})\n",
    "        print(\"\\n--- ✅ Final Agent Response ---\")\n",
    "        print(response[\"output\"])\n",
    "    except Exception as e:\n",
    "        print(f\"\\n🛑 An error occurred during agent execution: {e}\")\n",
    "\n",
    "async def agent_with_tool():\n",
    "    tasks = [\n",
    "        run_agent_with_tool(\"What is the capital of France?\"),\n",
    "        run_agent_with_tool(\"What's the weather like in London?\"),\n",
    "        run_agent_with_tool(\"Tell me something about dogs.\"),  # default branch\n",
    "    ]\n",
    "    await asyncio.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0237d74-bf37-4bdb-97a3-055e52c55fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🏃 Running Agent with Query: 'What is the capital of France?' ---\n",
      "\n",
      "--- 🏃 Running Agent with Query: 'What's the weather like in London?' ---\n",
      "\n",
      "--- 🏃 Running Agent with Query: 'Tell me something about dogs.' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_information` with `{'query': 'dogs'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "--- 🛠️ Tool Called: search_information with query: 'dogs' ---\n",
      "--- TOOL RESULT: Simulated search result for 'dogs': No specific information found, but the topic seems interesting. ---\n",
      "\u001b[36;1m\u001b[1;3mSimulated search result for 'dogs': No specific information found, but the topic seems interesting.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_information` with `{'query': 'capital of France'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "--- 🛠️ Tool Called: search_information with query: 'capital of France' ---\n",
      "--- TOOL RESULT: The capital of France is Paris. ---\n",
      "\u001b[36;1m\u001b[1;3mThe capital of France is Paris.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_information` with `{'query': 'current weather in London'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "--- 🛠️ Tool Called: search_information with query: 'current weather in London' ---\n",
      "--- TOOL RESULT: Simulated search result for 'current weather in London': No specific information found, but the topic seems interesting. ---\n",
      "\u001b[36;1m\u001b[1;3mSimulated search result for 'current weather in London': No specific information found, but the topic seems interesting.\u001b[0m\u001b[32;1m\u001b[1;3mThe capital of France is Paris.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- ✅ Final Agent Response ---\n",
      "The capital of France is Paris.\n",
      "\u001b[32;1m\u001b[1;3mI couldn't find the current weather information for London. You might want to check a reliable weather website or app for the latest updates.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- ✅ Final Agent Response ---\n",
      "I couldn't find the current weather information for London. You might want to check a reliable weather website or app for the latest updates.\n",
      "\u001b[32;1m\u001b[1;3mDogs are domesticated mammals and are often referred to as \"man's best friend\" due to their long-standing relationship with humans. They belong to the Canidae family and are descendants of wolves. Dogs are known for their loyalty, intelligence, and ability to be trained for various tasks, including companionship, service, and work roles such as herding, hunting, and protection.\n",
      "\n",
      "There are hundreds of different breeds of dogs, each with unique characteristics, sizes, and temperaments. Dogs communicate through vocalizations, body language, and facial expressions, and they have a strong sense of smell, which makes them excellent at tracking and detecting scents.\n",
      "\n",
      "In addition to being pets, dogs play important roles in various fields, including therapy, search and rescue, and law enforcement. They require regular exercise, socialization, and training to thrive as companions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- ✅ Final Agent Response ---\n",
      "Dogs are domesticated mammals and are often referred to as \"man's best friend\" due to their long-standing relationship with humans. They belong to the Canidae family and are descendants of wolves. Dogs are known for their loyalty, intelligence, and ability to be trained for various tasks, including companionship, service, and work roles such as herding, hunting, and protection.\n",
      "\n",
      "There are hundreds of different breeds of dogs, each with unique characteristics, sizes, and temperaments. Dogs communicate through vocalizations, body language, and facial expressions, and they have a strong sense of smell, which makes them excellent at tracking and detecting scents.\n",
      "\n",
      "In addition to being pets, dogs play important roles in various fields, including therapy, search and rescue, and law enforcement. They require regular exercise, socialization, and training to thrive as companions.\n"
     ]
    }
   ],
   "source": [
    "await agent_with_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1905afd-98fa-4591-ba7e-f7bf6c80de63",
   "metadata": {},
   "source": [
    "# Planning\n",
    "Planning enables agents to go beyond reactive responses by formulating a **sequence of actions** that lead from an initial state to a goal state.\n",
    "\n",
    "* **Core Idea** – The agent discovers the *how*, not just executes the *what*. It breaks down complex goals into manageable steps, adapts when constraints change, and replans when obstacles arise.\n",
    "* **Trade-off** – Use planning when the solution path is uncertain or dynamic. For repeatable, well-defined tasks, fixed workflows are more predictable and reliable.\n",
    "* **Applications**:\n",
    "\n",
    "  * **Task automation** – orchestrating multi-step business processes (e.g., employee onboarding).\n",
    "  * **Robotics/navigation** – generating paths under constraints (e.g., obstacle avoidance, efficiency).\n",
    "  * **Information synthesis** – structuring outputs like research reports in phases.\n",
    "  * **Customer support** – diagnosing and resolving multi-step problems systematically.\n",
    "\n",
    "👉 **Benefit:** Planning equips agents with foresight, adaptability, and goal-oriented reasoning, making them effective in complex, uncertain, or evolving environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14ce9455-974a-4dc5-ba7a-bf7e08a2ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "151021d4-20f8-4bdf-a6b5-41024721e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Running the planning and writing task ##\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Article Planner and Writer</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. Create a bullet-point plan for a summary on the topic: 'The importance of Reinforcement Learning in </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AI'.</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. Write the summary based on your plan, keeping it around 200 words.</span>                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mArticle Planner and Writer\u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92m1. Create a bullet-point plan for a summary on the topic: 'The importance of Reinforcement Learning in \u001b[0m  \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mAI'.\u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m2. Write the summary based on your plan, keeping it around 200 words.\u001b[0m                                          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Article Planner and Writer</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Plan</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Define Reinforcement Learning (RL) and its role in AI.</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Explain the key principles of RL: agents, environments, actions, rewards.</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Discuss the significance of RL in decision-making processes.</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Highlight real-world applications of RL in various industries (e.g., gaming, robotics, healthcare).</span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Mention the advantages of RL over traditional machine learning methods.</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Address the challenges and limitations of implementing RL.</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Conclude with the future potential of RL in advancing AI technologies.</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Summary</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Reinforcement Learning (RL) is a crucial subset of artificial intelligence that focuses on how agents should </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">take actions in an environment to maximize cumulative rewards. The core principles of RL involve agents </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">interacting with their environment, making decisions, and receiving feedback in the form of rewards or </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">penalties. This framework is particularly significant in decision-making processes, allowing systems to learn</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimal strategies through trial and error.</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">RL has found extensive applications across various industries, including gaming, where it powers advanced AI </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">opponents, robotics for autonomous navigation, and healthcare for personalized treatment plans. Its ability </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to adapt and improve over time offers distinct advantages over traditional machine learning methods, which </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">often rely on static datasets.</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">However, implementing RL comes with challenges, such as the need for substantial computational resources and </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the difficulty of defining appropriate reward structures. Despite these hurdles, the future of RL is </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">promising, with ongoing research aimed at enhancing its efficiency and applicability, paving the way for more</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">intelligent and autonomous systems in AI.</span>                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mArticle Planner and Writer\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m### Plan\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Define Reinforcement Learning (RL) and its role in AI.\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Explain the key principles of RL: agents, environments, actions, rewards.\u001b[0m                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Discuss the significance of RL in decision-making processes.\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Highlight real-world applications of RL in various industries (e.g., gaming, robotics, healthcare).\u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Mention the advantages of RL over traditional machine learning methods.\u001b[0m                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Address the challenges and limitations of implementing RL.\u001b[0m                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- Conclude with the future potential of RL in advancing AI technologies.\u001b[0m                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m### Summary\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mReinforcement Learning (RL) is a crucial subset of artificial intelligence that focuses on how agents should \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtake actions in an environment to maximize cumulative rewards. The core principles of RL involve agents \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92minteracting with their environment, making decisions, and receiving feedback in the form of rewards or \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mpenalties. This framework is particularly significant in decision-making processes, allowing systems to learn\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92moptimal strategies through trial and error.\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mRL has found extensive applications across various industries, including gaming, where it powers advanced AI \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mopponents, robotics for autonomous navigation, and healthcare for personalized treatment plans. Its ability \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mto adapt and improve over time offers distinct advantages over traditional machine learning methods, which \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92moften rely on static datasets.\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mHowever, implementing RL comes with challenges, such as the need for substantial computational resources and \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mthe difficulty of defining appropriate reward structures. Despite these hurdles, the future of RL is \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mpromising, with ongoing research aimed at enhancing its efficiency and applicability, paving the way for more\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mintelligent and autonomous systems in AI.\u001b[0m                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Define a clear and focused agent\n",
    "planner_writer_agent = Agent(\n",
    "    role='Article Planner and Writer',\n",
    "    goal='Plan and then write a concise, engaging summary on a specified topic.',\n",
    "    backstory=(\n",
    "        'You are an expert technical writer and content strategist. '\n",
    "        'Your strength lies in creating a clear, actionable plan before writing, '\n",
    "        'ensuring the final summary is both informative and easy to digest.'\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm # Assign the specific LLM to the agent\n",
    ")\n",
    "\n",
    "# 3. Define a task with a more structured and specific expected output\n",
    "topic = \"The importance of Reinforcement Learning in AI\"\n",
    "high_level_task = Task(\n",
    "    description=(\n",
    "        f\"1. Create a bullet-point plan for a summary on the topic: '{topic}'.\\n\"\n",
    "        f\"2. Write the summary based on your plan, keeping it around 200 words.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A final report containing two distinct sections:\\n\\n\"\n",
    "        \"### Plan\\n\"\n",
    "        \"- A bulleted list outlining the main points of the summary.\\n\\n\"\n",
    "        \"### Summary\\n\"\n",
    "        \"- A concise and well-structured summary of the topic.\"\n",
    "    ),\n",
    "    agent=planner_writer_agent,\n",
    ")\n",
    "\n",
    "# Create the crew with a clear process\n",
    "crew = Crew(\n",
    "    agents=[planner_writer_agent],\n",
    "    tasks=[high_level_task],\n",
    "    process=Process.sequential,\n",
    ")\n",
    "\n",
    "# Execute the task\n",
    "print(\"## Running the planning and writing task ##\")\n",
    "result = crew.kickoff()\n",
    "\n",
    "# print(\"\\n\\n---\\n## Task Result ##\\n---\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fc506-193d-4406-b5ac-bf3f53d60211",
   "metadata": {},
   "source": [
    "# Multi-Agent Collaboration Models\n",
    "Designing effective multi-agent systems requires careful choice of interrelationships and communication structures, each with unique strengths and trade-offs:\n",
    "\n",
    "* **Single Agent** – Independent, simple, but limited in scope.\n",
    "* **Network** – Peer-to-peer collaboration, resilient but prone to communication overhead.\n",
    "* **Supervisor** – Centralized control and coordination, simplifies management but risks bottlenecks and single points of failure.\n",
    "* **Supervisor as a Tool** – Supervisor provides resources/guidance without strict control, balancing support and autonomy.\n",
    "* **Hierarchical** – Multi-layered supervision for complex, decomposable tasks; scalable but rigid.\n",
    "* **Custom** – Tailored or hybrid structures optimized for specific goals, dynamic environments, or domain needs.\n",
    "\n",
    "👉 **Key takeaway:** No single model is best; the optimal choice depends on task complexity, agent count, autonomy needs, robustness requirements, and communication overhead. Future systems will likely blend and extend these models to achieve more adaptive collaborative intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de3cd6eb-ed3f-4242-869d-543544f1ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Running the blog creation crew with OpenAI gpt-4o-mini... ##\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────── Crew Execution Started ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">532b3c54-a728-4c75-9ba1-cb62495889f1</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m532b3c54-a728-4c75-9ba1-cb62495889f1\u001b[0m                                                                       \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Research Analyst</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Research the top 3 emerging trends in applying Small Language Models for Agentic AI. Provide bullet </span>     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">points with brief explanations and (if known) notable papers.</span>                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Research Analyst\u001b[0m                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mResearch the top 3 emerging trends in applying Small Language Models for Agentic AI. Provide bullet \u001b[0m     \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mpoints with brief explanations and (if known) notable papers.\u001b[0m                                                  \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f54524fb88e43908b8b24a99e0bc53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Research Analyst</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Trend 1: Enhanced Adaptability Through Fine-Tuning</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- **Explanation**: Small language models (SLMs) can be fine-tuned on specific tasks or domains with minimal </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">data. This allows for rapid adaptability to niche applications in agentic AI, such as personalized virtual </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">assistants or specialized customer service bots.</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- **Notable Paper**: “Fine-tuning Language Models from Human Preferences” by Stiennon et al. (2020) discusses</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">methods for adapting language models to align with human values, showcasing the adaptability aspect.</span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Trend 2: Efficient Resource Utilization in Deployment</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- **Explanation**: SLMs are less resource-intensive than their larger counterparts, making them suitable for </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">deployment in environments with hardware constraints, such as mobile devices or edge computing. This trend </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">addresses the ongoing need for real-time processing in agentic applications.</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- **Notable Paper**: “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">et al. (2019) illustrates the efficiency gains of smaller models, supporting the trend towards using SLMs in </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">practical applications.</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Trend 3: Collaborative and Compositional Capabilities</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- **Explanation**: Research is exploring how SLMs can engage in collaborative interactions and combine </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">outputs from multiple models to enhance performance on complex tasks. This ability can lead to more </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">intelligent agentic systems that work together for better outcomes.</span>                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- **Notable Paper**: “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(2022) emphasizes the model's capacity for collaborative reasoning, hinting at the future direction where </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">SLMs can compose their strengths for nuanced tasks in agentic AI.</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">These trends demonstrate the adaptability, efficiency, and collaborative potential of small language models, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">positioning them as pivotal tools for evolving agentic AI solutions.</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Research Analyst\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m### Trend 1: Enhanced Adaptability Through Fine-Tuning\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- **Explanation**: Small language models (SLMs) can be fine-tuned on specific tasks or domains with minimal \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdata. This allows for rapid adaptability to niche applications in agentic AI, such as personalized virtual \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92massistants or specialized customer service bots.\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- **Notable Paper**: “Fine-tuning Language Models from Human Preferences” by Stiennon et al. (2020) discusses\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmethods for adapting language models to align with human values, showcasing the adaptability aspect.\u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m### Trend 2: Efficient Resource Utilization in Deployment\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- **Explanation**: SLMs are less resource-intensive than their larger counterparts, making them suitable for \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdeployment in environments with hardware constraints, such as mobile devices or edge computing. This trend \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92maddresses the ongoing need for real-time processing in agentic applications.\u001b[0m                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- **Notable Paper**: “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92met al. (2019) illustrates the efficiency gains of smaller models, supporting the trend towards using SLMs in \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mpractical applications.\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m### Trend 3: Collaborative and Compositional Capabilities\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- **Explanation**: Research is exploring how SLMs can engage in collaborative interactions and combine \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92moutputs from multiple models to enhance performance on complex tasks. This ability can lead to more \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mintelligent agentic systems that work together for better outcomes.\u001b[0m                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m- **Notable Paper**: “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m(2022) emphasizes the model's capacity for collaborative reasoning, hinting at the future direction where \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mSLMs can compose their strengths for nuanced tasks in agentic AI.\u001b[0m                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThese trends demonstrate the adaptability, efficiency, and collaborative potential of small language models, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mpositioning them as pivotal tools for evolving agentic AI solutions.\u001b[0m                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Task Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">9b921542-9df0-4f81-a947-1c6abbd75e1d</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Senior Research Analyst</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32m9b921542-9df0-4f81-a947-1c6abbd75e1d\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mSenior Research Analyst\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Technical Content Writer</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Write a ~500-word blog post for a general audience based on the research summary. Hook -&gt; overview -&gt; 3</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trend sections -&gt; closing takeaway.</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mTechnical Content Writer\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mWrite a ~500-word blog post for a general audience based on the research summary. Hook -> overview -> 3\u001b[0m  \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mtrend sections -> closing takeaway.\u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2b99f525c549319bd0b96b55b4372a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Technical Content Writer</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```markdown</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"># The Future of AI: Unlocking the Power of Small Language Models</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As artificial intelligence continues to evolve, emerging trends in small language models (SLMs) are poised to</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">transform the landscape of agentic AI. These nimble models are gaining traction due to their ability to adapt</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">quickly, utilize resources efficiently, and collaborate intelligently. In this blog post, we’ll explore three</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">key trends that spotlight the potential of SLMs, making them essential tools in the realm of personalized AI </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">applications.</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">## Enhanced Adaptability Through Fine-Tuning</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One of the most exciting trends in the development of small language models is their improved adaptability. </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">SLMs can be fine-tuned with minimal data for specific tasks or domains, enabling them to quickly adjust to </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">niche applications. This agility is particularly valuable for creating personalized virtual assistants or </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">specialized customer service bots that can cater to diverse user needs.</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A notable paper on this topic, “Fine-tuning Language Models from Human Preferences” by Stiennon et al. </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(2020), delves into techniques for refining these models to better align with human values. Fine-tuning </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">allows SLMs to learn from fewer examples while maintaining high performance. This adaptability not only </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">increases the relevance of AI interactions but also ensures a deeper connection with user preferences, </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">leading to enhanced user satisfaction.</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">## Efficient Resource Utilization in Deployment</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Another significant trend is the efficient resource utilization of small language models. Compared to their </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">larger counterparts, SLMs are less resource-intensive, making them ideal for deployment in </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hardware-constrained environments such as mobile devices or edge computing. This efficiency is crucial in an </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">era where real-time processing abilities can dictate the success of AI applications, especially in fields </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reliant on immediate responses.</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The paper “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh et al. </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(2019) highlights how smaller models can achieve remarkable efficiency gains without sacrificing performance.</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">By using less memory and processing power, SLMs allow developers to bring powerful AI capabilities to a </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">broader array of devices, ensuring that cutting-edge technologies are accessible and functional across </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">different platforms.</span>                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">## Collaborative and Compositional Capabilities</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Finally, researchers are investigating how small language models can engage in collaborative interactions to </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">further bolster their capabilities. This trend focuses on the ability of SLMs to combine outputs from </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multiple models, enhancing performance on complex tasks. Imagine a scenario where several AI agents work </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">together seamlessly to improve problem-solving or decision-making processes—this is the potential the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">collaborative nature of SLMs offers.</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The paper “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. (2022) </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">demonstrates how models can leverage collaborative reasoning to tackle intricate issues. This hint at </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compositional capabilities suggests a future where different models amplify each other's strengths for more </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">nuanced and intelligent interactions.</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">## Closing Takeaway</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The advancements in small language models illustrate their pivotal role in shaping the future of agentic AI. </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Enhanced adaptability, efficient resource utilization, and collaborative capabilities position these models </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">as powerful tools for both developers and users alike. As we continue to refine and harness the potential of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">SLMs, we will likely see a transformation in how AI integrates into our everyday lives, ultimately leading to</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">more responsive, personalized, and intelligent systems. The future of AI is small, adaptable, and ready to </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">collaborate!</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mTechnical Content Writer\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```markdown\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m# The Future of AI: Unlocking the Power of Small Language Models\u001b[0m                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mAs artificial intelligence continues to evolve, emerging trends in small language models (SLMs) are poised to\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtransform the landscape of agentic AI. These nimble models are gaining traction due to their ability to adapt\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mquickly, utilize resources efficiently, and collaborate intelligently. In this blog post, we’ll explore three\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mkey trends that spotlight the potential of SLMs, making them essential tools in the realm of personalized AI \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mapplications.\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m## Enhanced Adaptability Through Fine-Tuning\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mOne of the most exciting trends in the development of small language models is their improved adaptability. \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mSLMs can be fine-tuned with minimal data for specific tasks or domains, enabling them to quickly adjust to \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mniche applications. This agility is particularly valuable for creating personalized virtual assistants or \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mspecialized customer service bots that can cater to diverse user needs.\u001b[0m                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mA notable paper on this topic, “Fine-tuning Language Models from Human Preferences” by Stiennon et al. \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m(2020), delves into techniques for refining these models to better align with human values. Fine-tuning \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mallows SLMs to learn from fewer examples while maintaining high performance. This adaptability not only \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mincreases the relevance of AI interactions but also ensures a deeper connection with user preferences, \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mleading to enhanced user satisfaction.\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m## Efficient Resource Utilization in Deployment\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mAnother significant trend is the efficient resource utilization of small language models. Compared to their \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mlarger counterparts, SLMs are less resource-intensive, making them ideal for deployment in \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mhardware-constrained environments such as mobile devices or edge computing. This efficiency is crucial in an \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mera where real-time processing abilities can dictate the success of AI applications, especially in fields \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mreliant on immediate responses.\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe paper “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh et al. \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m(2019) highlights how smaller models can achieve remarkable efficiency gains without sacrificing performance.\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mBy using less memory and processing power, SLMs allow developers to bring powerful AI capabilities to a \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mbroader array of devices, ensuring that cutting-edge technologies are accessible and functional across \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdifferent platforms.\u001b[0m                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m## Collaborative and Compositional Capabilities\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mFinally, researchers are investigating how small language models can engage in collaborative interactions to \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfurther bolster their capabilities. This trend focuses on the ability of SLMs to combine outputs from \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmultiple models, enhancing performance on complex tasks. Imagine a scenario where several AI agents work \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtogether seamlessly to improve problem-solving or decision-making processes—this is the potential the \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcollaborative nature of SLMs offers.\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe paper “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. (2022) \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdemonstrates how models can leverage collaborative reasoning to tackle intricate issues. This hint at \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcompositional capabilities suggests a future where different models amplify each other's strengths for more \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mnuanced and intelligent interactions.\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m## Closing Takeaway\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe advancements in small language models illustrate their pivotal role in shaping the future of agentic AI. \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mEnhanced adaptability, efficient resource utilization, and collaborative capabilities position these models \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mas powerful tools for both developers and users alike. As we continue to refine and harness the potential of \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mSLMs, we will likely see a transformation in how AI integrates into our everyday lives, ultimately leading to\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmore responsive, personalized, and intelligent systems. The future of AI is small, adaptable, and ready to \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcollaborate!\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Task Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">c472bc9e-721b-4acd-866d-3963b3ecfaae</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Technical Content Writer</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mc472bc9e-721b-4acd-866d-3963b3ecfaae\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mTechnical Content Writer\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Crew Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Crew Execution Completed</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">crew</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008000; text-decoration-color: #008000\">532b3c54-a728-4c75-9ba1-cb62495889f1</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: ```markdown</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"># The Future of AI: Unlocking the Power of Small Language Models</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">As artificial intelligence continues to evolve, emerging trends in small language models (SLMs) are poised to</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">transform the landscape of agentic AI. These nimble models are gaining traction due to their ability to adapt</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">quickly, utilize resources efficiently, and collaborate intelligently. In this blog post, we’ll explore three</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">key trends that spotlight the potential of SLMs, making them essential tools in the realm of personalized AI </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">applications.</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">## Enhanced Adaptability Through Fine-Tuning</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">One of the most exciting trends in the development of small language models is their improved adaptability. </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">SLMs can be fine-tuned with minimal data for specific tasks or domains, enabling them to quickly adjust to </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">niche applications. This agility is particularly valuable for creating personalized virtual assistants or </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">specialized customer service bots that can cater to diverse user needs.</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">A notable paper on this topic, “Fine-tuning Language Models from Human Preferences” by Stiennon et al. </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">(2020), delves into techniques for refining these models to better align with human values. Fine-tuning </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">allows SLMs to learn from fewer examples while maintaining high performance. This adaptability not only </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">increases the relevance of AI interactions but also ensures a deeper connection with user preferences, </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">leading to enhanced user satisfaction.</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">## Efficient Resource Utilization in Deployment</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Another significant trend is the efficient resource utilization of small language models. Compared to their </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">larger counterparts, SLMs are less resource-intensive, making them ideal for deployment in </span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">hardware-constrained environments such as mobile devices or edge computing. This efficiency is crucial in an </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">era where real-time processing abilities can dictate the success of AI applications, especially in fields </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">reliant on immediate responses.</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">The paper “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh et al. </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">(2019) highlights how smaller models can achieve remarkable efficiency gains without sacrificing performance.</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">By using less memory and processing power, SLMs allow developers to bring powerful AI capabilities to a </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">broader array of devices, ensuring that cutting-edge technologies are accessible and functional across </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">different platforms.</span>                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">## Collaborative and Compositional Capabilities</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Finally, researchers are investigating how small language models can engage in collaborative interactions to </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">further bolster their capabilities. This trend focuses on the ability of SLMs to combine outputs from </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">multiple models, enhancing performance on complex tasks. Imagine a scenario where several AI agents work </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">together seamlessly to improve problem-solving or decision-making processes—this is the potential the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">collaborative nature of SLMs offers.</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">The paper “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. (2022) </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">demonstrates how models can leverage collaborative reasoning to tackle intricate issues. This hint at </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">compositional capabilities suggests a future where different models amplify each other's strengths for more </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">nuanced and intelligent interactions.</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">## Closing Takeaway</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">The advancements in small language models illustrate their pivotal role in shaping the future of agentic AI. </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Enhanced adaptability, efficient resource utilization, and collaborative capabilities position these models </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">as powerful tools for both developers and users alike. As we continue to refine and harness the potential of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">SLMs, we will likely see a transformation in how AI integrates into our everyday lives, ultimately leading to</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">more responsive, personalized, and intelligent systems. The future of AI is small, adaptable, and ready to </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">collaborate!</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Crew Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mCrew Execution Completed\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mcrew\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[32m532b3c54-a728-4c75-9ba1-cb62495889f1\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Output: ```markdown\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m# The Future of AI: Unlocking the Power of Small Language Models\u001b[0m                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAs artificial intelligence continues to evolve, emerging trends in small language models (SLMs) are poised to\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mtransform the landscape of agentic AI. These nimble models are gaining traction due to their ability to adapt\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mquickly, utilize resources efficiently, and collaborate intelligently. In this blog post, we’ll explore three\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mkey trends that spotlight the potential of SLMs, making them essential tools in the realm of personalized AI \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mapplications.\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m## Enhanced Adaptability Through Fine-Tuning\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mOne of the most exciting trends in the development of small language models is their improved adaptability. \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mSLMs can be fine-tuned with minimal data for specific tasks or domains, enabling them to quickly adjust to \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mniche applications. This agility is particularly valuable for creating personalized virtual assistants or \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mspecialized customer service bots that can cater to diverse user needs.\u001b[0m                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mA notable paper on this topic, “Fine-tuning Language Models from Human Preferences” by Stiennon et al. \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m(2020), delves into techniques for refining these models to better align with human values. Fine-tuning \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mallows SLMs to learn from fewer examples while maintaining high performance. This adaptability not only \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mincreases the relevance of AI interactions but also ensures a deeper connection with user preferences, \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mleading to enhanced user satisfaction.\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m## Efficient Resource Utilization in Deployment\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAnother significant trend is the efficient resource utilization of small language models. Compared to their \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mlarger counterparts, SLMs are less resource-intensive, making them ideal for deployment in \u001b[0m                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mhardware-constrained environments such as mobile devices or edge computing. This efficiency is crucial in an \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mera where real-time processing abilities can dictate the success of AI applications, especially in fields \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mreliant on immediate responses.\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mThe paper “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh et al. \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m(2019) highlights how smaller models can achieve remarkable efficiency gains without sacrificing performance.\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mBy using less memory and processing power, SLMs allow developers to bring powerful AI capabilities to a \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mbroader array of devices, ensuring that cutting-edge technologies are accessible and functional across \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mdifferent platforms.\u001b[0m                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m## Collaborative and Compositional Capabilities\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinally, researchers are investigating how small language models can engage in collaborative interactions to \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mfurther bolster their capabilities. This trend focuses on the ability of SLMs to combine outputs from \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mmultiple models, enhancing performance on complex tasks. Imagine a scenario where several AI agents work \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mtogether seamlessly to improve problem-solving or decision-making processes—this is the potential the \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mcollaborative nature of SLMs offers.\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mThe paper “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. (2022) \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mdemonstrates how models can leverage collaborative reasoning to tackle intricate issues. This hint at \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mcompositional capabilities suggests a future where different models amplify each other's strengths for more \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mnuanced and intelligent interactions.\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m## Closing Takeaway\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mThe advancements in small language models illustrate their pivotal role in shaping the future of agentic AI. \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mEnhanced adaptability, efficient resource utilization, and collaborative capabilities position these models \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mas powerful tools for both developers and users alike. As we continue to refine and harness the potential of \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mSLMs, we will likely see a transformation in how AI integrates into our everyday lives, ultimately leading to\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mmore responsive, personalized, and intelligent systems. The future of AI is small, adaptable, and ready to \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mcollaborate!\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "## Crew Final Output ##\n",
      "\n",
      "```markdown\n",
      "# The Future of AI: Unlocking the Power of Small Language Models\n",
      "\n",
      "As artificial intelligence continues to evolve, emerging trends in small language models (SLMs) are poised to transform the landscape of agentic AI. These nimble models are gaining traction due to their ability to adapt quickly, utilize resources efficiently, and collaborate intelligently. In this blog post, we’ll explore three key trends that spotlight the potential of SLMs, making them essential tools in the realm of personalized AI applications.\n",
      "\n",
      "## Enhanced Adaptability Through Fine-Tuning\n",
      "\n",
      "One of the most exciting trends in the development of small language models is their improved adaptability. SLMs can be fine-tuned with minimal data for specific tasks or domains, enabling them to quickly adjust to niche applications. This agility is particularly valuable for creating personalized virtual assistants or specialized customer service bots that can cater to diverse user needs.\n",
      "\n",
      "A notable paper on this topic, “Fine-tuning Language Models from Human Preferences” by Stiennon et al. (2020), delves into techniques for refining these models to better align with human values. Fine-tuning allows SLMs to learn from fewer examples while maintaining high performance. This adaptability not only increases the relevance of AI interactions but also ensures a deeper connection with user preferences, leading to enhanced user satisfaction.\n",
      "\n",
      "## Efficient Resource Utilization in Deployment\n",
      "\n",
      "Another significant trend is the efficient resource utilization of small language models. Compared to their larger counterparts, SLMs are less resource-intensive, making them ideal for deployment in hardware-constrained environments such as mobile devices or edge computing. This efficiency is crucial in an era where real-time processing abilities can dictate the success of AI applications, especially in fields reliant on immediate responses.\n",
      "\n",
      "The paper “DistilBERT, a distilled version of BERT: smaller, faster, cheaper, and lighter” by Sanh et al. (2019) highlights how smaller models can achieve remarkable efficiency gains without sacrificing performance. By using less memory and processing power, SLMs allow developers to bring powerful AI capabilities to a broader array of devices, ensuring that cutting-edge technologies are accessible and functional across different platforms.\n",
      "\n",
      "## Collaborative and Compositional Capabilities\n",
      "\n",
      "Finally, researchers are investigating how small language models can engage in collaborative interactions to further bolster their capabilities. This trend focuses on the ability of SLMs to combine outputs from multiple models, enhancing performance on complex tasks. Imagine a scenario where several AI agents work together seamlessly to improve problem-solving or decision-making processes—this is the potential the collaborative nature of SLMs offers.\n",
      "\n",
      "The paper “Chain of Thought Prompting Elicits Reasoning in Large Language Models” by Wei et al. (2022) demonstrates how models can leverage collaborative reasoning to tackle intricate issues. This hint at compositional capabilities suggests a future where different models amplify each other's strengths for more nuanced and intelligent interactions.\n",
      "\n",
      "## Closing Takeaway\n",
      "\n",
      "The advancements in small language models illustrate their pivotal role in shaping the future of agentic AI. Enhanced adaptability, efficient resource utilization, and collaborative capabilities position these models as powerful tools for both developers and users alike. As we continue to refine and harness the potential of SLMs, we will likely see a transformation in how AI integrates into our everyday lives, ultimately leading to more responsive, personalized, and intelligent systems. The future of AI is small, adaptable, and ready to collaborate!\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# pip install crewai langchain-openai\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# --- LLM (crew-level) ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# --- Agents ---\n",
    "researcher = Agent(\n",
    "    role='Senior Research Analyst',\n",
    "    goal='Find and summarize the latest trends in applying Small Language Models for Agentic AI.',\n",
    "    backstory=\"You identify key trends and synthesize findings.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    # llm=llm,  # optional when provided at Crew level\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    role='Technical Content Writer',\n",
    "    goal='Write a clear and engaging blog post based on research findings.',\n",
    "    backstory=\"You translate complex topics into accessible content.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    # llm=llm,\n",
    ")\n",
    "\n",
    "# --- Tasks ---\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Research the top 3 emerging trends in applying Small Language Models for Agentic AI. \"\n",
    "        \"Provide bullet points with brief explanations and (if known) notable papers.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured summary: 3 trends with 2–3 bullets each; include short rationale and any sources.\"\n",
    "    ),\n",
    "    agent=researcher,\n",
    ")\n",
    "\n",
    "writing_task = Task(\n",
    "    description=(\n",
    "        \"Write a ~500-word blog post for a general audience based on the research summary. \"\n",
    "        \"Hook -> overview -> 3 trend sections -> closing takeaway.\"\n",
    "    ),\n",
    "    expected_output=\"A polished ~500-word post in markdown.\",\n",
    "    agent=writer,\n",
    "    context=[research_task],  # uses the researcher’s output\n",
    ")\n",
    "\n",
    "# --- Crew ---\n",
    "blog_creation_crew = Crew(\n",
    "    agents=[researcher, writer],\n",
    "    tasks=[research_task, writing_task],\n",
    "    process=Process.sequential,  # researcher -> writer\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# --- Run ---\n",
    "print(\"## Running the blog creation crew with OpenAI gpt-4o-mini... ##\")\n",
    "try:\n",
    "    result = blog_creation_crew.kickoff()\n",
    "    print(\"\\n------------------\\n## Crew Final Output ##\\n\")\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
