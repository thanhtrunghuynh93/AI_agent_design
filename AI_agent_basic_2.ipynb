{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f6a9f4-5282-4f41-83e2-2e5d15a24f4d",
   "metadata": {},
   "source": [
    "# Memory  \n",
    "Memory management is essential for intelligent agents, enabling them to retain, recall, and use information effectively. Like humans, agents need both short-term and long-term memory to function efficiently.\n",
    "\n",
    "# Types of Memory\n",
    "\n",
    "**Short-Term Memory (Contextual):**\n",
    "\n",
    "+ Exists in the LLMâ€™s context window (recent messages, tool outputs, reflections).\n",
    "\n",
    "+ Limited in size, ephemeral, and lost after a session.\n",
    "\n",
    "+ Managed via summarization and prioritization of key details.\n",
    "\n",
    "+ Long context models extend this capacity but remain costly and temporary.\n",
    "\n",
    "**Long-Term Memory (Persistent):**\n",
    "\n",
    "+ Stores information across sessions (databases, knowledge graphs, vector stores).\n",
    "\n",
    "+ Enables semantic retrieval (via similarity search).\n",
    "\n",
    "+ Integrates retrieved data back into short-term memory for use in interactions.\n",
    "\n",
    "  \n",
    "# Applications\n",
    "\n",
    "+ Chatbots & Conversational AI: Maintain flow (short-term) and remember user preferences/history (long-term).\n",
    "\n",
    "+ Task-Oriented Agents: Track steps/goals (short-term) and recall user/task data (long-term).\n",
    "\n",
    "+ Personalization: Store user behaviors/preferences for tailored experiences.\n",
    "\n",
    "+ Learning & Improvement: Retain successful strategies, errors, and knowledge for adaptation.\n",
    "\n",
    "+ Information Retrieval (RAG): Use external knowledge bases to answer queries.\n",
    "\n",
    "+ Autonomous Systems: Combine immediate environment data (short-term) with general maps/behaviors (long-term).\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Effective memory management allows agents to maintain history, personalize interactions, learn, and solve complex, time-dependent problems beyond simple Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706ebb5f-361e-443a-8899-edb805069668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40beda9a-7d07-4402-9139-806b6c397e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e244d044-9fe5-4e9a-83d9-f2ba4aee17e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Small language models refer to AI models that have a relatively low number of parameters compared to larger models. These models are typically used for tasks that require less computational resources and can be trained on smaller datasets. Small language models are often used for tasks such as text generation, sentiment analysis, and language translation. While they may not have the same level of performance as larger models, small language models can still be effective for certain applications and are more accessible for researchers and developers with limited resources.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Language Model (using ChatOpenAI is recommended)\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "instruct_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are an expert in AI and LLM. Answer this question:\\n\\n{input_text}\"\n",
    ")\n",
    "answer_chain = instruct_prompt | llm | StrOutputParser()\n",
    "\n",
    "input_text = \"What are Small Language Models?\"\n",
    "answer_chain.invoke({\"input_text\" : input_text})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bef08cbe-155b-4bf9-8ac8-5f72b3e66ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7759/1612728893.py:18: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\")\n",
      "/tmp/ipykernel_7759/1612728893.py:21: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(llm=llm, prompt=prompt, memory=memory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Where are you looking to fly to and from, and on what dates? Let me know your preferences and I can help you find the best flight options for you.\n",
      "Nice to meet you, Sam! How can I assist you with your travel plans today?\n",
      "Your name is Sam. How can I assist you with your travel plans today, Sam?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 1. Define LLM and Prompt\n",
    "template = \"\"\"You are a helpful travel agent.\n",
    "\n",
    "Previous conversation:\n",
    "{history}\n",
    "\n",
    "New question: {question}\n",
    "Response:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 2. Configure Memory\n",
    "# The memory_key \"history\" matches the variable in the prompt\n",
    "memory = ConversationBufferMemory(memory_key=\"history\")\n",
    "\n",
    "# 3. Build the Chain\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "# 4. Run the Conversation\n",
    "response = conversation.predict(question=\"I want to book a flight.\")\n",
    "print(response)\n",
    "response = conversation.predict(question=\"My name is Sam, by the way.\")\n",
    "print(response)\n",
    "response = conversation.predict(question=\"What was my name again?\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a05ecaca-6ffe-4cf4-b1d0-fdae9b25a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langgraph) (0.3.60)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langgraph) (2.11.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading langsmith-0.4.27-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.18)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
      "Requirement already satisfied: anyio in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.8)\n",
      "Requirement already satisfied: idna in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/trunght/miniconda3/envs/llm/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
      "Downloading langsmith-0.4.27-py3-none-any.whl (384 kB)\n",
      "Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "Installing collected packages: ormsgpack, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.42\n",
      "    Uninstalling langsmith-0.3.42:\n",
      "      Successfully uninstalled langsmith-0.3.42\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.60\n",
      "    Uninstalling langchain-core-0.3.60:\n",
      "      Successfully uninstalled langchain-core-0.3.60\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.27 which is incompatible.\n",
      "langchain 0.3.25 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.27 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.75 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 langsmith-0.4.27 ormsgpack-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7a82e74-ad48-44bc-a07c-edca59f09660",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryStore\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# A placeholder for a real embedding function\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m      5\u001b[39m    \u001b[38;5;66;03m# In a real application, use a proper embedding model\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph'"
     ]
    }
   ],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# A placeholder for a real embedding function\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "   # In a real application, use a proper embedding model\n",
    "   return [[1.0, 2.0] for _ in texts]\n",
    "\n",
    "# Initialize an in-memory store. For production, use a database-backed store.\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": 2})\n",
    "\n",
    "# Define a namespace for a specific user and application context\n",
    "user_id = \"my-user\"\n",
    "application_context = \"chitchat\"\n",
    "namespace = (user_id, application_context)\n",
    "\n",
    "# 1. Put a memory into the store\n",
    "store.put(\n",
    "   namespace,\n",
    "   \"a-memory\",  # The key for this memory\n",
    "   {\n",
    "       \"rules\": [\n",
    "           \"User likes short, direct language\",\n",
    "           \"User only speaks English & python\",\n",
    "       ],\n",
    "       \"my-key\": \"my-value\",\n",
    "   },\n",
    ")\n",
    "\n",
    "# 2. Get the memory by its namespace and key\n",
    "item = store.get(namespace, \"a-memory\")\n",
    "print(\"Retrieved Item:\", item)\n",
    "\n",
    "# 3. Search for memories within the namespace, filtering by content\n",
    "# and sorting by vector similarity to the query.\n",
    "items = store.search(\n",
    "   namespace,\n",
    "   filter={\"my-key\": \"my-value\"},\n",
    "   query=\"language preferences\"\n",
    ")\n",
    "print(\"Search Results:\", items)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
